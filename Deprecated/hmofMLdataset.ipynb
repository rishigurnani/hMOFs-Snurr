{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'hmofMLdataset' from '/home/rgur/py_scripts/hmofMLdataset.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from os import path\n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib import rcParams\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from rdkit import Chem\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "sys.path.append('/home/rgur/py_scripts')\n",
    "import efrc_ml_production as ml\n",
    "importlib.reload(ml)\n",
    "\n",
    "from skopt import gp_minimize\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "import hmofMLdataset as hmof\n",
    "importlib.reload(hmof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = '/data/rgur/efrc/ml/tests/specify_jobs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_DICT = {'10000': ([.5], [20])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now().strftime(\"%I_%M%p_on_%B_%d_%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 unique feature codes\n",
      "now is 04_39PM_on_April_22_2020\n",
      "\n",
      "Starting to Construct Gravimetric Uptake Data Frame\n",
      "Using start_str_sd CH4_v/v_248_bar\n",
      "Using end_str_sd norm_Dom._Pore_(ang.)\n",
      "Using start_str_si filename\n",
      "Using end_str_si valence_pa\n",
      "Total frac equals 1\n",
      "\n",
      "\n",
      "Starting To Make Linker Size Columns\n",
      "Starting to sort Linker Size Columns\n",
      "Finished Making Linker Size Columns\n",
      "The following columns have been dropped: ['norm_Mafp_C1_N2_N3', 'norm_Mafp_N2_O2_N3', 'norm_Mmfp_MQNs22', 'norm_Mmfp_MQNs23', 'norm_Mmfp_MQNs24', 'norm_Mmfp_MQNs25']\n",
      "\n",
      "Starting to Construct Isotherm Stacked Data Frame\n",
      "Using start_str_sd Density\n",
      "Using end_str_sd norm_Dom._Pore_(ang.)\n",
      "Using start_str_si filename\n",
      "Using end_str_si valence_pa\n",
      "Total frac equals 1\n",
      "\n",
      "\n",
      "Starting To Make Linker Size Columns\n",
      "Finished Making Linker Size Columns\n",
      "The following columns have been dropped: ['norm_Mafp_C1_N2_N3', 'norm_Mafp_N2_O2_N3', 'norm_Mmfp_MQNs22', 'norm_Mmfp_MQNs23', 'norm_Mmfp_MQNs24', 'norm_Mmfp_MQNs25']\n",
      "\n",
      "\n",
      "Running code 1000 for gravimetric uptake model\n",
      "Starting to make KDTree\n",
      "Finished making KDTree in 0.03764796257019043 seconds\n"
     ]
    }
   ],
   "source": [
    "hmof.hmofMLdataset(PATH, now,\n",
    "                   SI_grav_data_path='/data/rgur/efrc/prep_data/all_v1/ml_data_head.csv', \n",
    "                 SD_grav_data_path='/data/rgur/efrc/prep_data/all_no_norm/ml_data_head.csv',SI_stacked_path=\n",
    "                '/data/rgur/efrc/prep_data/all_v1/stacked_head.csv',\n",
    "                 SD_stacked_path='/data/rgur/efrc/prep_data/all_no_norm/stacked_head.csv', n_core=15,\n",
    "             job_dict=JOB_DICT).makeAllResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
