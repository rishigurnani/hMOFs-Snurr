{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/modules/anaconda3/lib/python3.7/site-packages/dask/config.py:168: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  data = yaml.load(f.read()) or {}\n",
      "/home/modules/anaconda3/lib/python3.7/site-packages/distributed/config.py:20: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "  defaults = yaml.load(f)\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "from os import path\n",
    "import pandas as pd \n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow_docs as tfdocs\n",
    "import tensorflow_docs.plots\n",
    "import tensorflow_docs.modeling\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "from matplotlib import rcParams\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "import sys\n",
    "from sklearn.metrics import r2_score as r2\n",
    "from rdkit import Chem\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'efrc_ml_production' from '/home/rgur/py_scripts/efrc_ml_production.py'>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import efrc_ml_production as ml\n",
    "importlib.reload(ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class hmofMLdataset:\n",
    "    def __init__(self, results_dir, SI_grav_data_path='/data/rgur/efrc/prep_data/all_v1/ml_data.csv', \n",
    "                 SD_grav_data_path='/data/rgur/efrc/prep_data/all_no_norm/ml_data.csv',SI_stacked_path=\n",
    "                '/data/rgur/efrc/prep_data/all_v1/stacked.csv',\n",
    "                 SD_stacked_path='/data/rgur/efrc/prep_data/all_no_norm/stacked.csv',\n",
    "                 Y_DATA_PATH='/data/rgur/efrc/data_DONOTTOUCH/hMOF_allData_March25_2013.xlsx', n_core=18):\n",
    "        self.results_dir = results_dir\n",
    "        os.chdir(self.results_dir)\n",
    "        self.SI_grav_data_path = SI_grav_data_path\n",
    "        self.SD_grav_data_path = SD_grav_data_path\n",
    "        self.SI_stacked_path = SI_stacked_path\n",
    "        self.SD_stacked_path = SD_stacked_path\n",
    "        self.n_core = n_core\n",
    "        self.Y_DATA_PATH = Y_DATA_PATH\n",
    "        self.PCA_COMPONENTS = 400\n",
    "        self.del_defective_mofs = False\n",
    "        self.cat_si_sd = True\n",
    "        self.add_size_fp = True #make True if you want to add 20 feature columns, where each feature is the number of atoms in a linker\n",
    "        self.srt_size_fp = True\n",
    "        self.iso_start_str_sd = 'Density'\n",
    "        self.iso_end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "        self.grav_start_str_sd = 'CH4_v/v_248_bar'\n",
    "        self.grav_end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "        self.start_str_si = 'filename'\n",
    "        self.end_str_si = 'valence_pa'\n",
    "        self.cat_col_names = ['cat_1', 'cat_2', 'cat_3', 'cat_4']\n",
    "        self.feature_codes = ['10000', '11000', '01000', '10100', '11100', '01100',\n",
    "                             '10010', '11010', '01010', '10110', '11110', '01110',\n",
    "                             '10001', '11001', '01001', '10101', '11101', '01101',\n",
    "                             '10011', '11011', '01011', '10111', '11111', '01111']\n",
    "        print(\"There are %s unique feature codes\" %len(set(self.feature_codes)))\n",
    "        print(\"now is %s\" %now)\n",
    "        \n",
    "    \n",
    "    def makeMasterDFs(self):\n",
    "        #gravimetric\n",
    "        self.grav, self.grav_prop, self.grav_target_mean, self.grav_target_std, self.grav_all_features = ml.prepToSplit(\n",
    "                                            'xgb', self.cat_si_sd, self.SD_grav_data_path, self.SI_grav_data_path, \n",
    "                                            self.grav_start_str_sd, self.grav_end_str_sd, self.start_str_si, \n",
    "                                            self.end_str_si, 1, self.del_defective_mofs, self.add_size_fp, \n",
    "                                            self.srt_size_fp, None, stacked=False, n_core=self.n_core, \n",
    "                                            del_geometric_fp=False, cat_col_names=self.cat_col_names, \n",
    "                                            Y_DATA_PATH=self.Y_DATA_PATH)\n",
    "        size_cols = [\"size_%s\" %s for s in range(20)]\n",
    "        self.LS_dict = {row[1]['filename']:row[1][size_cols] for row in self.grav.iterrows()} # map from filename \n",
    "                                                                                        #to linkersize-vector\n",
    "        #stacked\n",
    "        self.iso, self.iso_prop, self.iso_target_mean, self.iso_target_std, self.iso_all_features, self.pinfo = \\\n",
    "                                            ml.prepToSplit(\n",
    "                                            'nn', self.cat_si_sd, self.SD_stacked_path, self.SI_stacked_path, \n",
    "                                            self.iso_start_str_sd, self.iso_end_str_sd, self.start_str_si, \n",
    "                                            self.end_str_si, 1, self.del_defective_mofs, self.add_size_fp, \n",
    "                                            self.srt_size_fp, None, True, self.n_core, False, self.cat_col_names, \n",
    "                                            self.Y_DATA_PATH, self.LS_dict)\n",
    "\n",
    "    def select_features(self, code, stacked):\n",
    "        '''\n",
    "        Should only be called after makeMasterDFs\n",
    "        '''\n",
    "        si = bool(int(code[0])) #True (=1) if size-independent features are included\n",
    "        sd = bool(int(code[1])) #True (=1) if size-dependent features are included\n",
    "        size_fp = bool(int(code[2])) #True (=1) if linker size features are included\n",
    "        geo_fp = bool(int(code[3])) #True (=1) if geometric features are included\n",
    "        non_pg = ml.getNonPGcolNames(size_fp, stacked, not geo_fp, self.cat_col_names)\n",
    "        pg = []\n",
    "        if si:\n",
    "            si_df = pd.read_csv(self.SI_grav_data_path)\n",
    "            self.all_pg = [s for s in ml.getPGcolNames(si_df, start_str=self.start_str_si, end_str=self.end_str_si)]\n",
    "            pg += [s+'_si' for s in ml.getPGcolNames(si_df, start_str=self.start_str_si, end_str=self.end_str_si) \n",
    "                   if s+'_si' in self.grav_all_features]\n",
    "            del si_df\n",
    "        if sd:\n",
    "            sd_df = pd.read_csv(self.SD_grav_data_path)\n",
    "            pg += [s for s in ml.getPGcolNames(sd_df, self.grav_start_str_sd, self.grav_end_str_sd) if s in\n",
    "                  self.grav_all_features]\n",
    "        return non_pg + pg\n",
    "    \n",
    "    def makeResults(self):\n",
    "        self.makeMasterDFs()\n",
    "        print('\\n')\n",
    "        l = []\n",
    "        for i in self.feature_codes: #True if stacked\n",
    "                STACKED = bool(int(i[-1])) #True (=1) if stacked\n",
    "                CODE = i[:-1]\n",
    "                run_features = self.select_features(code=CODE, stacked=STACKED)\n",
    "                if STACKED:\n",
    "                    print(\"Running code %s for isotherm model\" %CODE)\n",
    "                    drop_features = [s for s in self.iso_all_features if s not in run_features]\n",
    "                    #l.append(self.iso.drop(drop_features, axis=1))\n",
    "                    l.append(FpDataSet(self.iso.drop(drop_features, axis=1), run_features, self.iso_prop, \n",
    "                                       self.iso_target_mean, self.iso_target_std, stacked=STACKED, fp_code=CODE))\n",
    "                else:\n",
    "                    print(\"Running code %s for gravimetric uptake model\" %CODE)\n",
    "                    drop_features = [s for s in self.grav_all_features if s not in run_features]\n",
    "                    l.append(FpDataSet(self.grav.drop(drop_features, axis=1), run_features, self.grav_prop, \n",
    "                                       self.grav_target_mean, self.grav_target_std, stacked=STACKED, fp_code=CODE))\n",
    "        return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FpDataSet:\n",
    "    def __init__(self, df, features, property_used, target_mean, target_std, stacked, fp_code, PCA_DIM=400, rand_seeds=[0, 10, 20], \n",
    "                 train_grid = [.5, .6, .7, .8, .9]):\n",
    "        self.df = df\n",
    "        self.rand_seeds = rand_seeds\n",
    "        self.fp_code = fp_code\n",
    "        self.property_used = property_used\n",
    "        self.target_mean = target_mean\n",
    "        self.target_std = target_std\n",
    "        self.n_samples = len(self.df)\n",
    "        self.PCA_DIM = min(PCA_DIM, self.n_samples)\n",
    "        self.features = features\n",
    "        self.stacked = stacked\n",
    "        if self.stacked:\n",
    "            self.algo = 'nn'\n",
    "            self.model_tag = 'iso'\n",
    "        else:\n",
    "            self.algo = 'xgb'\n",
    "            self.model_tag = 'grav'\n",
    "        self.train_grid = train_grid\n",
    "    \n",
    "    def sortRemoteInds(self):\n",
    "        '''\n",
    "        Create list of most remote indices\n",
    "        '''\n",
    "        n_core = 1\n",
    "        use_pca = True\n",
    "        nn_tree, filenames = ml.NNtree(self.df, self.stacked, n_core, self.features, use_pca, self.PCA_DIM)\n",
    "        dt = nn_tree[0] #distance tree\n",
    "        nt = nn_tree[1] #neighbor tree\n",
    "        to_sort = list(zip(nt[:, 0],dt[:, 1]))\n",
    "\n",
    "        srt_d = {}\n",
    "        for i in to_sort:\n",
    "            try:\n",
    "                srt_d[i[0]] += i[1]\n",
    "            except:\n",
    "                srt_d[i[0]] = [i[1]]\n",
    "\n",
    "        srt_ind_set = [(k, max(v)) for k,v in zip(srt_d.keys(), srt_d.values())]\n",
    "\n",
    "        srt = sorted(srt_ind_set, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        srt_inds = list([x[0] for x in srt])\n",
    "        self.remote_info = [(x, filenames[x]) for x in srt_inds]\n",
    "        \n",
    "    def run(self):\n",
    "        self.sortRemoteInds()\n",
    "        #self.params_list = []\n",
    "        #self.TTS = []\n",
    "        self.results = []\n",
    "        for train_pct in self.train_grid:\n",
    "            TRAIN_PCT = int(round(train_pct*100))\n",
    "            for seed in self.rand_seeds:\n",
    "#                 self.results.append(trainTestSplit(self.df, train_pct, self.features, self.property_used,\n",
    "#                                  self.target_mean, self.target_std, seed, self.remote_info,\n",
    "#                                  self.stacked)) \n",
    "                TTS_obj =  trainTestSplit(self.df, train_pct, self.features, self.property_used,\n",
    "                                                 self.target_mean, self.target_std, seed, self.remote_info,\n",
    "                                                 self.stacked)\n",
    "                df, MODEL = TTS_obj.makeResults()\n",
    "                save_fragment = '%s_code_%s_train_%s_seed_%s_%s' %(self.model_tag, self.fp_code, TRAIN_PCT, seed, now)\n",
    "                print(\"Save Results using Fragment %s\" %save_fragment)\n",
    "                df.to_csv('results_%s.csv' %save_fragment)\n",
    "                try:\n",
    "                    MODEL.save_model('%s.xgb' %save_fragment)\n",
    "                except:\n",
    "                    MODEL.save('%s.h5' %save_fragment,save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class trainTestSplit:\n",
    "    def __init__(self, df, train_pct, features, property_used, target_mean, target_std, seed, remote_info, stacked, \n",
    "                 hp_frac=.1, n_trees=5000):\n",
    "        self.df = df\n",
    "        self.filenames = df['filename'].unique().tolist()\n",
    "        self.n_samples = len(self.filenames)\n",
    "        self.train_pct = train_pct\n",
    "        self.seed = seed\n",
    "        self.target_mean = target_mean\n",
    "        self.target_std = target_std\n",
    "        self.remote_info = remote_info\n",
    "        self.pct_remote = self.train_pct - .5\n",
    "        self.n_remote = round(self.n_samples*self.pct_remote)\n",
    "        self.n_train = round(self.n_samples*self.train_pct)\n",
    "        self.n_random = self.n_train - self.n_remote\n",
    "        self.stacked = stacked\n",
    "        self.features = features\n",
    "        self.property_used = property_used\n",
    "        self.hp_frac = hp_frac\n",
    "        self.n_trees = n_trees\n",
    "\n",
    "        if self.stacked:\n",
    "            self.algo = 'nn'\n",
    "            self.model_tag = 'iso'\n",
    "        else:\n",
    "            self.algo = 'xgb'\n",
    "            self.model_tag = 'grav'\n",
    "        #print(\"algo is\" %self.algo)\n",
    "        \n",
    "    \n",
    "    def split(self):\n",
    "        '''\n",
    "        Split into train and test set\n",
    "        '''\n",
    "\n",
    "        self.train_fn = [x[1] for x in self.remote_info[:self.n_remote]]\n",
    "        \n",
    "        self.remaining = list(set(self.filenames) - set(self.train_fn))\n",
    "        \n",
    "        random.Random(self.seed).shuffle(self.remaining)\n",
    "\n",
    "        self.train_fn += self.remaining[:self.n_random]\n",
    "        self.test_fn = self.remaining[self.n_random:]\n",
    "        train_df = self.df[self.df['filename'].isin(self.train_fn)].reset_index().drop('index', axis=1)\n",
    "        test_df = self.df[self.df['filename'].isin(self.test_fn)].reset_index().drop('index', axis=1)\n",
    "        print(\"Total len of test_df + train_df: %s\" %(len(train_df) + len(test_df)))\n",
    "        train_fp = train_df[self.features].to_numpy().astype('float32')\n",
    "        train_label = train_df[self.property_used]\n",
    "        test_fp = test_df[self.features].to_numpy().astype('float32')\n",
    "        test_label = test_df[self.property_used]\n",
    "    \n",
    "        if self.algo == 'xgb':\n",
    "            train_d = xgb.DMatrix(data=train_fp, label=train_label)\n",
    "            test_d = xgb.DMatrix(data=test_fp, label=test_label)\n",
    "            return train_d, test_d, train_label, test_label\n",
    "        if self.algo == 'nn':\n",
    "            train_files = train_df['filename'].tolist()\n",
    "            test_files = test_df['filename'].tolist()\n",
    "            train_pressures = train_df['pressure'].tolist()\n",
    "            test_pressures = test_df['pressure'].tolist()\n",
    "            return (train_fp, train_label.to_numpy(), train_files, train_pressures), (test_fp, test_label.to_numpy(), \\\n",
    "                    test_files, test_pressures), train_label, test_label\n",
    "        \n",
    "    def hp_opt(self):\n",
    "        if self.algo == 'nn':\n",
    "            self.max_batch = 512\n",
    "            if self.max_batch > self.n_train:\n",
    "                self.max_batch = self.n_train // 2\n",
    "            self.space = [(100, 400), #n_units\n",
    "                    (.0005, .003),#learning rate\n",
    "                    (2, 15), #patience\n",
    "                    (12, self.max_batch), #batch size\n",
    "                    (.01, .6)] #validation split\n",
    "            \n",
    "        else:\n",
    "            self.max_depth_ub = 15\n",
    "            if self.n_train < 200:\n",
    "                self.max_depth_ub = 4\n",
    "            self.space = [(.3, .95), #colsample_bytree\n",
    "                            (.01, .5),#learning_rate\n",
    "                            (2, 15), #max_depth\n",
    "                            (1, 20)] #alpha\n",
    "            \n",
    "        hp_df = self.df.sample(frac=self.hp_frac, random_state=self.seed)\n",
    "        hp_remote_info = [x for x in self.remote_info if x[1] in hp_df['filename'].tolist()]\n",
    "#         self.hp_instance = HPOpt(hp_df, self.train_pct, self.features, self.property_used, self.target_mean, \n",
    "#                             self.target_std, self.seed, hp_remote_info, self.stacked, self.space)\n",
    "        self.params = HPOpt(hp_df, self.train_pct, self.features, self.property_used, self.target_mean, \n",
    "                            self.target_std, self.seed, hp_remote_info, self.stacked, self.space).get_params()\n",
    "    \n",
    "    def run_model(self):\n",
    "        self.hp_opt()\n",
    "        self.train_d, self.test_d, self.train_label, self.test_label = self.split()\n",
    "        self.MODEL = ml.run_model(self.algo, self.train_d, self.n_trees, self.params)\n",
    "        \n",
    "        \n",
    "    def makeResults(self):\n",
    "        self.run_model()\n",
    "        if self.algo=='xgb':\n",
    "            test_predictions = self.MODEL.predict(self.test_d)\n",
    "            train_predictions = self.MODEL.predict(self.train_d)\n",
    "            pressures = [35]*(self.n_samples)\n",
    "            files = self.train_fn + self.test_fn\n",
    "        if self.algo=='nn':\n",
    "            test_fp = self.test_d[0]\n",
    "            train_fp = self.train_d[0]\n",
    "            files = self.train_d[2] + self.test_d[2]\n",
    "            pressures = self.train_d[3] + self.test_d[3]\n",
    "            test_predictions = self.MODEL.predict(test_fp).flatten()\n",
    "            train_predictions = self.MODEL.predict(train_fp).flatten()        \n",
    "        \n",
    "        res_test_predictions, res_test_label, res_train_label, res_train_predictions = ml.unscale(self.property_used, \n",
    "                                                                                       test_predictions, \n",
    "                                                                                       train_predictions, \n",
    "                                                                                       self.test_label, \n",
    "                                                                                       self.train_label, \n",
    "                                                                                    self.target_mean, \n",
    "                                                                                    self.target_std)\n",
    "        preds = res_train_predictions.tolist() + res_test_predictions.tolist()\n",
    "        sample_class = ['Train']*len(res_train_predictions) + ['Test']*len(res_test_predictions)\n",
    "#        truth = res_train_label.tolist() + res_test_label.tolist()\n",
    "#         results_df = pd.DataFrame({\"Filename\": files, \"Pressure\": pressures, \"Class\": sample_class,\n",
    "#                                   \"Prediction\": preds, \"Truth\": truth})\n",
    "        results_df = pd.DataFrame({\"Filename\": files, \"Pressure\": pressures, \"Class\": sample_class,\n",
    "                                  \"Prediction\": preds})\n",
    "        return results_df, self.MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HPOpt:\n",
    "    def __init__(self, df, train_pct, features, property_used, target_mean, target_std, seed, remote_info, stacked, \n",
    "                 space, n_trees=50):\n",
    "        self.df = df\n",
    "        self.seed = seed\n",
    "        self.space = space\n",
    "        self.remote_info = remote_info\n",
    "        self.stacked = stacked\n",
    "        self.property_used = property_used\n",
    "        self.features = features\n",
    "        self.target_mean = target_mean\n",
    "        self.target_std = target_std\n",
    "        self.n_trees = n_trees\n",
    "        self.N_CALLS = 75\n",
    "        \n",
    "        \n",
    "        if self.stacked:\n",
    "            self.algo = 'nn'\n",
    "        else:\n",
    "            self.algo = 'xgb'\n",
    "        self.train_pct = train_pct\n",
    "        if self.algo == 'xgb':\n",
    "            self.train_pct -= .1\n",
    "    \n",
    "    def objective(self, params):\n",
    "        print(\"Trial parameters %s\" %params)\n",
    "        print(\"Size of training set %s\" %len(self.train_label))\n",
    "        MODEL = ml.run_model(self.algo, self.train_d, self.n_trees, params)\n",
    "        return ml.model_rmse(MODEL, self.train_d, self.test_d, self.stacked, self.algo, self.target_mean, \n",
    "                             self.target_std, self.property_used, self.test_label, self.train_label, save=False, \n",
    "                             fname=None, subset_inds=None)\n",
    "    \n",
    "    def get_params(self):\n",
    "        self.train_d, self.test_d, self.train_label, self.test_label = trainTestSplit(self.df, self.train_pct, \n",
    "                                                        self.features, self.property_used, self.target_mean,\n",
    "                                                        self.target_std, self.seed, self.remote_info, \n",
    "                                                        self.stacked).split()\n",
    "        defects = []\n",
    "        start = time.time()\n",
    "        print(\"Number of trial parameters %s\" %self.N_CALLS)\n",
    "        r = gp_minimize(self.objective, self.space, n_calls=self.N_CALLS, random_state=self.seed)\n",
    "        end = time.time()\n",
    "        print(\"\\nTime elapsed for hp opt: %s\" %(end-start))        \n",
    "        self.params = r.x\n",
    "        return self.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "global now\n",
    "now = datetime.datetime.now().strftime(\"%I_%M%p_on_%B_%d_%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 24 unique feature codes\n",
      "now is 07_23PM_on_April_16_2020\n"
     ]
    }
   ],
   "source": [
    "obj = hmofMLdataset('/data/rgur/efrc/ml/results/', \n",
    "                   SI_grav_data_path='/data/rgur/efrc/prep_data/all_v1/ml_data_head.csv', \n",
    "                 SD_grav_data_path='/data/rgur/efrc/prep_data/all_no_norm/ml_data_head.csv',SI_stacked_path=\n",
    "                '/data/rgur/efrc/prep_data/all_v1/stacked_head.csv',\n",
    "                 SD_stacked_path='/data/rgur/efrc/prep_data/all_no_norm/stacked_head.csv')\n",
    "# obj = hmofMLdataset('/data/rgur/efrc/ml/results/', \n",
    "#                    SI_grav_data_path='/data/rgur/efrc/prep_data/all_v1/ml_data.csv', \n",
    "#                  SD_grav_data_path='/data/rgur/efrc/prep_data/all_no_norm/ml_data.csv',SI_stacked_path=\n",
    "#                 '/data/rgur/efrc/prep_data/all_v1/stacked.csv',\n",
    "#                  SD_stacked_path='/data/rgur/efrc/prep_data/all_no_norm/stacked.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to Construct Gravimetric Uptake Data Frame\n",
      "Using start_str_sd CH4_v/v_248_bar\n",
      "Using end_str_sd norm_Dom._Pore_(ang.)\n",
      "Using start_str_si filename\n",
      "Using end_str_si valence_pa\n",
      "Total frac equals 1\n",
      "\n",
      "\n",
      "Starting To Make Linker Size Columns\n",
      "Starting to sort Linker Size Columns\n",
      "Finished Making Linker Size Columns\n",
      "The following columns have been dropped: ['norm_Mafp_C1_N2_N3', 'norm_Mafp_N2_O2_N3', 'norm_Mmfp_MQNs22', 'norm_Mmfp_MQNs23', 'norm_Mmfp_MQNs24', 'norm_Mmfp_MQNs25']\n",
      "\n",
      "Starting to Construct Isotherm Stacked Data Frame\n",
      "Using start_str_sd Density\n",
      "Using end_str_sd norm_Dom._Pore_(ang.)\n",
      "Using start_str_si filename\n",
      "Using end_str_si valence_pa\n",
      "Total frac equals 1\n",
      "\n",
      "\n",
      "Starting To Make Linker Size Columns\n",
      "Finished Making Linker Size Columns\n",
      "The following columns have been dropped: ['norm_Mafp_C1_N2_N3', 'norm_Mafp_N2_O2_N3', 'norm_Mmfp_MQNs22', 'norm_Mmfp_MQNs23', 'norm_Mmfp_MQNs24', 'norm_Mmfp_MQNs25']\n",
      "\n",
      "\n",
      "Running code 1000 for gravimetric uptake model\n",
      "Running code 1100 for gravimetric uptake model\n",
      "Running code 0100 for gravimetric uptake model\n",
      "Running code 1010 for gravimetric uptake model\n",
      "Running code 1110 for gravimetric uptake model\n",
      "Running code 0110 for gravimetric uptake model\n",
      "Running code 1001 for gravimetric uptake model\n",
      "Running code 1101 for gravimetric uptake model\n",
      "Running code 0101 for gravimetric uptake model\n",
      "Running code 1011 for gravimetric uptake model\n",
      "Running code 1111 for gravimetric uptake model\n",
      "Running code 0111 for gravimetric uptake model\n",
      "Running code 1000 for isotherm model\n",
      "Running code 1100 for isotherm model\n",
      "Running code 0100 for isotherm model\n",
      "Running code 1010 for isotherm model\n",
      "Running code 1110 for isotherm model\n",
      "Running code 0110 for isotherm model\n",
      "Running code 1001 for isotherm model\n",
      "Running code 1101 for isotherm model\n",
      "Running code 0101 for isotherm model\n",
      "Running code 1011 for isotherm model\n",
      "Running code 1111 for isotherm model\n",
      "Running code 0111 for isotherm model\n"
     ]
    }
   ],
   "source": [
    "l = obj.makeResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "FP_DF = l[1] #no geometric fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.FpDataSet"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(FP_DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to make KDTree\n",
      "Finished making KDTree in 0.04947853088378906 seconds\n",
      "Total len of test_df + train_df: 199\n",
      "Total len of test_df + train_df: 20\n",
      "Number of trial parameters 75\n",
      "Trial parameters [0.6853490018462619, 0.4236902168046986, 13, 17]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.13972687721252441\n",
      "Trial parameters [0.705316402910882, 0.19834703657342298, 6, 2]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.13448166847229004\n",
      "Trial parameters [0.4772265914770736, 0.2440559074874615, 13, 10]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0650327205657959\n",
      "Trial parameters [0.5553101174655393, 0.4196785941333151, 6, 13]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.04935741424560547\n",
      "Trial parameters [0.5393570008963562, 0.4790060278869928, 4, 18]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.042382240295410156\n",
      "Trial parameters [0.6078452294279117, 0.4024462684700258, 9, 14]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.04692792892456055\n",
      "Trial parameters [0.7684112255718458, 0.29518969811680257, 9, 15]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.05505681037902832\n",
      "Trial parameters [0.3688399446720649, 0.24206420547986218, 4, 15]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.053238868713378906\n",
      "Trial parameters [0.44075773037584176, 0.07625690496867152, 6, 4]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10812664031982422\n",
      "Trial parameters [0.44450890236353197, 0.1993796007516724, 14, 10]\n",
      "Size of training set 20\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07071566581726074\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-bc464a464e10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mFP_DF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-40-a62565a33ae7>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     59\u001b[0m                                                  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_std\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_info\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m                                                  self.stacked)\n\u001b[0;32m---> 61\u001b[0;31m                 \u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTTS_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmakeResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m                 \u001b[0msave_fragment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'%s_code_%s_train_%s_seed_%s_%s'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp_code\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTRAIN_PCT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Save Results using Fragment %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0msave_fragment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-24933e635587>\u001b[0m in \u001b[0;36mmakeResults\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmakeResults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'xgb'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m             \u001b[0mtest_predictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_d\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-24933e635587>\u001b[0m in \u001b[0;36mrun_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhp_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMODEL\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_trees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-41-24933e635587>\u001b[0m in \u001b[0;36mhp_opt\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;31m#                             self.target_std, self.seed, hp_remote_info, self.stacked, self.space)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m         self.params = HPOpt(hp_df, self.train_pct, self.features, self.property_used, self.target_mean, \n\u001b[0;32m---> 89\u001b[0;31m                             self.target_std, self.seed, hp_remote_info, self.stacked, self.space).get_params()\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-42-2b4054bfa465>\u001b[0m in \u001b[0;36mget_params\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of trial parameters %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_CALLS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgp_minimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_calls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mN_CALLS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTime elapsed for hp opt: %s\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/skopt/optimizer/gp.py\u001b[0m in \u001b[0;36mgp_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, noise, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_restarts_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrng\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         callback=callback, n_jobs=n_jobs, model_queue_size=model_queue_size)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/skopt/optimizer/base.py\u001b[0m in \u001b[0;36mbase_minimize\u001b[0;34m(func, dimensions, base_estimator, n_calls, n_random_starts, acq_func, acq_optimizer, x0, y0, random_state, verbose, callback, n_points, n_restarts_optimizer, xi, kappa, n_jobs, model_queue_size)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0mnext_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0mnext_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m         \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspecs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0meval_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36mtell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    451\u001b[0m                 \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_tell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py\u001b[0m in \u001b[0;36m_tell\u001b[0;34m(self, x, y, fit)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msimplefilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m                 \u001b[0mest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"next_xs_\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_func\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"gp_hedge\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/skopt/learning/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mnoise_level\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnoise_level_bounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"fixed\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             )\n\u001b[0;32m--> 195\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGaussianProcessRegressor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnoise_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/sklearn/gaussian_process/gpr.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_rng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_numeric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m         \u001b[0;31m# Normalize target value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n\u001b[0;32m--> 759\u001b[0;31m                         dtype=None)\n\u001b[0m\u001b[1;32m    760\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m             _assert_all_finite(array,\n\u001b[0;32m--> 573\u001b[0;31m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[1;32m    574\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan)\u001b[0m\n\u001b[1;32m     54\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m     55\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "FP_DF.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTS_obj = trainTestSplit(FP_DF.df, .6, FP_DF.features, FP_DF.property_used,\n",
    "                                                 FP_DF.target_mean, FP_DF.target_std, 0, FP_DF.remote_info,\n",
    "                                                 FP_DF.stacked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len of test_df + train_df: 199\n",
      "Total len of test_df + train_df: 20\n",
      "Number of trial parameters 75\n",
      "Trial parameters [0.6853490018462619, 0.4236902168046986, 13, 17]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0929112434387207\n",
      "Trial parameters [0.705316402910882, 0.19834703657342298, 6, 2]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11790990829467773\n",
      "Trial parameters [0.4772265914770736, 0.2440559074874615, 13, 10]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.04503226280212402\n",
      "Trial parameters [0.5553101174655393, 0.4196785941333151, 6, 13]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.058557748794555664\n",
      "Trial parameters [0.5393570008963562, 0.4790060278869928, 4, 18]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0570831298828125\n",
      "Trial parameters [0.6078452294279117, 0.4024462684700258, 9, 14]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.05158376693725586\n",
      "Trial parameters [0.7684112255718458, 0.29518969811680257, 9, 15]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.05053567886352539\n",
      "Trial parameters [0.3688399446720649, 0.24206420547986218, 4, 15]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.043875694274902344\n",
      "Trial parameters [0.44075773037584176, 0.07625690496867152, 6, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.09929633140563965\n",
      "Trial parameters [0.44450890236353197, 0.1993796007516724, 14, 10]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.04079103469848633\n",
      "Trial parameters [0.95, 0.5, 15, 5]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11924886703491211\n",
      "Trial parameters [0.95, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0853118896484375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.95, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.05037665367126465\n",
      "Trial parameters [0.3, 0.5, 8, 3]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08443975448608398\n",
      "Trial parameters [0.9200934307829076, 0.5, 14, 7]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0683751106262207\n",
      "Trial parameters [0.95, 0.5, 15, 3]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0897378921508789\n",
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11343193054199219\n",
      "Trial parameters [0.3, 0.42266453563475354, 2, 3]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.12149786949157715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11041784286499023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11517977714538574\n",
      "Trial parameters [0.3, 0.5, 15, 1]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.17781567573547363\n",
      "Trial parameters [0.3, 0.5, 15, 3]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.06745314598083496\n",
      "Trial parameters [0.3, 0.5, 3, 5]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.06315159797668457\n",
      "Trial parameters [0.3, 0.5, 6, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.06074857711791992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07802128791809082\n",
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08541631698608398\n",
      "Trial parameters [0.3, 0.5, 5, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08417510986328125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08049297332763672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0793161392211914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10315847396850586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08838558197021484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0923013687133789\n",
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08138108253479004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10052037239074707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07887148857116699\n",
      "Trial parameters [0.3, 0.5, 9, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07175254821777344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0957643985748291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11151385307312012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.16387009620666504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.16487407684326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08222627639770508\n",
      "Trial parameters [0.3, 0.5, 12, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07279157638549805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07476592063903809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.08223915100097656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10205554962158203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.13541626930236816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 13, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1534130573272705\n",
      "Trial parameters [0.3, 0.5, 8, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.23766493797302246\n",
      "Trial parameters [0.3, 0.5, 11, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.15776968002319336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.15514516830444336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1098184585571289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.16028046607971191\n",
      "Trial parameters [0.3, 0.5, 10, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07984161376953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11594653129577637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07680821418762207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 9, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.09197568893432617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 12, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.06806540489196777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07411432266235352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 11, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.09613656997680664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.058580875396728516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.12273859977722168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10662484169006348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11500716209411621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 9, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1148841381072998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 10, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1669628620147705\n",
      "Trial parameters [0.3, 0.5, 7, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.19226384162902832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 15, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.09720206260681152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.0697019100189209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.10140204429626465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 9, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1461772918701172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.12093734741210938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 12, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1078035831451416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.1480114459991455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 12, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.07778048515319824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial parameters [0.3, 0.5, 14, 4]\n",
      "Size of training set 10\n",
      "Number of trees: 50\n",
      "Elapsed time during model training:  0.11716866493225098\n",
      "\n",
      "Time elapsed for hp opt: 62.61372923851013\n",
      "Number of trees: 5000\n",
      "Elapsed time during model training:  2.280653715133667\n"
     ]
    }
   ],
   "source": [
    "df, MODEL = TTS_obj.makeResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FP_DF.TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "TTS_instance = FP_DF.TTS[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total len of test_df + train_df: 199\n",
      "Total len of test_df + train_df: 20\n",
      "Number of trial parameters 10\n",
      "Trial parameters [0.876817608501866, 0.4776620138946926, 14, 13]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.048571109771728516\n",
      "Trial parameters [0.7162310961607279, 0.4757213097479468, 11, 2]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.033069610595703125\n",
      "Trial parameters [0.8470231870264011, 0.41011160458203444, 12, 15]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.01489877700805664\n",
      "Trial parameters [0.6103020068460179, 0.43443913824759434, 6, 18]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.00978541374206543\n",
      "Trial parameters [0.3008911318207715, 0.29199009252501223, 8, 6]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.008946418762207031\n",
      "Trial parameters [0.47445916583654557, 0.49368605058809045, 14, 5]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.011971235275268555\n",
      "Trial parameters [0.5947386001799082, 0.22919798798348015, 5, 18]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.008850812911987305\n",
      "Trial parameters [0.4877600973372239, 0.16653537551247663, 9, 16]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.006084442138671875\n",
      "Trial parameters [0.4569651048165636, 0.41910672320431563, 12, 9]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.0063893795013427734\n",
      "Trial parameters [0.35788360336360847, 0.19784113212807575, 7, 16]\n",
      "Size of training set 10\n",
      "Number of trees: 10\n",
      "Elapsed time during model training:  0.005557060241699219\n",
      "\n",
      "Time elapsed for hp opt: 0.6354813575744629\n",
      "Number of trees: 20\n",
      "Elapsed time during model training:  0.1392202377319336\n"
     ]
    }
   ],
   "source": [
    "results_df = TTS_instance.makeResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do preptosplit manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'nn'\n",
    "cat_si_sd = obj.cat_si_sd\n",
    "SD_ML_DATA_PATH = obj.SD_stacked_path\n",
    "SI_ML_DATA_PATH = obj.SI_stacked_path\n",
    "start_str_sd = obj.iso_start_str_sd\n",
    "end_str_sd = obj.iso_end_str_sd\n",
    "start_str_si = obj.start_str_si\n",
    "end_str_si = obj.end_str_si\n",
    "end_str_sd = obj.iso_end_str_sd\n",
    "total_frac = 1\n",
    "del_defective_mofs = obj.del_defective_mofs\n",
    "add_size_fp = obj.add_size_fp\n",
    "srt_size_fp = obj.srt_size_fp\n",
    "size_dependent = None\n",
    "stacked = True\n",
    "n_core = 18\n",
    "del_geometric_fp = False\n",
    "cat_col_names = obj.cat_col_names\n",
    "Y_DATA_PATH = obj.Y_DATA_PATH\n",
    "LS_DICT = obj.LS_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting to Construct Isotherm Stacked Data Frame\n",
      "Using start_str_sd Density\n",
      "Using end_str_sd norm_Dom._Pore_(ang.)\n",
      "Using start_str_si filename\n",
      "Using end_str_si valence_pa\n",
      "Total frac equals 1\n",
      "\n",
      "\n",
      "Using following 844 features\n",
      "Mafp_Br1_C2_C1_si\n",
      "Mafp_Br1_C2_C2_si\n",
      "Mafp_Br1_C2_C3_si\n",
      "Mafp_Br1_C3_Br1_si\n",
      "Mafp_Br1_C3_C1_si\n",
      "Mafp_Br1_C3_C2_si\n",
      "Mafp_Br1_C3_C3_si\n",
      "Mafp_Br1_C3_C4_si\n",
      "Mafp_Br1_C3_N1_si\n",
      "Mafp_Br1_C3_N2_si\n",
      "Mafp_Br1_C3_N3_si\n",
      "Mafp_Br1_C3_O1_si\n",
      "Mafp_Br1_C4_Br1_si\n",
      "Mafp_Br1_C4_C2_si\n",
      "Mafp_Br1_C4_C3_si\n",
      "Mafp_Br1_C4_C4_si\n",
      "Mafp_Br1_C4_H1_si\n",
      "Mafp_Br1_C4_N1_si\n",
      "Mafp_Br1_C4_N2_si\n",
      "Mafp_Br1_C4_N3_si\n",
      "Mafp_Br1_C4_O1_si\n",
      "Mafp_Br1_C4_O2_si\n",
      "Mafp_Br1_N2_C2_si\n",
      "Mafp_Br1_N2_C3_si\n",
      "Mafp_Br1_N2_C4_si\n",
      "Mafp_Br1_N2_N1_si\n",
      "Mafp_Br1_N2_N2_si\n",
      "Mafp_Br1_N2_N3_si\n",
      "Mafp_Br1_N3_Br1_si\n",
      "Mafp_Br1_N3_C2_si\n",
      "Mafp_Br1_N3_C3_si\n",
      "Mafp_Br1_N3_H1_si\n",
      "Mafp_Br1_N3_N2_si\n",
      "Mafp_Br1_N3_O2_si\n",
      "Mafp_Br1_O2_C2_si\n",
      "Mafp_Br1_O2_C3_si\n",
      "Mafp_Br1_O2_C4_si\n",
      "Mafp_C1_C2_C2_si\n",
      "Mafp_C1_C2_C3_si\n",
      "Mafp_C1_C2_C4_si\n",
      "Mafp_C1_C2_F1_si\n",
      "Mafp_C1_C2_H1_si\n",
      "Mafp_C1_C2_O1_si\n",
      "Mafp_C1_C2_O2_si\n",
      "Mafp_C1_C3_C2_si\n",
      "Mafp_C1_C3_C3_si\n",
      "Mafp_C1_C3_C4_si\n",
      "Mafp_C1_C3_Cl1_si\n",
      "Mafp_C1_C3_F1_si\n",
      "Mafp_C1_C3_H1_si\n",
      "Mafp_C1_C3_N2_si\n",
      "Mafp_C1_C3_N3_si\n",
      "Mafp_C1_C3_O1_si\n",
      "Mafp_C1_C3_O2_si\n",
      "Mafp_C1_C4_C2_si\n",
      "Mafp_C1_C4_C3_si\n",
      "Mafp_C1_C4_C4_si\n",
      "Mafp_C1_C4_H1_si\n",
      "Mafp_C1_C4_O1_si\n",
      "Mafp_C1_C4_O2_si\n",
      "Mafp_C1_N2_C2_si\n",
      "Mafp_C1_N2_C3_si\n",
      "Mafp_C1_N2_N2_si\n",
      "Mafp_C1_N2_N3_si\n",
      "Mafp_C1_N3_C3_si\n",
      "Mafp_C1_N3_C4_si\n",
      "Mafp_C1_N3_N2_si\n",
      "Mafp_C1_N3_N3_si\n",
      "Mafp_C1_N3_O1_si\n",
      "Mafp_C1_O2_C3_si\n",
      "Mafp_C1_O2_C4_si\n",
      "Mafp_C2_C2_C2_si\n",
      "Mafp_C2_C2_C3_si\n",
      "Mafp_C2_C2_C4_si\n",
      "Mafp_C2_C2_Cl1_si\n",
      "Mafp_C2_C2_F1_si\n",
      "Mafp_C2_C2_H1_si\n",
      "Mafp_C2_C2_N1_si\n",
      "Mafp_C2_C2_N2_si\n",
      "Mafp_C2_C2_N3_si\n",
      "Mafp_C2_C2_O1_si\n",
      "Mafp_C2_C2_O2_si\n",
      "Mafp_C2_C3_C2_si\n",
      "Mafp_C2_C3_C3_si\n",
      "Mafp_C2_C3_C4_si\n",
      "Mafp_C2_C3_Cl1_si\n",
      "Mafp_C2_C3_F1_si\n",
      "Mafp_C2_C3_H1_si\n",
      "Mafp_C2_C3_N1_si\n",
      "Mafp_C2_C3_N2_si\n",
      "Mafp_C2_C3_N3_si\n",
      "Mafp_C2_C3_O1_si\n",
      "Mafp_C2_C3_O2_si\n",
      "Mafp_C2_C4_C2_si\n",
      "Mafp_C2_C4_C3_si\n",
      "Mafp_C2_C4_C4_si\n",
      "Mafp_C2_C4_Cl1_si\n",
      "Mafp_C2_C4_F1_si\n",
      "Mafp_C2_C4_H1_si\n",
      "Mafp_C2_C4_N2_si\n",
      "Mafp_C2_C4_N3_si\n",
      "Mafp_C2_C4_O1_si\n",
      "Mafp_C2_C4_O2_si\n",
      "Mafp_C2_N2_C2_si\n",
      "Mafp_C2_N2_C3_si\n",
      "Mafp_C2_N2_C4_si\n",
      "Mafp_C2_N2_Cl1_si\n",
      "Mafp_C2_N2_F1_si\n",
      "Mafp_C2_N2_H1_si\n",
      "Mafp_C2_N2_N1_si\n",
      "Mafp_C2_N2_N2_si\n",
      "Mafp_C2_N2_N3_si\n",
      "Mafp_C2_N2_O1_si\n",
      "Mafp_C2_N2_O2_si\n",
      "Mafp_C2_N3_C2_si\n",
      "Mafp_C2_N3_C3_si\n",
      "Mafp_C2_N3_C4_si\n",
      "Mafp_C2_N3_F1_si\n",
      "Mafp_C2_N3_H1_si\n",
      "Mafp_C2_N3_N2_si\n",
      "Mafp_C2_N3_N3_si\n",
      "Mafp_C2_N3_O1_si\n",
      "Mafp_C2_N3_O2_si\n",
      "Mafp_C2_O2_C2_si\n",
      "Mafp_C2_O2_C3_si\n",
      "Mafp_C2_O2_C4_si\n",
      "Mafp_C2_O2_Cl1_si\n",
      "Mafp_C2_O2_H1_si\n",
      "Mafp_C2_O2_N2_si\n",
      "Mafp_C2_O2_N3_si\n",
      "Mafp_C3_C2_C3_si\n",
      "Mafp_C3_C2_C4_si\n",
      "Mafp_C3_C2_Cl1_si\n",
      "Mafp_C3_C2_F1_si\n",
      "Mafp_C3_C2_H1_si\n",
      "Mafp_C3_C2_N1_si\n",
      "Mafp_C3_C2_N2_si\n",
      "Mafp_C3_C2_N3_si\n",
      "Mafp_C3_C2_O1_si\n",
      "Mafp_C3_C2_O2_si\n",
      "Mafp_C3_C3_C3_si\n",
      "Mafp_C3_C3_C4_si\n",
      "Mafp_C3_C3_Cl1_si\n",
      "Mafp_C3_C3_F1_si\n",
      "Mafp_C3_C3_H1_si\n",
      "Mafp_C3_C3_N1_si\n",
      "Mafp_C3_C3_N2_si\n",
      "Mafp_C3_C3_N3_si\n",
      "Mafp_C3_C3_O1_si\n",
      "Mafp_C3_C3_O2_si\n",
      "Mafp_C3_C4_C3_si\n",
      "Mafp_C3_C4_C4_si\n",
      "Mafp_C3_C4_Cl1_si\n",
      "Mafp_C3_C4_F1_si\n",
      "Mafp_C3_C4_H1_si\n",
      "Mafp_C3_C4_N1_si\n",
      "Mafp_C3_C4_N2_si\n",
      "Mafp_C3_C4_N3_si\n",
      "Mafp_C3_C4_O1_si\n",
      "Mafp_C3_C4_O2_si\n",
      "Mafp_C3_N2_C3_si\n",
      "Mafp_C3_N2_C4_si\n",
      "Mafp_C3_N2_Cl1_si\n",
      "Mafp_C3_N2_F1_si\n",
      "Mafp_C3_N2_H1_si\n",
      "Mafp_C3_N2_N1_si\n",
      "Mafp_C3_N2_N2_si\n",
      "Mafp_C3_N2_N3_si\n",
      "Mafp_C3_N2_O1_si\n",
      "Mafp_C3_N2_O2_si\n",
      "Mafp_C3_N3_C3_si\n",
      "Mafp_C3_N3_C4_si\n",
      "Mafp_C3_N3_Cl1_si\n",
      "Mafp_C3_N3_F1_si\n",
      "Mafp_C3_N3_H1_si\n",
      "Mafp_C3_N3_N1_si\n",
      "Mafp_C3_N3_N2_si\n",
      "Mafp_C3_N3_N3_si\n",
      "Mafp_C3_N3_O2_si\n",
      "Mafp_C3_O2_C3_si\n",
      "Mafp_C3_O2_C4_si\n",
      "Mafp_C3_O2_Cl1_si\n",
      "Mafp_C3_O2_F1_si\n",
      "Mafp_C3_O2_H1_si\n",
      "Mafp_C3_O2_N2_si\n",
      "Mafp_C3_O2_N3_si\n",
      "Mafp_C3_O2_O1_si\n",
      "Mafp_C3_O2_O2_si\n",
      "Mafp_C4_C2_C4_si\n",
      "Mafp_C4_C2_H1_si\n",
      "Mafp_C4_C2_N1_si\n",
      "Mafp_C4_C2_N2_si\n",
      "Mafp_C4_C2_N3_si\n",
      "Mafp_C4_C2_O1_si\n",
      "Mafp_C4_C2_O2_si\n",
      "Mafp_C4_C3_C4_si\n",
      "Mafp_C4_C3_Cl1_si\n",
      "Mafp_C4_C3_F1_si\n",
      "Mafp_C4_C3_H1_si\n",
      "Mafp_C4_C3_N1_si\n",
      "Mafp_C4_C3_N2_si\n",
      "Mafp_C4_C3_N3_si\n",
      "Mafp_C4_C3_O1_si\n",
      "Mafp_C4_C3_O2_si\n",
      "Mafp_C4_C4_C4_si\n",
      "Mafp_C4_C4_Cl1_si\n",
      "Mafp_C4_C4_F1_si\n",
      "Mafp_C4_C4_H1_si\n",
      "Mafp_C4_C4_N1_si\n",
      "Mafp_C4_C4_N2_si\n",
      "Mafp_C4_C4_N3_si\n",
      "Mafp_C4_C4_O1_si\n",
      "Mafp_C4_C4_O2_si\n",
      "Mafp_C4_N2_C4_si\n",
      "Mafp_C4_N2_H1_si\n",
      "Mafp_C4_N2_N1_si\n",
      "Mafp_C4_N2_N2_si\n",
      "Mafp_C4_N2_N3_si\n",
      "Mafp_C4_N2_O1_si\n",
      "Mafp_C4_N3_C4_si\n",
      "Mafp_C4_N3_F1_si\n",
      "Mafp_C4_N3_H1_si\n",
      "Mafp_C4_N3_N1_si\n",
      "Mafp_C4_N3_N2_si\n",
      "Mafp_C4_N3_N3_si\n",
      "Mafp_C4_N3_O1_si\n",
      "Mafp_C4_N3_O2_si\n",
      "Mafp_C4_O2_C4_si\n",
      "Mafp_C4_O2_Cl1_si\n",
      "Mafp_C4_O2_F1_si\n",
      "Mafp_C4_O2_H1_si\n",
      "Mafp_C4_O2_N2_si\n",
      "Mafp_C4_O2_N3_si\n",
      "Mafp_C4_O2_O1_si\n",
      "Mafp_C4_O2_O2_si\n",
      "Mafp_Cl1_C3_Cl1_si\n",
      "Mafp_Cl1_C3_H1_si\n",
      "Mafp_Cl1_C3_N1_si\n",
      "Mafp_Cl1_C3_N2_si\n",
      "Mafp_Cl1_C3_N3_si\n",
      "Mafp_Cl1_C3_O1_si\n",
      "Mafp_Cl1_C4_Cl1_si\n",
      "Mafp_Cl1_C4_H1_si\n",
      "Mafp_Cl1_C4_N2_si\n",
      "Mafp_Cl1_C4_N3_si\n",
      "Mafp_Cl1_C4_O1_si\n",
      "Mafp_Cl1_C4_O2_si\n",
      "Mafp_Cl1_N2_N1_si\n",
      "Mafp_Cl1_N2_N2_si\n",
      "Mafp_Cl1_N3_Cl1_si\n",
      "Mafp_Cl1_N3_H1_si\n",
      "Mafp_Cl1_N3_N2_si\n",
      "Mafp_F1_C3_F1_si\n",
      "Mafp_F1_C3_N1_si\n",
      "Mafp_F1_C3_N2_si\n",
      "Mafp_F1_C3_N3_si\n",
      "Mafp_F1_C3_O1_si\n",
      "Mafp_F1_C3_O2_si\n",
      "Mafp_F1_C4_F1_si\n",
      "Mafp_F1_C4_H1_si\n",
      "Mafp_F1_C4_N2_si\n",
      "Mafp_F1_C4_N3_si\n",
      "Mafp_F1_C4_O1_si\n",
      "Mafp_F1_C4_O2_si\n",
      "Mafp_F1_N2_N2_si\n",
      "Mafp_F1_N3_F1_si\n",
      "Mafp_F1_N3_H1_si\n",
      "Mafp_F1_N3_N1_si\n",
      "Mafp_F1_N3_N2_si\n",
      "Mafp_F1_N3_N3_si\n",
      "Mafp_H1_C2_H1_si\n",
      "Mafp_H1_C2_N1_si\n",
      "Mafp_H1_C2_N2_si\n",
      "Mafp_H1_C2_N3_si\n",
      "Mafp_H1_C2_O1_si\n",
      "Mafp_H1_C2_O2_si\n",
      "Mafp_H1_C3_H1_si\n",
      "Mafp_H1_C3_N1_si\n",
      "Mafp_H1_C3_N2_si\n",
      "Mafp_H1_C3_N3_si\n",
      "Mafp_H1_C3_O1_si\n",
      "Mafp_H1_C3_O2_si\n",
      "Mafp_H1_C4_H1_si\n",
      "Mafp_H1_C4_N2_si\n",
      "Mafp_H1_C4_N3_si\n",
      "Mafp_H1_C4_O1_si\n",
      "Mafp_H1_C4_O2_si\n",
      "Mafp_H1_N2_H1_si\n",
      "Mafp_H1_N2_N1_si\n",
      "Mafp_H1_N2_N2_si\n",
      "Mafp_H1_N2_N3_si\n",
      "Mafp_H1_N3_H1_si\n",
      "Mafp_H1_N3_N1_si\n",
      "Mafp_H1_N3_N2_si\n",
      "Mafp_H1_N3_N3_si\n",
      "Mafp_H1_N3_O2_si\n",
      "Mafp_H1_O2_H1_si\n",
      "Mafp_H1_O2_N2_si\n",
      "Mafp_H1_O2_O1_si\n",
      "Mafp_H1_O2_O2_si\n",
      "Mafp_N1_C2_N2_si\n",
      "Mafp_N1_C2_N3_si\n",
      "Mafp_N1_C2_O2_si\n",
      "Mafp_N1_C3_N2_si\n",
      "Mafp_N1_C3_N3_si\n",
      "Mafp_N1_C3_O1_si\n",
      "Mafp_N1_C3_O2_si\n",
      "Mafp_N1_C4_N2_si\n",
      "Mafp_N1_C4_N3_si\n",
      "Mafp_N1_C4_O2_si\n",
      "Mafp_N1_N2_N3_si\n",
      "Mafp_N1_N3_N2_si\n",
      "Mafp_N1_N3_N3_si\n",
      "Mafp_N2_C2_N2_si\n",
      "Mafp_N2_C2_N3_si\n",
      "Mafp_N2_C2_O2_si\n",
      "Mafp_N2_C3_N2_si\n",
      "Mafp_N2_C3_N3_si\n",
      "Mafp_N2_C3_O1_si\n",
      "Mafp_N2_C3_O2_si\n",
      "Mafp_N2_C4_N2_si\n",
      "Mafp_N2_C4_N3_si\n",
      "Mafp_N2_C4_O1_si\n",
      "Mafp_N2_C4_O2_si\n",
      "Mafp_N2_N2_N2_si\n",
      "Mafp_N2_N2_N3_si\n",
      "Mafp_N2_N2_O2_si\n",
      "Mafp_N2_N3_N2_si\n",
      "Mafp_N2_N3_N3_si\n",
      "Mafp_N2_N3_O2_si\n",
      "Mafp_N2_O2_N3_si\n",
      "Mafp_N3_C2_O1_si\n",
      "Mafp_N3_C3_N3_si\n",
      "Mafp_N3_C3_O1_si\n",
      "Mafp_N3_C3_O2_si\n",
      "Mafp_N3_C4_N3_si\n",
      "Mafp_N3_C4_O1_si\n",
      "Mafp_N3_C4_O2_si\n",
      "Mafp_N3_N2_N3_si\n",
      "Mafp_N3_N2_O1_si\n",
      "Mafp_N3_N2_O2_si\n",
      "Mafp_N3_N3_N3_si\n",
      "Mafp_N3_N3_O1_si\n",
      "Mafp_N3_N3_O2_si\n",
      "Mafp_N3_O2_N3_si\n",
      "Mafp_O1_C2_O1_si\n",
      "Mafp_O1_C2_O2_si\n",
      "Mafp_O1_C3_O1_si\n",
      "Mafp_O1_C3_O2_si\n",
      "Mafp_O1_C4_O1_si\n",
      "Mafp_O1_C4_O2_si\n",
      "Mafp_O1_N3_O2_si\n",
      "Mafp_O2_C2_O2_si\n",
      "Mafp_O2_C3_O2_si\n",
      "Mafp_O2_C4_O2_si\n",
      "Mafp_O2_N3_O2_si\n",
      "Mefp_fam_acrylate_si\n",
      "Mefp_fam_carbonateester_si\n",
      "Mefp_fam_ketone_si\n",
      "Mefp_fam_polyamides_si\n",
      "Mefp_fam_single_si\n",
      "Mefp_norm_mol_wt_si\n",
      "Mefp_numatoms_none_H_si\n",
      "Mefp_ring_si\n",
      "Mmfp_Chi0n_si\n",
      "Mmfp_Chi0v_si\n",
      "Mmfp_Chi1n_si\n",
      "Mmfp_Chi1v_si\n",
      "Mmfp_Chi2n_si\n",
      "Mmfp_Chi2v_si\n",
      "Mmfp_HallKierAlpha_si\n",
      "Mmfp_MQNs13_si\n",
      "Mmfp_MQNs14_si\n",
      "Mmfp_MQNs15_si\n",
      "Mmfp_MQNs16_si\n",
      "Mmfp_MQNs17_si\n",
      "Mmfp_MQNs18_si\n",
      "Mmfp_MQNs19_si\n",
      "Mmfp_MQNs20_si\n",
      "Mmfp_MQNs21_si\n",
      "Mmfp_MQNs22_si\n",
      "Mmfp_MQNs23_si\n",
      "Mmfp_MQNs24_si\n",
      "Mmfp_MQNs25_si\n",
      "Mmfp_MQNs26_si\n",
      "Mmfp_MQNs27_si\n",
      "Mmfp_MQNs28_si\n",
      "Mmfp_MQNs29_si\n",
      "Mmfp_MQNs30_si\n",
      "Mmfp_MQNs31_si\n",
      "Mmfp_MQNs32_si\n",
      "Mmfp_MQNs33_si\n",
      "Mmfp_MQNs34_si\n",
      "Mmfp_MQNs35_si\n",
      "Mmfp_MQNs36_si\n",
      "Mmfp_MQNs37_si\n",
      "Mmfp_MQNs38_si\n",
      "Mmfp_MQNs39_si\n",
      "Mmfp_MQNs40_si\n",
      "Mmfp_MQNs41_si\n",
      "Mmfp_MQNs42_si\n",
      "Mmfp_NumAliphaticRings_si\n",
      "Mmfp_NumAromaticRings_si\n",
      "Mmfp_tpsa_si\n",
      "norm_Mafp_Br1_C2_C1\n",
      "norm_Mafp_Br1_C2_C2\n",
      "norm_Mafp_Br1_C2_C3\n",
      "norm_Mafp_Br1_C3_Br1\n",
      "norm_Mafp_Br1_C3_C1\n",
      "norm_Mafp_Br1_C3_C2\n",
      "norm_Mafp_Br1_C3_C3\n",
      "norm_Mafp_Br1_C3_C4\n",
      "norm_Mafp_Br1_C3_N1\n",
      "norm_Mafp_Br1_C3_N2\n",
      "norm_Mafp_Br1_C3_N3\n",
      "norm_Mafp_Br1_C3_O1\n",
      "norm_Mafp_Br1_C4_Br1\n",
      "norm_Mafp_Br1_C4_C2\n",
      "norm_Mafp_Br1_C4_C3\n",
      "norm_Mafp_Br1_C4_C4\n",
      "norm_Mafp_Br1_C4_H1\n",
      "norm_Mafp_Br1_C4_N1\n",
      "norm_Mafp_Br1_C4_N2\n",
      "norm_Mafp_Br1_C4_N3\n",
      "norm_Mafp_Br1_C4_O1\n",
      "norm_Mafp_Br1_C4_O2\n",
      "norm_Mafp_Br1_N2_C2\n",
      "norm_Mafp_Br1_N2_C3\n",
      "norm_Mafp_Br1_N2_C4\n",
      "norm_Mafp_Br1_N2_N1\n",
      "norm_Mafp_Br1_N2_N2\n",
      "norm_Mafp_Br1_N2_N3\n",
      "norm_Mafp_Br1_N3_Br1\n",
      "norm_Mafp_Br1_N3_C2\n",
      "norm_Mafp_Br1_N3_C3\n",
      "norm_Mafp_Br1_N3_H1\n",
      "norm_Mafp_Br1_N3_N2\n",
      "norm_Mafp_Br1_N3_O2\n",
      "norm_Mafp_Br1_O2_C2\n",
      "norm_Mafp_Br1_O2_C3\n",
      "norm_Mafp_Br1_O2_C4\n",
      "norm_Mafp_C1_C2_C2\n",
      "norm_Mafp_C1_C2_C3\n",
      "norm_Mafp_C1_C2_C4\n",
      "norm_Mafp_C1_C2_F1\n",
      "norm_Mafp_C1_C2_H1\n",
      "norm_Mafp_C1_C2_O1\n",
      "norm_Mafp_C1_C2_O2\n",
      "norm_Mafp_C1_C3_C2\n",
      "norm_Mafp_C1_C3_C3\n",
      "norm_Mafp_C1_C3_C4\n",
      "norm_Mafp_C1_C3_Cl1\n",
      "norm_Mafp_C1_C3_F1\n",
      "norm_Mafp_C1_C3_H1\n",
      "norm_Mafp_C1_C3_N2\n",
      "norm_Mafp_C1_C3_N3\n",
      "norm_Mafp_C1_C3_O1\n",
      "norm_Mafp_C1_C3_O2\n",
      "norm_Mafp_C1_C4_C2\n",
      "norm_Mafp_C1_C4_C3\n",
      "norm_Mafp_C1_C4_C4\n",
      "norm_Mafp_C1_C4_H1\n",
      "norm_Mafp_C1_C4_O1\n",
      "norm_Mafp_C1_C4_O2\n",
      "norm_Mafp_C1_N2_C2\n",
      "norm_Mafp_C1_N2_C3\n",
      "norm_Mafp_C1_N2_N2\n",
      "norm_Mafp_C1_N2_N3\n",
      "norm_Mafp_C1_N3_C3\n",
      "norm_Mafp_C1_N3_C4\n",
      "norm_Mafp_C1_N3_N2\n",
      "norm_Mafp_C1_N3_N3\n",
      "norm_Mafp_C1_N3_O1\n",
      "norm_Mafp_C1_O2_C3\n",
      "norm_Mafp_C1_O2_C4\n",
      "norm_Mafp_C2_C2_C2\n",
      "norm_Mafp_C2_C2_C3\n",
      "norm_Mafp_C2_C2_C4\n",
      "norm_Mafp_C2_C2_Cl1\n",
      "norm_Mafp_C2_C2_F1\n",
      "norm_Mafp_C2_C2_H1\n",
      "norm_Mafp_C2_C2_N1\n",
      "norm_Mafp_C2_C2_N2\n",
      "norm_Mafp_C2_C2_N3\n",
      "norm_Mafp_C2_C2_O1\n",
      "norm_Mafp_C2_C2_O2\n",
      "norm_Mafp_C2_C3_C2\n",
      "norm_Mafp_C2_C3_C3\n",
      "norm_Mafp_C2_C3_C4\n",
      "norm_Mafp_C2_C3_Cl1\n",
      "norm_Mafp_C2_C3_F1\n",
      "norm_Mafp_C2_C3_H1\n",
      "norm_Mafp_C2_C3_N1\n",
      "norm_Mafp_C2_C3_N2\n",
      "norm_Mafp_C2_C3_N3\n",
      "norm_Mafp_C2_C3_O1\n",
      "norm_Mafp_C2_C3_O2\n",
      "norm_Mafp_C2_C4_C2\n",
      "norm_Mafp_C2_C4_C3\n",
      "norm_Mafp_C2_C4_C4\n",
      "norm_Mafp_C2_C4_Cl1\n",
      "norm_Mafp_C2_C4_F1\n",
      "norm_Mafp_C2_C4_H1\n",
      "norm_Mafp_C2_C4_N2\n",
      "norm_Mafp_C2_C4_N3\n",
      "norm_Mafp_C2_C4_O1\n",
      "norm_Mafp_C2_C4_O2\n",
      "norm_Mafp_C2_N2_C2\n",
      "norm_Mafp_C2_N2_C3\n",
      "norm_Mafp_C2_N2_C4\n",
      "norm_Mafp_C2_N2_Cl1\n",
      "norm_Mafp_C2_N2_F1\n",
      "norm_Mafp_C2_N2_H1\n",
      "norm_Mafp_C2_N2_N1\n",
      "norm_Mafp_C2_N2_N2\n",
      "norm_Mafp_C2_N2_N3\n",
      "norm_Mafp_C2_N2_O1\n",
      "norm_Mafp_C2_N2_O2\n",
      "norm_Mafp_C2_N3_C2\n",
      "norm_Mafp_C2_N3_C3\n",
      "norm_Mafp_C2_N3_C4\n",
      "norm_Mafp_C2_N3_F1\n",
      "norm_Mafp_C2_N3_H1\n",
      "norm_Mafp_C2_N3_N2\n",
      "norm_Mafp_C2_N3_N3\n",
      "norm_Mafp_C2_N3_O1\n",
      "norm_Mafp_C2_N3_O2\n",
      "norm_Mafp_C2_O2_C2\n",
      "norm_Mafp_C2_O2_C3\n",
      "norm_Mafp_C2_O2_C4\n",
      "norm_Mafp_C2_O2_Cl1\n",
      "norm_Mafp_C2_O2_H1\n",
      "norm_Mafp_C2_O2_N2\n",
      "norm_Mafp_C2_O2_N3\n",
      "norm_Mafp_C3_C2_C3\n",
      "norm_Mafp_C3_C2_C4\n",
      "norm_Mafp_C3_C2_Cl1\n",
      "norm_Mafp_C3_C2_F1\n",
      "norm_Mafp_C3_C2_H1\n",
      "norm_Mafp_C3_C2_N1\n",
      "norm_Mafp_C3_C2_N2\n",
      "norm_Mafp_C3_C2_N3\n",
      "norm_Mafp_C3_C2_O1\n",
      "norm_Mafp_C3_C2_O2\n",
      "norm_Mafp_C3_C3_C3\n",
      "norm_Mafp_C3_C3_C4\n",
      "norm_Mafp_C3_C3_Cl1\n",
      "norm_Mafp_C3_C3_F1\n",
      "norm_Mafp_C3_C3_H1\n",
      "norm_Mafp_C3_C3_N1\n",
      "norm_Mafp_C3_C3_N2\n",
      "norm_Mafp_C3_C3_N3\n",
      "norm_Mafp_C3_C3_O1\n",
      "norm_Mafp_C3_C3_O2\n",
      "norm_Mafp_C3_C4_C3\n",
      "norm_Mafp_C3_C4_C4\n",
      "norm_Mafp_C3_C4_Cl1\n",
      "norm_Mafp_C3_C4_F1\n",
      "norm_Mafp_C3_C4_H1\n",
      "norm_Mafp_C3_C4_N1\n",
      "norm_Mafp_C3_C4_N2\n",
      "norm_Mafp_C3_C4_N3\n",
      "norm_Mafp_C3_C4_O1\n",
      "norm_Mafp_C3_C4_O2\n",
      "norm_Mafp_C3_N2_C3\n",
      "norm_Mafp_C3_N2_C4\n",
      "norm_Mafp_C3_N2_Cl1\n",
      "norm_Mafp_C3_N2_F1\n",
      "norm_Mafp_C3_N2_H1\n",
      "norm_Mafp_C3_N2_N1\n",
      "norm_Mafp_C3_N2_N2\n",
      "norm_Mafp_C3_N2_N3\n",
      "norm_Mafp_C3_N2_O1\n",
      "norm_Mafp_C3_N2_O2\n",
      "norm_Mafp_C3_N3_C3\n",
      "norm_Mafp_C3_N3_C4\n",
      "norm_Mafp_C3_N3_Cl1\n",
      "norm_Mafp_C3_N3_F1\n",
      "norm_Mafp_C3_N3_H1\n",
      "norm_Mafp_C3_N3_N1\n",
      "norm_Mafp_C3_N3_N2\n",
      "norm_Mafp_C3_N3_N3\n",
      "norm_Mafp_C3_N3_O2\n",
      "norm_Mafp_C3_O2_C3\n",
      "norm_Mafp_C3_O2_C4\n",
      "norm_Mafp_C3_O2_Cl1\n",
      "norm_Mafp_C3_O2_F1\n",
      "norm_Mafp_C3_O2_H1\n",
      "norm_Mafp_C3_O2_N2\n",
      "norm_Mafp_C3_O2_N3\n",
      "norm_Mafp_C3_O2_O1\n",
      "norm_Mafp_C3_O2_O2\n",
      "norm_Mafp_C4_C2_C4\n",
      "norm_Mafp_C4_C2_H1\n",
      "norm_Mafp_C4_C2_N1\n",
      "norm_Mafp_C4_C2_N2\n",
      "norm_Mafp_C4_C2_N3\n",
      "norm_Mafp_C4_C2_O1\n",
      "norm_Mafp_C4_C2_O2\n",
      "norm_Mafp_C4_C3_C4\n",
      "norm_Mafp_C4_C3_Cl1\n",
      "norm_Mafp_C4_C3_F1\n",
      "norm_Mafp_C4_C3_H1\n",
      "norm_Mafp_C4_C3_N1\n",
      "norm_Mafp_C4_C3_N2\n",
      "norm_Mafp_C4_C3_N3\n",
      "norm_Mafp_C4_C3_O1\n",
      "norm_Mafp_C4_C3_O2\n",
      "norm_Mafp_C4_C4_C4\n",
      "norm_Mafp_C4_C4_Cl1\n",
      "norm_Mafp_C4_C4_F1\n",
      "norm_Mafp_C4_C4_H1\n",
      "norm_Mafp_C4_C4_N1\n",
      "norm_Mafp_C4_C4_N2\n",
      "norm_Mafp_C4_C4_N3\n",
      "norm_Mafp_C4_C4_O1\n",
      "norm_Mafp_C4_C4_O2\n",
      "norm_Mafp_C4_N2_C4\n",
      "norm_Mafp_C4_N2_H1\n",
      "norm_Mafp_C4_N2_N1\n",
      "norm_Mafp_C4_N2_N2\n",
      "norm_Mafp_C4_N2_N3\n",
      "norm_Mafp_C4_N2_O1\n",
      "norm_Mafp_C4_N3_C4\n",
      "norm_Mafp_C4_N3_F1\n",
      "norm_Mafp_C4_N3_H1\n",
      "norm_Mafp_C4_N3_N1\n",
      "norm_Mafp_C4_N3_N2\n",
      "norm_Mafp_C4_N3_N3\n",
      "norm_Mafp_C4_N3_O1\n",
      "norm_Mafp_C4_N3_O2\n",
      "norm_Mafp_C4_O2_C4\n",
      "norm_Mafp_C4_O2_Cl1\n",
      "norm_Mafp_C4_O2_F1\n",
      "norm_Mafp_C4_O2_H1\n",
      "norm_Mafp_C4_O2_N2\n",
      "norm_Mafp_C4_O2_N3\n",
      "norm_Mafp_C4_O2_O1\n",
      "norm_Mafp_C4_O2_O2\n",
      "norm_Mafp_Cl1_C3_Cl1\n",
      "norm_Mafp_Cl1_C3_H1\n",
      "norm_Mafp_Cl1_C3_N1\n",
      "norm_Mafp_Cl1_C3_N2\n",
      "norm_Mafp_Cl1_C3_N3\n",
      "norm_Mafp_Cl1_C3_O1\n",
      "norm_Mafp_Cl1_C4_Cl1\n",
      "norm_Mafp_Cl1_C4_H1\n",
      "norm_Mafp_Cl1_C4_N2\n",
      "norm_Mafp_Cl1_C4_N3\n",
      "norm_Mafp_Cl1_C4_O1\n",
      "norm_Mafp_Cl1_C4_O2\n",
      "norm_Mafp_Cl1_N2_N1\n",
      "norm_Mafp_Cl1_N2_N2\n",
      "norm_Mafp_Cl1_N3_Cl1\n",
      "norm_Mafp_Cl1_N3_H1\n",
      "norm_Mafp_Cl1_N3_N2\n",
      "norm_Mafp_F1_C3_F1\n",
      "norm_Mafp_F1_C3_N1\n",
      "norm_Mafp_F1_C3_N2\n",
      "norm_Mafp_F1_C3_N3\n",
      "norm_Mafp_F1_C3_O1\n",
      "norm_Mafp_F1_C3_O2\n",
      "norm_Mafp_F1_C4_F1\n",
      "norm_Mafp_F1_C4_H1\n",
      "norm_Mafp_F1_C4_N2\n",
      "norm_Mafp_F1_C4_N3\n",
      "norm_Mafp_F1_C4_O1\n",
      "norm_Mafp_F1_C4_O2\n",
      "norm_Mafp_F1_N2_N2\n",
      "norm_Mafp_F1_N3_F1\n",
      "norm_Mafp_F1_N3_H1\n",
      "norm_Mafp_F1_N3_N1\n",
      "norm_Mafp_F1_N3_N2\n",
      "norm_Mafp_F1_N3_N3\n",
      "norm_Mafp_H1_C2_H1\n",
      "norm_Mafp_H1_C2_N1\n",
      "norm_Mafp_H1_C2_N2\n",
      "norm_Mafp_H1_C2_N3\n",
      "norm_Mafp_H1_C2_O1\n",
      "norm_Mafp_H1_C2_O2\n",
      "norm_Mafp_H1_C3_H1\n",
      "norm_Mafp_H1_C3_N1\n",
      "norm_Mafp_H1_C3_N2\n",
      "norm_Mafp_H1_C3_N3\n",
      "norm_Mafp_H1_C3_O1\n",
      "norm_Mafp_H1_C3_O2\n",
      "norm_Mafp_H1_C4_H1\n",
      "norm_Mafp_H1_C4_N2\n",
      "norm_Mafp_H1_C4_N3\n",
      "norm_Mafp_H1_C4_O1\n",
      "norm_Mafp_H1_C4_O2\n",
      "norm_Mafp_H1_N2_H1\n",
      "norm_Mafp_H1_N2_N1\n",
      "norm_Mafp_H1_N2_N2\n",
      "norm_Mafp_H1_N2_N3\n",
      "norm_Mafp_H1_N3_H1\n",
      "norm_Mafp_H1_N3_N1\n",
      "norm_Mafp_H1_N3_N2\n",
      "norm_Mafp_H1_N3_N3\n",
      "norm_Mafp_H1_N3_O2\n",
      "norm_Mafp_H1_O2_H1\n",
      "norm_Mafp_H1_O2_N2\n",
      "norm_Mafp_H1_O2_O1\n",
      "norm_Mafp_H1_O2_O2\n",
      "norm_Mafp_N1_C2_N2\n",
      "norm_Mafp_N1_C2_N3\n",
      "norm_Mafp_N1_C2_O2\n",
      "norm_Mafp_N1_C3_N2\n",
      "norm_Mafp_N1_C3_N3\n",
      "norm_Mafp_N1_C3_O1\n",
      "norm_Mafp_N1_C3_O2\n",
      "norm_Mafp_N1_C4_N2\n",
      "norm_Mafp_N1_C4_N3\n",
      "norm_Mafp_N1_C4_O2\n",
      "norm_Mafp_N1_N2_N3\n",
      "norm_Mafp_N1_N3_N2\n",
      "norm_Mafp_N1_N3_N3\n",
      "norm_Mafp_N2_C2_N2\n",
      "norm_Mafp_N2_C2_N3\n",
      "norm_Mafp_N2_C2_O2\n",
      "norm_Mafp_N2_C3_N2\n",
      "norm_Mafp_N2_C3_N3\n",
      "norm_Mafp_N2_C3_O1\n",
      "norm_Mafp_N2_C3_O2\n",
      "norm_Mafp_N2_C4_N2\n",
      "norm_Mafp_N2_C4_N3\n",
      "norm_Mafp_N2_C4_O1\n",
      "norm_Mafp_N2_C4_O2\n",
      "norm_Mafp_N2_N2_N2\n",
      "norm_Mafp_N2_N2_N3\n",
      "norm_Mafp_N2_N2_O2\n",
      "norm_Mafp_N2_N3_N2\n",
      "norm_Mafp_N2_N3_N3\n",
      "norm_Mafp_N2_N3_O2\n",
      "norm_Mafp_N2_O2_N3\n",
      "norm_Mafp_N3_C2_O1\n",
      "norm_Mafp_N3_C3_N3\n",
      "norm_Mafp_N3_C3_O1\n",
      "norm_Mafp_N3_C3_O2\n",
      "norm_Mafp_N3_C4_N3\n",
      "norm_Mafp_N3_C4_O1\n",
      "norm_Mafp_N3_C4_O2\n",
      "norm_Mafp_N3_N2_N3\n",
      "norm_Mafp_N3_N2_O1\n",
      "norm_Mafp_N3_N2_O2\n",
      "norm_Mafp_N3_N3_N3\n",
      "norm_Mafp_N3_N3_O1\n",
      "norm_Mafp_N3_N3_O2\n",
      "norm_Mafp_N3_O2_N3\n",
      "norm_Mafp_O1_C2_O1\n",
      "norm_Mafp_O1_C2_O2\n",
      "norm_Mafp_O1_C3_O1\n",
      "norm_Mafp_O1_C3_O2\n",
      "norm_Mafp_O1_C4_O1\n",
      "norm_Mafp_O1_C4_O2\n",
      "norm_Mafp_O1_N3_O2\n",
      "norm_Mafp_O2_C2_O2\n",
      "norm_Mafp_O2_C3_O2\n",
      "norm_Mafp_O2_C4_O2\n",
      "norm_Mafp_O2_N3_O2\n",
      "norm_Mefp_fam_acrylate\n",
      "norm_Mefp_fam_carbonateester\n",
      "norm_Mefp_fam_ketone\n",
      "norm_Mefp_fam_polyamides\n",
      "norm_Mefp_fam_single\n",
      "norm_Mefp_norm_mol_wt\n",
      "norm_Mefp_numatoms_none_H\n",
      "norm_Mefp_ring\n",
      "norm_Mmfp_Chi0n\n",
      "norm_Mmfp_Chi0v\n",
      "norm_Mmfp_Chi1n\n",
      "norm_Mmfp_Chi1v\n",
      "norm_Mmfp_Chi2n\n",
      "norm_Mmfp_Chi2v\n",
      "norm_Mmfp_HallKierAlpha\n",
      "norm_Mmfp_MQNs13\n",
      "norm_Mmfp_MQNs14\n",
      "norm_Mmfp_MQNs15\n",
      "norm_Mmfp_MQNs16\n",
      "norm_Mmfp_MQNs17\n",
      "norm_Mmfp_MQNs18\n",
      "norm_Mmfp_MQNs19\n",
      "norm_Mmfp_MQNs20\n",
      "norm_Mmfp_MQNs21\n",
      "norm_Mmfp_MQNs22\n",
      "norm_Mmfp_MQNs23\n",
      "norm_Mmfp_MQNs24\n",
      "norm_Mmfp_MQNs25\n",
      "norm_Mmfp_MQNs26\n",
      "norm_Mmfp_MQNs27\n",
      "norm_Mmfp_MQNs28\n",
      "norm_Mmfp_MQNs29\n",
      "norm_Mmfp_MQNs30\n",
      "norm_Mmfp_MQNs31\n",
      "norm_Mmfp_MQNs32\n",
      "norm_Mmfp_MQNs33\n",
      "norm_Mmfp_MQNs34\n",
      "norm_Mmfp_MQNs35\n",
      "norm_Mmfp_MQNs36\n",
      "norm_Mmfp_MQNs37\n",
      "norm_Mmfp_MQNs38\n",
      "norm_Mmfp_MQNs39\n",
      "norm_Mmfp_MQNs40\n",
      "norm_Mmfp_MQNs41\n",
      "norm_Mmfp_MQNs42\n",
      "norm_Mmfp_NumAliphaticRings\n",
      "norm_Mmfp_NumAromaticRings\n",
      "norm_Mmfp_tpsa\n",
      "norm_valence_pa\n",
      "norm_atomic_rad_pa_(angstroms)\n",
      "norm_affinity_pa_(eV)\n",
      "norm_ionization_potential_pa_(eV)\n",
      "norm_electronegativity_pa\n",
      "norm_Dom._Pore_(ang.)\n",
      "norm_Max._Pore_(ang.)\n",
      "norm_Void_Fraction\n",
      "norm_Surf._Area_(m2/g)\n",
      "norm_Vol._Surf._Area\n",
      "norm_Density\n",
      "cat_1\n",
      "cat_2\n",
      "cat_3\n",
      "cat_4\n",
      "norm_log_pressure\n",
      "size_0\n",
      "size_1\n",
      "size_2\n",
      "size_3\n",
      "size_4\n",
      "size_5\n",
      "size_6\n",
      "size_7\n",
      "size_8\n",
      "size_9\n",
      "size_10\n",
      "size_11\n",
      "size_12\n",
      "size_13\n",
      "size_14\n",
      "size_15\n",
      "size_16\n",
      "size_17\n",
      "size_18\n",
      "size_19\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'slim' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-90-f6b4e75acc3a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mml_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_frac\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'slim' is not defined"
     ]
    }
   ],
   "source": [
    "if stacked:\n",
    "    print('\\nStarting to Construct Isotherm Stacked Data Frame')\n",
    "else:\n",
    "    print('\\nStarting to Construct Gravimetric Uptake Data Frame')\n",
    "print('Using start_str_sd %s' %start_str_sd)\n",
    "print('Using end_str_sd %s' %end_str_sd)\n",
    "print('Using start_str_si %s' %start_str_si)\n",
    "print('Using end_str_si %s' %end_str_si)\n",
    "print('Total frac equals %s' %total_frac)\n",
    "\n",
    "if cat_si_sd:\n",
    "    ml_data_sd = pd.read_csv(SD_ML_DATA_PATH)\n",
    "    ml_data_si = pd.read_csv(SI_ML_DATA_PATH)\n",
    "\n",
    "    ml_data_si.columns = [col+'_si' for col in ml_data_si.columns]\n",
    "    si_cols = ml_data_si.keys().tolist()\n",
    "    si_start_ind = si_cols.index(start_str_si+'_si')\n",
    "    si_end_ind = si_cols.index(end_str_si+'_si')\n",
    "    si_pg_cols = si_cols[si_start_ind + 1:si_end_ind]\n",
    "\n",
    "    ml_data = ml_data_sd.join(ml_data_si[si_pg_cols], rsuffix='_si')\n",
    "\n",
    "\n",
    "    sd_cols = ml_data_sd.keys().tolist()\n",
    "    sd_start_ind = sd_cols.index(start_str_sd)\n",
    "    sd_end_ind = sd_cols.index(end_str_sd)\n",
    "    sd_pg_cols = sd_cols[sd_start_ind + 1:sd_end_ind]\n",
    "\n",
    "    pg_cols = si_pg_cols + sd_pg_cols\n",
    "else:\n",
    "    if size_dependent:\n",
    "        ML_DATA_PATH=SD_ML_DATA_PATH\n",
    "        start_str = start_str_sd\n",
    "        end_str= end_str_sd\n",
    "    else:\n",
    "        ML_DATA_PATH=SI_ML_DATA_PATH\n",
    "        start_str = start_str_si\n",
    "        end_str= end_str_si\n",
    "    ml_data = load_ml_data(ML_DATA_PATH)\n",
    "    pg_cols = ml.getPGcolNames(ml_data, start_str, end_str)\n",
    "\n",
    "\n",
    "non_pg_cols = ml.getNonPGcolNames(add_size_fp, stacked, del_geometric_fp, cat_col_names)\n",
    "\n",
    "features = pg_cols + non_pg_cols\n",
    "\n",
    "print('\\n')\n",
    "print(\"Using following %s features\" %len(features))\n",
    "for i in features:\n",
    "    print(i)\n",
    "\n",
    "ml_data = slim(ml_data, total_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting To Make Linker Size Columns\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "Finished Making Linker Size Columns\n"
     ]
    }
   ],
   "source": [
    "if add_size_fp:\n",
    "    size_names = ['size_%s' %n for n in range(20)] \n",
    "    print('Starting To Make Linker Size Columns')        \n",
    "    if LS_DICT == None:\n",
    "        for col in [col for col in ml_data.keys() if 'Smiles' in col]:\n",
    "            makeSizeCol(ml_data, col)\n",
    "        if srt_size_fp:\n",
    "            print('Starting to sort Linker Size Columns')           \n",
    "            a = ml_data[size_names].values\n",
    "            a.sort(axis=1)\n",
    "            a = a[:, ::-1]\n",
    "            ml_data[size_names] = a\n",
    "    else:\n",
    "        smiles_cols = [col for col in ml_data.keys() if 'Smiles' in col]\n",
    "        \n",
    "        def makeLSfromDict(row):\n",
    "            fail = 0\n",
    "            f_name = row['filename']\n",
    "            try:\n",
    "                LS_list = LS_DICT[f_name].tolist()\n",
    "            except:\n",
    "                fail += 1\n",
    "                smiles = row[smiles_cols]\n",
    "                LS_list = [ml.getNAtoms(s) for s in smiles]\n",
    "            print(fail)\n",
    "            return pd.Series(row.tolist() + LS_list)\n",
    "\n",
    "        old_cols = ml_data.columns.tolist()\n",
    "        ml_data = ml_data.apply(makeLSfromDict, axis=1)\n",
    "        ml_data.columns = old_cols + size_names\n",
    "    print('Finished Making Linker Size Columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      42\n",
       "1      38\n",
       "2      12\n",
       "3      30\n",
       "4      94\n",
       "5      10\n",
       "6      28\n",
       "7      44\n",
       "8      30\n",
       "9      24\n",
       "10     36\n",
       "11     32\n",
       "12     40\n",
       "13     12\n",
       "14     62\n",
       "15     49\n",
       "16     16\n",
       "17     39\n",
       "18     12\n",
       "19     30\n",
       "20     26\n",
       "21     40\n",
       "22     72\n",
       "23     64\n",
       "24     37\n",
       "25     16\n",
       "26     28\n",
       "27     50\n",
       "28     30\n",
       "29     73\n",
       "       ..\n",
       "169    26\n",
       "170    10\n",
       "171     8\n",
       "172    30\n",
       "173    14\n",
       "174    48\n",
       "175    10\n",
       "176    44\n",
       "177    18\n",
       "178    29\n",
       "179    41\n",
       "180    32\n",
       "181    26\n",
       "182    30\n",
       "183    28\n",
       "184    47\n",
       "185    10\n",
       "186    32\n",
       "187    50\n",
       "188    30\n",
       "189    26\n",
       "190    19\n",
       "191    14\n",
       "192    14\n",
       "193    16\n",
       "194    20\n",
       "195    16\n",
       "196     8\n",
       "197    24\n",
       "198    16\n",
       "Name: size_0, Length: 199, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ml_data['size_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
