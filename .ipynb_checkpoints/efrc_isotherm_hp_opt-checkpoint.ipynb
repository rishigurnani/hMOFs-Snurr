{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "tickfontsize=20\n",
    "labelfontsize = tickfontsize\n",
    "\n",
    "import importlib\n",
    "import efrc_ml_production as ml\n",
    "importlib.reload(ml)\n",
    "\n",
    "from rdkit import Chem\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following must be defined\n",
    "algo = 'nn' #am I using XGBoost (xgb) or Neural Nets (nn)?\n",
    "total_frac = .05 #total fraction of data set to work with\n",
    "training_pct = .7 #how much percent of total fraction should be used for training\n",
    "random_split = True #make True if the training data should be chosen randomly\n",
    "n_remote = 10000 #the n_remote most remote points will be added to training set if random_split = False\n",
    "USE_PCA = True #should I use PCA?\n",
    "N_COMPONENTS=400 #how many PCA Components should I use?\n",
    "del_defective_mofs = False #make True if you want to remove all MOFs which a '0' value for at least one geometric property\n",
    "cat_si_sd = False #make True if you want to concatenate size-indep and size-dep fps\n",
    "add_size_fp = False #make True if you want to add 20 feature columns, where each feature is the number of atoms in a linker\n",
    "size_dependent = False #make True if the input ML-ready data contains fingerprint which does not normalize each PG feature$\n",
    "stacked = True #make True if the input ML-ready data contains pressure as feature\n",
    "n_core = 18 #number of cores to use\n",
    "if not stacked:\n",
    "    SD_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_no_norm/ml_data.csv' #path to size-dep data\n",
    "else:\n",
    "    SD_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_no_norm/stacked.csv'\n",
    "if not stacked:\n",
    "    SI_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_v1/ml_data.csv' #path to size-indep data\n",
    "else:\n",
    "    SI_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_v1/stacked.csv'\n",
    "if not stacked:\n",
    "    start_str_sd = 'CH4_v/v_248_bar'\n",
    "    end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "else:\n",
    "    start_str_sd = 'Density'\n",
    "    end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "\n",
    "start_str_si = 'filename'\n",
    "end_str_si = 'valence_pa'\n",
    "del_geometric_fp = False #make True if you want to ignore the geometric features\n",
    "cat_col_names = ['oh_1', 'oh_2', 'oh_3', 'oh_4'] #names for interpenetration columns\n",
    "Y_DATA_PATH = '/data/rgur/efrc/data_DONOTTOUCH/hMOF_allData_March25_2013.xlsx' #path to original hMOF data\n",
    "default_params = {'objective':'reg:linear', 'colsample_bytree':0.3, 'learning_rate':0.1,\n",
    "                'max_depth':15, 'alpha':10, 'n_estimators':10}\n",
    "n_trees = 50 #number of weak learners. Bigger is better until 5000\n",
    "save_pp = False #make True if you want to save the parity plot\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steps before hp_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0ea478d2fcef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                             \u001b[0mSI_ML_DATA_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_str_sd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_str_sd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_str_si\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_str_si\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                             \u001b[0mtotal_frac\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdel_defective_mofs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_size_fp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_dependent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacked\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_core\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                             del_geometric_fp, cat_col_names, Y_DATA_PATH)\n\u001b[0m",
      "\u001b[0;32m~/py_scripts/efrc_ml_production.py\u001b[0m in \u001b[0;36mprepToSplit\u001b[0;34m(cat_si_sd, SD_ML_DATA_PATH, SI_ML_DATA_PATH, start_str_sd, end_str_sd, start_str_si, end_str_si, total_frac, del_defective_mofs, add_size_fp, size_dependent, stacked, n_core, del_geometric_fp, cat_col_names, Y_DATA_PATH, return_features)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mstart_str\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstart_str_si\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mend_str\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mend_str_si\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mml_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0mpg_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetPGcolNames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mml_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_str\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/py_scripts/efrc_ml_production.py\u001b[0m in \u001b[0;36mload_ml_data\u001b[0;34m(ML_DATA_PATH)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_ml_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mML_DATA_PATH\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mreduce_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    703\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nrows'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;31m# May alter columns / col_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1993\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1994\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1995\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1996\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1997\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/home/modules/anaconda3/lib/python3.7/site-packages/pandas/core/dtypes/common.py\u001b[0m in \u001b[0;36mis_categorical_dtype\u001b[0;34m(arr_or_dtype)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mis_categorical_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m     \"\"\"\n\u001b[1;32m    574\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0man\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlike\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCategorical\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if not stacked:\n",
    "    ml_data, property_used, target_mean, target_std, features = ml.prepToSplit(cat_si_sd, SD_ML_DATA_PATH, \n",
    "                                            SI_ML_DATA_PATH, start_str_sd, end_str_sd, start_str_si, end_str_si, \n",
    "                                            total_frac, del_defective_mofs, add_size_fp, size_dependent, stacked, n_core, \n",
    "                                            del_geometric_fp, cat_col_names, Y_DATA_PATH)\n",
    "if stacked:\n",
    "    ml_data, property_used, target_mean, target_std, features, p_info = ml.prepToSplit(cat_si_sd, SD_ML_DATA_PATH, \n",
    "                                            SI_ML_DATA_PATH, start_str_sd, end_str_sd, start_str_si, end_str_si, \n",
    "                                            total_frac, del_defective_mofs, add_size_fp, size_dependent, stacked, n_core, \n",
    "                                            del_geometric_fp, cat_col_names, Y_DATA_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df, test_df= ml.trainTestSplit(ml_data, property_used, training_pct, stacked, \n",
    "                                     n_core, random_split, n_remote, features, USE_PCA, N_COMPONENTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'xgb':\n",
    "    train_d, test_d, train_label, test_label = ml.alter_dtype(train_df, test_df, property_used, n_core, algo, features)\n",
    "else:\n",
    "    train_d, test_d, train_label, test_label = ml.alter_dtype(train_df, test_df, property_used, n_core, algo, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_label) + len(test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(params):\n",
    "    print(\"Size of training set %s\" %len(train_label))\n",
    "    MODEL = ml.run_model(algo, train_d, n_trees, params)\n",
    "    return ml.model_rmse(MODEL, train_d, test_d, stacked, algo, target_mean, target_std, property_used, \n",
    "                         test_label, train_label, save=False, fname=None, subset_inds=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with two hyperparameters in the model:<br>\n",
    "<br>\n",
    "1)Number of units in the first dense layer<br>\n",
    "2)Learning rate<br>\n",
    "3)Patience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skopt import gp_minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = [(100, 400), #n_units\n",
    "        (.001, .002),#learning rate\n",
    "        (2, 15), #patience\n",
    "        (4, 512), #batch size\n",
    "        (.1, .9)] #validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0457 - mae: 0.1475 - mse: 0.0457\n",
      "Epoch 00001: val_loss improved from inf to 0.03139, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0456,  mae:0.1473,  mse:0.0456,  val_loss:0.0314,  val_mae:0.1313,  val_mse:0.0314,  \n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0456 - mae: 0.1473 - mse: 0.0456 - val_loss: 0.0314 - val_mae: 0.1313 - val_mse: 0.0314\n",
      "Epoch 2/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0239 - mae: 0.1142 - mse: 0.0239\n",
      "Epoch 00002: val_loss improved from 0.03139 to 0.01908, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0238 - mae: 0.1141 - mse: 0.0238 - val_loss: 0.0191 - val_mae: 0.1008 - val_mse: 0.0191\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0209 - mae: 0.1062 - mse: 0.0209\n",
      "Epoch 00003: val_loss did not improve from 0.01908\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0209 - mae: 0.1062 - mse: 0.0209 - val_loss: 0.0228 - val_mae: 0.1162 - val_mse: 0.0228\n",
      "Epoch 4/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0194 - mae: 0.1011 - mse: 0.0194\n",
      "Epoch 00004: val_loss improved from 0.01908 to 0.01657, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0194 - mae: 0.1010 - mse: 0.0194 - val_loss: 0.0166 - val_mae: 0.0921 - val_mse: 0.0166\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0185 - mae: 0.0987 - mse: 0.0185\n",
      "Epoch 00005: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0185 - mae: 0.0986 - mse: 0.0185 - val_loss: 0.0219 - val_mae: 0.1063 - val_mse: 0.0219\n",
      "Epoch 6/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0943 - mse: 0.0172\n",
      "Epoch 00006: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0172 - mae: 0.0944 - mse: 0.0172 - val_loss: 0.0190 - val_mae: 0.0987 - val_mse: 0.0190\n",
      "Epoch 7/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0932 - mse: 0.0170\n",
      "Epoch 00007: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0170 - mae: 0.0933 - mse: 0.0170 - val_loss: 0.0221 - val_mae: 0.1115 - val_mse: 0.0221\n",
      "Epoch 8/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0930 - mse: 0.0166\n",
      "Epoch 00008: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0166 - mae: 0.0931 - mse: 0.0166 - val_loss: 0.0167 - val_mae: 0.0907 - val_mse: 0.0167\n",
      "Epoch 9/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0901 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0157 - mae: 0.0903 - mse: 0.0157 - val_loss: 0.0194 - val_mae: 0.1015 - val_mse: 0.0194\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0883 - mse: 0.0152\n",
      "Epoch 00010: val_loss improved from 0.01657 to 0.01599, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0151 - mae: 0.0882 - mse: 0.0151 - val_loss: 0.0160 - val_mae: 0.0873 - val_mse: 0.0160\n",
      "Epoch 11/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0874 - mse: 0.0148\n",
      "Epoch 00011: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0148 - mae: 0.0874 - mse: 0.0148 - val_loss: 0.0175 - val_mae: 0.1005 - val_mse: 0.0175\n",
      "Epoch 12/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0850 - mse: 0.0142\n",
      "Epoch 00012: val_loss improved from 0.01599 to 0.01434, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0142 - mae: 0.0849 - mse: 0.0142 - val_loss: 0.0143 - val_mae: 0.0829 - val_mse: 0.0143\n",
      "Epoch 13/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0829 - mse: 0.0136\n",
      "Epoch 00013: val_loss did not improve from 0.01434\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0137 - mae: 0.0832 - mse: 0.0137 - val_loss: 0.0197 - val_mae: 0.0967 - val_mse: 0.0197\n",
      "Epoch 14/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0823 - mse: 0.0133\n",
      "Epoch 00014: val_loss improved from 0.01434 to 0.01418, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0133 - mae: 0.0822 - mse: 0.0133 - val_loss: 0.0142 - val_mae: 0.0832 - val_mse: 0.0142\n",
      "Epoch 15/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0824 - mse: 0.0134\n",
      "Epoch 00015: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0134 - mae: 0.0823 - mse: 0.0134 - val_loss: 0.0145 - val_mae: 0.0846 - val_mse: 0.0145\n",
      "Epoch 16/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0793 - mse: 0.0126\n",
      "Epoch 00016: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0126 - mae: 0.0792 - mse: 0.0126 - val_loss: 0.0149 - val_mae: 0.0888 - val_mse: 0.0149\n",
      "Epoch 17/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0797 - mse: 0.0125\n",
      "Epoch 00017: val_loss improved from 0.01418 to 0.01354, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0124 - mae: 0.0798 - mse: 0.0124 - val_loss: 0.0135 - val_mae: 0.0796 - val_mse: 0.0135\n",
      "Epoch 18/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0762 - mse: 0.0119\n",
      "Epoch 00018: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0119 - mae: 0.0762 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0894 - val_mse: 0.0158\n",
      "Epoch 19/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0775 - mse: 0.0120\n",
      "Epoch 00019: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0120 - mae: 0.0775 - mse: 0.0120 - val_loss: 0.0147 - val_mae: 0.0835 - val_mse: 0.0147\n",
      "Epoch 20/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0112 - mae: 0.0746 - mse: 0.0112\n",
      "Epoch 00020: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0113 - mae: 0.0746 - mse: 0.0113 - val_loss: 0.0142 - val_mae: 0.0823 - val_mse: 0.0142\n",
      "Epoch 21/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0735 - mse: 0.0109\n",
      "Epoch 00021: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0112 - mae: 0.0740 - mse: 0.0112 - val_loss: 0.0146 - val_mae: 0.0853 - val_mse: 0.0146\n",
      "Epoch 22/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0109 - mae: 0.0733 - mse: 0.0109\n",
      "Epoch 00022: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0109 - mae: 0.0734 - mse: 0.0109 - val_loss: 0.0150 - val_mae: 0.0863 - val_mse: 0.0150\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0106 - mae: 0.0723 - mse: 0.0106\n",
      "Epoch 00023: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0106 - mae: 0.0723 - mse: 0.0106 - val_loss: 0.0153 - val_mae: 0.0850 - val_mse: 0.0153\n",
      "Epoch 24/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0699 - mse: 0.0101\n",
      "Epoch 00024: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0100 - mae: 0.0699 - mse: 0.0100 - val_loss: 0.0136 - val_mae: 0.0765 - val_mse: 0.0136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0705 - mse: 0.0101\n",
      "Epoch 00025: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0101 - mae: 0.0704 - mse: 0.0101 - val_loss: 0.0143 - val_mae: 0.0794 - val_mse: 0.0143\n",
      "Elapsed time during model training:  33.84223675727844\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0455 - mae: 0.1468 - mse: 0.0455\n",
      "Epoch 00001: val_loss improved from inf to 0.02742, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0452,  mae:0.1463,  mse:0.0452,  val_loss:0.0274,  val_mae:0.1183,  val_mse:0.0274,  \n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0452 - mae: 0.1463 - mse: 0.0452 - val_loss: 0.0274 - val_mae: 0.1183 - val_mse: 0.0274\n",
      "Epoch 2/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1092 - mse: 0.0221\n",
      "Epoch 00002: val_loss improved from 0.02742 to 0.02201, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0221 - mae: 0.1094 - mse: 0.0221 - val_loss: 0.0220 - val_mae: 0.1100 - val_mse: 0.0220\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0211 - mae: 0.1057 - mse: 0.0211\n",
      "Epoch 00003: val_loss improved from 0.02201 to 0.01719, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0211 - mae: 0.1056 - mse: 0.0211 - val_loss: 0.0172 - val_mae: 0.0935 - val_mse: 0.0172\n",
      "Epoch 4/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0991 - mse: 0.0187\n",
      "Epoch 00004: val_loss improved from 0.01719 to 0.01666, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0187 - mae: 0.0990 - mse: 0.0187 - val_loss: 0.0167 - val_mae: 0.0922 - val_mse: 0.0167\n",
      "Epoch 5/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0182 - mae: 0.0981 - mse: 0.0182\n",
      "Epoch 00005: val_loss did not improve from 0.01666\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0181 - mae: 0.0979 - mse: 0.0181 - val_loss: 0.0182 - val_mae: 0.0968 - val_mse: 0.0182\n",
      "Epoch 6/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0983 - mse: 0.0184\n",
      "Epoch 00006: val_loss improved from 0.01666 to 0.01543, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0183 - mae: 0.0980 - mse: 0.0183 - val_loss: 0.0154 - val_mae: 0.0854 - val_mse: 0.0154\n",
      "Epoch 7/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0928 - mse: 0.0167\n",
      "Epoch 00007: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0167 - mae: 0.0929 - mse: 0.0167 - val_loss: 0.0179 - val_mae: 0.0976 - val_mse: 0.0179\n",
      "Epoch 8/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0169 - mae: 0.0945 - mse: 0.0169\n",
      "Epoch 00008: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0169 - mae: 0.0945 - mse: 0.0169 - val_loss: 0.0212 - val_mae: 0.1129 - val_mse: 0.0212\n",
      "Epoch 9/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0901 - mse: 0.0159\n",
      "Epoch 00009: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0159 - mae: 0.0901 - mse: 0.0159 - val_loss: 0.0206 - val_mae: 0.1088 - val_mse: 0.0206\n",
      "Epoch 10/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0864 - mse: 0.0148\n",
      "Epoch 00010: val_loss improved from 0.01543 to 0.01537, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0149 - mae: 0.0865 - mse: 0.0149 - val_loss: 0.0154 - val_mae: 0.0867 - val_mse: 0.0154\n",
      "Epoch 11/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0861 - mse: 0.0146\n",
      "Epoch 00011: val_loss did not improve from 0.01537\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0146 - mae: 0.0861 - mse: 0.0146 - val_loss: 0.0165 - val_mae: 0.0911 - val_mse: 0.0165\n",
      "Epoch 12/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0861 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01537\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0145 - mae: 0.0861 - mse: 0.0145 - val_loss: 0.0178 - val_mae: 0.0968 - val_mse: 0.0178\n",
      "Epoch 13/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0831 - mse: 0.0137\n",
      "Epoch 00013: val_loss improved from 0.01537 to 0.01495, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0137 - mae: 0.0831 - mse: 0.0137 - val_loss: 0.0150 - val_mae: 0.0855 - val_mse: 0.0150\n",
      "Epoch 14/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0815 - mse: 0.0133\n",
      "Epoch 00014: val_loss did not improve from 0.01495\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0133 - mae: 0.0815 - mse: 0.0133 - val_loss: 0.0167 - val_mae: 0.0942 - val_mse: 0.0167\n",
      "Epoch 15/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0788 - mse: 0.0126\n",
      "Epoch 00015: val_loss did not improve from 0.01495\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0126 - mae: 0.0790 - mse: 0.0126 - val_loss: 0.0171 - val_mae: 0.0960 - val_mse: 0.0171\n",
      "Epoch 16/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0802 - mse: 0.0129\n",
      "Epoch 00016: val_loss improved from 0.01495 to 0.01479, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0129 - mae: 0.0802 - mse: 0.0129 - val_loss: 0.0148 - val_mae: 0.0867 - val_mse: 0.0148\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0798 - mse: 0.0127\n",
      "Epoch 00017: val_loss improved from 0.01479 to 0.01415, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0127 - mae: 0.0797 - mse: 0.0127 - val_loss: 0.0142 - val_mae: 0.0794 - val_mse: 0.0142\n",
      "Epoch 18/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0767 - mse: 0.0119\n",
      "Epoch 00018: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0119 - mae: 0.0766 - mse: 0.0119 - val_loss: 0.0142 - val_mae: 0.0790 - val_mse: 0.0142\n",
      "Epoch 19/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0761 - mse: 0.0117\n",
      "Epoch 00019: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0149 - val_mae: 0.0860 - val_mse: 0.0149\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0757 - mse: 0.0116\n",
      "Epoch 00020: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0116 - mae: 0.0755 - mse: 0.0116 - val_loss: 0.0150 - val_mae: 0.0878 - val_mse: 0.0150\n",
      "Epoch 21/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0747 - mse: 0.0112\n",
      "Epoch 00021: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0112 - mae: 0.0746 - mse: 0.0112 - val_loss: 0.0143 - val_mae: 0.0828 - val_mse: 0.0143\n",
      "Epoch 22/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0727 - mse: 0.0107\n",
      "Epoch 00022: val_loss improved from 0.01415 to 0.01355, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0108 - mae: 0.0728 - mse: 0.0108 - val_loss: 0.0135 - val_mae: 0.0796 - val_mse: 0.0135\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0734 - mse: 0.0106\n",
      "Epoch 00023: val_loss did not improve from 0.01355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0106 - mae: 0.0734 - mse: 0.0106 - val_loss: 0.0139 - val_mae: 0.0794 - val_mse: 0.0139\n",
      "Epoch 24/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0726 - mse: 0.0108\n",
      "Epoch 00024: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0108 - mae: 0.0725 - mse: 0.0108 - val_loss: 0.0157 - val_mae: 0.0889 - val_mse: 0.0157\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0724 - mse: 0.0105\n",
      "Epoch 00025: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0106 - mae: 0.0726 - mse: 0.0106 - val_loss: 0.0138 - val_mae: 0.0851 - val_mse: 0.0138\n",
      "Epoch 26/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0715 - mse: 0.0103\n",
      "Epoch 00026: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0103 - mae: 0.0716 - mse: 0.0103 - val_loss: 0.0150 - val_mae: 0.0845 - val_mse: 0.0150\n",
      "Epoch 27/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0694 - mse: 0.0098\n",
      "Epoch 00027: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0153 - val_mae: 0.0871 - val_mse: 0.0153\n",
      "Epoch 28/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0688 - mse: 0.0097\n",
      "Epoch 00028: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0097 - mae: 0.0689 - mse: 0.0097 - val_loss: 0.0152 - val_mae: 0.0832 - val_mse: 0.0152\n",
      "Epoch 29/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0694 - mse: 0.0097\n",
      "Epoch 00029: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0097 - mae: 0.0694 - mse: 0.0097 - val_loss: 0.0143 - val_mae: 0.0829 - val_mse: 0.0143\n",
      "Epoch 30/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0675 - mse: 0.0091\n",
      "Epoch 00030: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0092 - mae: 0.0679 - mse: 0.0092 - val_loss: 0.0155 - val_mae: 0.0867 - val_mse: 0.0155\n",
      "Epoch 31/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0683 - mse: 0.0094\n",
      "Epoch 00031: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0094 - mae: 0.0682 - mse: 0.0094 - val_loss: 0.0139 - val_mae: 0.0811 - val_mse: 0.0139\n",
      "Epoch 32/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0649 - mse: 0.0086\n",
      "Epoch 00032: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0087 - mae: 0.0652 - mse: 0.0087 - val_loss: 0.0146 - val_mae: 0.0847 - val_mse: 0.0146\n",
      "Epoch 33/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0645 - mse: 0.0086\n",
      "Epoch 00033: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0086 - mae: 0.0647 - mse: 0.0086 - val_loss: 0.0139 - val_mae: 0.0804 - val_mse: 0.0139\n",
      "Elapsed time during model training:  48.9982008934021\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0531 - mae: 0.1572 - mse: 0.0531\n",
      "Epoch 00001: val_loss improved from inf to 0.02309, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0523,  mae:0.1560,  mse:0.0523,  val_loss:0.0231,  val_mae:0.1146,  val_mse:0.0231,  \n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0523 - mae: 0.1560 - mse: 0.0523 - val_loss: 0.0231 - val_mae: 0.1146 - val_mse: 0.0231\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0214 - mae: 0.1065 - mse: 0.0214\n",
      "Epoch 00002: val_loss improved from 0.02309 to 0.01942, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0214 - mae: 0.1065 - mse: 0.0214 - val_loss: 0.0194 - val_mae: 0.1071 - val_mse: 0.0194\n",
      "Epoch 3/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1029 - mse: 0.0203\n",
      "Epoch 00003: val_loss did not improve from 0.01942\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0202 - mae: 0.1029 - mse: 0.0202 - val_loss: 0.0200 - val_mae: 0.1095 - val_mse: 0.0200\n",
      "Epoch 4/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.0999 - mse: 0.0191\n",
      "Epoch 00004: val_loss improved from 0.01942 to 0.01795, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0190 - mae: 0.0996 - mse: 0.0190 - val_loss: 0.0179 - val_mae: 0.0975 - val_mse: 0.0179\n",
      "Epoch 5/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0185 - mae: 0.0971 - mse: 0.0185\n",
      "Epoch 00005: val_loss did not improve from 0.01795\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0184 - mae: 0.0969 - mse: 0.0184 - val_loss: 0.0189 - val_mae: 0.0964 - val_mse: 0.0189\n",
      "Epoch 6/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0169 - mae: 0.0921 - mse: 0.0169\n",
      "Epoch 00006: val_loss improved from 0.01795 to 0.01605, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0168 - mae: 0.0918 - mse: 0.0168 - val_loss: 0.0161 - val_mae: 0.0880 - val_mse: 0.0161\n",
      "Epoch 7/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0921 - mse: 0.0166\n",
      "Epoch 00007: val_loss did not improve from 0.01605\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0166 - mae: 0.0921 - mse: 0.0166 - val_loss: 0.0172 - val_mae: 0.0925 - val_mse: 0.0172\n",
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0894 - mse: 0.0157\n",
      "Epoch 00008: val_loss did not improve from 0.01605\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0157 - mae: 0.0895 - mse: 0.0157 - val_loss: 0.0193 - val_mae: 0.1024 - val_mse: 0.0193\n",
      "Epoch 9/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0879 - mse: 0.0154\n",
      "Epoch 00009: val_loss improved from 0.01605 to 0.01531, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0154 - mae: 0.0879 - mse: 0.0154 - val_loss: 0.0153 - val_mae: 0.0881 - val_mse: 0.0153\n",
      "Epoch 10/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0879 - mse: 0.0151\n",
      "Epoch 00010: val_loss did not improve from 0.01531\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0151 - mae: 0.0879 - mse: 0.0151 - val_loss: 0.0193 - val_mae: 0.1040 - val_mse: 0.0193\n",
      "Epoch 11/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0857 - mse: 0.0146\n",
      "Epoch 00011: val_loss improved from 0.01531 to 0.01514, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0145 - mae: 0.0855 - mse: 0.0145 - val_loss: 0.0151 - val_mae: 0.0838 - val_mse: 0.0151\n",
      "Epoch 12/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0837 - mse: 0.0141\n",
      "Epoch 00012: val_loss did not improve from 0.01514\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0140 - mae: 0.0837 - mse: 0.0140 - val_loss: 0.0191 - val_mae: 0.1000 - val_mse: 0.0191\n",
      "Epoch 13/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0142 - mae: 0.0844 - mse: 0.0142\n",
      "Epoch 00013: val_loss did not improve from 0.01514\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0142 - mae: 0.0846 - mse: 0.0142 - val_loss: 0.0174 - val_mae: 0.0980 - val_mse: 0.0174\n",
      "Epoch 14/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0831 - mse: 0.0138\n",
      "Epoch 00014: val_loss did not improve from 0.01514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0138 - mae: 0.0830 - mse: 0.0138 - val_loss: 0.0156 - val_mae: 0.0878 - val_mse: 0.0156\n",
      "Epoch 15/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0795 - mse: 0.0127\n",
      "Epoch 00015: val_loss improved from 0.01514 to 0.01395, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0127 - mae: 0.0795 - mse: 0.0127 - val_loss: 0.0139 - val_mae: 0.0796 - val_mse: 0.0139\n",
      "Epoch 16/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0786 - mse: 0.0125\n",
      "Epoch 00016: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0125 - mae: 0.0786 - mse: 0.0125 - val_loss: 0.0166 - val_mae: 0.0919 - val_mse: 0.0166\n",
      "Epoch 17/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0788 - mse: 0.0125\n",
      "Epoch 00017: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0125 - mae: 0.0788 - mse: 0.0125 - val_loss: 0.0165 - val_mae: 0.0928 - val_mse: 0.0165\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0767 - mse: 0.0120\n",
      "Epoch 00018: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0119 - mae: 0.0764 - mse: 0.0119 - val_loss: 0.0144 - val_mae: 0.0813 - val_mse: 0.0144\n",
      "Epoch 19/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0749 - mse: 0.0114\n",
      "Epoch 00019: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0115 - mae: 0.0752 - mse: 0.0115 - val_loss: 0.0178 - val_mae: 0.1005 - val_mse: 0.0178\n",
      "Epoch 20/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0759 - mse: 0.0116\n",
      "Epoch 00020: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0116 - mae: 0.0760 - mse: 0.0116 - val_loss: 0.0157 - val_mae: 0.0883 - val_mse: 0.0157\n",
      "Epoch 21/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0765 - mse: 0.0117\n",
      "Epoch 00021: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0117 - mae: 0.0765 - mse: 0.0117 - val_loss: 0.0149 - val_mae: 0.0860 - val_mse: 0.0149\n",
      "Epoch 22/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00022: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0110 - mae: 0.0738 - mse: 0.0110 - val_loss: 0.0145 - val_mae: 0.0877 - val_mse: 0.0145\n",
      "Epoch 23/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0702 - mse: 0.0099\n",
      "Epoch 00023: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0104 - mae: 0.0711 - mse: 0.0104 - val_loss: 0.0156 - val_mae: 0.0901 - val_mse: 0.0156\n",
      "Epoch 24/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0708 - mse: 0.0102\n",
      "Epoch 00024: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0102 - mae: 0.0709 - mse: 0.0102 - val_loss: 0.0152 - val_mae: 0.0908 - val_mse: 0.0152\n",
      "Epoch 25/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0707 - mse: 0.0101\n",
      "Epoch 00025: val_loss improved from 0.01395 to 0.01391, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0101 - mae: 0.0706 - mse: 0.0101 - val_loss: 0.0139 - val_mae: 0.0800 - val_mse: 0.0139\n",
      "Epoch 26/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0698 - mse: 0.0100\n",
      "Epoch 00026: val_loss did not improve from 0.01391\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0100 - mae: 0.0701 - mse: 0.0100 - val_loss: 0.0154 - val_mae: 0.0882 - val_mse: 0.0154\n",
      "Epoch 27/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0702 - mse: 0.0100\n",
      "Epoch 00027: val_loss did not improve from 0.01391\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0099 - mae: 0.0701 - mse: 0.0099 - val_loss: 0.0140 - val_mae: 0.0794 - val_mse: 0.0140\n",
      "Epoch 28/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0673 - mse: 0.0094\n",
      "Epoch 00028: val_loss did not improve from 0.01391\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0094 - mae: 0.0673 - mse: 0.0094 - val_loss: 0.0152 - val_mae: 0.0844 - val_mse: 0.0152\n",
      "Epoch 29/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0687 - mse: 0.0095\n",
      "Epoch 00029: val_loss improved from 0.01391 to 0.01368, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0095 - mae: 0.0688 - mse: 0.0095 - val_loss: 0.0137 - val_mae: 0.0784 - val_mse: 0.0137\n",
      "Epoch 30/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00030: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0091 - mae: 0.0675 - mse: 0.0091 - val_loss: 0.0137 - val_mae: 0.0836 - val_mse: 0.0137\n",
      "Epoch 31/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0667 - mse: 0.0091\n",
      "Epoch 00031: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0091 - mae: 0.0669 - mse: 0.0091 - val_loss: 0.0140 - val_mae: 0.0837 - val_mse: 0.0140\n",
      "Epoch 32/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0667 - mse: 0.0091\n",
      "Epoch 00032: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0091 - mae: 0.0666 - mse: 0.0091 - val_loss: 0.0150 - val_mae: 0.0848 - val_mse: 0.0150\n",
      "Epoch 33/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0651 - mse: 0.0087\n",
      "Epoch 00033: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0088 - mae: 0.0651 - mse: 0.0088 - val_loss: 0.0146 - val_mae: 0.0808 - val_mse: 0.0146\n",
      "Epoch 34/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0640 - mse: 0.0082\n",
      "Epoch 00034: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0085 - mae: 0.0642 - mse: 0.0085 - val_loss: 0.0169 - val_mae: 0.0979 - val_mse: 0.0169\n",
      "Epoch 35/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0655 - mse: 0.0087\n",
      "Epoch 00035: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0087 - mae: 0.0656 - mse: 0.0087 - val_loss: 0.0144 - val_mae: 0.0851 - val_mse: 0.0144\n",
      "Epoch 36/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0637 - mse: 0.0082\n",
      "Epoch 00036: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0142 - val_mae: 0.0804 - val_mse: 0.0142\n",
      "Epoch 37/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0609 - mse: 0.0077\n",
      "Epoch 00037: val_loss did not improve from 0.01368\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0077 - mae: 0.0609 - mse: 0.0077 - val_loss: 0.0142 - val_mae: 0.0813 - val_mse: 0.0142\n",
      "Epoch 38/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0619 - mse: 0.0079\n",
      "Epoch 00038: val_loss improved from 0.01368 to 0.01302, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0079 - mae: 0.0619 - mse: 0.0079 - val_loss: 0.0130 - val_mae: 0.0769 - val_mse: 0.0130\n",
      "Epoch 39/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0622 - mse: 0.0079\n",
      "Epoch 00039: val_loss did not improve from 0.01302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0078 - mae: 0.0621 - mse: 0.0078 - val_loss: 0.0138 - val_mae: 0.0798 - val_mse: 0.0138\n",
      "Epoch 40/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0609 - mse: 0.0075\n",
      "Epoch 00040: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0075 - mae: 0.0609 - mse: 0.0075 - val_loss: 0.0136 - val_mae: 0.0781 - val_mse: 0.0136\n",
      "Epoch 41/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0612 - mse: 0.0075\n",
      "Epoch 00041: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0075 - mae: 0.0612 - mse: 0.0075 - val_loss: 0.0130 - val_mae: 0.0763 - val_mse: 0.0130\n",
      "Epoch 42/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00042: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0073 - mae: 0.0602 - mse: 0.0073 - val_loss: 0.0141 - val_mae: 0.0800 - val_mse: 0.0141\n",
      "Epoch 43/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0589 - mse: 0.0072\n",
      "Epoch 00043: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0072 - mae: 0.0590 - mse: 0.0072 - val_loss: 0.0136 - val_mae: 0.0767 - val_mse: 0.0136\n",
      "Epoch 44/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0599 - mse: 0.0073\n",
      "Epoch 00044: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0074 - mae: 0.0601 - mse: 0.0074 - val_loss: 0.0166 - val_mae: 0.0903 - val_mse: 0.0166\n",
      "Epoch 45/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0590 - mse: 0.0071\n",
      "Epoch 00045: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0071 - mae: 0.0589 - mse: 0.0071 - val_loss: 0.0143 - val_mae: 0.0818 - val_mse: 0.0143\n",
      "Epoch 46/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0576 - mse: 0.0068\n",
      "Epoch 00046: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0068 - mae: 0.0577 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0795 - val_mse: 0.0138\n",
      "Epoch 47/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0571 - mse: 0.0066\n",
      "Epoch 00047: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0066 - mae: 0.0573 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0807 - val_mse: 0.0133\n",
      "Epoch 48/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0577 - mse: 0.0067\n",
      "Epoch 00048: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0067 - mae: 0.0575 - mse: 0.0067 - val_loss: 0.0142 - val_mae: 0.0771 - val_mse: 0.0142\n",
      "Epoch 49/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0573 - mse: 0.0066\n",
      "Epoch 00049: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0066 - mae: 0.0573 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0752 - val_mse: 0.0133\n",
      "Epoch 50/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0567 - mse: 0.0065\n",
      "Epoch 00050: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0065 - mae: 0.0568 - mse: 0.0065 - val_loss: 0.0137 - val_mae: 0.0807 - val_mse: 0.0137\n",
      "Epoch 51/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0560 - mse: 0.0063\n",
      "Epoch 00051: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0063 - mae: 0.0560 - mse: 0.0063 - val_loss: 0.0135 - val_mae: 0.0777 - val_mse: 0.0135\n",
      "Elapsed time during model training:  70.34889674186707\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0497 - mae: 0.1524 - mse: 0.0497\n",
      "Epoch 00001: val_loss improved from inf to 0.02175, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0488,  mae:0.1512,  mse:0.0488,  val_loss:0.0217,  val_mae:0.1108,  val_mse:0.0217,  \n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0488 - mae: 0.1512 - mse: 0.0488 - val_loss: 0.0217 - val_mae: 0.1108 - val_mse: 0.0217\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0222 - mae: 0.1079 - mse: 0.0222\n",
      "Epoch 00002: val_loss did not improve from 0.02175\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0224 - mae: 0.1086 - mse: 0.0224 - val_loss: 0.0654 - val_mae: 0.2088 - val_mse: 0.0654\n",
      "Epoch 3/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0199 - mae: 0.1014 - mse: 0.0199\n",
      "Epoch 00003: val_loss improved from 0.02175 to 0.01937, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0199 - mae: 0.1014 - mse: 0.0199 - val_loss: 0.0194 - val_mae: 0.1011 - val_mse: 0.0194\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0195 - mae: 0.1006 - mse: 0.0195\n",
      "Epoch 00004: val_loss improved from 0.01937 to 0.01551, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0195 - mae: 0.1007 - mse: 0.0195 - val_loss: 0.0155 - val_mae: 0.0867 - val_mse: 0.0155\n",
      "Epoch 5/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0942 - mse: 0.0172\n",
      "Epoch 00005: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0172 - mae: 0.0942 - mse: 0.0172 - val_loss: 0.0178 - val_mae: 0.0997 - val_mse: 0.0178\n",
      "Epoch 6/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0158 - mae: 0.0888 - mse: 0.0158\n",
      "Epoch 00006: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0159 - mae: 0.0892 - mse: 0.0159 - val_loss: 0.0183 - val_mae: 0.0985 - val_mse: 0.0183\n",
      "Epoch 7/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0932 - mse: 0.0168\n",
      "Epoch 00007: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0169 - mae: 0.0933 - mse: 0.0169 - val_loss: 0.0174 - val_mae: 0.0921 - val_mse: 0.0174\n",
      "Epoch 8/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0914 - mse: 0.0163\n",
      "Epoch 00008: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0163 - mae: 0.0916 - mse: 0.0163 - val_loss: 0.0165 - val_mae: 0.0892 - val_mse: 0.0165\n",
      "Epoch 9/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0869 - mse: 0.0150\n",
      "Epoch 00009: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0150 - mae: 0.0869 - mse: 0.0150 - val_loss: 0.0167 - val_mae: 0.0923 - val_mse: 0.0167\n",
      "Epoch 10/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0856 - mse: 0.0145\n",
      "Epoch 00010: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0146 - mae: 0.0856 - mse: 0.0146 - val_loss: 0.0178 - val_mae: 0.0930 - val_mse: 0.0178\n",
      "Epoch 11/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0840 - mse: 0.0143\n",
      "Epoch 00011: val_loss improved from 0.01551 to 0.01549, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0143 - mae: 0.0841 - mse: 0.0143 - val_loss: 0.0155 - val_mae: 0.0885 - val_mse: 0.0155\n",
      "Epoch 12/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0836 - mse: 0.0138\n",
      "Epoch 00012: val_loss did not improve from 0.01549\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0138 - mae: 0.0835 - mse: 0.0138 - val_loss: 0.0157 - val_mae: 0.0865 - val_mse: 0.0157\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0828 - mse: 0.0136\n",
      "Epoch 00013: val_loss improved from 0.01549 to 0.01540, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0136 - mae: 0.0828 - mse: 0.0136 - val_loss: 0.0154 - val_mae: 0.0876 - val_mse: 0.0154\n",
      "Epoch 14/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0819 - mse: 0.0134\n",
      "Epoch 00014: val_loss improved from 0.01540 to 0.01445, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0134 - mae: 0.0818 - mse: 0.0134 - val_loss: 0.0144 - val_mae: 0.0814 - val_mse: 0.0144\n",
      "Epoch 15/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0794 - mse: 0.0127\n",
      "Epoch 00015: val_loss did not improve from 0.01445\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0128 - mae: 0.0795 - mse: 0.0128 - val_loss: 0.0157 - val_mae: 0.0894 - val_mse: 0.0157\n",
      "Epoch 16/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0122 - mae: 0.0779 - mse: 0.0122\n",
      "Epoch 00016: val_loss improved from 0.01445 to 0.01397, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0122 - mae: 0.0779 - mse: 0.0122 - val_loss: 0.0140 - val_mae: 0.0810 - val_mse: 0.0140\n",
      "Epoch 17/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0753 - mse: 0.0116\n",
      "Epoch 00017: val_loss did not improve from 0.01397\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0116 - mae: 0.0754 - mse: 0.0116 - val_loss: 0.0157 - val_mae: 0.0882 - val_mse: 0.0157\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0752 - mse: 0.0115\n",
      "Epoch 00018: val_loss did not improve from 0.01397\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0115 - mae: 0.0754 - mse: 0.0115 - val_loss: 0.0153 - val_mae: 0.0870 - val_mse: 0.0153\n",
      "Epoch 19/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0765 - mse: 0.0117\n",
      "Epoch 00019: val_loss did not improve from 0.01397\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0117 - mae: 0.0765 - mse: 0.0117 - val_loss: 0.0150 - val_mae: 0.0858 - val_mse: 0.0150\n",
      "Epoch 20/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0747 - mse: 0.0113\n",
      "Epoch 00020: val_loss did not improve from 0.01397\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0112 - mae: 0.0745 - mse: 0.0112 - val_loss: 0.0157 - val_mae: 0.0891 - val_mse: 0.0157\n",
      "Epoch 21/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0742 - mse: 0.0112\n",
      "Epoch 00021: val_loss did not improve from 0.01397\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0111 - mae: 0.0741 - mse: 0.0111 - val_loss: 0.0143 - val_mae: 0.0816 - val_mse: 0.0143\n",
      "Epoch 22/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0734 - mse: 0.0109\n",
      "Epoch 00022: val_loss improved from 0.01397 to 0.01389, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0139 - val_mae: 0.0794 - val_mse: 0.0139\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0102 - mae: 0.0708 - mse: 0.0102\n",
      "Epoch 00023: val_loss did not improve from 0.01389\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0102 - mae: 0.0707 - mse: 0.0102 - val_loss: 0.0141 - val_mae: 0.0791 - val_mse: 0.0141\n",
      "Epoch 24/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0718 - mse: 0.0103\n",
      "Epoch 00024: val_loss did not improve from 0.01389\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0103 - mae: 0.0717 - mse: 0.0103 - val_loss: 0.0148 - val_mae: 0.0816 - val_mse: 0.0148\n",
      "Epoch 25/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0686 - mse: 0.0096\n",
      "Epoch 00025: val_loss did not improve from 0.01389\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0096 - mae: 0.0685 - mse: 0.0096 - val_loss: 0.0150 - val_mae: 0.0814 - val_mse: 0.0150\n",
      "Epoch 26/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0699 - mse: 0.0100\n",
      "Epoch 00026: val_loss did not improve from 0.01389\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0100 - mae: 0.0699 - mse: 0.0100 - val_loss: 0.0147 - val_mae: 0.0832 - val_mse: 0.0147\n",
      "Epoch 27/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0678 - mse: 0.0094\n",
      "Epoch 00027: val_loss improved from 0.01389 to 0.01360, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0094 - mae: 0.0677 - mse: 0.0094 - val_loss: 0.0136 - val_mae: 0.0775 - val_mse: 0.0136\n",
      "Epoch 28/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0676 - mse: 0.0093\n",
      "Epoch 00028: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0093 - mae: 0.0677 - mse: 0.0093 - val_loss: 0.0156 - val_mae: 0.0885 - val_mse: 0.0156\n",
      "Epoch 29/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0666 - mse: 0.0091\n",
      "Epoch 00029: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0090 - mae: 0.0663 - mse: 0.0090 - val_loss: 0.0180 - val_mae: 0.0928 - val_mse: 0.0180\n",
      "Epoch 30/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0665 - mse: 0.0090\n",
      "Epoch 00030: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0664 - mse: 0.0089 - val_loss: 0.0145 - val_mae: 0.0814 - val_mse: 0.0145\n",
      "Epoch 31/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0651 - mse: 0.0087\n",
      "Epoch 00031: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0087 - mae: 0.0652 - mse: 0.0087 - val_loss: 0.0156 - val_mae: 0.0879 - val_mse: 0.0156\n",
      "Epoch 32/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0636 - mse: 0.0083\n",
      "Epoch 00032: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0084 - mae: 0.0637 - mse: 0.0084 - val_loss: 0.0149 - val_mae: 0.0864 - val_mse: 0.0149\n",
      "Epoch 33/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0651 - mse: 0.0083\n",
      "Epoch 00033: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0086 - mae: 0.0652 - mse: 0.0086 - val_loss: 0.0149 - val_mae: 0.0893 - val_mse: 0.0149\n",
      "Epoch 34/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0645 - mse: 0.0082\n",
      "Epoch 00034: val_loss improved from 0.01360 to 0.01345, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0081 - mae: 0.0645 - mse: 0.0081 - val_loss: 0.0135 - val_mae: 0.0770 - val_mse: 0.0135\n",
      "Epoch 35/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0624 - mse: 0.0079\n",
      "Epoch 00035: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0079 - mae: 0.0625 - mse: 0.0079 - val_loss: 0.0153 - val_mae: 0.0805 - val_mse: 0.0153\n",
      "Epoch 36/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0637 - mse: 0.0081\n",
      "Epoch 00036: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0081 - mae: 0.0637 - mse: 0.0081 - val_loss: 0.0135 - val_mae: 0.0790 - val_mse: 0.0135\n",
      "Epoch 37/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0603 - mse: 0.0072\n",
      "Epoch 00037: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0074 - mae: 0.0604 - mse: 0.0074 - val_loss: 0.0158 - val_mae: 0.0894 - val_mse: 0.0158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0607 - mse: 0.0074\n",
      "Epoch 00038: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0074 - mae: 0.0606 - mse: 0.0074 - val_loss: 0.0136 - val_mae: 0.0760 - val_mse: 0.0136\n",
      "Epoch 39/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0605 - mse: 0.0075\n",
      "Epoch 00039: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0075 - mae: 0.0605 - mse: 0.0075 - val_loss: 0.0143 - val_mae: 0.0800 - val_mse: 0.0143\n",
      "Epoch 40/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0602 - mse: 0.0074\n",
      "Epoch 00040: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0074 - mae: 0.0602 - mse: 0.0074 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 41/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00041: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0072 - mae: 0.0600 - mse: 0.0072 - val_loss: 0.0140 - val_mae: 0.0777 - val_mse: 0.0140\n",
      "Epoch 42/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0580 - mse: 0.0067\n",
      "Epoch 00042: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0068 - mae: 0.0583 - mse: 0.0068 - val_loss: 0.0170 - val_mae: 0.0915 - val_mse: 0.0170\n",
      "Epoch 43/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0570 - mse: 0.0065\n",
      "Epoch 00043: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0065 - mae: 0.0571 - mse: 0.0065 - val_loss: 0.0139 - val_mae: 0.0778 - val_mse: 0.0139\n",
      "Epoch 44/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0565 - mse: 0.0063\n",
      "Epoch 00044: val_loss did not improve from 0.01345\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0063 - mae: 0.0565 - mse: 0.0063 - val_loss: 0.0144 - val_mae: 0.0785 - val_mse: 0.0144\n",
      "Epoch 45/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0066 - mae: 0.0572 - mse: 0.0066\n",
      "Epoch 00045: val_loss improved from 0.01345 to 0.01339, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0066 - mae: 0.0570 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0769 - val_mse: 0.0134\n",
      "Epoch 46/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0568 - mse: 0.0063\n",
      "Epoch 00046: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0065 - mae: 0.0569 - mse: 0.0065 - val_loss: 0.0155 - val_mae: 0.0924 - val_mse: 0.0155\n",
      "Epoch 47/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0569 - mse: 0.0065\n",
      "Epoch 00047: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0065 - mae: 0.0569 - mse: 0.0065 - val_loss: 0.0151 - val_mae: 0.0886 - val_mse: 0.0151\n",
      "Epoch 48/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0547 - mse: 0.0060\n",
      "Epoch 00048: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0060 - mae: 0.0548 - mse: 0.0060 - val_loss: 0.0142 - val_mae: 0.0787 - val_mse: 0.0142\n",
      "Epoch 49/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0057 - mae: 0.0527 - mse: 0.0057\n",
      "Epoch 00049: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0058 - mae: 0.0529 - mse: 0.0058 - val_loss: 0.0146 - val_mae: 0.0795 - val_mse: 0.0146\n",
      "Epoch 50/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0546 - mse: 0.0058\n",
      "Epoch 00050: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0058 - mae: 0.0545 - mse: 0.0058 - val_loss: 0.0142 - val_mae: 0.0801 - val_mse: 0.0142\n",
      "Epoch 51/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0542 - mse: 0.0058\n",
      "Epoch 00051: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0058 - mae: 0.0541 - mse: 0.0058 - val_loss: 0.0143 - val_mae: 0.0799 - val_mse: 0.0143\n",
      "Epoch 52/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0539 - mse: 0.0059\n",
      "Epoch 00052: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0059 - mae: 0.0539 - mse: 0.0059 - val_loss: 0.0145 - val_mae: 0.0778 - val_mse: 0.0145\n",
      "Epoch 53/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0527 - mse: 0.0057\n",
      "Epoch 00053: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0057 - mae: 0.0526 - mse: 0.0057 - val_loss: 0.0144 - val_mae: 0.0778 - val_mse: 0.0144\n",
      "Epoch 54/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0057 - mae: 0.0535 - mse: 0.0057\n",
      "Epoch 00054: val_loss did not improve from 0.01339\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0057 - mae: 0.0536 - mse: 0.0057 - val_loss: 0.0150 - val_mae: 0.0848 - val_mse: 0.0150\n",
      "Epoch 55/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0055 - mae: 0.0513 - mse: 0.0055\n",
      "Epoch 00055: val_loss improved from 0.01339 to 0.01338, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0054 - mae: 0.0512 - mse: 0.0054 - val_loss: 0.0134 - val_mae: 0.0751 - val_mse: 0.0134\n",
      "Epoch 56/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0519 - mse: 0.0052\n",
      "Epoch 00056: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0052 - mae: 0.0519 - mse: 0.0052 - val_loss: 0.0154 - val_mae: 0.0834 - val_mse: 0.0154\n",
      "Epoch 57/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0049 - mae: 0.0498 - mse: 0.0049\n",
      "Epoch 00057: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0049 - mae: 0.0500 - mse: 0.0049 - val_loss: 0.0162 - val_mae: 0.0898 - val_mse: 0.0162\n",
      "Epoch 58/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0055 - mae: 0.0519 - mse: 0.0055\n",
      "Epoch 00058: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0055 - mae: 0.0519 - mse: 0.0055 - val_loss: 0.0146 - val_mae: 0.0810 - val_mse: 0.0146\n",
      "Epoch 59/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0048 - mae: 0.0492 - mse: 0.0048\n",
      "Epoch 00059: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0050 - mae: 0.0496 - mse: 0.0050 - val_loss: 0.0158 - val_mae: 0.0854 - val_mse: 0.0158\n",
      "Epoch 60/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0518 - mse: 0.0054\n",
      "Epoch 00060: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0053 - mae: 0.0517 - mse: 0.0053 - val_loss: 0.0150 - val_mae: 0.0803 - val_mse: 0.0150\n",
      "Epoch 61/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0048 - mae: 0.0497 - mse: 0.0048\n",
      "Epoch 00061: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0048 - mae: 0.0497 - mse: 0.0048 - val_loss: 0.0141 - val_mae: 0.0779 - val_mse: 0.0141\n",
      "Epoch 62/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0048 - mae: 0.0492 - mse: 0.0048\n",
      "Epoch 00062: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0048 - mae: 0.0491 - mse: 0.0048 - val_loss: 0.0137 - val_mae: 0.0761 - val_mse: 0.0137\n",
      "Epoch 63/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0043 - mae: 0.0461 - mse: 0.0043\n",
      "Epoch 00063: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0043 - mae: 0.0462 - mse: 0.0043 - val_loss: 0.0145 - val_mae: 0.0785 - val_mse: 0.0145\n",
      "Epoch 64/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0048 - mae: 0.0488 - mse: 0.0048\n",
      "Epoch 00064: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0048 - mae: 0.0488 - mse: 0.0048 - val_loss: 0.0153 - val_mae: 0.0843 - val_mse: 0.0153\n",
      "Epoch 65/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0052 - mae: 0.0500 - mse: 0.0052\n",
      "Epoch 00065: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0051 - mae: 0.0499 - mse: 0.0051 - val_loss: 0.0148 - val_mae: 0.0781 - val_mse: 0.0148\n",
      "Epoch 66/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0045 - mae: 0.0474 - mse: 0.0045\n",
      "Epoch 00066: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0045 - mae: 0.0473 - mse: 0.0045 - val_loss: 0.0149 - val_mae: 0.0822 - val_mse: 0.0149\n",
      "Epoch 67/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0044 - mae: 0.0470 - mse: 0.0044\n",
      "Epoch 00067: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0044 - mae: 0.0470 - mse: 0.0044 - val_loss: 0.0144 - val_mae: 0.0781 - val_mse: 0.0144\n",
      "Elapsed time during model training:  94.11554789543152\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0470 - mae: 0.1508 - mse: 0.0470\n",
      "Epoch 00001: val_loss improved from inf to 0.02572, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0465,  mae:0.1499,  mse:0.0465,  val_loss:0.0257,  val_mae:0.1234,  val_mse:0.0257,  \n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0465 - mae: 0.1499 - mse: 0.0465 - val_loss: 0.0257 - val_mae: 0.1234 - val_mse: 0.0257\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0234 - mae: 0.1126 - mse: 0.0234\n",
      "Epoch 00002: val_loss improved from 0.02572 to 0.02533, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0234 - mae: 0.1128 - mse: 0.0234 - val_loss: 0.0253 - val_mae: 0.1218 - val_mse: 0.0253\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0207 - mae: 0.1048 - mse: 0.0207\n",
      "Epoch 00003: val_loss improved from 0.02533 to 0.01868, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0207 - mae: 0.1047 - mse: 0.0207 - val_loss: 0.0187 - val_mae: 0.1021 - val_mse: 0.0187\n",
      "Epoch 4/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0192 - mae: 0.1007 - mse: 0.0192\n",
      "Epoch 00004: val_loss improved from 0.01868 to 0.01838, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0192 - mae: 0.1007 - mse: 0.0192 - val_loss: 0.0184 - val_mae: 0.0981 - val_mse: 0.0184\n",
      "Epoch 5/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.0960 - mse: 0.0180\n",
      "Epoch 00005: val_loss did not improve from 0.01838\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0181 - mae: 0.0962 - mse: 0.0181 - val_loss: 0.0187 - val_mae: 0.1014 - val_mse: 0.0187\n",
      "Epoch 6/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0995 - mse: 0.0187\n",
      "Epoch 00006: val_loss did not improve from 0.01838\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0187 - mae: 0.0994 - mse: 0.0187 - val_loss: 0.0257 - val_mae: 0.1193 - val_mse: 0.0257\n",
      "Epoch 7/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0956 - mse: 0.0178\n",
      "Epoch 00007: val_loss improved from 0.01838 to 0.01560, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0177 - mae: 0.0955 - mse: 0.0177 - val_loss: 0.0156 - val_mae: 0.0871 - val_mse: 0.0156\n",
      "Epoch 8/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0923 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0165 - mae: 0.0923 - mse: 0.0165 - val_loss: 0.0180 - val_mae: 0.0910 - val_mse: 0.0180\n",
      "Epoch 9/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0924 - mse: 0.0163\n",
      "Epoch 00009: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0163 - mae: 0.0923 - mse: 0.0163 - val_loss: 0.0182 - val_mae: 0.0944 - val_mse: 0.0182\n",
      "Epoch 10/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0869 - mse: 0.0151\n",
      "Epoch 00010: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0151 - mae: 0.0869 - mse: 0.0151 - val_loss: 0.0163 - val_mae: 0.0894 - val_mse: 0.0163\n",
      "Epoch 11/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0879 - mse: 0.0153\n",
      "Epoch 00011: val_loss improved from 0.01560 to 0.01431, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0153 - mae: 0.0880 - mse: 0.0153 - val_loss: 0.0143 - val_mae: 0.0814 - val_mse: 0.0143\n",
      "Epoch 12/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0859 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0145 - mae: 0.0859 - mse: 0.0145 - val_loss: 0.0162 - val_mae: 0.0884 - val_mse: 0.0162\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0871 - mse: 0.0148\n",
      "Epoch 00013: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0148 - mae: 0.0871 - mse: 0.0148 - val_loss: 0.0166 - val_mae: 0.0879 - val_mse: 0.0166\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0136 - mae: 0.0826 - mse: 0.0136\n",
      "Epoch 00014: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0138 - mae: 0.0832 - mse: 0.0138 - val_loss: 0.0158 - val_mae: 0.0857 - val_mse: 0.0158\n",
      "Epoch 15/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0813 - mse: 0.0133\n",
      "Epoch 00015: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0133 - mae: 0.0812 - mse: 0.0133 - val_loss: 0.0167 - val_mae: 0.0879 - val_mse: 0.0167\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0834 - mse: 0.0138\n",
      "Epoch 00016: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0137 - mae: 0.0832 - mse: 0.0137 - val_loss: 0.0144 - val_mae: 0.0825 - val_mse: 0.0144\n",
      "Epoch 17/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0130 - mae: 0.0801 - mse: 0.0130\n",
      "Epoch 00017: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0130 - mae: 0.0802 - mse: 0.0130 - val_loss: 0.0153 - val_mae: 0.0910 - val_mse: 0.0153\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0786 - mse: 0.0124\n",
      "Epoch 00018: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0124 - mae: 0.0786 - mse: 0.0124 - val_loss: 0.0154 - val_mae: 0.0865 - val_mse: 0.0154\n",
      "Epoch 19/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0769 - mse: 0.0120\n",
      "Epoch 00019: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0121 - mae: 0.0770 - mse: 0.0121 - val_loss: 0.0178 - val_mae: 0.0884 - val_mse: 0.0178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0793 - mse: 0.0123\n",
      "Epoch 00020: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0123 - mae: 0.0793 - mse: 0.0123 - val_loss: 0.0146 - val_mae: 0.0836 - val_mse: 0.0146\n",
      "Epoch 21/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0121 - mae: 0.0782 - mse: 0.0121\n",
      "Epoch 00021: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0120 - mae: 0.0780 - mse: 0.0120 - val_loss: 0.0145 - val_mae: 0.0867 - val_mse: 0.0145\n",
      "Epoch 22/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0771 - mse: 0.0118\n",
      "Epoch 00022: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0119 - mae: 0.0771 - mse: 0.0119 - val_loss: 0.0165 - val_mae: 0.0920 - val_mse: 0.0165\n",
      "Elapsed time during model training:  32.72320580482483\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0455 - mae: 0.1501 - mse: 0.0455\n",
      "Epoch 00001: val_loss improved from inf to 0.02165, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0446,  mae:0.1485,  mse:0.0446,  val_loss:0.0217,  val_mae:0.1091,  val_mse:0.0217,  \n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0446 - mae: 0.1485 - mse: 0.0446 - val_loss: 0.0217 - val_mae: 0.1091 - val_mse: 0.0217\n",
      "Epoch 2/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0227 - mae: 0.1104 - mse: 0.0227\n",
      "Epoch 00002: val_loss did not improve from 0.02165\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0226 - mae: 0.1103 - mse: 0.0226 - val_loss: 0.0245 - val_mae: 0.1221 - val_mse: 0.0245\n",
      "Epoch 3/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1078 - mse: 0.0216\n",
      "Epoch 00003: val_loss did not improve from 0.02165\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0215 - mae: 0.1076 - mse: 0.0215 - val_loss: 0.0227 - val_mae: 0.1088 - val_mse: 0.0227\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1032 - mse: 0.0201\n",
      "Epoch 00004: val_loss improved from 0.02165 to 0.01656, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0201 - mae: 0.1030 - mse: 0.0201 - val_loss: 0.0166 - val_mae: 0.0914 - val_mse: 0.0166\n",
      "Epoch 5/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0196 - mae: 0.1018 - mse: 0.0196\n",
      "Epoch 00005: val_loss did not improve from 0.01656\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0196 - mae: 0.1018 - mse: 0.0196 - val_loss: 0.0172 - val_mae: 0.0938 - val_mse: 0.0172\n",
      "Epoch 6/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0178 - mae: 0.0957 - mse: 0.0178\n",
      "Epoch 00006: val_loss did not improve from 0.01656\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0181 - mae: 0.0967 - mse: 0.0181 - val_loss: 0.0295 - val_mae: 0.1419 - val_mse: 0.0295\n",
      "Epoch 7/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0986 - mse: 0.0183\n",
      "Epoch 00007: val_loss did not improve from 0.01656\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0183 - mae: 0.0986 - mse: 0.0183 - val_loss: 0.0215 - val_mae: 0.1091 - val_mse: 0.0215\n",
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0162 - mae: 0.0915 - mse: 0.0162\n",
      "Epoch 00008: val_loss improved from 0.01656 to 0.01539, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0161 - mae: 0.0914 - mse: 0.0161 - val_loss: 0.0154 - val_mae: 0.0871 - val_mse: 0.0154\n",
      "Epoch 9/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0914 - mse: 0.0163\n",
      "Epoch 00009: val_loss did not improve from 0.01539\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0163 - mae: 0.0913 - mse: 0.0163 - val_loss: 0.0166 - val_mae: 0.0960 - val_mse: 0.0166\n",
      "Epoch 10/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0893 - mse: 0.0156\n",
      "Epoch 00010: val_loss did not improve from 0.01539\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0156 - mae: 0.0893 - mse: 0.0156 - val_loss: 0.0174 - val_mae: 0.0929 - val_mse: 0.0174\n",
      "Epoch 11/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0151 - mae: 0.0883 - mse: 0.0151\n",
      "Epoch 00011: val_loss improved from 0.01539 to 0.01481, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0151 - mae: 0.0883 - mse: 0.0151 - val_loss: 0.0148 - val_mae: 0.0835 - val_mse: 0.0148\n",
      "Epoch 12/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0150 - mae: 0.0874 - mse: 0.0150\n",
      "Epoch 00012: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0149 - mae: 0.0873 - mse: 0.0149 - val_loss: 0.0164 - val_mae: 0.0898 - val_mse: 0.0164\n",
      "Epoch 13/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0852 - mse: 0.0145\n",
      "Epoch 00013: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0144 - mae: 0.0850 - mse: 0.0144 - val_loss: 0.0162 - val_mae: 0.0888 - val_mse: 0.0162\n",
      "Epoch 14/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0823 - mse: 0.0136\n",
      "Epoch 00014: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0136 - mae: 0.0825 - mse: 0.0136 - val_loss: 0.0167 - val_mae: 0.0937 - val_mse: 0.0167\n",
      "Epoch 15/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0827 - mse: 0.0136\n",
      "Epoch 00015: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0136 - mae: 0.0827 - mse: 0.0136 - val_loss: 0.0160 - val_mae: 0.0875 - val_mse: 0.0160\n",
      "Epoch 16/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0801 - mse: 0.0130\n",
      "Epoch 00016: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0130 - mae: 0.0802 - mse: 0.0130 - val_loss: 0.0181 - val_mae: 0.0933 - val_mse: 0.0181\n",
      "Epoch 17/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0772 - mse: 0.0119\n",
      "Epoch 00017: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0123 - mae: 0.0775 - mse: 0.0123 - val_loss: 0.0209 - val_mae: 0.1152 - val_mse: 0.0209\n",
      "Epoch 18/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0825 - mse: 0.0135\n",
      "Epoch 00018: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0134 - mae: 0.0824 - mse: 0.0134 - val_loss: 0.0164 - val_mae: 0.0921 - val_mse: 0.0164\n",
      "Epoch 19/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0779 - mse: 0.0123\n",
      "Epoch 00019: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0123 - mae: 0.0779 - mse: 0.0123 - val_loss: 0.0171 - val_mae: 0.0932 - val_mse: 0.0171\n",
      "Elapsed time during model training:  27.722841501235962\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0466 - mae: 0.1491 - mse: 0.0466\n",
      "Epoch 00001: val_loss improved from inf to 0.03016, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0462,  mae:0.1484,  mse:0.0462,  val_loss:0.0302,  val_mae:0.1266,  val_mse:0.0302,  \n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0462 - mae: 0.1484 - mse: 0.0462 - val_loss: 0.0302 - val_mae: 0.1266 - val_mse: 0.0302\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0230 - mae: 0.1121 - mse: 0.0230\n",
      "Epoch 00002: val_loss improved from 0.03016 to 0.02053, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0230 - mae: 0.1121 - mse: 0.0230 - val_loss: 0.0205 - val_mae: 0.1037 - val_mse: 0.0205\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0207 - mae: 0.1048 - mse: 0.0207\n",
      "Epoch 00003: val_loss did not improve from 0.02053\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0207 - mae: 0.1047 - mse: 0.0207 - val_loss: 0.0233 - val_mae: 0.1178 - val_mse: 0.0233\n",
      "Epoch 4/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1039 - mse: 0.0203\n",
      "Epoch 00004: val_loss improved from 0.02053 to 0.01922, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0203 - mae: 0.1038 - mse: 0.0203 - val_loss: 0.0192 - val_mae: 0.0945 - val_mse: 0.0192\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0971 - mse: 0.0181\n",
      "Epoch 00005: val_loss did not improve from 0.01922\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0181 - mae: 0.0970 - mse: 0.0181 - val_loss: 0.0242 - val_mae: 0.1113 - val_mse: 0.0242\n",
      "Epoch 6/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0175 - mae: 0.0952 - mse: 0.0175\n",
      "Epoch 00006: val_loss did not improve from 0.01922\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0176 - mae: 0.0956 - mse: 0.0176 - val_loss: 0.0249 - val_mae: 0.1177 - val_mse: 0.0249\n",
      "Epoch 7/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0938 - mse: 0.0170\n",
      "Epoch 00007: val_loss improved from 0.01922 to 0.01543, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0170 - mae: 0.0938 - mse: 0.0170 - val_loss: 0.0154 - val_mae: 0.0848 - val_mse: 0.0154\n",
      "Epoch 8/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0931 - mse: 0.0170\n",
      "Epoch 00008: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0169 - mae: 0.0929 - mse: 0.0169 - val_loss: 0.0210 - val_mae: 0.1102 - val_mse: 0.0210\n",
      "Epoch 9/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0893 - mse: 0.0157\n",
      "Epoch 00009: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0156 - mae: 0.0890 - mse: 0.0156 - val_loss: 0.0162 - val_mae: 0.0903 - val_mse: 0.0162\n",
      "Epoch 10/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0884 - mse: 0.0152\n",
      "Epoch 00010: val_loss did not improve from 0.01543\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0152 - mae: 0.0884 - mse: 0.0152 - val_loss: 0.0186 - val_mae: 0.0976 - val_mse: 0.0186\n",
      "Elapsed time during model training:  14.798550605773926\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0486 - mae: 0.1524 - mse: 0.0486\n",
      "Epoch 00001: val_loss improved from inf to 0.02273, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0486,  mae:0.1520,  mse:0.0486,  val_loss:0.0227,  val_mae:0.1090,  val_mse:0.0227,  \n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0486 - mae: 0.1520 - mse: 0.0486 - val_loss: 0.0227 - val_mae: 0.1090 - val_mse: 0.0227\n",
      "Epoch 2/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1079 - mse: 0.0221\n",
      "Epoch 00002: val_loss improved from 0.02273 to 0.01957, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0220 - mae: 0.1075 - mse: 0.0220 - val_loss: 0.0196 - val_mae: 0.0986 - val_mse: 0.0196\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0195 - mae: 0.1001 - mse: 0.0195\n",
      "Epoch 00003: val_loss did not improve from 0.01957\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0196 - mae: 0.1003 - mse: 0.0196 - val_loss: 0.0212 - val_mae: 0.1100 - val_mse: 0.0212\n",
      "Epoch 4/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0186 - mae: 0.0983 - mse: 0.0186\n",
      "Epoch 00004: val_loss improved from 0.01957 to 0.01892, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0186 - mae: 0.0983 - mse: 0.0186 - val_loss: 0.0189 - val_mae: 0.1007 - val_mse: 0.0189\n",
      "Epoch 5/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0181 - mae: 0.0970 - mse: 0.0181\n",
      "Epoch 00005: val_loss improved from 0.01892 to 0.01780, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0180 - mae: 0.0968 - mse: 0.0180 - val_loss: 0.0178 - val_mae: 0.0948 - val_mse: 0.0178\n",
      "Epoch 6/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0176 - mae: 0.0955 - mse: 0.0176\n",
      "Epoch 00006: val_loss improved from 0.01780 to 0.01733, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0176 - mae: 0.0957 - mse: 0.0176 - val_loss: 0.0173 - val_mae: 0.0927 - val_mse: 0.0173\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0905 - mse: 0.0161\n",
      "Epoch 00007: val_loss improved from 0.01733 to 0.01672, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0162 - mae: 0.0908 - mse: 0.0162 - val_loss: 0.0167 - val_mae: 0.0905 - val_mse: 0.0167\n",
      "Epoch 8/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0891 - mse: 0.0157\n",
      "Epoch 00008: val_loss improved from 0.01672 to 0.01648, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0156 - mae: 0.0890 - mse: 0.0156 - val_loss: 0.0165 - val_mae: 0.0905 - val_mse: 0.0165\n",
      "Epoch 9/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0867 - mse: 0.0151\n",
      "Epoch 00009: val_loss did not improve from 0.01648\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0151 - mae: 0.0867 - mse: 0.0151 - val_loss: 0.0169 - val_mae: 0.0939 - val_mse: 0.0169\n",
      "Epoch 10/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0876 - mse: 0.0152\n",
      "Epoch 00010: val_loss improved from 0.01648 to 0.01593, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0151 - mae: 0.0875 - mse: 0.0151 - val_loss: 0.0159 - val_mae: 0.0873 - val_mse: 0.0159\n",
      "Epoch 11/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0854 - mse: 0.0145\n",
      "Epoch 00011: val_loss improved from 0.01593 to 0.01535, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0145 - mae: 0.0853 - mse: 0.0145 - val_loss: 0.0154 - val_mae: 0.0865 - val_mse: 0.0154\n",
      "Epoch 12/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0813 - mse: 0.0135\n",
      "Epoch 00012: val_loss did not improve from 0.01535\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0135 - mae: 0.0818 - mse: 0.0135 - val_loss: 0.0159 - val_mae: 0.0861 - val_mse: 0.0159\n",
      "Epoch 13/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0834 - mse: 0.0137\n",
      "Epoch 00013: val_loss improved from 0.01535 to 0.01527, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0137 - mae: 0.0833 - mse: 0.0137 - val_loss: 0.0153 - val_mae: 0.0857 - val_mse: 0.0153\n",
      "Epoch 14/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0836 - mse: 0.0139\n",
      "Epoch 00014: val_loss improved from 0.01527 to 0.01479, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0138 - mae: 0.0835 - mse: 0.0138 - val_loss: 0.0148 - val_mae: 0.0852 - val_mse: 0.0148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0801 - mse: 0.0130\n",
      "Epoch 00015: val_loss improved from 0.01479 to 0.01472, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0130 - mae: 0.0800 - mse: 0.0130 - val_loss: 0.0147 - val_mae: 0.0819 - val_mse: 0.0147\n",
      "Epoch 16/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0772 - mse: 0.0121\n",
      "Epoch 00016: val_loss improved from 0.01472 to 0.01442, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0121 - mae: 0.0773 - mse: 0.0121 - val_loss: 0.0144 - val_mae: 0.0803 - val_mse: 0.0144\n",
      "Epoch 17/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0786 - mse: 0.0123\n",
      "Epoch 00017: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0123 - mae: 0.0786 - mse: 0.0123 - val_loss: 0.0163 - val_mae: 0.0878 - val_mse: 0.0163\n",
      "Epoch 18/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0766 - mse: 0.0118\n",
      "Epoch 00018: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0118 - mae: 0.0766 - mse: 0.0118 - val_loss: 0.0152 - val_mae: 0.0887 - val_mse: 0.0152\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0745 - mse: 0.0113\n",
      "Epoch 00019: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0113 - mae: 0.0746 - mse: 0.0113 - val_loss: 0.0164 - val_mae: 0.0928 - val_mse: 0.0164\n",
      "Elapsed time during model training:  26.35139226913452\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0487 - mae: 0.1501 - mse: 0.0487\n",
      "Epoch 00001: val_loss improved from inf to 0.02185, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0482,  mae:0.1495,  mse:0.0482,  val_loss:0.0219,  val_mae:0.1060,  val_mse:0.0219,  \n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0482 - mae: 0.1495 - mse: 0.0482 - val_loss: 0.0219 - val_mae: 0.1060 - val_mse: 0.0219\n",
      "Epoch 2/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0218 - mae: 0.1071 - mse: 0.0218\n",
      "Epoch 00002: val_loss did not improve from 0.02185\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0219 - mae: 0.1075 - mse: 0.0219 - val_loss: 0.0232 - val_mae: 0.1173 - val_mse: 0.0232\n",
      "Epoch 3/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0200 - mae: 0.1026 - mse: 0.0200\n",
      "Epoch 00003: val_loss improved from 0.02185 to 0.02012, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0200 - mae: 0.1026 - mse: 0.0200 - val_loss: 0.0201 - val_mae: 0.0973 - val_mse: 0.0201\n",
      "Epoch 4/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.0994 - mse: 0.0191\n",
      "Epoch 00004: val_loss improved from 0.02012 to 0.01755, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0191 - mae: 0.0993 - mse: 0.0191 - val_loss: 0.0176 - val_mae: 0.0930 - val_mse: 0.0176\n",
      "Epoch 5/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0959 - mse: 0.0181\n",
      "Epoch 00005: val_loss improved from 0.01755 to 0.01645, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0181 - mae: 0.0958 - mse: 0.0181 - val_loss: 0.0164 - val_mae: 0.0900 - val_mse: 0.0164\n",
      "Epoch 6/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0931 - mse: 0.0172\n",
      "Epoch 00006: val_loss improved from 0.01645 to 0.01631, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0171 - mae: 0.0931 - mse: 0.0171 - val_loss: 0.0163 - val_mae: 0.0912 - val_mse: 0.0163\n",
      "Epoch 7/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0168 - mae: 0.0930 - mse: 0.0168\n",
      "Epoch 00007: val_loss did not improve from 0.01631\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0168 - mae: 0.0929 - mse: 0.0168 - val_loss: 0.0181 - val_mae: 0.0994 - val_mse: 0.0181\n",
      "Epoch 8/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0911 - mse: 0.0164\n",
      "Epoch 00008: val_loss did not improve from 0.01631\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0164 - mae: 0.0911 - mse: 0.0164 - val_loss: 0.0170 - val_mae: 0.0945 - val_mse: 0.0170\n",
      "Epoch 9/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0897 - mse: 0.0159\n",
      "Epoch 00009: val_loss did not improve from 0.01631\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0159 - mae: 0.0898 - mse: 0.0159 - val_loss: 0.0202 - val_mae: 0.1041 - val_mse: 0.0202\n",
      "Epoch 10/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0885 - mse: 0.0157\n",
      "Epoch 00010: val_loss improved from 0.01631 to 0.01622, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0156 - mae: 0.0884 - mse: 0.0156 - val_loss: 0.0162 - val_mae: 0.0891 - val_mse: 0.0162\n",
      "Epoch 11/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0846 - mse: 0.0145\n",
      "Epoch 00011: val_loss did not improve from 0.01622\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0146 - mae: 0.0848 - mse: 0.0146 - val_loss: 0.0192 - val_mae: 0.1021 - val_mse: 0.0192\n",
      "Epoch 12/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0882 - mse: 0.0153\n",
      "Epoch 00012: val_loss improved from 0.01622 to 0.01572, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0153 - mae: 0.0882 - mse: 0.0153 - val_loss: 0.0157 - val_mae: 0.0869 - val_mse: 0.0157\n",
      "Epoch 13/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0843 - mse: 0.0142\n",
      "Epoch 00013: val_loss improved from 0.01572 to 0.01490, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0143 - mae: 0.0845 - mse: 0.0143 - val_loss: 0.0149 - val_mae: 0.0842 - val_mse: 0.0149\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0829 - mse: 0.0138\n",
      "Epoch 00014: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0138 - mae: 0.0828 - mse: 0.0138 - val_loss: 0.0162 - val_mae: 0.0912 - val_mse: 0.0162\n",
      "Epoch 15/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0807 - mse: 0.0132\n",
      "Epoch 00015: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0132 - mae: 0.0806 - mse: 0.0132 - val_loss: 0.0175 - val_mae: 0.0946 - val_mse: 0.0175\n",
      "Epoch 16/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.0826 - mse: 0.0137\n",
      "Epoch 00016: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 79us/sample - loss: 0.0136 - mae: 0.0825 - mse: 0.0136 - val_loss: 0.0157 - val_mae: 0.0838 - val_mse: 0.0157\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0795 - mse: 0.0129\n",
      "Epoch 00017: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0128 - mae: 0.0795 - mse: 0.0128 - val_loss: 0.0159 - val_mae: 0.0858 - val_mse: 0.0159\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0790 - mse: 0.0128\n",
      "Epoch 00018: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0128 - mae: 0.0790 - mse: 0.0128 - val_loss: 0.0154 - val_mae: 0.0857 - val_mse: 0.0154\n",
      "Epoch 19/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0127 - mae: 0.0787 - mse: 0.0127\n",
      "Epoch 00019: val_loss did not improve from 0.01490\n",
      "14926/14926 [==============================] - 1s 79us/sample - loss: 0.0127 - mae: 0.0790 - mse: 0.0127 - val_loss: 0.0164 - val_mae: 0.0906 - val_mse: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0756 - mse: 0.0117\n",
      "Epoch 00020: val_loss improved from 0.01490 to 0.01392, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0117 - mae: 0.0757 - mse: 0.0117 - val_loss: 0.0139 - val_mae: 0.0813 - val_mse: 0.0139\n",
      "Epoch 21/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0759 - mse: 0.0118\n",
      "Epoch 00021: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0118 - mae: 0.0760 - mse: 0.0118 - val_loss: 0.0149 - val_mae: 0.0846 - val_mse: 0.0149\n",
      "Epoch 22/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0762 - mse: 0.0118\n",
      "Epoch 00022: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0118 - mae: 0.0764 - mse: 0.0118 - val_loss: 0.0150 - val_mae: 0.0862 - val_mse: 0.0150\n",
      "Epoch 23/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0738 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0112 - mae: 0.0741 - mse: 0.0112 - val_loss: 0.0161 - val_mae: 0.0872 - val_mse: 0.0161\n",
      "Epoch 24/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0737 - mse: 0.0111\n",
      "Epoch 00024: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0111 - mae: 0.0737 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0791 - val_mse: 0.0141\n",
      "Epoch 25/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0729 - mse: 0.0108\n",
      "Epoch 00025: val_loss improved from 0.01392 to 0.01373, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0107 - mae: 0.0728 - mse: 0.0107 - val_loss: 0.0137 - val_mae: 0.0787 - val_mse: 0.0137\n",
      "Epoch 26/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0721 - mse: 0.0107\n",
      "Epoch 00026: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0107 - mae: 0.0721 - mse: 0.0107 - val_loss: 0.0169 - val_mae: 0.0889 - val_mse: 0.0169\n",
      "Epoch 27/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0716 - mse: 0.0105\n",
      "Epoch 00027: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0105 - mae: 0.0716 - mse: 0.0105 - val_loss: 0.0154 - val_mae: 0.0858 - val_mse: 0.0154\n",
      "Epoch 28/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00028: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0105 - mae: 0.0719 - mse: 0.0105 - val_loss: 0.0146 - val_mae: 0.0819 - val_mse: 0.0146\n",
      "Epoch 29/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00029: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0105 - mae: 0.0718 - mse: 0.0105 - val_loss: 0.0153 - val_mae: 0.0829 - val_mse: 0.0153\n",
      "Epoch 30/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0695 - mse: 0.0100\n",
      "Epoch 00030: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0100 - mae: 0.0695 - mse: 0.0100 - val_loss: 0.0154 - val_mae: 0.0847 - val_mse: 0.0154\n",
      "Epoch 31/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0713 - mse: 0.0104\n",
      "Epoch 00031: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0104 - mae: 0.0712 - mse: 0.0104 - val_loss: 0.0147 - val_mae: 0.0837 - val_mse: 0.0147\n",
      "Epoch 32/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0693 - mse: 0.0098\n",
      "Epoch 00032: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0138 - val_mae: 0.0797 - val_mse: 0.0138\n",
      "Epoch 33/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0677 - mse: 0.0095\n",
      "Epoch 00033: val_loss did not improve from 0.01373\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0095 - mae: 0.0678 - mse: 0.0095 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 34/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0672 - mse: 0.0092\n",
      "Epoch 00034: val_loss improved from 0.01373 to 0.01360, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0092 - mae: 0.0671 - mse: 0.0092 - val_loss: 0.0136 - val_mae: 0.0775 - val_mse: 0.0136\n",
      "Epoch 35/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0656 - mse: 0.0090\n",
      "Epoch 00035: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0089 - mae: 0.0655 - mse: 0.0089 - val_loss: 0.0139 - val_mae: 0.0779 - val_mse: 0.0139\n",
      "Epoch 36/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00036: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0092 - mae: 0.0675 - mse: 0.0092 - val_loss: 0.0139 - val_mae: 0.0776 - val_mse: 0.0139\n",
      "Epoch 37/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00037: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0091 - mae: 0.0675 - mse: 0.0091 - val_loss: 0.0145 - val_mae: 0.0824 - val_mse: 0.0145\n",
      "Epoch 38/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0654 - mse: 0.0089\n",
      "Epoch 00038: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0089 - mae: 0.0654 - mse: 0.0089 - val_loss: 0.0151 - val_mae: 0.0823 - val_mse: 0.0151\n",
      "Epoch 39/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0647 - mse: 0.0086\n",
      "Epoch 00039: val_loss did not improve from 0.01360\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0085 - mae: 0.0646 - mse: 0.0085 - val_loss: 0.0136 - val_mae: 0.0812 - val_mse: 0.0136\n",
      "Epoch 40/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0645 - mse: 0.0085\n",
      "Epoch 00040: val_loss improved from 0.01360 to 0.01351, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0085 - mae: 0.0645 - mse: 0.0085 - val_loss: 0.0135 - val_mae: 0.0769 - val_mse: 0.0135\n",
      "Epoch 41/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0651 - mse: 0.0086\n",
      "Epoch 00041: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0086 - mae: 0.0652 - mse: 0.0086 - val_loss: 0.0158 - val_mae: 0.0868 - val_mse: 0.0158\n",
      "Epoch 42/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0637 - mse: 0.0081\n",
      "Epoch 00042: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0083 - mae: 0.0638 - mse: 0.0083 - val_loss: 0.0163 - val_mae: 0.0861 - val_mse: 0.0163\n",
      "Epoch 43/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0623 - mse: 0.0079\n",
      "Epoch 00043: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0079 - mae: 0.0623 - mse: 0.0079 - val_loss: 0.0136 - val_mae: 0.0773 - val_mse: 0.0136\n",
      "Epoch 44/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0631 - mse: 0.0081\n",
      "Epoch 00044: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0081 - mae: 0.0632 - mse: 0.0081 - val_loss: 0.0160 - val_mae: 0.0883 - val_mse: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0632 - mse: 0.0080\n",
      "Epoch 00045: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0080 - mae: 0.0632 - mse: 0.0080 - val_loss: 0.0145 - val_mae: 0.0823 - val_mse: 0.0145\n",
      "Epoch 46/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0641 - mse: 0.0082\n",
      "Epoch 00046: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0082 - mae: 0.0640 - mse: 0.0082 - val_loss: 0.0141 - val_mae: 0.0787 - val_mse: 0.0141\n",
      "Epoch 47/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0628 - mse: 0.0082\n",
      "Epoch 00047: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0081 - mae: 0.0628 - mse: 0.0081 - val_loss: 0.0144 - val_mae: 0.0801 - val_mse: 0.0144\n",
      "Epoch 48/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0604 - mse: 0.0076\n",
      "Epoch 00048: val_loss improved from 0.01351 to 0.01342, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0075 - mae: 0.0604 - mse: 0.0075 - val_loss: 0.0134 - val_mae: 0.0771 - val_mse: 0.0134\n",
      "Epoch 49/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0612 - mse: 0.0075\n",
      "Epoch 00049: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0075 - mae: 0.0610 - mse: 0.0075 - val_loss: 0.0138 - val_mae: 0.0791 - val_mse: 0.0138\n",
      "Epoch 50/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0596 - mse: 0.0072\n",
      "Epoch 00050: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0072 - mae: 0.0597 - mse: 0.0072 - val_loss: 0.0150 - val_mae: 0.0806 - val_mse: 0.0150\n",
      "Epoch 51/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0614 - mse: 0.0073\n",
      "Epoch 00051: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0077 - mae: 0.0618 - mse: 0.0077 - val_loss: 0.0190 - val_mae: 0.1015 - val_mse: 0.0190\n",
      "Epoch 52/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0608 - mse: 0.0074\n",
      "Epoch 00052: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0074 - mae: 0.0606 - mse: 0.0074 - val_loss: 0.0143 - val_mae: 0.0822 - val_mse: 0.0143\n",
      "Epoch 53/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0607 - mse: 0.0075\n",
      "Epoch 00053: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0075 - mae: 0.0606 - mse: 0.0075 - val_loss: 0.0143 - val_mae: 0.0789 - val_mse: 0.0143\n",
      "Epoch 54/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0598 - mse: 0.0071\n",
      "Epoch 00054: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0071 - mae: 0.0597 - mse: 0.0071 - val_loss: 0.0147 - val_mae: 0.0790 - val_mse: 0.0147\n",
      "Epoch 55/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0584 - mse: 0.0069\n",
      "Epoch 00055: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0069 - mae: 0.0584 - mse: 0.0069 - val_loss: 0.0144 - val_mae: 0.0811 - val_mse: 0.0144\n",
      "Epoch 56/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0575 - mse: 0.0068\n",
      "Epoch 00056: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0068 - mae: 0.0576 - mse: 0.0068 - val_loss: 0.0143 - val_mae: 0.0801 - val_mse: 0.0143\n",
      "Epoch 57/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0572 - mse: 0.0066\n",
      "Epoch 00057: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0066 - mae: 0.0572 - mse: 0.0066 - val_loss: 0.0138 - val_mae: 0.0821 - val_mse: 0.0138\n",
      "Elapsed time during model training:  77.50758266448975\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0447 - mae: 0.1466 - mse: 0.0447\n",
      "Epoch 00001: val_loss improved from inf to 0.02646, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0446,  mae:0.1465,  mse:0.0446,  val_loss:0.0265,  val_mae:0.1212,  val_mse:0.0265,  \n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0446 - mae: 0.1465 - mse: 0.0446 - val_loss: 0.0265 - val_mae: 0.1212 - val_mse: 0.0265\n",
      "Epoch 2/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0217 - mae: 0.1065 - mse: 0.0217\n",
      "Epoch 00002: val_loss improved from 0.02646 to 0.02330, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0218 - mae: 0.1067 - mse: 0.0218 - val_loss: 0.0233 - val_mae: 0.1125 - val_mse: 0.0233\n",
      "Epoch 3/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0198 - mae: 0.1013 - mse: 0.0198\n",
      "Epoch 00003: val_loss improved from 0.02330 to 0.01870, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0198 - mae: 0.1013 - mse: 0.0198 - val_loss: 0.0187 - val_mae: 0.0950 - val_mse: 0.0187\n",
      "Epoch 4/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1004 - mse: 0.0193\n",
      "Epoch 00004: val_loss did not improve from 0.01870\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0193 - mae: 0.1004 - mse: 0.0193 - val_loss: 0.0206 - val_mae: 0.1111 - val_mse: 0.0206\n",
      "Epoch 5/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0958 - mse: 0.0178\n",
      "Epoch 00005: val_loss improved from 0.01870 to 0.01754, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0178 - mae: 0.0959 - mse: 0.0178 - val_loss: 0.0175 - val_mae: 0.0966 - val_mse: 0.0175\n",
      "Epoch 6/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0930 - mse: 0.0171\n",
      "Epoch 00006: val_loss improved from 0.01754 to 0.01707, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0171 - mae: 0.0930 - mse: 0.0171 - val_loss: 0.0171 - val_mae: 0.0964 - val_mse: 0.0171\n",
      "Epoch 7/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0916 - mse: 0.0164\n",
      "Epoch 00007: val_loss did not improve from 0.01707\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0164 - mae: 0.0915 - mse: 0.0164 - val_loss: 0.0174 - val_mae: 0.0871 - val_mse: 0.0174\n",
      "Epoch 8/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0163 - mae: 0.0917 - mse: 0.0163\n",
      "Epoch 00008: val_loss improved from 0.01707 to 0.01624, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0163 - mae: 0.0919 - mse: 0.0163 - val_loss: 0.0162 - val_mae: 0.0904 - val_mse: 0.0162\n",
      "Epoch 9/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0871 - mse: 0.0145\n",
      "Epoch 00009: val_loss did not improve from 0.01624\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0150 - mae: 0.0876 - mse: 0.0150 - val_loss: 0.0207 - val_mae: 0.1056 - val_mse: 0.0207\n",
      "Epoch 10/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0890 - mse: 0.0157\n",
      "Epoch 00010: val_loss improved from 0.01624 to 0.01611, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0157 - mae: 0.0892 - mse: 0.0157 - val_loss: 0.0161 - val_mae: 0.0902 - val_mse: 0.0161\n",
      "Epoch 11/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0838 - mse: 0.0141\n",
      "Epoch 00011: val_loss did not improve from 0.01611\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0142 - mae: 0.0839 - mse: 0.0142 - val_loss: 0.0183 - val_mae: 0.0985 - val_mse: 0.0183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0836 - mse: 0.0139\n",
      "Epoch 00012: val_loss improved from 0.01611 to 0.01559, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0138 - mae: 0.0836 - mse: 0.0138 - val_loss: 0.0156 - val_mae: 0.0866 - val_mse: 0.0156\n",
      "Epoch 13/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0850 - mse: 0.0143\n",
      "Epoch 00013: val_loss did not improve from 0.01559\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0142 - mae: 0.0850 - mse: 0.0142 - val_loss: 0.0171 - val_mae: 0.0933 - val_mse: 0.0171\n",
      "Epoch 14/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0812 - mse: 0.0131\n",
      "Epoch 00014: val_loss did not improve from 0.01559\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0131 - mae: 0.0812 - mse: 0.0131 - val_loss: 0.0160 - val_mae: 0.0863 - val_mse: 0.0160\n",
      "Epoch 15/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0805 - mse: 0.0130\n",
      "Epoch 00015: val_loss improved from 0.01559 to 0.01497, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0130 - mae: 0.0806 - mse: 0.0130 - val_loss: 0.0150 - val_mae: 0.0848 - val_mse: 0.0150\n",
      "Epoch 16/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0121 - mae: 0.0775 - mse: 0.0121\n",
      "Epoch 00016: val_loss improved from 0.01497 to 0.01488, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0121 - mae: 0.0776 - mse: 0.0121 - val_loss: 0.0149 - val_mae: 0.0852 - val_mse: 0.0149\n",
      "Epoch 17/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0782 - mse: 0.0122\n",
      "Epoch 00017: val_loss improved from 0.01488 to 0.01412, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0122 - mae: 0.0781 - mse: 0.0122 - val_loss: 0.0141 - val_mae: 0.0791 - val_mse: 0.0141\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0766 - mse: 0.0118\n",
      "Epoch 00018: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0118 - mae: 0.0766 - mse: 0.0118 - val_loss: 0.0168 - val_mae: 0.0892 - val_mse: 0.0168\n",
      "Epoch 19/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0757 - mse: 0.0115\n",
      "Epoch 00019: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0115 - mae: 0.0755 - mse: 0.0115 - val_loss: 0.0143 - val_mae: 0.0838 - val_mse: 0.0143\n",
      "Epoch 20/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0116 - mae: 0.0756 - mse: 0.0116\n",
      "Epoch 00020: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0116 - mae: 0.0756 - mse: 0.0116 - val_loss: 0.0141 - val_mae: 0.0817 - val_mse: 0.0141\n",
      "Epoch 21/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00021: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0110 - mae: 0.0739 - mse: 0.0110 - val_loss: 0.0163 - val_mae: 0.0913 - val_mse: 0.0163\n",
      "Epoch 22/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0732 - mse: 0.0108\n",
      "Epoch 00022: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0108 - mae: 0.0732 - mse: 0.0108 - val_loss: 0.0165 - val_mae: 0.0921 - val_mse: 0.0165\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0714 - mse: 0.0104\n",
      "Epoch 00023: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0105 - mae: 0.0715 - mse: 0.0105 - val_loss: 0.0160 - val_mae: 0.0859 - val_mse: 0.0160\n",
      "Epoch 24/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0097 - mae: 0.0696 - mse: 0.0097\n",
      "Epoch 00024: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0100 - mae: 0.0696 - mse: 0.0100 - val_loss: 0.0166 - val_mae: 0.0914 - val_mse: 0.0166\n",
      "Epoch 25/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0715 - mse: 0.0104\n",
      "Epoch 00025: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0104 - mae: 0.0715 - mse: 0.0104 - val_loss: 0.0154 - val_mae: 0.0814 - val_mse: 0.0154\n",
      "Epoch 26/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0692 - mse: 0.0098\n",
      "Epoch 00026: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0098 - mae: 0.0692 - mse: 0.0098 - val_loss: 0.0143 - val_mae: 0.0804 - val_mse: 0.0143\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0690 - mse: 0.0096\n",
      "Epoch 00027: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0096 - mae: 0.0691 - mse: 0.0096 - val_loss: 0.0151 - val_mae: 0.0821 - val_mse: 0.0151\n",
      "Epoch 28/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0679 - mse: 0.0092\n",
      "Epoch 00028: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0092 - mae: 0.0679 - mse: 0.0092 - val_loss: 0.0146 - val_mae: 0.0845 - val_mse: 0.0146\n",
      "Epoch 29/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0670 - mse: 0.0091\n",
      "Epoch 00029: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0091 - mae: 0.0671 - mse: 0.0091 - val_loss: 0.0142 - val_mae: 0.0788 - val_mse: 0.0142\n",
      "Epoch 30/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0679 - mse: 0.0095\n",
      "Epoch 00030: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0095 - mae: 0.0683 - mse: 0.0095 - val_loss: 0.0155 - val_mae: 0.0885 - val_mse: 0.0155\n",
      "Epoch 31/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0676 - mse: 0.0091\n",
      "Epoch 00031: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0091 - mae: 0.0675 - mse: 0.0091 - val_loss: 0.0144 - val_mae: 0.0837 - val_mse: 0.0144\n",
      "Epoch 32/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0658 - mse: 0.0088\n",
      "Epoch 00032: val_loss improved from 0.01412 to 0.01399, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0660 - mse: 0.0089 - val_loss: 0.0140 - val_mae: 0.0826 - val_mse: 0.0140\n",
      "Epoch 33/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0640 - mse: 0.0084\n",
      "Epoch 00033: val_loss did not improve from 0.01399\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0084 - mae: 0.0643 - mse: 0.0084 - val_loss: 0.0151 - val_mae: 0.0837 - val_mse: 0.0151\n",
      "Epoch 34/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0648 - mse: 0.0085\n",
      "Epoch 00034: val_loss improved from 0.01399 to 0.01325, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0084 - mae: 0.0648 - mse: 0.0084 - val_loss: 0.0132 - val_mae: 0.0763 - val_mse: 0.0132\n",
      "Epoch 35/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0646 - mse: 0.0084\n",
      "Epoch 00035: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0084 - mae: 0.0644 - mse: 0.0084 - val_loss: 0.0134 - val_mae: 0.0770 - val_mse: 0.0134\n",
      "Epoch 36/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0641 - mse: 0.0082\n",
      "Epoch 00036: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0082 - mae: 0.0640 - mse: 0.0082 - val_loss: 0.0143 - val_mae: 0.0835 - val_mse: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0631 - mse: 0.0080\n",
      "Epoch 00037: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0080 - mae: 0.0630 - mse: 0.0080 - val_loss: 0.0135 - val_mae: 0.0789 - val_mse: 0.0135\n",
      "Epoch 38/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0613 - mse: 0.0076\n",
      "Epoch 00038: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0077 - mae: 0.0614 - mse: 0.0077 - val_loss: 0.0147 - val_mae: 0.0853 - val_mse: 0.0147\n",
      "Epoch 39/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0606 - mse: 0.0075\n",
      "Epoch 00039: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0075 - mae: 0.0604 - mse: 0.0075 - val_loss: 0.0136 - val_mae: 0.0770 - val_mse: 0.0136\n",
      "Epoch 40/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0606 - mse: 0.0076\n",
      "Epoch 00040: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0076 - mae: 0.0607 - mse: 0.0076 - val_loss: 0.0141 - val_mae: 0.0786 - val_mse: 0.0141\n",
      "Epoch 41/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0600 - mse: 0.0073\n",
      "Epoch 00041: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0073 - mae: 0.0599 - mse: 0.0073 - val_loss: 0.0150 - val_mae: 0.0813 - val_mse: 0.0150\n",
      "Epoch 42/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0588 - mse: 0.0070\n",
      "Epoch 00042: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0070 - mae: 0.0588 - mse: 0.0070 - val_loss: 0.0139 - val_mae: 0.0756 - val_mse: 0.0139\n",
      "Epoch 43/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0586 - mse: 0.0069\n",
      "Epoch 00043: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0069 - mae: 0.0586 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0807 - val_mse: 0.0139\n",
      "Epoch 44/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0581 - mse: 0.0069\n",
      "Epoch 00044: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0068 - mae: 0.0581 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0781 - val_mse: 0.0140\n",
      "Epoch 45/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0067 - mae: 0.0574 - mse: 0.0067\n",
      "Epoch 00045: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0067 - mae: 0.0574 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0785 - val_mse: 0.0137\n",
      "Epoch 46/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0067 - mae: 0.0578 - mse: 0.0067\n",
      "Epoch 00046: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0067 - mae: 0.0580 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0793 - val_mse: 0.0143\n",
      "Epoch 47/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0063 - mae: 0.0562 - mse: 0.0063\n",
      "Epoch 00047: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0063 - mae: 0.0563 - mse: 0.0063 - val_loss: 0.0140 - val_mae: 0.0794 - val_mse: 0.0140\n",
      "Epoch 48/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0570 - mse: 0.0067\n",
      "Epoch 00048: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0067 - mae: 0.0570 - mse: 0.0067 - val_loss: 0.0140 - val_mae: 0.0782 - val_mse: 0.0140\n",
      "Epoch 49/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0568 - mse: 0.0068\n",
      "Epoch 00049: val_loss did not improve from 0.01325\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0067 - mae: 0.0568 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0807 - val_mse: 0.0134\n",
      "Elapsed time during model training:  68.29833912849426\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0529 - mae: 0.1523 - mse: 0.0529\n",
      "Epoch 00001: val_loss improved from inf to 0.02915, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0518,  mae:0.1507,  mse:0.0518,  val_loss:0.0291,  val_mae:0.1288,  val_mse:0.0291,  \n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0518 - mae: 0.1507 - mse: 0.0518 - val_loss: 0.0291 - val_mae: 0.1288 - val_mse: 0.0291\n",
      "Epoch 2/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1078 - mse: 0.0221\n",
      "Epoch 00002: val_loss improved from 0.02915 to 0.01809, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0221 - mae: 0.1079 - mse: 0.0221 - val_loss: 0.0181 - val_mae: 0.0961 - val_mse: 0.0181\n",
      "Epoch 3/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1013 - mse: 0.0201\n",
      "Epoch 00003: val_loss improved from 0.01809 to 0.01657, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0200 - mae: 0.1013 - mse: 0.0200 - val_loss: 0.0166 - val_mae: 0.0900 - val_mse: 0.0166\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0192 - mae: 0.0997 - mse: 0.0192\n",
      "Epoch 00004: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0192 - mae: 0.0996 - mse: 0.0192 - val_loss: 0.0175 - val_mae: 0.0975 - val_mse: 0.0175\n",
      "Epoch 5/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.0962 - mse: 0.0180\n",
      "Epoch 00005: val_loss did not improve from 0.01657\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0180 - mae: 0.0963 - mse: 0.0180 - val_loss: 0.0191 - val_mae: 0.1032 - val_mse: 0.0191\n",
      "Epoch 6/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0958 - mse: 0.0181\n",
      "Epoch 00006: val_loss improved from 0.01657 to 0.01570, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0180 - mae: 0.0957 - mse: 0.0180 - val_loss: 0.0157 - val_mae: 0.0882 - val_mse: 0.0157\n",
      "Epoch 7/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0931 - mse: 0.0170\n",
      "Epoch 00007: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0172 - mae: 0.0934 - mse: 0.0172 - val_loss: 0.0171 - val_mae: 0.0916 - val_mse: 0.0171\n",
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0162 - mae: 0.0902 - mse: 0.0162\n",
      "Epoch 00008: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0161 - mae: 0.0899 - mse: 0.0161 - val_loss: 0.0204 - val_mae: 0.1042 - val_mse: 0.0204\n",
      "Epoch 9/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0904 - mse: 0.0160\n",
      "Epoch 00009: val_loss improved from 0.01570 to 0.01557, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0160 - mae: 0.0905 - mse: 0.0160 - val_loss: 0.0156 - val_mae: 0.0888 - val_mse: 0.0156\n",
      "Epoch 10/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0155 - mae: 0.0888 - mse: 0.0155\n",
      "Epoch 00010: val_loss did not improve from 0.01557\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0155 - mae: 0.0888 - mse: 0.0155 - val_loss: 0.0170 - val_mae: 0.0915 - val_mse: 0.0170\n",
      "Epoch 11/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0868 - mse: 0.0150\n",
      "Epoch 00011: val_loss did not improve from 0.01557\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0150 - mae: 0.0868 - mse: 0.0150 - val_loss: 0.0175 - val_mae: 0.0959 - val_mse: 0.0175\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0858 - mse: 0.0146\n",
      "Epoch 00012: val_loss did not improve from 0.01557\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0147 - mae: 0.0860 - mse: 0.0147 - val_loss: 0.0240 - val_mae: 0.1165 - val_mse: 0.0240\n",
      "Epoch 13/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0888 - mse: 0.0154\n",
      "Epoch 00013: val_loss improved from 0.01557 to 0.01552, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0154 - mae: 0.0888 - mse: 0.0154 - val_loss: 0.0155 - val_mae: 0.0873 - val_mse: 0.0155\n",
      "Epoch 14/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0819 - mse: 0.0137\n",
      "Epoch 00014: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0137 - mae: 0.0818 - mse: 0.0137 - val_loss: 0.0160 - val_mae: 0.0878 - val_mse: 0.0160\n",
      "Epoch 15/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0803 - mse: 0.0131\n",
      "Epoch 00015: val_loss improved from 0.01552 to 0.01535, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0131 - mae: 0.0802 - mse: 0.0131 - val_loss: 0.0154 - val_mae: 0.0852 - val_mse: 0.0154\n",
      "Epoch 16/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0818 - mse: 0.0135\n",
      "Epoch 00016: val_loss did not improve from 0.01535\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0135 - mae: 0.0817 - mse: 0.0135 - val_loss: 0.0164 - val_mae: 0.0911 - val_mse: 0.0164\n",
      "Epoch 17/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0818 - mse: 0.0134\n",
      "Epoch 00017: val_loss did not improve from 0.01535\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0135 - mae: 0.0820 - mse: 0.0135 - val_loss: 0.0169 - val_mae: 0.0933 - val_mse: 0.0169\n",
      "Epoch 18/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0786 - mse: 0.0127\n",
      "Epoch 00018: val_loss improved from 0.01535 to 0.01442, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0126 - mae: 0.0785 - mse: 0.0126 - val_loss: 0.0144 - val_mae: 0.0822 - val_mse: 0.0144\n",
      "Epoch 19/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0788 - mse: 0.0125\n",
      "Epoch 00019: val_loss improved from 0.01442 to 0.01437, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0125 - mae: 0.0788 - mse: 0.0125 - val_loss: 0.0144 - val_mae: 0.0817 - val_mse: 0.0144\n",
      "Epoch 20/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0763 - mse: 0.0121\n",
      "Epoch 00020: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0120 - mae: 0.0763 - mse: 0.0120 - val_loss: 0.0150 - val_mae: 0.0864 - val_mse: 0.0150\n",
      "Epoch 21/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0120 - mae: 0.0764 - mse: 0.0120\n",
      "Epoch 00021: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0120 - mae: 0.0763 - mse: 0.0120 - val_loss: 0.0146 - val_mae: 0.0835 - val_mse: 0.0146\n",
      "Epoch 22/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0746 - mse: 0.0115\n",
      "Epoch 00022: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0751 - mse: 0.0117 - val_loss: 0.0159 - val_mae: 0.0903 - val_mse: 0.0159\n",
      "Epoch 23/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0757 - mse: 0.0116\n",
      "Epoch 00023: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0116 - mae: 0.0755 - mse: 0.0116 - val_loss: 0.0158 - val_mae: 0.0831 - val_mse: 0.0158\n",
      "Epoch 24/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0731 - mse: 0.0111\n",
      "Epoch 00024: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0111 - mae: 0.0733 - mse: 0.0111 - val_loss: 0.0164 - val_mae: 0.0877 - val_mse: 0.0164\n",
      "Epoch 25/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0739 - mse: 0.0111\n",
      "Epoch 00025: val_loss improved from 0.01437 to 0.01427, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0143 - val_mae: 0.0816 - val_mse: 0.0143\n",
      "Epoch 26/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0739 - mse: 0.0110\n",
      "Epoch 00026: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0110 - mae: 0.0740 - mse: 0.0110 - val_loss: 0.0160 - val_mae: 0.0893 - val_mse: 0.0160\n",
      "Epoch 27/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0721 - mse: 0.0105\n",
      "Epoch 00027: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0109 - mae: 0.0724 - mse: 0.0109 - val_loss: 0.0174 - val_mae: 0.0912 - val_mse: 0.0174\n",
      "Epoch 28/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00028: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0105 - mae: 0.0718 - mse: 0.0105 - val_loss: 0.0150 - val_mae: 0.0884 - val_mse: 0.0150\n",
      "Epoch 29/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0711 - mse: 0.0104\n",
      "Epoch 00029: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0104 - mae: 0.0711 - mse: 0.0104 - val_loss: 0.0152 - val_mae: 0.0827 - val_mse: 0.0152\n",
      "Epoch 30/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0714 - mse: 0.0103\n",
      "Epoch 00030: val_loss improved from 0.01427 to 0.01392, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0103 - mae: 0.0714 - mse: 0.0103 - val_loss: 0.0139 - val_mae: 0.0809 - val_mse: 0.0139\n",
      "Epoch 31/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0686 - mse: 0.0098\n",
      "Epoch 00031: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0098 - mae: 0.0686 - mse: 0.0098 - val_loss: 0.0146 - val_mae: 0.0844 - val_mse: 0.0146\n",
      "Epoch 32/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0705 - mse: 0.0100\n",
      "Epoch 00032: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0100 - mae: 0.0704 - mse: 0.0100 - val_loss: 0.0140 - val_mae: 0.0797 - val_mse: 0.0140\n",
      "Epoch 33/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0687 - mse: 0.0097\n",
      "Epoch 00033: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0097 - mae: 0.0687 - mse: 0.0097 - val_loss: 0.0145 - val_mae: 0.0785 - val_mse: 0.0145\n",
      "Epoch 34/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0682 - mse: 0.0095\n",
      "Epoch 00034: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0095 - mae: 0.0682 - mse: 0.0095 - val_loss: 0.0149 - val_mae: 0.0813 - val_mse: 0.0149\n",
      "Epoch 35/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0687 - mse: 0.0096\n",
      "Epoch 00035: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0096 - mae: 0.0687 - mse: 0.0096 - val_loss: 0.0146 - val_mae: 0.0837 - val_mse: 0.0146\n",
      "Epoch 36/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0674 - mse: 0.0092\n",
      "Epoch 00036: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0166 - val_mae: 0.0834 - val_mse: 0.0166\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0675 - mse: 0.0095\n",
      "Epoch 00037: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0094 - mae: 0.0675 - mse: 0.0094 - val_loss: 0.0142 - val_mae: 0.0781 - val_mse: 0.0142\n",
      "Epoch 38/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0661 - mse: 0.0090\n",
      "Epoch 00038: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0090 - mae: 0.0661 - mse: 0.0090 - val_loss: 0.0147 - val_mae: 0.0812 - val_mse: 0.0147\n",
      "Epoch 39/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0649 - mse: 0.0086\n",
      "Epoch 00039: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0086 - mae: 0.0649 - mse: 0.0086 - val_loss: 0.0144 - val_mae: 0.0819 - val_mse: 0.0144\n",
      "Epoch 40/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0642 - mse: 0.0084\n",
      "Epoch 00040: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0085 - mae: 0.0644 - mse: 0.0085 - val_loss: 0.0149 - val_mae: 0.0835 - val_mse: 0.0149\n",
      "Epoch 41/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0659 - mse: 0.0088\n",
      "Epoch 00041: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0181 - val_mae: 0.1013 - val_mse: 0.0181\n",
      "Epoch 42/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0649 - mse: 0.0086\n",
      "Epoch 00042: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0086 - mae: 0.0651 - mse: 0.0086 - val_loss: 0.0157 - val_mae: 0.0871 - val_mse: 0.0157\n",
      "Epoch 43/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0643 - mse: 0.0085\n",
      "Epoch 00043: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0085 - mae: 0.0643 - mse: 0.0085 - val_loss: 0.0146 - val_mae: 0.0806 - val_mse: 0.0146\n",
      "Epoch 44/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0640 - mse: 0.0082\n",
      "Epoch 00044: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0083 - mae: 0.0641 - mse: 0.0083 - val_loss: 0.0143 - val_mae: 0.0784 - val_mse: 0.0143\n",
      "Elapsed time during model training:  58.62872266769409\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0461 - mae: 0.1490 - mse: 0.0461\n",
      "Epoch 00001: val_loss improved from inf to 0.03279, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0460,  mae:0.1489,  mse:0.0460,  val_loss:0.0328,  val_mae:0.1321,  val_mse:0.0328,  \n",
      "14926/14926 [==============================] - 2s 144us/sample - loss: 0.0460 - mae: 0.1489 - mse: 0.0460 - val_loss: 0.0328 - val_mae: 0.1321 - val_mse: 0.0328\n",
      "Epoch 2/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1087 - mse: 0.0221\n",
      "Epoch 00002: val_loss improved from 0.03279 to 0.02202, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0221 - mae: 0.1085 - mse: 0.0221 - val_loss: 0.0220 - val_mae: 0.1067 - val_mse: 0.0220\n",
      "Epoch 3/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0201 - mae: 0.1024 - mse: 0.0201\n",
      "Epoch 00003: val_loss did not improve from 0.02202\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0201 - mae: 0.1024 - mse: 0.0201 - val_loss: 0.0224 - val_mae: 0.1150 - val_mse: 0.0224\n",
      "Epoch 4/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0192 - mae: 0.1007 - mse: 0.0192\n",
      "Epoch 00004: val_loss improved from 0.02202 to 0.02008, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0193 - mae: 0.1011 - mse: 0.0193 - val_loss: 0.0201 - val_mae: 0.1049 - val_mse: 0.0201\n",
      "Epoch 5/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0175 - mae: 0.0951 - mse: 0.0175\n",
      "Epoch 00005: val_loss did not improve from 0.02008\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0176 - mae: 0.0953 - mse: 0.0176 - val_loss: 0.0210 - val_mae: 0.1054 - val_mse: 0.0210\n",
      "Epoch 6/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0924 - mse: 0.0166\n",
      "Epoch 00006: val_loss improved from 0.02008 to 0.01673, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0165 - mae: 0.0923 - mse: 0.0165 - val_loss: 0.0167 - val_mae: 0.0936 - val_mse: 0.0167\n",
      "Epoch 7/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0900 - mse: 0.0158\n",
      "Epoch 00007: val_loss improved from 0.01673 to 0.01610, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0158 - mae: 0.0900 - mse: 0.0158 - val_loss: 0.0161 - val_mae: 0.0898 - val_mse: 0.0161\n",
      "Epoch 8/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0888 - mse: 0.0154\n",
      "Epoch 00008: val_loss did not improve from 0.01610\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0154 - mae: 0.0890 - mse: 0.0154 - val_loss: 0.0219 - val_mae: 0.1100 - val_mse: 0.0219\n",
      "Epoch 9/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0876 - mse: 0.0153\n",
      "Epoch 00009: val_loss improved from 0.01610 to 0.01545, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0151 - mae: 0.0872 - mse: 0.0151 - val_loss: 0.0155 - val_mae: 0.0856 - val_mse: 0.0155\n",
      "Epoch 10/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0834 - mse: 0.0139\n",
      "Epoch 00010: val_loss improved from 0.01545 to 0.01523, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0139 - mae: 0.0835 - mse: 0.0139 - val_loss: 0.0152 - val_mae: 0.0869 - val_mse: 0.0152\n",
      "Epoch 11/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0849 - mse: 0.0143\n",
      "Epoch 00011: val_loss improved from 0.01523 to 0.01384, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0142 - mae: 0.0846 - mse: 0.0142 - val_loss: 0.0138 - val_mae: 0.0790 - val_mse: 0.0138\n",
      "Epoch 12/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0806 - mse: 0.0132\n",
      "Epoch 00012: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0133 - mae: 0.0809 - mse: 0.0133 - val_loss: 0.0156 - val_mae: 0.0900 - val_mse: 0.0156\n",
      "Epoch 13/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0802 - mse: 0.0127\n",
      "Epoch 00013: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0131 - mae: 0.0804 - mse: 0.0131 - val_loss: 0.0170 - val_mae: 0.0920 - val_mse: 0.0170\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0126 - mae: 0.0797 - mse: 0.0126\n",
      "Epoch 00014: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0125 - mae: 0.0793 - mse: 0.0125 - val_loss: 0.0148 - val_mae: 0.0877 - val_mse: 0.0148\n",
      "Epoch 15/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0120 - mae: 0.0767 - mse: 0.0120\n",
      "Epoch 00015: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0120 - mae: 0.0768 - mse: 0.0120 - val_loss: 0.0150 - val_mae: 0.0895 - val_mse: 0.0150\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0761 - mse: 0.0117\n",
      "Epoch 00016: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0761 - mse: 0.0117 - val_loss: 0.0141 - val_mae: 0.0817 - val_mse: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0116 - mae: 0.0764 - mse: 0.0116\n",
      "Epoch 00017: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0770 - mse: 0.0117 - val_loss: 0.0168 - val_mae: 0.0932 - val_mse: 0.0168\n",
      "Epoch 18/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0753 - mse: 0.0113\n",
      "Epoch 00018: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0113 - mae: 0.0753 - mse: 0.0113 - val_loss: 0.0140 - val_mae: 0.0800 - val_mse: 0.0140\n",
      "Epoch 19/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0732 - mse: 0.0109\n",
      "Epoch 00019: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0108 - mae: 0.0732 - mse: 0.0108 - val_loss: 0.0152 - val_mae: 0.0868 - val_mse: 0.0152\n",
      "Epoch 20/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0105 - mae: 0.0721 - mse: 0.0105\n",
      "Epoch 00020: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0106 - mae: 0.0722 - mse: 0.0106 - val_loss: 0.0174 - val_mae: 0.1005 - val_mse: 0.0174\n",
      "Epoch 21/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0717 - mse: 0.0103\n",
      "Epoch 00021: val_loss improved from 0.01384 to 0.01327, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0103 - mae: 0.0716 - mse: 0.0103 - val_loss: 0.0133 - val_mae: 0.0791 - val_mse: 0.0133\n",
      "Epoch 22/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0711 - mse: 0.0100\n",
      "Epoch 00022: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0100 - mae: 0.0711 - mse: 0.0100 - val_loss: 0.0137 - val_mae: 0.0766 - val_mse: 0.0137\n",
      "Epoch 23/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0685 - mse: 0.0093\n",
      "Epoch 00023: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0096 - mae: 0.0687 - mse: 0.0096 - val_loss: 0.0164 - val_mae: 0.0988 - val_mse: 0.0164\n",
      "Epoch 24/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0689 - mse: 0.0096\n",
      "Epoch 00024: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0096 - mae: 0.0689 - mse: 0.0096 - val_loss: 0.0136 - val_mae: 0.0790 - val_mse: 0.0136\n",
      "Epoch 25/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0687 - mse: 0.0096\n",
      "Epoch 00025: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0096 - mae: 0.0687 - mse: 0.0096 - val_loss: 0.0144 - val_mae: 0.0848 - val_mse: 0.0144\n",
      "Epoch 26/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0671 - mse: 0.0091\n",
      "Epoch 00026: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0091 - mae: 0.0671 - mse: 0.0091 - val_loss: 0.0143 - val_mae: 0.0840 - val_mse: 0.0143\n",
      "Epoch 27/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0090 - mae: 0.0670 - mse: 0.0090\n",
      "Epoch 00027: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0090 - mae: 0.0670 - mse: 0.0090 - val_loss: 0.0169 - val_mae: 0.0919 - val_mse: 0.0169\n",
      "Epoch 28/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0654 - mse: 0.0086\n",
      "Epoch 00028: val_loss improved from 0.01327 to 0.01280, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0085 - mae: 0.0651 - mse: 0.0085 - val_loss: 0.0128 - val_mae: 0.0757 - val_mse: 0.0128\n",
      "Epoch 29/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0636 - mse: 0.0082\n",
      "Epoch 00029: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0137 - val_mae: 0.0789 - val_mse: 0.0137\n",
      "Epoch 30/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0085 - mae: 0.0650 - mse: 0.0085\n",
      "Epoch 00030: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0084 - mae: 0.0649 - mse: 0.0084 - val_loss: 0.0150 - val_mae: 0.0847 - val_mse: 0.0150\n",
      "Epoch 31/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0636 - mse: 0.0082\n",
      "Epoch 00031: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0082 - mae: 0.0637 - mse: 0.0082 - val_loss: 0.0142 - val_mae: 0.0805 - val_mse: 0.0142\n",
      "Epoch 32/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0626 - mse: 0.0080\n",
      "Epoch 00032: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0080 - mae: 0.0627 - mse: 0.0080 - val_loss: 0.0140 - val_mae: 0.0814 - val_mse: 0.0140\n",
      "Epoch 33/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0602 - mse: 0.0074\n",
      "Epoch 00033: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0074 - mae: 0.0602 - mse: 0.0074 - val_loss: 0.0137 - val_mae: 0.0789 - val_mse: 0.0137\n",
      "Epoch 34/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0593 - mse: 0.0073\n",
      "Epoch 00034: val_loss improved from 0.01280 to 0.01249, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0072 - mae: 0.0593 - mse: 0.0072 - val_loss: 0.0125 - val_mae: 0.0749 - val_mse: 0.0125\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0601 - mse: 0.0072\n",
      "Epoch 00035: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0073 - mae: 0.0603 - mse: 0.0073 - val_loss: 0.0155 - val_mae: 0.0872 - val_mse: 0.0155\n",
      "Epoch 36/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0068 - mae: 0.0576 - mse: 0.0068\n",
      "Epoch 00036: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0068 - mae: 0.0577 - mse: 0.0068 - val_loss: 0.0134 - val_mae: 0.0774 - val_mse: 0.0134\n",
      "Epoch 37/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0586 - mse: 0.0070\n",
      "Epoch 00037: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0070 - mae: 0.0587 - mse: 0.0070 - val_loss: 0.0146 - val_mae: 0.0815 - val_mse: 0.0146\n",
      "Epoch 38/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0582 - mse: 0.0069\n",
      "Epoch 00038: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0068 - mae: 0.0581 - mse: 0.0068 - val_loss: 0.0137 - val_mae: 0.0788 - val_mse: 0.0137\n",
      "Epoch 39/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0591 - mse: 0.0070\n",
      "Epoch 00039: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0070 - mae: 0.0590 - mse: 0.0070 - val_loss: 0.0126 - val_mae: 0.0729 - val_mse: 0.0126\n",
      "Epoch 40/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0556 - mse: 0.0062\n",
      "Epoch 00040: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0062 - mae: 0.0556 - mse: 0.0062 - val_loss: 0.0151 - val_mae: 0.0852 - val_mse: 0.0151\n",
      "Epoch 41/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0552 - mse: 0.0061\n",
      "Epoch 00041: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0061 - mae: 0.0551 - mse: 0.0061 - val_loss: 0.0141 - val_mae: 0.0775 - val_mse: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0062 - mae: 0.0556 - mse: 0.0062\n",
      "Epoch 00042: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0062 - mae: 0.0556 - mse: 0.0062 - val_loss: 0.0131 - val_mae: 0.0747 - val_mse: 0.0131\n",
      "Epoch 43/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0535 - mse: 0.0058\n",
      "Epoch 00043: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0060 - mae: 0.0538 - mse: 0.0060 - val_loss: 0.0164 - val_mae: 0.0879 - val_mse: 0.0164\n",
      "Epoch 44/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0544 - mse: 0.0060\n",
      "Epoch 00044: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0060 - mae: 0.0545 - mse: 0.0060 - val_loss: 0.0155 - val_mae: 0.0889 - val_mse: 0.0155\n",
      "Epoch 45/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0524 - mse: 0.0053\n",
      "Epoch 00045: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0057 - mae: 0.0532 - mse: 0.0057 - val_loss: 0.0191 - val_mae: 0.1001 - val_mse: 0.0191\n",
      "Epoch 46/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0060 - mae: 0.0538 - mse: 0.0060\n",
      "Epoch 00046: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0060 - mae: 0.0540 - mse: 0.0060 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 47/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0527 - mse: 0.0056\n",
      "Epoch 00047: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0056 - mae: 0.0527 - mse: 0.0056 - val_loss: 0.0133 - val_mae: 0.0748 - val_mse: 0.0133\n",
      "Epoch 48/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0513 - mse: 0.0056\n",
      "Epoch 00048: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0056 - mae: 0.0514 - mse: 0.0056 - val_loss: 0.0127 - val_mae: 0.0726 - val_mse: 0.0127\n",
      "Epoch 49/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0052 - mae: 0.0510 - mse: 0.0052\n",
      "Epoch 00049: val_loss did not improve from 0.01249\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0053 - mae: 0.0513 - mse: 0.0053 - val_loss: 0.0138 - val_mae: 0.0780 - val_mse: 0.0138\n",
      "Elapsed time during model training:  69.7277660369873\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0435 - mae: 0.1440 - mse: 0.0435\n",
      "Epoch 00001: val_loss improved from inf to 0.02892, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0432,  mae:0.1437,  mse:0.0432,  val_loss:0.0289,  val_mae:0.1296,  val_mse:0.0289,  \n",
      "14926/14926 [==============================] - 2s 140us/sample - loss: 0.0432 - mae: 0.1437 - mse: 0.0432 - val_loss: 0.0289 - val_mae: 0.1296 - val_mse: 0.0289\n",
      "Epoch 2/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0220 - mae: 0.1080 - mse: 0.0220\n",
      "Epoch 00002: val_loss improved from 0.02892 to 0.01676, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0219 - mae: 0.1076 - mse: 0.0219 - val_loss: 0.0168 - val_mae: 0.0906 - val_mse: 0.0168\n",
      "Epoch 3/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0204 - mae: 0.1039 - mse: 0.0204\n",
      "Epoch 00003: val_loss improved from 0.01676 to 0.01606, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0204 - mae: 0.1040 - mse: 0.0204 - val_loss: 0.0161 - val_mae: 0.0895 - val_mse: 0.0161\n",
      "Epoch 4/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0980 - mse: 0.0183\n",
      "Epoch 00004: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0186 - mae: 0.0981 - mse: 0.0186 - val_loss: 0.0188 - val_mae: 0.1022 - val_mse: 0.0188\n",
      "Epoch 5/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0179 - mae: 0.0965 - mse: 0.0179\n",
      "Epoch 00005: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0180 - mae: 0.0967 - mse: 0.0180 - val_loss: 0.0199 - val_mae: 0.1069 - val_mse: 0.0199\n",
      "Epoch 6/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0173 - mae: 0.0938 - mse: 0.0173\n",
      "Epoch 00006: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0173 - mae: 0.0939 - mse: 0.0173 - val_loss: 0.0199 - val_mae: 0.1077 - val_mse: 0.0199\n",
      "Epoch 7/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0948 - mse: 0.0172\n",
      "Epoch 00007: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0172 - mae: 0.0948 - mse: 0.0172 - val_loss: 0.0216 - val_mae: 0.1062 - val_mse: 0.0216\n",
      "Epoch 8/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0892 - mse: 0.0156\n",
      "Epoch 00008: val_loss improved from 0.01606 to 0.01574, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0156 - mae: 0.0891 - mse: 0.0156 - val_loss: 0.0157 - val_mae: 0.0859 - val_mse: 0.0157\n",
      "Epoch 9/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0870 - mse: 0.0152\n",
      "Epoch 00009: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0152 - mae: 0.0871 - mse: 0.0152 - val_loss: 0.0174 - val_mae: 0.0989 - val_mse: 0.0174\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0859 - mse: 0.0147\n",
      "Epoch 00010: val_loss improved from 0.01574 to 0.01506, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0146 - mae: 0.0858 - mse: 0.0146 - val_loss: 0.0151 - val_mae: 0.0852 - val_mse: 0.0151\n",
      "Epoch 11/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0855 - mse: 0.0144\n",
      "Epoch 00011: val_loss did not improve from 0.01506\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0145 - mae: 0.0855 - mse: 0.0145 - val_loss: 0.0170 - val_mae: 0.0957 - val_mse: 0.0170\n",
      "Epoch 12/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0842 - mse: 0.0140\n",
      "Epoch 00012: val_loss did not improve from 0.01506\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0140 - mae: 0.0841 - mse: 0.0140 - val_loss: 0.0156 - val_mae: 0.0873 - val_mse: 0.0156\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0815 - mse: 0.0133\n",
      "Epoch 00013: val_loss did not improve from 0.01506\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0133 - mae: 0.0815 - mse: 0.0133 - val_loss: 0.0175 - val_mae: 0.0935 - val_mse: 0.0175\n",
      "Epoch 14/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0807 - mse: 0.0130\n",
      "Epoch 00014: val_loss did not improve from 0.01506\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0131 - mae: 0.0808 - mse: 0.0131 - val_loss: 0.0224 - val_mae: 0.0986 - val_mse: 0.0224\n",
      "Epoch 15/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0805 - mse: 0.0129\n",
      "Epoch 00015: val_loss improved from 0.01506 to 0.01469, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0130 - mae: 0.0806 - mse: 0.0130 - val_loss: 0.0147 - val_mae: 0.0834 - val_mse: 0.0147\n",
      "Epoch 16/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0799 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01469\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0127 - mae: 0.0798 - mse: 0.0127 - val_loss: 0.0155 - val_mae: 0.0903 - val_mse: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0777 - mse: 0.0121\n",
      "Epoch 00017: val_loss improved from 0.01469 to 0.01402, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0121 - mae: 0.0777 - mse: 0.0121 - val_loss: 0.0140 - val_mae: 0.0817 - val_mse: 0.0140\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0766 - mse: 0.0118\n",
      "Epoch 00018: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0118 - mae: 0.0765 - mse: 0.0118 - val_loss: 0.0165 - val_mae: 0.0909 - val_mse: 0.0165\n",
      "Epoch 19/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0758 - mse: 0.0117\n",
      "Epoch 00019: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0116 - mae: 0.0757 - mse: 0.0116 - val_loss: 0.0144 - val_mae: 0.0800 - val_mse: 0.0144\n",
      "Epoch 20/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0735 - mse: 0.0110\n",
      "Epoch 00020: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0109 - mae: 0.0735 - mse: 0.0109 - val_loss: 0.0149 - val_mae: 0.0862 - val_mse: 0.0149\n",
      "Epoch 21/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0719 - mse: 0.0106\n",
      "Epoch 00021: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0106 - mae: 0.0719 - mse: 0.0106 - val_loss: 0.0146 - val_mae: 0.0830 - val_mse: 0.0146\n",
      "Epoch 22/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0713 - mse: 0.0101\n",
      "Epoch 00022: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0104 - mae: 0.0717 - mse: 0.0104 - val_loss: 0.0183 - val_mae: 0.1036 - val_mse: 0.0183\n",
      "Epoch 23/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0703 - mse: 0.0102\n",
      "Epoch 00023: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0103 - mae: 0.0705 - mse: 0.0103 - val_loss: 0.0142 - val_mae: 0.0809 - val_mse: 0.0142\n",
      "Epoch 24/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0707 - mse: 0.0101\n",
      "Epoch 00024: val_loss improved from 0.01402 to 0.01359, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0101 - mae: 0.0708 - mse: 0.0101 - val_loss: 0.0136 - val_mae: 0.0802 - val_mse: 0.0136\n",
      "Epoch 25/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0708 - mse: 0.0100\n",
      "Epoch 00025: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0100 - mae: 0.0709 - mse: 0.0100 - val_loss: 0.0139 - val_mae: 0.0816 - val_mse: 0.0139\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0700 - mse: 0.0099\n",
      "Epoch 00026: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0099 - mae: 0.0699 - mse: 0.0099 - val_loss: 0.0150 - val_mae: 0.0891 - val_mse: 0.0150\n",
      "Epoch 27/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0682 - mse: 0.0095\n",
      "Epoch 00027: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0095 - mae: 0.0681 - mse: 0.0095 - val_loss: 0.0139 - val_mae: 0.0793 - val_mse: 0.0139\n",
      "Epoch 28/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00028: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0092 - mae: 0.0675 - mse: 0.0092 - val_loss: 0.0138 - val_mae: 0.0782 - val_mse: 0.0138\n",
      "Epoch 29/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0687 - mse: 0.0095\n",
      "Epoch 00029: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0094 - mae: 0.0687 - mse: 0.0094 - val_loss: 0.0140 - val_mae: 0.0804 - val_mse: 0.0140\n",
      "Epoch 30/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0645 - mse: 0.0085\n",
      "Epoch 00030: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0086 - mae: 0.0646 - mse: 0.0086 - val_loss: 0.0147 - val_mae: 0.0819 - val_mse: 0.0147\n",
      "Epoch 31/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00031: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0089 - mae: 0.0660 - mse: 0.0089 - val_loss: 0.0140 - val_mae: 0.0796 - val_mse: 0.0140\n",
      "Elapsed time during model training:  45.77460241317749\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0508 - mae: 0.1495 - mse: 0.0508\n",
      "Epoch 00001: val_loss improved from inf to 0.02131, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0506,  mae:0.1493,  mse:0.0506,  val_loss:0.0213,  val_mae:0.1075,  val_mse:0.0213,  \n",
      "14926/14926 [==============================] - 2s 141us/sample - loss: 0.0506 - mae: 0.1493 - mse: 0.0506 - val_loss: 0.0213 - val_mae: 0.1075 - val_mse: 0.0213\n",
      "Epoch 2/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0230 - mae: 0.1110 - mse: 0.0230\n",
      "Epoch 00002: val_loss did not improve from 0.02131\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0231 - mae: 0.1111 - mse: 0.0231 - val_loss: 0.0251 - val_mae: 0.1242 - val_mse: 0.0251\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0205 - mae: 0.1034 - mse: 0.0205\n",
      "Epoch 00003: val_loss improved from 0.02131 to 0.01852, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0205 - mae: 0.1033 - mse: 0.0205 - val_loss: 0.0185 - val_mae: 0.0971 - val_mse: 0.0185\n",
      "Epoch 4/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0196 - mae: 0.1012 - mse: 0.0196\n",
      "Epoch 00004: val_loss did not improve from 0.01852\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0196 - mae: 0.1012 - mse: 0.0196 - val_loss: 0.0207 - val_mae: 0.1048 - val_mse: 0.0207\n",
      "Epoch 5/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0969 - mse: 0.0181\n",
      "Epoch 00005: val_loss improved from 0.01852 to 0.01700, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0181 - mae: 0.0970 - mse: 0.0181 - val_loss: 0.0170 - val_mae: 0.0958 - val_mse: 0.0170\n",
      "Epoch 6/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0176 - mae: 0.0958 - mse: 0.0176\n",
      "Epoch 00006: val_loss did not improve from 0.01700\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0176 - mae: 0.0958 - mse: 0.0176 - val_loss: 0.0171 - val_mae: 0.0953 - val_mse: 0.0171\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0943 - mse: 0.0174\n",
      "Epoch 00007: val_loss did not improve from 0.01700\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0174 - mae: 0.0943 - mse: 0.0174 - val_loss: 0.0177 - val_mae: 0.0951 - val_mse: 0.0177\n",
      "Epoch 8/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0917 - mse: 0.0166\n",
      "Epoch 00008: val_loss improved from 0.01700 to 0.01548, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0165 - mae: 0.0915 - mse: 0.0165 - val_loss: 0.0155 - val_mae: 0.0867 - val_mse: 0.0155\n",
      "Epoch 9/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0160 - mae: 0.0905 - mse: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.01548\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0160 - mae: 0.0903 - mse: 0.0160 - val_loss: 0.0176 - val_mae: 0.0913 - val_mse: 0.0176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0869 - mse: 0.0152\n",
      "Epoch 00010: val_loss did not improve from 0.01548\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0152 - mae: 0.0869 - mse: 0.0152 - val_loss: 0.0157 - val_mae: 0.0898 - val_mse: 0.0157\n",
      "Epoch 11/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0153 - mae: 0.0874 - mse: 0.0153\n",
      "Epoch 00011: val_loss did not improve from 0.01548\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0151 - mae: 0.0872 - mse: 0.0151 - val_loss: 0.0169 - val_mae: 0.0915 - val_mse: 0.0169\n",
      "Epoch 12/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0851 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01548\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0145 - mae: 0.0851 - mse: 0.0145 - val_loss: 0.0158 - val_mae: 0.0876 - val_mse: 0.0158\n",
      "Epoch 13/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0879 - mse: 0.0152\n",
      "Epoch 00013: val_loss improved from 0.01548 to 0.01443, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0151 - mae: 0.0878 - mse: 0.0151 - val_loss: 0.0144 - val_mae: 0.0829 - val_mse: 0.0144\n",
      "Epoch 14/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0824 - mse: 0.0136\n",
      "Epoch 00014: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0136 - mae: 0.0824 - mse: 0.0136 - val_loss: 0.0145 - val_mae: 0.0850 - val_mse: 0.0145\n",
      "Epoch 15/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0827 - mse: 0.0138\n",
      "Epoch 00015: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0139 - mae: 0.0827 - mse: 0.0139 - val_loss: 0.0149 - val_mae: 0.0833 - val_mse: 0.0149\n",
      "Epoch 16/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0799 - mse: 0.0130\n",
      "Epoch 00016: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0131 - mae: 0.0802 - mse: 0.0131 - val_loss: 0.0153 - val_mae: 0.0861 - val_mse: 0.0153\n",
      "Epoch 17/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0835 - mse: 0.0140\n",
      "Epoch 00017: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0140 - mae: 0.0834 - mse: 0.0140 - val_loss: 0.0146 - val_mae: 0.0819 - val_mse: 0.0146\n",
      "Epoch 18/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0799 - mse: 0.0130\n",
      "Epoch 00018: val_loss improved from 0.01443 to 0.01431, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0129 - mae: 0.0796 - mse: 0.0129 - val_loss: 0.0143 - val_mae: 0.0820 - val_mse: 0.0143\n",
      "Epoch 19/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0785 - mse: 0.0124\n",
      "Epoch 00019: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0124 - mae: 0.0785 - mse: 0.0124 - val_loss: 0.0168 - val_mae: 0.0919 - val_mse: 0.0168\n",
      "Epoch 20/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0752 - mse: 0.0118\n",
      "Epoch 00020: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0119 - mae: 0.0754 - mse: 0.0119 - val_loss: 0.0167 - val_mae: 0.0908 - val_mse: 0.0167\n",
      "Epoch 21/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0757 - mse: 0.0118\n",
      "Epoch 00021: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0118 - mae: 0.0758 - mse: 0.0118 - val_loss: 0.0231 - val_mae: 0.1145 - val_mse: 0.0231\n",
      "Epoch 22/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0120 - mae: 0.0767 - mse: 0.0120\n",
      "Epoch 00022: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0120 - mae: 0.0768 - mse: 0.0120 - val_loss: 0.0158 - val_mae: 0.0885 - val_mse: 0.0158\n",
      "Epoch 23/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0735 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0111 - mae: 0.0734 - mse: 0.0111 - val_loss: 0.0162 - val_mae: 0.0878 - val_mse: 0.0162\n",
      "Epoch 24/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0764 - mse: 0.0117\n",
      "Epoch 00024: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0117 - mae: 0.0763 - mse: 0.0117 - val_loss: 0.0150 - val_mae: 0.0834 - val_mse: 0.0150\n",
      "Epoch 25/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0753 - mse: 0.0114\n",
      "Epoch 00025: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0114 - mae: 0.0753 - mse: 0.0114 - val_loss: 0.0162 - val_mae: 0.0901 - val_mse: 0.0162\n",
      "Epoch 26/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0110 - mae: 0.0730 - mse: 0.0110\n",
      "Epoch 00026: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0109 - mae: 0.0730 - mse: 0.0109 - val_loss: 0.0166 - val_mae: 0.0938 - val_mse: 0.0166\n",
      "Epoch 27/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0731 - mse: 0.0108\n",
      "Epoch 00027: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0108 - mae: 0.0731 - mse: 0.0108 - val_loss: 0.0170 - val_mae: 0.0894 - val_mse: 0.0170\n",
      "Epoch 28/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0704 - mse: 0.0101\n",
      "Epoch 00028: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0104 - mae: 0.0709 - mse: 0.0104 - val_loss: 0.0168 - val_mae: 0.0928 - val_mse: 0.0168\n",
      "Epoch 29/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0717 - mse: 0.0105\n",
      "Epoch 00029: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0105 - mae: 0.0717 - mse: 0.0105 - val_loss: 0.0148 - val_mae: 0.0820 - val_mse: 0.0148\n",
      "Epoch 30/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0709 - mse: 0.0103\n",
      "Epoch 00030: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0103 - mae: 0.0709 - mse: 0.0103 - val_loss: 0.0189 - val_mae: 0.0934 - val_mse: 0.0189\n",
      "Epoch 31/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0688 - mse: 0.0096\n",
      "Epoch 00031: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0097 - mae: 0.0690 - mse: 0.0097 - val_loss: 0.0180 - val_mae: 0.1001 - val_mse: 0.0180\n",
      "Elapsed time during model training:  42.22848105430603\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0444 - mae: 0.1479 - mse: 0.0444\n",
      "Epoch 00001: val_loss improved from inf to 0.02921, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0440,  mae:0.1473,  mse:0.0440,  val_loss:0.0292,  val_mae:0.1284,  val_mse:0.0292,  \n",
      "14926/14926 [==============================] - 2s 139us/sample - loss: 0.0440 - mae: 0.1473 - mse: 0.0440 - val_loss: 0.0292 - val_mae: 0.1284 - val_mse: 0.0292\n",
      "Epoch 2/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0227 - mae: 0.1100 - mse: 0.0227\n",
      "Epoch 00002: val_loss improved from 0.02921 to 0.02332, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0227 - mae: 0.1101 - mse: 0.0227 - val_loss: 0.0233 - val_mae: 0.1125 - val_mse: 0.0233\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0212 - mae: 0.1057 - mse: 0.0212\n",
      "Epoch 00003: val_loss improved from 0.02332 to 0.01772, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0211 - mae: 0.1057 - mse: 0.0211 - val_loss: 0.0177 - val_mae: 0.0961 - val_mse: 0.0177\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0197 - mae: 0.1021 - mse: 0.0197\n",
      "Epoch 00004: val_loss did not improve from 0.01772\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0197 - mae: 0.1021 - mse: 0.0197 - val_loss: 0.0199 - val_mae: 0.0990 - val_mse: 0.0199\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0961 - mse: 0.0174\n",
      "Epoch 00005: val_loss did not improve from 0.01772\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0179 - mae: 0.0967 - mse: 0.0179 - val_loss: 0.0181 - val_mae: 0.0968 - val_mse: 0.0181\n",
      "Epoch 6/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.0963 - mse: 0.0180\n",
      "Epoch 00006: val_loss improved from 0.01772 to 0.01756, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0179 - mae: 0.0960 - mse: 0.0179 - val_loss: 0.0176 - val_mae: 0.0955 - val_mse: 0.0176\n",
      "Epoch 7/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0165 - mae: 0.0930 - mse: 0.0165\n",
      "Epoch 00007: val_loss did not improve from 0.01756\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0169 - mae: 0.0933 - mse: 0.0169 - val_loss: 0.0223 - val_mae: 0.1099 - val_mse: 0.0223\n",
      "Epoch 8/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0918 - mse: 0.0165\n",
      "Epoch 00008: val_loss improved from 0.01756 to 0.01686, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0165 - mae: 0.0918 - mse: 0.0165 - val_loss: 0.0169 - val_mae: 0.0963 - val_mse: 0.0169\n",
      "Epoch 9/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0905 - mse: 0.0159\n",
      "Epoch 00009: val_loss improved from 0.01686 to 0.01649, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0159 - mae: 0.0903 - mse: 0.0159 - val_loss: 0.0165 - val_mae: 0.0895 - val_mse: 0.0165\n",
      "Epoch 10/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0901 - mse: 0.0158\n",
      "Epoch 00010: val_loss improved from 0.01649 to 0.01615, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0158 - mae: 0.0900 - mse: 0.0158 - val_loss: 0.0162 - val_mae: 0.0875 - val_mse: 0.0162\n",
      "Epoch 11/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0857 - mse: 0.0147\n",
      "Epoch 00011: val_loss improved from 0.01615 to 0.01550, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0146 - mae: 0.0855 - mse: 0.0146 - val_loss: 0.0155 - val_mae: 0.0841 - val_mse: 0.0155\n",
      "Epoch 12/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0856 - mse: 0.0143\n",
      "Epoch 00012: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0142 - mae: 0.0855 - mse: 0.0142 - val_loss: 0.0158 - val_mae: 0.0891 - val_mse: 0.0158\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0828 - mse: 0.0135\n",
      "Epoch 00013: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0135 - mae: 0.0828 - mse: 0.0135 - val_loss: 0.0170 - val_mae: 0.0923 - val_mse: 0.0170\n",
      "Epoch 14/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0835 - mse: 0.0137\n",
      "Epoch 00014: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0137 - mae: 0.0835 - mse: 0.0137 - val_loss: 0.0164 - val_mae: 0.0893 - val_mse: 0.0164\n",
      "Epoch 15/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0806 - mse: 0.0130\n",
      "Epoch 00015: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0130 - mae: 0.0806 - mse: 0.0130 - val_loss: 0.0167 - val_mae: 0.0930 - val_mse: 0.0167\n",
      "Epoch 16/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0807 - mse: 0.0129\n",
      "Epoch 00016: val_loss improved from 0.01550 to 0.01412, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 127us/sample - loss: 0.0129 - mae: 0.0806 - mse: 0.0129 - val_loss: 0.0141 - val_mae: 0.0822 - val_mse: 0.0141\n",
      "Epoch 17/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0771 - mse: 0.0118\n",
      "Epoch 00017: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0122 - mae: 0.0775 - mse: 0.0122 - val_loss: 0.0207 - val_mae: 0.1095 - val_mse: 0.0207\n",
      "Epoch 18/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0789 - mse: 0.0124\n",
      "Epoch 00018: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0124 - mae: 0.0790 - mse: 0.0124 - val_loss: 0.0151 - val_mae: 0.0843 - val_mse: 0.0151\n",
      "Epoch 19/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0779 - mse: 0.0121\n",
      "Epoch 00019: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0122 - mae: 0.0780 - mse: 0.0122 - val_loss: 0.0174 - val_mae: 0.0970 - val_mse: 0.0174\n",
      "Epoch 20/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0119 - mae: 0.0775 - mse: 0.0119\n",
      "Epoch 00020: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0119 - mae: 0.0774 - mse: 0.0119 - val_loss: 0.0154 - val_mae: 0.0932 - val_mse: 0.0154\n",
      "Epoch 21/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0741 - mse: 0.0112\n",
      "Epoch 00021: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0112 - mae: 0.0742 - mse: 0.0112 - val_loss: 0.0163 - val_mae: 0.0879 - val_mse: 0.0163\n",
      "Epoch 22/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0754 - mse: 0.0113\n",
      "Epoch 00022: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0112 - mae: 0.0753 - mse: 0.0112 - val_loss: 0.0155 - val_mae: 0.0845 - val_mse: 0.0155\n",
      "Epoch 23/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0735 - mse: 0.0108\n",
      "Epoch 00023: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0108 - mae: 0.0736 - mse: 0.0108 - val_loss: 0.0200 - val_mae: 0.1097 - val_mse: 0.0200\n",
      "Elapsed time during model training:  33.58852243423462\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0446 - mae: 0.1461 - mse: 0.0446\n",
      "Epoch 00001: val_loss improved from inf to 0.01975, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0443,  mae:0.1456,  mse:0.0443,  val_loss:0.0197,  val_mae:0.1036,  val_mse:0.0197,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0443 - mae: 0.1456 - mse: 0.0443 - val_loss: 0.0197 - val_mae: 0.1036 - val_mse: 0.0197\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1087 - mse: 0.0221\n",
      "Epoch 00002: val_loss did not improve from 0.01975\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0222 - mae: 0.1090 - mse: 0.0222 - val_loss: 0.0250 - val_mae: 0.1145 - val_mse: 0.0250\n",
      "Epoch 3/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0209 - mae: 0.1053 - mse: 0.0209\n",
      "Epoch 00003: val_loss did not improve from 0.01975\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0209 - mae: 0.1052 - mse: 0.0209 - val_loss: 0.0217 - val_mae: 0.1074 - val_mse: 0.0217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0190 - mae: 0.0993 - mse: 0.0190\n",
      "Epoch 00004: val_loss did not improve from 0.01975\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0190 - mae: 0.0993 - mse: 0.0190 - val_loss: 0.0204 - val_mae: 0.1030 - val_mse: 0.0204\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0975 - mse: 0.0184\n",
      "Epoch 00005: val_loss did not improve from 0.01975\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0185 - mae: 0.0980 - mse: 0.0185 - val_loss: 0.0245 - val_mae: 0.1247 - val_mse: 0.0245\n",
      "Epoch 6/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0176 - mae: 0.0958 - mse: 0.0176\n",
      "Epoch 00006: val_loss did not improve from 0.01975\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0176 - mae: 0.0960 - mse: 0.0176 - val_loss: 0.0206 - val_mae: 0.1098 - val_mse: 0.0206\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0934 - mse: 0.0168\n",
      "Epoch 00007: val_loss improved from 0.01975 to 0.01574, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0168 - mae: 0.0934 - mse: 0.0168 - val_loss: 0.0157 - val_mae: 0.0868 - val_mse: 0.0157\n",
      "Epoch 8/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0916 - mse: 0.0164\n",
      "Epoch 00008: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0163 - mae: 0.0915 - mse: 0.0163 - val_loss: 0.0169 - val_mae: 0.0895 - val_mse: 0.0169\n",
      "Epoch 9/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.0897 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0155 - mae: 0.0898 - mse: 0.0155 - val_loss: 0.0214 - val_mae: 0.1113 - val_mse: 0.0214\n",
      "Epoch 10/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0154 - mae: 0.0887 - mse: 0.0154\n",
      "Epoch 00010: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0156 - mae: 0.0893 - mse: 0.0156 - val_loss: 0.0201 - val_mae: 0.1064 - val_mse: 0.0201\n",
      "Epoch 11/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0837 - mse: 0.0141\n",
      "Epoch 00011: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0141 - mae: 0.0836 - mse: 0.0141 - val_loss: 0.0160 - val_mae: 0.0922 - val_mse: 0.0160\n",
      "Epoch 12/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0143 - mae: 0.0849 - mse: 0.0143\n",
      "Epoch 00012: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0143 - mae: 0.0852 - mse: 0.0143 - val_loss: 0.0189 - val_mae: 0.1046 - val_mse: 0.0189\n",
      "Epoch 13/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0839 - mse: 0.0141\n",
      "Epoch 00013: val_loss did not improve from 0.01574\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0140 - mae: 0.0837 - mse: 0.0140 - val_loss: 0.0175 - val_mae: 0.0956 - val_mse: 0.0175\n",
      "Epoch 14/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0825 - mse: 0.0135\n",
      "Epoch 00014: val_loss improved from 0.01574 to 0.01504, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0135 - mae: 0.0825 - mse: 0.0135 - val_loss: 0.0150 - val_mae: 0.0860 - val_mse: 0.0150\n",
      "Epoch 15/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0132 - mae: 0.0811 - mse: 0.0132\n",
      "Epoch 00015: val_loss did not improve from 0.01504\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0131 - mae: 0.0809 - mse: 0.0131 - val_loss: 0.0167 - val_mae: 0.0954 - val_mse: 0.0167\n",
      "Epoch 16/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0783 - mse: 0.0125\n",
      "Epoch 00016: val_loss did not improve from 0.01504\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0125 - mae: 0.0783 - mse: 0.0125 - val_loss: 0.0162 - val_mae: 0.0896 - val_mse: 0.0162\n",
      "Epoch 17/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0126 - mae: 0.0801 - mse: 0.0126\n",
      "Epoch 00017: val_loss did not improve from 0.01504\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0125 - mae: 0.0798 - mse: 0.0125 - val_loss: 0.0161 - val_mae: 0.0893 - val_mse: 0.0161\n",
      "Epoch 18/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0772 - mse: 0.0120\n",
      "Epoch 00018: val_loss improved from 0.01504 to 0.01439, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0120 - mae: 0.0771 - mse: 0.0120 - val_loss: 0.0144 - val_mae: 0.0821 - val_mse: 0.0144\n",
      "Epoch 19/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0755 - mse: 0.0117\n",
      "Epoch 00019: val_loss did not improve from 0.01439\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0118 - mae: 0.0759 - mse: 0.0118 - val_loss: 0.0169 - val_mae: 0.0887 - val_mse: 0.0169\n",
      "Epoch 20/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0761 - mse: 0.0116\n",
      "Epoch 00020: val_loss improved from 0.01439 to 0.01427, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0116 - mae: 0.0760 - mse: 0.0116 - val_loss: 0.0143 - val_mae: 0.0837 - val_mse: 0.0143\n",
      "Epoch 21/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0735 - mse: 0.0109\n",
      "Epoch 00021: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0109 - mae: 0.0735 - mse: 0.0109 - val_loss: 0.0157 - val_mae: 0.0861 - val_mse: 0.0157\n",
      "Epoch 22/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0740 - mse: 0.0111\n",
      "Epoch 00022: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0152 - val_mae: 0.0877 - val_mse: 0.0152\n",
      "Epoch 23/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0723 - mse: 0.0106\n",
      "Epoch 00023: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0106 - mae: 0.0723 - mse: 0.0106 - val_loss: 0.0165 - val_mae: 0.0899 - val_mse: 0.0165\n",
      "Epoch 24/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0710 - mse: 0.0102\n",
      "Epoch 00024: val_loss improved from 0.01427 to 0.01396, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0102 - mae: 0.0710 - mse: 0.0102 - val_loss: 0.0140 - val_mae: 0.0789 - val_mse: 0.0140\n",
      "Epoch 25/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0098 - mae: 0.0694 - mse: 0.0098\n",
      "Epoch 00025: val_loss did not improve from 0.01396\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0098 - mae: 0.0697 - mse: 0.0098 - val_loss: 0.0147 - val_mae: 0.0845 - val_mse: 0.0147\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0710 - mse: 0.0101\n",
      "Epoch 00026: val_loss did not improve from 0.01396\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0711 - mse: 0.0101 - val_loss: 0.0169 - val_mae: 0.0929 - val_mse: 0.0169\n",
      "Epoch 27/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0703 - mse: 0.0101\n",
      "Epoch 00027: val_loss did not improve from 0.01396\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0101 - mae: 0.0702 - mse: 0.0101 - val_loss: 0.0141 - val_mae: 0.0783 - val_mse: 0.0141\n",
      "Epoch 28/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0688 - mse: 0.0096\n",
      "Epoch 00028: val_loss improved from 0.01396 to 0.01372, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0096 - mae: 0.0688 - mse: 0.0096 - val_loss: 0.0137 - val_mae: 0.0802 - val_mse: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0667 - mse: 0.0091\n",
      "Epoch 00029: val_loss did not improve from 0.01372\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0091 - mae: 0.0667 - mse: 0.0091 - val_loss: 0.0153 - val_mae: 0.0868 - val_mse: 0.0153\n",
      "Epoch 30/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00030: val_loss did not improve from 0.01372\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0089 - mae: 0.0661 - mse: 0.0089 - val_loss: 0.0159 - val_mae: 0.0861 - val_mse: 0.0159\n",
      "Epoch 31/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0658 - mse: 0.0088\n",
      "Epoch 00031: val_loss improved from 0.01372 to 0.01371, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0137 - val_mae: 0.0783 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0652 - mse: 0.0088\n",
      "Epoch 00032: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0088 - mae: 0.0652 - mse: 0.0088 - val_loss: 0.0144 - val_mae: 0.0812 - val_mse: 0.0144\n",
      "Epoch 33/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0650 - mse: 0.0086\n",
      "Epoch 00033: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0087 - mae: 0.0655 - mse: 0.0087 - val_loss: 0.0142 - val_mae: 0.0807 - val_mse: 0.0142\n",
      "Epoch 34/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0665 - mse: 0.0088\n",
      "Epoch 00034: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0088 - mae: 0.0664 - mse: 0.0088 - val_loss: 0.0147 - val_mae: 0.0853 - val_mse: 0.0147\n",
      "Epoch 35/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0638 - mse: 0.0083\n",
      "Epoch 00035: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0138 - val_mae: 0.0785 - val_mse: 0.0138\n",
      "Epoch 36/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0649 - mse: 0.0086\n",
      "Epoch 00036: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0085 - mae: 0.0649 - mse: 0.0085 - val_loss: 0.0144 - val_mae: 0.0817 - val_mse: 0.0144\n",
      "Epoch 37/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0627 - mse: 0.0081\n",
      "Epoch 00037: val_loss improved from 0.01371 to 0.01336, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0081 - mae: 0.0626 - mse: 0.0081 - val_loss: 0.0134 - val_mae: 0.0768 - val_mse: 0.0134\n",
      "Epoch 38/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0077 - mae: 0.0619 - mse: 0.0077\n",
      "Epoch 00038: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0077 - mae: 0.0618 - mse: 0.0077 - val_loss: 0.0140 - val_mae: 0.0806 - val_mse: 0.0140\n",
      "Epoch 39/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0615 - mse: 0.0076\n",
      "Epoch 00039: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0076 - mae: 0.0614 - mse: 0.0076 - val_loss: 0.0138 - val_mae: 0.0805 - val_mse: 0.0138\n",
      "Epoch 40/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0070 - mae: 0.0595 - mse: 0.0070\n",
      "Epoch 00040: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0073 - mae: 0.0600 - mse: 0.0073 - val_loss: 0.0138 - val_mae: 0.0781 - val_mse: 0.0138\n",
      "Epoch 41/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00041: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0073 - mae: 0.0601 - mse: 0.0073 - val_loss: 0.0180 - val_mae: 0.0972 - val_mse: 0.0180\n",
      "Epoch 42/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0627 - mse: 0.0078\n",
      "Epoch 00042: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0078 - mae: 0.0629 - mse: 0.0078 - val_loss: 0.0166 - val_mae: 0.0884 - val_mse: 0.0166\n",
      "Epoch 43/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0614 - mse: 0.0075\n",
      "Epoch 00043: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0075 - mae: 0.0614 - mse: 0.0075 - val_loss: 0.0171 - val_mae: 0.0895 - val_mse: 0.0171\n",
      "Epoch 44/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0583 - mse: 0.0069\n",
      "Epoch 00044: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0069 - mae: 0.0583 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0782 - val_mse: 0.0139\n",
      "Epoch 45/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0569 - mse: 0.0065\n",
      "Epoch 00045: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0065 - mae: 0.0570 - mse: 0.0065 - val_loss: 0.0143 - val_mae: 0.0806 - val_mse: 0.0143\n",
      "Epoch 46/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0587 - mse: 0.0071\n",
      "Epoch 00046: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0071 - mae: 0.0588 - mse: 0.0071 - val_loss: 0.0139 - val_mae: 0.0832 - val_mse: 0.0139\n",
      "Epoch 47/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0561 - mse: 0.0063\n",
      "Epoch 00047: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0063 - mae: 0.0562 - mse: 0.0063 - val_loss: 0.0137 - val_mae: 0.0807 - val_mse: 0.0137\n",
      "Epoch 48/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0576 - mse: 0.0067\n",
      "Epoch 00048: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0067 - mae: 0.0576 - mse: 0.0067 - val_loss: 0.0143 - val_mae: 0.0788 - val_mse: 0.0143\n",
      "Elapsed time during model training:  71.25012612342834\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0439 - mae: 0.1447 - mse: 0.0439\n",
      "Epoch 00001: val_loss improved from inf to 0.02507, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0433,  mae:0.1440,  mse:0.0433,  val_loss:0.0251,  val_mae:0.1194,  val_mse:0.0251,  \n",
      "14926/14926 [==============================] - 2s 142us/sample - loss: 0.0433 - mae: 0.1440 - mse: 0.0433 - val_loss: 0.0251 - val_mae: 0.1194 - val_mse: 0.0251\n",
      "Epoch 2/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0246 - mae: 0.1165 - mse: 0.0246\n",
      "Epoch 00002: val_loss did not improve from 0.02507\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0245 - mae: 0.1164 - mse: 0.0245 - val_loss: 0.0254 - val_mae: 0.1242 - val_mse: 0.0254\n",
      "Epoch 3/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1032 - mse: 0.0201\n",
      "Epoch 00003: val_loss improved from 0.02507 to 0.02431, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0203 - mae: 0.1035 - mse: 0.0203 - val_loss: 0.0243 - val_mae: 0.1179 - val_mse: 0.0243\n",
      "Epoch 4/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1043 - mse: 0.0202\n",
      "Epoch 00004: val_loss improved from 0.02431 to 0.01917, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0202 - mae: 0.1041 - mse: 0.0202 - val_loss: 0.0192 - val_mae: 0.1053 - val_mse: 0.0192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.0994 - mse: 0.0188\n",
      "Epoch 00005: val_loss improved from 0.01917 to 0.01850, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0187 - mae: 0.0994 - mse: 0.0187 - val_loss: 0.0185 - val_mae: 0.0974 - val_mse: 0.0185\n",
      "Epoch 6/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0971 - mse: 0.0181\n",
      "Epoch 00006: val_loss improved from 0.01850 to 0.01723, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0180 - mae: 0.0968 - mse: 0.0180 - val_loss: 0.0172 - val_mae: 0.0953 - val_mse: 0.0172\n",
      "Epoch 7/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0175 - mae: 0.0959 - mse: 0.0175\n",
      "Epoch 00007: val_loss improved from 0.01723 to 0.01677, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0176 - mae: 0.0959 - mse: 0.0176 - val_loss: 0.0168 - val_mae: 0.0901 - val_mse: 0.0168\n",
      "Epoch 8/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0165 - mae: 0.0921 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01677\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0167 - mae: 0.0927 - mse: 0.0167 - val_loss: 0.0176 - val_mae: 0.0954 - val_mse: 0.0176\n",
      "Epoch 9/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0178 - mae: 0.0965 - mse: 0.0178\n",
      "Epoch 00009: val_loss did not improve from 0.01677\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0176 - mae: 0.0963 - mse: 0.0176 - val_loss: 0.0191 - val_mae: 0.1019 - val_mse: 0.0191\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0901 - mse: 0.0160\n",
      "Epoch 00010: val_loss did not improve from 0.01677\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0160 - mae: 0.0901 - mse: 0.0160 - val_loss: 0.0213 - val_mae: 0.1115 - val_mse: 0.0213\n",
      "Epoch 11/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0872 - mse: 0.0150\n",
      "Epoch 00011: val_loss improved from 0.01677 to 0.01583, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0150 - mae: 0.0873 - mse: 0.0150 - val_loss: 0.0158 - val_mae: 0.0882 - val_mse: 0.0158\n",
      "Epoch 12/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0874 - mse: 0.0150\n",
      "Epoch 00012: val_loss did not improve from 0.01583\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0150 - mae: 0.0874 - mse: 0.0150 - val_loss: 0.0170 - val_mae: 0.0913 - val_mse: 0.0170\n",
      "Epoch 13/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0860 - mse: 0.0146\n",
      "Epoch 00013: val_loss improved from 0.01583 to 0.01579, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0147 - mae: 0.0864 - mse: 0.0147 - val_loss: 0.0158 - val_mae: 0.0872 - val_mse: 0.0158\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0847 - mse: 0.0143\n",
      "Epoch 00014: val_loss improved from 0.01579 to 0.01551, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0143 - mae: 0.0846 - mse: 0.0143 - val_loss: 0.0155 - val_mae: 0.0855 - val_mse: 0.0155\n",
      "Epoch 15/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0835 - mse: 0.0140\n",
      "Epoch 00015: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0140 - mae: 0.0836 - mse: 0.0140 - val_loss: 0.0178 - val_mae: 0.0980 - val_mse: 0.0178\n",
      "Epoch 16/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0818 - mse: 0.0134\n",
      "Epoch 00016: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0133 - mae: 0.0818 - mse: 0.0133 - val_loss: 0.0191 - val_mae: 0.0994 - val_mse: 0.0191\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0807 - mse: 0.0129\n",
      "Epoch 00017: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0130 - mae: 0.0807 - mse: 0.0130 - val_loss: 0.0162 - val_mae: 0.0937 - val_mse: 0.0162\n",
      "Epoch 18/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0793 - mse: 0.0126\n",
      "Epoch 00018: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0126 - mae: 0.0795 - mse: 0.0126 - val_loss: 0.0190 - val_mae: 0.0958 - val_mse: 0.0190\n",
      "Epoch 19/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0798 - mse: 0.0126\n",
      "Epoch 00019: val_loss did not improve from 0.01551\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0126 - mae: 0.0798 - mse: 0.0126 - val_loss: 0.0155 - val_mae: 0.0864 - val_mse: 0.0155\n",
      "Epoch 20/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0761 - mse: 0.0117\n",
      "Epoch 00020: val_loss improved from 0.01551 to 0.01467, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0147 - val_mae: 0.0836 - val_mse: 0.0147\n",
      "Epoch 21/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0763 - mse: 0.0117\n",
      "Epoch 00021: val_loss improved from 0.01467 to 0.01384, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0138 - val_mae: 0.0793 - val_mse: 0.0138\n",
      "Epoch 22/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0777 - mse: 0.0120\n",
      "Epoch 00022: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0120 - mae: 0.0777 - mse: 0.0120 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 23/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0743 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0110 - mae: 0.0742 - mse: 0.0110 - val_loss: 0.0149 - val_mae: 0.0841 - val_mse: 0.0149\n",
      "Epoch 24/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0743 - mse: 0.0110\n",
      "Epoch 00024: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0110 - mae: 0.0743 - mse: 0.0110 - val_loss: 0.0154 - val_mae: 0.0881 - val_mse: 0.0154\n",
      "Epoch 25/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0725 - mse: 0.0107\n",
      "Epoch 00025: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0107 - mae: 0.0726 - mse: 0.0107 - val_loss: 0.0153 - val_mae: 0.0865 - val_mse: 0.0153\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0732 - mse: 0.0107\n",
      "Epoch 00026: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0107 - mae: 0.0733 - mse: 0.0107 - val_loss: 0.0169 - val_mae: 0.0925 - val_mse: 0.0169\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0719 - mse: 0.0104\n",
      "Epoch 00027: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0103 - mae: 0.0717 - mse: 0.0103 - val_loss: 0.0142 - val_mae: 0.0813 - val_mse: 0.0142\n",
      "Epoch 28/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0696 - mse: 0.0099\n",
      "Epoch 00028: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0099 - mae: 0.0695 - mse: 0.0099 - val_loss: 0.0161 - val_mae: 0.0907 - val_mse: 0.0161\n",
      "Epoch 29/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0705 - mse: 0.0100\n",
      "Epoch 00029: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0100 - mae: 0.0704 - mse: 0.0100 - val_loss: 0.0143 - val_mae: 0.0813 - val_mse: 0.0143\n",
      "Epoch 30/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0677 - mse: 0.0095\n",
      "Epoch 00030: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0095 - mae: 0.0677 - mse: 0.0095 - val_loss: 0.0154 - val_mae: 0.0834 - val_mse: 0.0154\n",
      "Epoch 31/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0671 - mse: 0.0091\n",
      "Epoch 00031: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0094 - mae: 0.0674 - mse: 0.0094 - val_loss: 0.0166 - val_mae: 0.0916 - val_mse: 0.0166\n",
      "Epoch 32/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0094 - mae: 0.0687 - mse: 0.0094\n",
      "Epoch 00032: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0094 - mae: 0.0689 - mse: 0.0094 - val_loss: 0.0161 - val_mae: 0.0952 - val_mse: 0.0161\n",
      "Epoch 33/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0093 - mae: 0.0683 - mse: 0.0093\n",
      "Epoch 00033: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0093 - mae: 0.0685 - mse: 0.0093 - val_loss: 0.0155 - val_mae: 0.0863 - val_mse: 0.0155\n",
      "Epoch 34/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0666 - mse: 0.0089\n",
      "Epoch 00034: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0666 - mse: 0.0089 - val_loss: 0.0139 - val_mae: 0.0797 - val_mse: 0.0139\n",
      "Elapsed time during model training:  49.13976216316223\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0463 - mae: 0.1464 - mse: 0.0463\n",
      "Epoch 00001: val_loss improved from inf to 0.02642, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0456,  mae:0.1455,  mse:0.0456,  val_loss:0.0264,  val_mae:0.1257,  val_mse:0.0264,  \n",
      "14926/14926 [==============================] - 2s 140us/sample - loss: 0.0456 - mae: 0.1455 - mse: 0.0456 - val_loss: 0.0264 - val_mae: 0.1257 - val_mse: 0.0264\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0223 - mae: 0.1090 - mse: 0.0223\n",
      "Epoch 00002: val_loss improved from 0.02642 to 0.01831, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0222 - mae: 0.1088 - mse: 0.0222 - val_loss: 0.0183 - val_mae: 0.0963 - val_mse: 0.0183\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1026 - mse: 0.0201\n",
      "Epoch 00003: val_loss did not improve from 0.01831\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0201 - mae: 0.1026 - mse: 0.0201 - val_loss: 0.0218 - val_mae: 0.1135 - val_mse: 0.0218\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.0986 - mse: 0.0188\n",
      "Epoch 00004: val_loss did not improve from 0.01831\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0188 - mae: 0.0985 - mse: 0.0188 - val_loss: 0.0203 - val_mae: 0.1044 - val_mse: 0.0203\n",
      "Epoch 5/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0954 - mse: 0.0179\n",
      "Epoch 00005: val_loss improved from 0.01831 to 0.01757, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0180 - mae: 0.0956 - mse: 0.0180 - val_loss: 0.0176 - val_mae: 0.0937 - val_mse: 0.0176\n",
      "Epoch 6/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0935 - mse: 0.0172\n",
      "Epoch 00006: val_loss did not improve from 0.01757\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0173 - mae: 0.0939 - mse: 0.0173 - val_loss: 0.0204 - val_mae: 0.1056 - val_mse: 0.0204\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0930 - mse: 0.0170\n",
      "Epoch 00007: val_loss improved from 0.01757 to 0.01607, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0170 - mae: 0.0931 - mse: 0.0170 - val_loss: 0.0161 - val_mae: 0.0903 - val_mse: 0.0161\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0906 - mse: 0.0160\n",
      "Epoch 00008: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0159 - mae: 0.0905 - mse: 0.0159 - val_loss: 0.0172 - val_mae: 0.0944 - val_mse: 0.0172\n",
      "Epoch 9/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.0886 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0156 - mae: 0.0886 - mse: 0.0156 - val_loss: 0.0172 - val_mae: 0.0949 - val_mse: 0.0172\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0883 - mse: 0.0153\n",
      "Epoch 00010: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0152 - mae: 0.0882 - mse: 0.0152 - val_loss: 0.0195 - val_mae: 0.0921 - val_mse: 0.0195\n",
      "Epoch 11/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0858 - mse: 0.0145\n",
      "Epoch 00011: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0145 - mae: 0.0858 - mse: 0.0145 - val_loss: 0.0186 - val_mae: 0.1015 - val_mse: 0.0186\n",
      "Epoch 12/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0853 - mse: 0.0144\n",
      "Epoch 00012: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0144 - mae: 0.0853 - mse: 0.0144 - val_loss: 0.0176 - val_mae: 0.0937 - val_mse: 0.0176\n",
      "Epoch 13/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0834 - mse: 0.0138\n",
      "Epoch 00013: val_loss improved from 0.01607 to 0.01571, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0138 - mae: 0.0832 - mse: 0.0138 - val_loss: 0.0157 - val_mae: 0.0883 - val_mse: 0.0157\n",
      "Epoch 14/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0136 - mae: 0.0825 - mse: 0.0136\n",
      "Epoch 00014: val_loss improved from 0.01571 to 0.01536, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0135 - mae: 0.0822 - mse: 0.0135 - val_loss: 0.0154 - val_mae: 0.0873 - val_mse: 0.0154\n",
      "Epoch 15/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0819 - mse: 0.0135\n",
      "Epoch 00015: val_loss improved from 0.01536 to 0.01494, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0134 - mae: 0.0820 - mse: 0.0134 - val_loss: 0.0149 - val_mae: 0.0857 - val_mse: 0.0149\n",
      "Epoch 16/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0796 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01494\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0128 - mae: 0.0796 - mse: 0.0128 - val_loss: 0.0155 - val_mae: 0.0858 - val_mse: 0.0155\n",
      "Epoch 17/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0799 - mse: 0.0128\n",
      "Epoch 00017: val_loss improved from 0.01494 to 0.01433, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0128 - mae: 0.0800 - mse: 0.0128 - val_loss: 0.0143 - val_mae: 0.0835 - val_mse: 0.0143\n",
      "Epoch 18/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0782 - mse: 0.0121\n",
      "Epoch 00018: val_loss did not improve from 0.01433\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0121 - mae: 0.0781 - mse: 0.0121 - val_loss: 0.0152 - val_mae: 0.0871 - val_mse: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0774 - mse: 0.0121\n",
      "Epoch 00019: val_loss did not improve from 0.01433\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0121 - mae: 0.0775 - mse: 0.0121 - val_loss: 0.0173 - val_mae: 0.0930 - val_mse: 0.0173\n",
      "Epoch 20/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0759 - mse: 0.0117\n",
      "Epoch 00020: val_loss improved from 0.01433 to 0.01351, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0117 - mae: 0.0759 - mse: 0.0117 - val_loss: 0.0135 - val_mae: 0.0788 - val_mse: 0.0135\n",
      "Epoch 21/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0121 - mae: 0.0779 - mse: 0.0121\n",
      "Epoch 00021: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0120 - mae: 0.0780 - mse: 0.0120 - val_loss: 0.0145 - val_mae: 0.0825 - val_mse: 0.0145\n",
      "Epoch 22/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0746 - mse: 0.0113\n",
      "Epoch 00022: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0112 - mae: 0.0745 - mse: 0.0112 - val_loss: 0.0151 - val_mae: 0.0817 - val_mse: 0.0151\n",
      "Epoch 23/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0746 - mse: 0.0112\n",
      "Epoch 00023: val_loss improved from 0.01351 to 0.01326, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0112 - mae: 0.0744 - mse: 0.0112 - val_loss: 0.0133 - val_mae: 0.0778 - val_mse: 0.0133\n",
      "Epoch 24/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00024: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0110 - mae: 0.0738 - mse: 0.0110 - val_loss: 0.0141 - val_mae: 0.0824 - val_mse: 0.0141\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0722 - mse: 0.0105\n",
      "Epoch 00025: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0106 - mae: 0.0725 - mse: 0.0106 - val_loss: 0.0151 - val_mae: 0.0863 - val_mse: 0.0151\n",
      "Epoch 26/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0100 - mae: 0.0702 - mse: 0.0100\n",
      "Epoch 00026: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0706 - mse: 0.0101 - val_loss: 0.0149 - val_mae: 0.0857 - val_mse: 0.0149\n",
      "Epoch 27/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0708 - mse: 0.0102\n",
      "Epoch 00027: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0101 - mae: 0.0708 - mse: 0.0101 - val_loss: 0.0148 - val_mae: 0.0830 - val_mse: 0.0148\n",
      "Epoch 28/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0707 - mse: 0.0101\n",
      "Epoch 00028: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0158 - val_mae: 0.0861 - val_mse: 0.0158\n",
      "Epoch 29/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0691 - mse: 0.0098\n",
      "Epoch 00029: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0097 - mae: 0.0690 - mse: 0.0097 - val_loss: 0.0136 - val_mae: 0.0778 - val_mse: 0.0136\n",
      "Epoch 30/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0696 - mse: 0.0098\n",
      "Epoch 00030: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0098 - mae: 0.0696 - mse: 0.0098 - val_loss: 0.0136 - val_mae: 0.0777 - val_mse: 0.0136\n",
      "Epoch 31/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0691 - mse: 0.0095\n",
      "Epoch 00031: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0095 - mae: 0.0691 - mse: 0.0095 - val_loss: 0.0140 - val_mae: 0.0811 - val_mse: 0.0140\n",
      "Epoch 32/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0662 - mse: 0.0090\n",
      "Epoch 00032: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0089 - mae: 0.0662 - mse: 0.0089 - val_loss: 0.0148 - val_mae: 0.0846 - val_mse: 0.0148\n",
      "Epoch 33/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0669 - mse: 0.0091\n",
      "Epoch 00033: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0091 - mae: 0.0670 - mse: 0.0091 - val_loss: 0.0152 - val_mae: 0.0812 - val_mse: 0.0152\n",
      "Epoch 34/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0667 - mse: 0.0090\n",
      "Epoch 00034: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0089 - mae: 0.0666 - mse: 0.0089 - val_loss: 0.0146 - val_mae: 0.0824 - val_mse: 0.0146\n",
      "Elapsed time during model training:  48.414018392562866\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0499 - mae: 0.1516 - mse: 0.0499\n",
      "Epoch 00001: val_loss improved from inf to 0.02137, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0492,  mae:0.1506,  mse:0.0492,  val_loss:0.0214,  val_mae:0.1040,  val_mse:0.0214,  \n",
      "14926/14926 [==============================] - 2s 153us/sample - loss: 0.0492 - mae: 0.1506 - mse: 0.0492 - val_loss: 0.0214 - val_mae: 0.1040 - val_mse: 0.0214\n",
      "Epoch 2/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0224 - mae: 0.1089 - mse: 0.0224\n",
      "Epoch 00002: val_loss improved from 0.02137 to 0.02006, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0224 - mae: 0.1089 - mse: 0.0224 - val_loss: 0.0201 - val_mae: 0.1016 - val_mse: 0.0201\n",
      "Epoch 3/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0207 - mae: 0.1043 - mse: 0.0207\n",
      "Epoch 00003: val_loss did not improve from 0.02006\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0207 - mae: 0.1044 - mse: 0.0207 - val_loss: 0.0224 - val_mae: 0.1125 - val_mse: 0.0224\n",
      "Epoch 4/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0192 - mae: 0.0999 - mse: 0.0192\n",
      "Epoch 00004: val_loss did not improve from 0.02006\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0193 - mae: 0.0999 - mse: 0.0193 - val_loss: 0.0214 - val_mae: 0.1066 - val_mse: 0.0214\n",
      "Epoch 5/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0963 - mse: 0.0183\n",
      "Epoch 00005: val_loss improved from 0.02006 to 0.01553, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0181 - mae: 0.0958 - mse: 0.0181 - val_loss: 0.0155 - val_mae: 0.0873 - val_mse: 0.0155\n",
      "Epoch 6/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0931 - mse: 0.0171\n",
      "Epoch 00006: val_loss did not improve from 0.01553\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0172 - mae: 0.0933 - mse: 0.0172 - val_loss: 0.0185 - val_mae: 0.0981 - val_mse: 0.0185\n",
      "Epoch 7/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0925 - mse: 0.0168\n",
      "Epoch 00007: val_loss did not improve from 0.01553\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0168 - mae: 0.0927 - mse: 0.0168 - val_loss: 0.0257 - val_mae: 0.1218 - val_mse: 0.0257\n",
      "Epoch 8/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0167 - mae: 0.0916 - mse: 0.0167\n",
      "Epoch 00008: val_loss did not improve from 0.01553\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0165 - mae: 0.0911 - mse: 0.0165 - val_loss: 0.0166 - val_mae: 0.0910 - val_mse: 0.0166\n",
      "Epoch 9/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0901 - mse: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.01553\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0160 - mae: 0.0901 - mse: 0.0160 - val_loss: 0.0176 - val_mae: 0.0959 - val_mse: 0.0176\n",
      "Epoch 10/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0155 - mae: 0.0887 - mse: 0.0155\n",
      "Epoch 00010: val_loss did not improve from 0.01553\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0154 - mae: 0.0885 - mse: 0.0154 - val_loss: 0.0172 - val_mae: 0.0910 - val_mse: 0.0172\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0856 - mse: 0.0147\n",
      "Epoch 00011: val_loss improved from 0.01553 to 0.01484, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0146 - mae: 0.0855 - mse: 0.0146 - val_loss: 0.0148 - val_mae: 0.0840 - val_mse: 0.0148\n",
      "Epoch 12/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0849 - mse: 0.0143\n",
      "Epoch 00012: val_loss did not improve from 0.01484\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0143 - mae: 0.0849 - mse: 0.0143 - val_loss: 0.0159 - val_mae: 0.0876 - val_mse: 0.0159\n",
      "Epoch 13/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0837 - mse: 0.0141\n",
      "Epoch 00013: val_loss improved from 0.01484 to 0.01482, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0141 - mae: 0.0837 - mse: 0.0141 - val_loss: 0.0148 - val_mae: 0.0852 - val_mse: 0.0148\n",
      "Epoch 14/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0845 - mse: 0.0142\n",
      "Epoch 00014: val_loss did not improve from 0.01482\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0143 - mae: 0.0846 - mse: 0.0143 - val_loss: 0.0171 - val_mae: 0.0890 - val_mse: 0.0171\n",
      "Epoch 15/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0842 - mse: 0.0141\n",
      "Epoch 00015: val_loss did not improve from 0.01482\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0140 - mae: 0.0838 - mse: 0.0140 - val_loss: 0.0163 - val_mae: 0.0854 - val_mse: 0.0163\n",
      "Epoch 16/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0789 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01482\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0128 - mae: 0.0789 - mse: 0.0128 - val_loss: 0.0163 - val_mae: 0.0916 - val_mse: 0.0163\n",
      "Epoch 17/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0791 - mse: 0.0126\n",
      "Epoch 00017: val_loss improved from 0.01482 to 0.01392, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0126 - mae: 0.0791 - mse: 0.0126 - val_loss: 0.0139 - val_mae: 0.0797 - val_mse: 0.0139\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0793 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01392\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0127 - mae: 0.0795 - mse: 0.0127 - val_loss: 0.0171 - val_mae: 0.0954 - val_mse: 0.0171\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0769 - mse: 0.0121\n",
      "Epoch 00019: val_loss improved from 0.01392 to 0.01387, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0121 - mae: 0.0768 - mse: 0.0121 - val_loss: 0.0139 - val_mae: 0.0785 - val_mse: 0.0139\n",
      "Epoch 20/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0119 - mae: 0.0769 - mse: 0.0119\n",
      "Epoch 00020: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0119 - mae: 0.0770 - mse: 0.0119 - val_loss: 0.0163 - val_mae: 0.0860 - val_mse: 0.0163\n",
      "Epoch 21/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0761 - mse: 0.0114\n",
      "Epoch 00021: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0118 - mae: 0.0763 - mse: 0.0118 - val_loss: 0.0179 - val_mae: 0.1023 - val_mse: 0.0179\n",
      "Epoch 22/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0746 - mse: 0.0113\n",
      "Epoch 00022: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0113 - mae: 0.0747 - mse: 0.0113 - val_loss: 0.0142 - val_mae: 0.0794 - val_mse: 0.0142\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0743 - mse: 0.0113\n",
      "Epoch 00023: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0112 - mae: 0.0740 - mse: 0.0112 - val_loss: 0.0152 - val_mae: 0.0840 - val_mse: 0.0152\n",
      "Epoch 24/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0732 - mse: 0.0108\n",
      "Epoch 00024: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0149 - val_mae: 0.0863 - val_mse: 0.0149\n",
      "Epoch 25/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0725 - mse: 0.0108\n",
      "Epoch 00025: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0108 - mae: 0.0726 - mse: 0.0108 - val_loss: 0.0153 - val_mae: 0.0851 - val_mse: 0.0153\n",
      "Epoch 26/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0744 - mse: 0.0111\n",
      "Epoch 00026: val_loss did not improve from 0.01387\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0111 - mae: 0.0744 - mse: 0.0111 - val_loss: 0.0145 - val_mae: 0.0846 - val_mse: 0.0145\n",
      "Elapsed time during model training:  38.111955642700195\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0515 - mae: 0.1540 - mse: 0.0515\n",
      "Epoch 00001: val_loss improved from inf to 0.02240, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0514,  mae:0.1540,  mse:0.0514,  val_loss:0.0224,  val_mae:0.1129,  val_mse:0.0224,  \n",
      "14926/14926 [==============================] - 2s 142us/sample - loss: 0.0514 - mae: 0.1540 - mse: 0.0514 - val_loss: 0.0224 - val_mae: 0.1129 - val_mse: 0.0224\n",
      "Epoch 2/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0235 - mae: 0.1128 - mse: 0.0235\n",
      "Epoch 00002: val_loss did not improve from 0.02240\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0236 - mae: 0.1129 - mse: 0.0236 - val_loss: 0.0235 - val_mae: 0.1152 - val_mse: 0.0235\n",
      "Epoch 3/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0195 - mae: 0.1020 - mse: 0.0195\n",
      "Epoch 00003: val_loss improved from 0.02240 to 0.02160, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0198 - mae: 0.1020 - mse: 0.0198 - val_loss: 0.0216 - val_mae: 0.1098 - val_mse: 0.0216\n",
      "Epoch 4/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1000 - mse: 0.0193\n",
      "Epoch 00004: val_loss improved from 0.02160 to 0.01775, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0192 - mae: 0.1000 - mse: 0.0192 - val_loss: 0.0177 - val_mae: 0.0932 - val_mse: 0.0177\n",
      "Epoch 5/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0962 - mse: 0.0179\n",
      "Epoch 00005: val_loss improved from 0.01775 to 0.01631, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0179 - mae: 0.0961 - mse: 0.0179 - val_loss: 0.0163 - val_mae: 0.0895 - val_mse: 0.0163\n",
      "Epoch 6/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0175 - mae: 0.0951 - mse: 0.0175\n",
      "Epoch 00006: val_loss improved from 0.01631 to 0.01628, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0174 - mae: 0.0948 - mse: 0.0174 - val_loss: 0.0163 - val_mae: 0.0922 - val_mse: 0.0163\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0941 - mse: 0.0170\n",
      "Epoch 00007: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0170 - mae: 0.0942 - mse: 0.0170 - val_loss: 0.0174 - val_mae: 0.0957 - val_mse: 0.0174\n",
      "Epoch 8/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0917 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0165 - mae: 0.0917 - mse: 0.0165 - val_loss: 0.0188 - val_mae: 0.0999 - val_mse: 0.0188\n",
      "Epoch 9/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0908 - mse: 0.0163\n",
      "Epoch 00009: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0164 - mae: 0.0914 - mse: 0.0164 - val_loss: 0.0222 - val_mae: 0.1097 - val_mse: 0.0222\n",
      "Epoch 10/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0891 - mse: 0.0157\n",
      "Epoch 00010: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0157 - mae: 0.0893 - mse: 0.0157 - val_loss: 0.0173 - val_mae: 0.0971 - val_mse: 0.0173\n",
      "Epoch 11/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0860 - mse: 0.0146\n",
      "Epoch 00011: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0146 - mae: 0.0861 - mse: 0.0146 - val_loss: 0.0190 - val_mae: 0.1029 - val_mse: 0.0190\n",
      "Epoch 12/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0857 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0145 - mae: 0.0856 - mse: 0.0145 - val_loss: 0.0191 - val_mae: 0.0995 - val_mse: 0.0191\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0860 - mse: 0.0148\n",
      "Epoch 00013: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0148 - mae: 0.0860 - mse: 0.0148 - val_loss: 0.0164 - val_mae: 0.0904 - val_mse: 0.0164\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0129 - mae: 0.0811 - mse: 0.0129\n",
      "Epoch 00014: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0133 - mae: 0.0816 - mse: 0.0133 - val_loss: 0.0168 - val_mae: 0.0934 - val_mse: 0.0168\n",
      "Elapsed time during model training:  21.03443455696106\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0445 - mae: 0.1506 - mse: 0.0445\n",
      "Epoch 00001: val_loss improved from inf to 0.02567, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0438,  mae:0.1493,  mse:0.0438,  val_loss:0.0257,  val_mae:0.1252,  val_mse:0.0257,  \n",
      "14926/14926 [==============================] - 2s 143us/sample - loss: 0.0438 - mae: 0.1493 - mse: 0.0438 - val_loss: 0.0257 - val_mae: 0.1252 - val_mse: 0.0257\n",
      "Epoch 2/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0235 - mae: 0.1123 - mse: 0.0235\n",
      "Epoch 00002: val_loss improved from 0.02567 to 0.01870, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0235 - mae: 0.1123 - mse: 0.0235 - val_loss: 0.0187 - val_mae: 0.1018 - val_mse: 0.0187\n",
      "Epoch 3/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0209 - mae: 0.1055 - mse: 0.0209\n",
      "Epoch 00003: val_loss improved from 0.01870 to 0.01831, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0210 - mae: 0.1055 - mse: 0.0210 - val_loss: 0.0183 - val_mae: 0.0994 - val_mse: 0.0183\n",
      "Epoch 4/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1002 - mse: 0.0193\n",
      "Epoch 00004: val_loss improved from 0.01831 to 0.01775, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0194 - mae: 0.1004 - mse: 0.0194 - val_loss: 0.0178 - val_mae: 0.0984 - val_mse: 0.0178\n",
      "Epoch 5/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0961 - mse: 0.0179\n",
      "Epoch 00005: val_loss did not improve from 0.01775\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0179 - mae: 0.0961 - mse: 0.0179 - val_loss: 0.0201 - val_mae: 0.1035 - val_mse: 0.0201\n",
      "Epoch 6/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0951 - mse: 0.0174\n",
      "Epoch 00006: val_loss did not improve from 0.01775\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0175 - mae: 0.0953 - mse: 0.0175 - val_loss: 0.0303 - val_mae: 0.1185 - val_mse: 0.0303\n",
      "Epoch 7/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0174 - mae: 0.0955 - mse: 0.0174\n",
      "Epoch 00007: val_loss did not improve from 0.01775\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0174 - mae: 0.0956 - mse: 0.0174 - val_loss: 0.0185 - val_mae: 0.0944 - val_mse: 0.0185\n",
      "Epoch 8/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0909 - mse: 0.0160\n",
      "Epoch 00008: val_loss improved from 0.01775 to 0.01616, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0159 - mae: 0.0908 - mse: 0.0159 - val_loss: 0.0162 - val_mae: 0.0889 - val_mse: 0.0162\n",
      "Epoch 9/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0904 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01616\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0159 - mae: 0.0905 - mse: 0.0159 - val_loss: 0.0184 - val_mae: 0.1005 - val_mse: 0.0184\n",
      "Epoch 10/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0886 - mse: 0.0154\n",
      "Epoch 00010: val_loss did not improve from 0.01616\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0154 - mae: 0.0887 - mse: 0.0154 - val_loss: 0.0166 - val_mae: 0.0924 - val_mse: 0.0166\n",
      "Epoch 11/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0886 - mse: 0.0153\n",
      "Epoch 00011: val_loss did not improve from 0.01616\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0154 - mae: 0.0890 - mse: 0.0154 - val_loss: 0.0180 - val_mae: 0.0979 - val_mse: 0.0180\n",
      "Epoch 12/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0870 - mse: 0.0151\n",
      "Epoch 00012: val_loss improved from 0.01616 to 0.01477, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0151 - mae: 0.0869 - mse: 0.0151 - val_loss: 0.0148 - val_mae: 0.0851 - val_mse: 0.0148\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0858 - mse: 0.0144\n",
      "Epoch 00013: val_loss did not improve from 0.01477\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0143 - mae: 0.0858 - mse: 0.0143 - val_loss: 0.0175 - val_mae: 0.0957 - val_mse: 0.0175\n",
      "Epoch 14/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0850 - mse: 0.0141\n",
      "Epoch 00014: val_loss did not improve from 0.01477\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0141 - mae: 0.0849 - mse: 0.0141 - val_loss: 0.0151 - val_mae: 0.0822 - val_mse: 0.0151\n",
      "Epoch 15/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0817 - mse: 0.0133\n",
      "Epoch 00015: val_loss improved from 0.01477 to 0.01476, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0133 - mae: 0.0814 - mse: 0.0133 - val_loss: 0.0148 - val_mae: 0.0831 - val_mse: 0.0148\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0822 - mse: 0.0134\n",
      "Epoch 00016: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0134 - mae: 0.0823 - mse: 0.0134 - val_loss: 0.0180 - val_mae: 0.0979 - val_mse: 0.0180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0793 - mse: 0.0127\n",
      "Epoch 00017: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0127 - mae: 0.0794 - mse: 0.0127 - val_loss: 0.0156 - val_mae: 0.0865 - val_mse: 0.0156\n",
      "Epoch 18/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0784 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0123 - mae: 0.0783 - mse: 0.0123 - val_loss: 0.0170 - val_mae: 0.0958 - val_mse: 0.0170\n",
      "Epoch 19/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0779 - mse: 0.0122\n",
      "Epoch 00019: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0122 - mae: 0.0779 - mse: 0.0122 - val_loss: 0.0156 - val_mae: 0.0877 - val_mse: 0.0156\n",
      "Epoch 20/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0747 - mse: 0.0113\n",
      "Epoch 00020: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0113 - mae: 0.0747 - mse: 0.0113 - val_loss: 0.0160 - val_mae: 0.0908 - val_mse: 0.0160\n",
      "Epoch 21/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0118 - mae: 0.0770 - mse: 0.0118\n",
      "Epoch 00021: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0118 - mae: 0.0769 - mse: 0.0118 - val_loss: 0.0164 - val_mae: 0.0925 - val_mse: 0.0164\n",
      "Epoch 22/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0750 - mse: 0.0111\n",
      "Epoch 00022: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0111 - mae: 0.0749 - mse: 0.0111 - val_loss: 0.0178 - val_mae: 0.0981 - val_mse: 0.0178\n",
      "Epoch 23/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0759 - mse: 0.0113\n",
      "Epoch 00023: val_loss improved from 0.01476 to 0.01412, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0113 - mae: 0.0760 - mse: 0.0113 - val_loss: 0.0141 - val_mae: 0.0833 - val_mse: 0.0141\n",
      "Epoch 24/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0732 - mse: 0.0108\n",
      "Epoch 00024: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0108 - mae: 0.0733 - mse: 0.0108 - val_loss: 0.0142 - val_mae: 0.0841 - val_mse: 0.0142\n",
      "Epoch 25/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0720 - mse: 0.0105\n",
      "Epoch 00025: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0104 - mae: 0.0719 - mse: 0.0104 - val_loss: 0.0155 - val_mae: 0.0895 - val_mse: 0.0155\n",
      "Epoch 26/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0104 - mae: 0.0723 - mse: 0.0104\n",
      "Epoch 00026: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0104 - mae: 0.0723 - mse: 0.0104 - val_loss: 0.0155 - val_mae: 0.0853 - val_mse: 0.0155\n",
      "Epoch 27/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0713 - mse: 0.0102\n",
      "Epoch 00027: val_loss improved from 0.01412 to 0.01376, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0101 - mae: 0.0712 - mse: 0.0101 - val_loss: 0.0138 - val_mae: 0.0800 - val_mse: 0.0138\n",
      "Epoch 28/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0098 - mae: 0.0691 - mse: 0.0098\n",
      "Epoch 00028: val_loss did not improve from 0.01376\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0184 - val_mae: 0.0995 - val_mse: 0.0184\n",
      "Epoch 29/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0706 - mse: 0.0100\n",
      "Epoch 00029: val_loss did not improve from 0.01376\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0099 - mae: 0.0706 - mse: 0.0099 - val_loss: 0.0138 - val_mae: 0.0793 - val_mse: 0.0138\n",
      "Epoch 30/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0689 - mse: 0.0094\n",
      "Epoch 00030: val_loss improved from 0.01376 to 0.01317, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0094 - mae: 0.0688 - mse: 0.0094 - val_loss: 0.0132 - val_mae: 0.0781 - val_mse: 0.0132\n",
      "Epoch 31/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00031: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0092 - mae: 0.0677 - mse: 0.0092 - val_loss: 0.0142 - val_mae: 0.0812 - val_mse: 0.0142\n",
      "Epoch 32/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0666 - mse: 0.0090\n",
      "Epoch 00032: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0134 - val_mae: 0.0766 - val_mse: 0.0134\n",
      "Epoch 33/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0672 - mse: 0.0090\n",
      "Epoch 00033: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0090 - mae: 0.0671 - mse: 0.0090 - val_loss: 0.0135 - val_mae: 0.0774 - val_mse: 0.0135\n",
      "Epoch 34/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0677 - mse: 0.0092\n",
      "Epoch 00034: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0092 - mae: 0.0678 - mse: 0.0092 - val_loss: 0.0141 - val_mae: 0.0800 - val_mse: 0.0141\n",
      "Epoch 35/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0677 - mse: 0.0092\n",
      "Epoch 00035: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0092 - mae: 0.0678 - mse: 0.0092 - val_loss: 0.0138 - val_mae: 0.0837 - val_mse: 0.0138\n",
      "Epoch 36/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0640 - mse: 0.0083\n",
      "Epoch 00036: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0082 - mae: 0.0639 - mse: 0.0082 - val_loss: 0.0149 - val_mae: 0.0867 - val_mse: 0.0149\n",
      "Epoch 37/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0650 - mse: 0.0084\n",
      "Epoch 00037: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0084 - mae: 0.0650 - mse: 0.0084 - val_loss: 0.0138 - val_mae: 0.0821 - val_mse: 0.0138\n",
      "Epoch 38/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0628 - mse: 0.0081\n",
      "Epoch 00038: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0081 - mae: 0.0629 - mse: 0.0081 - val_loss: 0.0138 - val_mae: 0.0813 - val_mse: 0.0138\n",
      "Epoch 39/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0645 - mse: 0.0084\n",
      "Epoch 00039: val_loss did not improve from 0.01317\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0084 - mae: 0.0645 - mse: 0.0084 - val_loss: 0.0138 - val_mae: 0.0793 - val_mse: 0.0138\n",
      "Epoch 40/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0642 - mse: 0.0082\n",
      "Epoch 00040: val_loss improved from 0.01317 to 0.01280, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0082 - mae: 0.0640 - mse: 0.0082 - val_loss: 0.0128 - val_mae: 0.0763 - val_mse: 0.0128\n",
      "Epoch 41/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0624 - mse: 0.0078\n",
      "Epoch 00041: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0078 - mae: 0.0625 - mse: 0.0078 - val_loss: 0.0132 - val_mae: 0.0763 - val_mse: 0.0132\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0618 - mse: 0.0076\n",
      "Epoch 00042: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0076 - mae: 0.0618 - mse: 0.0076 - val_loss: 0.0133 - val_mae: 0.0775 - val_mse: 0.0133\n",
      "Epoch 43/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0621 - mse: 0.0078\n",
      "Epoch 00043: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0078 - mae: 0.0620 - mse: 0.0078 - val_loss: 0.0137 - val_mae: 0.0793 - val_mse: 0.0137\n",
      "Epoch 44/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0620 - mse: 0.0077\n",
      "Epoch 00044: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0077 - mae: 0.0620 - mse: 0.0077 - val_loss: 0.0156 - val_mae: 0.0833 - val_mse: 0.0156\n",
      "Epoch 45/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0619 - mse: 0.0075\n",
      "Epoch 00045: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0075 - mae: 0.0618 - mse: 0.0075 - val_loss: 0.0137 - val_mae: 0.0783 - val_mse: 0.0137\n",
      "Epoch 46/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0598 - mse: 0.0072\n",
      "Epoch 00046: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0072 - mae: 0.0600 - mse: 0.0072 - val_loss: 0.0149 - val_mae: 0.0873 - val_mse: 0.0149\n",
      "Epoch 47/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0601 - mse: 0.0072\n",
      "Epoch 00047: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0072 - mae: 0.0603 - mse: 0.0072 - val_loss: 0.0136 - val_mae: 0.0779 - val_mse: 0.0136\n",
      "Epoch 48/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0603 - mse: 0.0072\n",
      "Epoch 00048: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0072 - mae: 0.0603 - mse: 0.0072 - val_loss: 0.0140 - val_mae: 0.0805 - val_mse: 0.0140\n",
      "Epoch 49/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0071 - mae: 0.0598 - mse: 0.0071\n",
      "Epoch 00049: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0071 - mae: 0.0600 - mse: 0.0071 - val_loss: 0.0147 - val_mae: 0.0815 - val_mse: 0.0147\n",
      "Epoch 50/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0069 - mae: 0.0598 - mse: 0.0069\n",
      "Epoch 00050: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0070 - mae: 0.0602 - mse: 0.0070 - val_loss: 0.0152 - val_mae: 0.0877 - val_mse: 0.0152\n",
      "Epoch 51/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0586 - mse: 0.0068\n",
      "Epoch 00051: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0068 - mae: 0.0586 - mse: 0.0068 - val_loss: 0.0164 - val_mae: 0.0941 - val_mse: 0.0164\n",
      "Epoch 52/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0593 - mse: 0.0071\n",
      "Epoch 00052: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0139 - val_mae: 0.0817 - val_mse: 0.0139\n",
      "Epoch 53/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0064 - mae: 0.0571 - mse: 0.0064\n",
      "Epoch 00053: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0064 - mae: 0.0571 - mse: 0.0064 - val_loss: 0.0139 - val_mae: 0.0793 - val_mse: 0.0139\n",
      "Epoch 54/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0579 - mse: 0.0066\n",
      "Epoch 00054: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0066 - mae: 0.0577 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0784 - val_mse: 0.0134\n",
      "Elapsed time during model training:  78.81293749809265\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0445 - mae: 0.1477 - mse: 0.0445\n",
      "Epoch 00001: val_loss improved from inf to 0.04688, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0441,  mae:0.1472,  mse:0.0441,  val_loss:0.0469,  val_mae:0.1655,  val_mse:0.0469,  \n",
      "14926/14926 [==============================] - 2s 138us/sample - loss: 0.0441 - mae: 0.1472 - mse: 0.0441 - val_loss: 0.0469 - val_mae: 0.1655 - val_mse: 0.0469\n",
      "Epoch 2/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0234 - mae: 0.1137 - mse: 0.0234\n",
      "Epoch 00002: val_loss improved from 0.04688 to 0.02119, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0234 - mae: 0.1136 - mse: 0.0234 - val_loss: 0.0212 - val_mae: 0.1037 - val_mse: 0.0212\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0208 - mae: 0.1055 - mse: 0.0208\n",
      "Epoch 00003: val_loss did not improve from 0.02119\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0208 - mae: 0.1053 - mse: 0.0208 - val_loss: 0.0215 - val_mae: 0.1089 - val_mse: 0.0215\n",
      "Epoch 4/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1001 - mse: 0.0191\n",
      "Epoch 00004: val_loss improved from 0.02119 to 0.01837, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0191 - mae: 0.1001 - mse: 0.0191 - val_loss: 0.0184 - val_mae: 0.1005 - val_mse: 0.0184\n",
      "Epoch 5/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0186 - mae: 0.0985 - mse: 0.0186\n",
      "Epoch 00005: val_loss improved from 0.01837 to 0.01686, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0185 - mae: 0.0983 - mse: 0.0185 - val_loss: 0.0169 - val_mae: 0.0904 - val_mse: 0.0169\n",
      "Epoch 6/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0942 - mse: 0.0172\n",
      "Epoch 00006: val_loss improved from 0.01686 to 0.01662, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0172 - mae: 0.0941 - mse: 0.0172 - val_loss: 0.0166 - val_mae: 0.0885 - val_mse: 0.0166\n",
      "Epoch 7/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0171 - mae: 0.0942 - mse: 0.0171\n",
      "Epoch 00007: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0170 - mae: 0.0939 - mse: 0.0170 - val_loss: 0.0215 - val_mae: 0.1004 - val_mse: 0.0215\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0929 - mse: 0.0166\n",
      "Epoch 00008: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0166 - mae: 0.0929 - mse: 0.0166 - val_loss: 0.0170 - val_mae: 0.0916 - val_mse: 0.0170\n",
      "Epoch 9/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0891 - mse: 0.0154\n",
      "Epoch 00009: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0154 - mae: 0.0891 - mse: 0.0154 - val_loss: 0.0201 - val_mae: 0.1021 - val_mse: 0.0201\n",
      "Epoch 10/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0911 - mse: 0.0157\n",
      "Epoch 00010: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0160 - mae: 0.0911 - mse: 0.0160 - val_loss: 0.0169 - val_mae: 0.0937 - val_mse: 0.0169\n",
      "Epoch 11/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0853 - mse: 0.0144\n",
      "Epoch 00011: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0144 - mae: 0.0855 - mse: 0.0144 - val_loss: 0.0188 - val_mae: 0.1006 - val_mse: 0.0188\n",
      "Epoch 12/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0834 - mse: 0.0139\n",
      "Epoch 00012: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0139 - mae: 0.0835 - mse: 0.0139 - val_loss: 0.0168 - val_mae: 0.0947 - val_mse: 0.0168\n",
      "Epoch 13/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0831 - mse: 0.0135\n",
      "Epoch 00013: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0140 - mae: 0.0840 - mse: 0.0140 - val_loss: 0.0167 - val_mae: 0.0918 - val_mse: 0.0167\n",
      "Epoch 14/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0833 - mse: 0.0137\n",
      "Epoch 00014: val_loss did not improve from 0.01662\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0137 - mae: 0.0833 - mse: 0.0137 - val_loss: 0.0182 - val_mae: 0.0961 - val_mse: 0.0182\n",
      "Epoch 15/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0132 - mae: 0.0812 - mse: 0.0132\n",
      "Epoch 00015: val_loss improved from 0.01662 to 0.01542, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0130 - mae: 0.0807 - mse: 0.0130 - val_loss: 0.0154 - val_mae: 0.0820 - val_mse: 0.0154\n",
      "Epoch 16/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0796 - mse: 0.0124\n",
      "Epoch 00016: val_loss did not improve from 0.01542\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0128 - mae: 0.0801 - mse: 0.0128 - val_loss: 0.0177 - val_mae: 0.0969 - val_mse: 0.0177\n",
      "Epoch 17/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0792 - mse: 0.0127\n",
      "Epoch 00017: val_loss did not improve from 0.01542\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0127 - mae: 0.0794 - mse: 0.0127 - val_loss: 0.0184 - val_mae: 0.1018 - val_mse: 0.0184\n",
      "Epoch 18/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0760 - mse: 0.0117\n",
      "Epoch 00018: val_loss improved from 0.01542 to 0.01420, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0117 - mae: 0.0763 - mse: 0.0117 - val_loss: 0.0142 - val_mae: 0.0808 - val_mse: 0.0142\n",
      "Epoch 19/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0778 - mse: 0.0121\n",
      "Epoch 00019: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0121 - mae: 0.0779 - mse: 0.0121 - val_loss: 0.0155 - val_mae: 0.0883 - val_mse: 0.0155\n",
      "Epoch 20/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0115 - mae: 0.0750 - mse: 0.0115\n",
      "Epoch 00020: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0114 - mae: 0.0749 - mse: 0.0114 - val_loss: 0.0145 - val_mae: 0.0853 - val_mse: 0.0145\n",
      "Epoch 21/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0745 - mse: 0.0113\n",
      "Epoch 00021: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0112 - mae: 0.0746 - mse: 0.0112 - val_loss: 0.0160 - val_mae: 0.0865 - val_mse: 0.0160\n",
      "Epoch 22/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0734 - mse: 0.0109\n",
      "Epoch 00022: val_loss improved from 0.01420 to 0.01402, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0140 - val_mae: 0.0812 - val_mse: 0.0140\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0112 - mae: 0.0743 - mse: 0.0112\n",
      "Epoch 00023: val_loss improved from 0.01402 to 0.01385, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0111 - mae: 0.0741 - mse: 0.0111 - val_loss: 0.0138 - val_mae: 0.0794 - val_mse: 0.0138\n",
      "Epoch 24/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0719 - mse: 0.0105\n",
      "Epoch 00024: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0105 - mae: 0.0719 - mse: 0.0105 - val_loss: 0.0169 - val_mae: 0.0951 - val_mse: 0.0169\n",
      "Epoch 25/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0699 - mse: 0.0100\n",
      "Epoch 00025: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0100 - mae: 0.0698 - mse: 0.0100 - val_loss: 0.0159 - val_mae: 0.0863 - val_mse: 0.0159\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0706 - mse: 0.0102\n",
      "Epoch 00026: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0102 - mae: 0.0709 - mse: 0.0102 - val_loss: 0.0159 - val_mae: 0.0909 - val_mse: 0.0159\n",
      "Epoch 27/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0695 - mse: 0.0099\n",
      "Epoch 00027: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0099 - mae: 0.0699 - mse: 0.0099 - val_loss: 0.0158 - val_mae: 0.0919 - val_mse: 0.0158\n",
      "Epoch 28/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0696 - mse: 0.0098\n",
      "Epoch 00028: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0098 - mae: 0.0696 - mse: 0.0098 - val_loss: 0.0154 - val_mae: 0.0880 - val_mse: 0.0154\n",
      "Epoch 29/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0670 - mse: 0.0089\n",
      "Epoch 00029: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0093 - mae: 0.0676 - mse: 0.0093 - val_loss: 0.0155 - val_mae: 0.0856 - val_mse: 0.0155\n",
      "Epoch 30/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0674 - mse: 0.0094\n",
      "Epoch 00030: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0093 - mae: 0.0673 - mse: 0.0093 - val_loss: 0.0147 - val_mae: 0.0845 - val_mse: 0.0147\n",
      "Epoch 31/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0668 - mse: 0.0091\n",
      "Epoch 00031: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0091 - mae: 0.0668 - mse: 0.0091 - val_loss: 0.0159 - val_mae: 0.0902 - val_mse: 0.0159\n",
      "Epoch 32/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0656 - mse: 0.0088\n",
      "Epoch 00032: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0088 - mae: 0.0656 - mse: 0.0088 - val_loss: 0.0141 - val_mae: 0.0806 - val_mse: 0.0141\n",
      "Epoch 33/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0643 - mse: 0.0085\n",
      "Epoch 00033: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0085 - mae: 0.0644 - mse: 0.0085 - val_loss: 0.0182 - val_mae: 0.0934 - val_mse: 0.0182\n",
      "Epoch 34/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0659 - mse: 0.0090\n",
      "Epoch 00034: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0090 - mae: 0.0659 - mse: 0.0090 - val_loss: 0.0141 - val_mae: 0.0808 - val_mse: 0.0141\n",
      "Epoch 35/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0636 - mse: 0.0083\n",
      "Epoch 00035: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0084 - mae: 0.0638 - mse: 0.0084 - val_loss: 0.0153 - val_mae: 0.0834 - val_mse: 0.0153\n",
      "Elapsed time during model training:  52.893186807632446\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0465 - mae: 0.1485 - mse: 0.0465\n",
      "Epoch 00001: val_loss improved from inf to 0.02102, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0464,  mae:0.1483,  mse:0.0464,  val_loss:0.0210,  val_mae:0.1065,  val_mse:0.0210,  \n",
      "14926/14926 [==============================] - 2s 146us/sample - loss: 0.0464 - mae: 0.1483 - mse: 0.0464 - val_loss: 0.0210 - val_mae: 0.1065 - val_mse: 0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0230 - mae: 0.1112 - mse: 0.0230\n",
      "Epoch 00002: val_loss improved from 0.02102 to 0.01864, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0230 - mae: 0.1111 - mse: 0.0230 - val_loss: 0.0186 - val_mae: 0.0982 - val_mse: 0.0186\n",
      "Epoch 3/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0211 - mae: 0.1060 - mse: 0.0211\n",
      "Epoch 00003: val_loss did not improve from 0.01864\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0211 - mae: 0.1060 - mse: 0.0211 - val_loss: 0.0231 - val_mae: 0.1175 - val_mse: 0.0231\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1007 - mse: 0.0191\n",
      "Epoch 00004: val_loss improved from 0.01864 to 0.01709, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0191 - mae: 0.1005 - mse: 0.0191 - val_loss: 0.0171 - val_mae: 0.0957 - val_mse: 0.0171\n",
      "Epoch 5/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0987 - mse: 0.0187\n",
      "Epoch 00005: val_loss did not improve from 0.01709\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0185 - mae: 0.0984 - mse: 0.0185 - val_loss: 0.0180 - val_mae: 0.0970 - val_mse: 0.0180\n",
      "Epoch 6/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0986 - mse: 0.0183\n",
      "Epoch 00006: val_loss did not improve from 0.01709\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0183 - mae: 0.0985 - mse: 0.0183 - val_loss: 0.0214 - val_mae: 0.1106 - val_mse: 0.0214\n",
      "Epoch 7/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0930 - mse: 0.0167\n",
      "Epoch 00007: val_loss did not improve from 0.01709\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0170 - mae: 0.0931 - mse: 0.0170 - val_loss: 0.0207 - val_mae: 0.1112 - val_mse: 0.0207\n",
      "Epoch 8/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0927 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01709\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0165 - mae: 0.0926 - mse: 0.0165 - val_loss: 0.0179 - val_mae: 0.0979 - val_mse: 0.0179\n",
      "Epoch 9/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0914 - mse: 0.0163\n",
      "Epoch 00009: val_loss improved from 0.01709 to 0.01597, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0161 - mae: 0.0911 - mse: 0.0161 - val_loss: 0.0160 - val_mae: 0.0877 - val_mse: 0.0160\n",
      "Epoch 10/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0868 - mse: 0.0149\n",
      "Epoch 00010: val_loss did not improve from 0.01597\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0150 - mae: 0.0868 - mse: 0.0150 - val_loss: 0.0168 - val_mae: 0.0941 - val_mse: 0.0168\n",
      "Epoch 11/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0155 - mae: 0.0906 - mse: 0.0155\n",
      "Epoch 00011: val_loss did not improve from 0.01597\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0157 - mae: 0.0903 - mse: 0.0157 - val_loss: 0.0171 - val_mae: 0.0972 - val_mse: 0.0171\n",
      "Epoch 12/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0892 - mse: 0.0153\n",
      "Epoch 00012: val_loss did not improve from 0.01597\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0152 - mae: 0.0890 - mse: 0.0152 - val_loss: 0.0167 - val_mae: 0.0877 - val_mse: 0.0167\n",
      "Epoch 13/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0860 - mse: 0.0145\n",
      "Epoch 00013: val_loss improved from 0.01597 to 0.01587, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0145 - mae: 0.0859 - mse: 0.0145 - val_loss: 0.0159 - val_mae: 0.0882 - val_mse: 0.0159\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0134 - mae: 0.0821 - mse: 0.0134\n",
      "Epoch 00014: val_loss improved from 0.01587 to 0.01529, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0134 - mae: 0.0823 - mse: 0.0134 - val_loss: 0.0153 - val_mae: 0.0871 - val_mse: 0.0153\n",
      "Epoch 15/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0817 - mse: 0.0135\n",
      "Epoch 00015: val_loss improved from 0.01529 to 0.01500, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0134 - mae: 0.0815 - mse: 0.0134 - val_loss: 0.0150 - val_mae: 0.0878 - val_mse: 0.0150\n",
      "Epoch 16/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0794 - mse: 0.0127\n",
      "Epoch 00016: val_loss did not improve from 0.01500\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0127 - mae: 0.0794 - mse: 0.0127 - val_loss: 0.0167 - val_mae: 0.0976 - val_mse: 0.0167\n",
      "Epoch 17/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0782 - mse: 0.0123\n",
      "Epoch 00017: val_loss did not improve from 0.01500\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0123 - mae: 0.0782 - mse: 0.0123 - val_loss: 0.0152 - val_mae: 0.0827 - val_mse: 0.0152\n",
      "Epoch 18/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0127 - mae: 0.0801 - mse: 0.0127\n",
      "Epoch 00018: val_loss did not improve from 0.01500\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0127 - mae: 0.0802 - mse: 0.0127 - val_loss: 0.0152 - val_mae: 0.0878 - val_mse: 0.0152\n",
      "Epoch 19/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0767 - mse: 0.0118\n",
      "Epoch 00019: val_loss did not improve from 0.01500\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0118 - mae: 0.0767 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0894 - val_mse: 0.0161\n",
      "Epoch 20/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0762 - mse: 0.0116\n",
      "Epoch 00020: val_loss improved from 0.01500 to 0.01418, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0116 - mae: 0.0761 - mse: 0.0116 - val_loss: 0.0142 - val_mae: 0.0835 - val_mse: 0.0142\n",
      "Epoch 21/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0760 - mse: 0.0115\n",
      "Epoch 00021: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0116 - mae: 0.0760 - mse: 0.0116 - val_loss: 0.0164 - val_mae: 0.0899 - val_mse: 0.0164\n",
      "Epoch 22/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0746 - mse: 0.0113\n",
      "Epoch 00022: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0113 - mae: 0.0746 - mse: 0.0113 - val_loss: 0.0149 - val_mae: 0.0844 - val_mse: 0.0149\n",
      "Epoch 23/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00023: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0109 - mae: 0.0738 - mse: 0.0109 - val_loss: 0.0154 - val_mae: 0.0869 - val_mse: 0.0154\n",
      "Epoch 24/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0711 - mse: 0.0104\n",
      "Epoch 00024: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0103 - mae: 0.0711 - mse: 0.0103 - val_loss: 0.0155 - val_mae: 0.0879 - val_mse: 0.0155\n",
      "Epoch 25/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0715 - mse: 0.0102\n",
      "Epoch 00025: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0102 - mae: 0.0716 - mse: 0.0102 - val_loss: 0.0172 - val_mae: 0.0929 - val_mse: 0.0172\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0707 - mse: 0.0101\n",
      "Epoch 00026: val_loss did not improve from 0.01418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0148 - val_mae: 0.0825 - val_mse: 0.0148\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0713 - mse: 0.0104\n",
      "Epoch 00027: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0104 - mae: 0.0713 - mse: 0.0104 - val_loss: 0.0144 - val_mae: 0.0807 - val_mse: 0.0144\n",
      "Epoch 28/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0097 - mae: 0.0689 - mse: 0.0097\n",
      "Epoch 00028: val_loss improved from 0.01418 to 0.01371, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0097 - mae: 0.0688 - mse: 0.0097 - val_loss: 0.0137 - val_mae: 0.0760 - val_mse: 0.0137\n",
      "Epoch 29/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0687 - mse: 0.0096\n",
      "Epoch 00029: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0096 - mae: 0.0686 - mse: 0.0096 - val_loss: 0.0155 - val_mae: 0.0865 - val_mse: 0.0155\n",
      "Epoch 30/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0674 - mse: 0.0091\n",
      "Epoch 00030: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0091 - mae: 0.0673 - mse: 0.0091 - val_loss: 0.0143 - val_mae: 0.0814 - val_mse: 0.0143\n",
      "Epoch 31/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0093 - mae: 0.0670 - mse: 0.0093\n",
      "Epoch 00031: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0092 - mae: 0.0669 - mse: 0.0092 - val_loss: 0.0143 - val_mae: 0.0808 - val_mse: 0.0143\n",
      "Epoch 32/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0088 - mae: 0.0658 - mse: 0.0088\n",
      "Epoch 00032: val_loss did not improve from 0.01371\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0144 - val_mae: 0.0797 - val_mse: 0.0144\n",
      "Epoch 33/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0670 - mse: 0.0090\n",
      "Epoch 00033: val_loss improved from 0.01371 to 0.01344, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0090 - mae: 0.0670 - mse: 0.0090 - val_loss: 0.0134 - val_mae: 0.0780 - val_mse: 0.0134\n",
      "Epoch 34/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0666 - mse: 0.0089\n",
      "Epoch 00034: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0090 - mae: 0.0667 - mse: 0.0090 - val_loss: 0.0145 - val_mae: 0.0822 - val_mse: 0.0145\n",
      "Epoch 35/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0650 - mse: 0.0086\n",
      "Epoch 00035: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0086 - mae: 0.0649 - mse: 0.0086 - val_loss: 0.0138 - val_mae: 0.0801 - val_mse: 0.0138\n",
      "Epoch 36/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0642 - mse: 0.0084\n",
      "Epoch 00036: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0084 - mae: 0.0643 - mse: 0.0084 - val_loss: 0.0156 - val_mae: 0.0887 - val_mse: 0.0156\n",
      "Epoch 37/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0625 - mse: 0.0080\n",
      "Epoch 00037: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0080 - mae: 0.0625 - mse: 0.0080 - val_loss: 0.0143 - val_mae: 0.0818 - val_mse: 0.0143\n",
      "Epoch 38/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0622 - mse: 0.0078\n",
      "Epoch 00038: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0078 - mae: 0.0622 - mse: 0.0078 - val_loss: 0.0150 - val_mae: 0.0856 - val_mse: 0.0150\n",
      "Epoch 39/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0631 - mse: 0.0080\n",
      "Epoch 00039: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0080 - mae: 0.0632 - mse: 0.0080 - val_loss: 0.0151 - val_mae: 0.0870 - val_mse: 0.0151\n",
      "Epoch 40/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0621 - mse: 0.0078\n",
      "Epoch 00040: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0077 - mae: 0.0621 - mse: 0.0077 - val_loss: 0.0138 - val_mae: 0.0797 - val_mse: 0.0138\n",
      "Epoch 41/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0615 - mse: 0.0075\n",
      "Epoch 00041: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0075 - mae: 0.0615 - mse: 0.0075 - val_loss: 0.0136 - val_mae: 0.0788 - val_mse: 0.0136\n",
      "Epoch 42/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0077 - mae: 0.0620 - mse: 0.0077\n",
      "Epoch 00042: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0077 - mae: 0.0618 - mse: 0.0077 - val_loss: 0.0146 - val_mae: 0.0810 - val_mse: 0.0146\n",
      "Epoch 43/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0593 - mse: 0.0071\n",
      "Epoch 00043: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0145 - val_mae: 0.0812 - val_mse: 0.0145\n",
      "Epoch 44/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0625 - mse: 0.0079\n",
      "Epoch 00044: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0078 - mae: 0.0626 - mse: 0.0078 - val_loss: 0.0150 - val_mae: 0.0881 - val_mse: 0.0150\n",
      "Epoch 45/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0592 - mse: 0.0069\n",
      "Epoch 00045: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0069 - mae: 0.0592 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 46/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0605 - mse: 0.0073\n",
      "Epoch 00046: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0072 - mae: 0.0606 - mse: 0.0072 - val_loss: 0.0136 - val_mae: 0.0765 - val_mse: 0.0136\n",
      "Epoch 47/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0564 - mse: 0.0065\n",
      "Epoch 00047: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0065 - mae: 0.0565 - mse: 0.0065 - val_loss: 0.0141 - val_mae: 0.0812 - val_mse: 0.0141\n",
      "Epoch 48/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0571 - mse: 0.0066\n",
      "Epoch 00048: val_loss did not improve from 0.01344\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0066 - mae: 0.0574 - mse: 0.0066 - val_loss: 0.0138 - val_mae: 0.0815 - val_mse: 0.0138\n",
      "Elapsed time during model training:  65.67739772796631\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0467 - mae: 0.1507 - mse: 0.0467\n",
      "Epoch 00001: val_loss improved from inf to 0.02328, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0465,  mae:0.1504,  mse:0.0465,  val_loss:0.0233,  val_mae:0.1126,  val_mse:0.0233,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0465 - mae: 0.1504 - mse: 0.0465 - val_loss: 0.0233 - val_mae: 0.1126 - val_mse: 0.0233\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0227 - mae: 0.1100 - mse: 0.0227\n",
      "Epoch 00002: val_loss improved from 0.02328 to 0.02029, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0228 - mae: 0.1100 - mse: 0.0228 - val_loss: 0.0203 - val_mae: 0.1039 - val_mse: 0.0203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0208 - mae: 0.1049 - mse: 0.0208\n",
      "Epoch 00003: val_loss did not improve from 0.02029\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0208 - mae: 0.1050 - mse: 0.0208 - val_loss: 0.0290 - val_mae: 0.1169 - val_mse: 0.0290\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1011 - mse: 0.0193\n",
      "Epoch 00004: val_loss improved from 0.02029 to 0.01979, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0193 - mae: 0.1011 - mse: 0.0193 - val_loss: 0.0198 - val_mae: 0.0997 - val_mse: 0.0198\n",
      "Epoch 5/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1006 - mse: 0.0193\n",
      "Epoch 00005: val_loss did not improve from 0.01979\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0194 - mae: 0.1006 - mse: 0.0194 - val_loss: 0.0348 - val_mae: 0.1444 - val_mse: 0.0348\n",
      "Epoch 6/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.0969 - mse: 0.0180\n",
      "Epoch 00006: val_loss improved from 0.01979 to 0.01854, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0181 - mae: 0.0972 - mse: 0.0181 - val_loss: 0.0185 - val_mae: 0.1028 - val_mse: 0.0185\n",
      "Epoch 7/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0926 - mse: 0.0166\n",
      "Epoch 00007: val_loss improved from 0.01854 to 0.01655, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0166 - mae: 0.0926 - mse: 0.0166 - val_loss: 0.0166 - val_mae: 0.0900 - val_mse: 0.0166\n",
      "Epoch 8/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0932 - mse: 0.0162\n",
      "Epoch 00008: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0166 - mae: 0.0934 - mse: 0.0166 - val_loss: 0.0195 - val_mae: 0.0990 - val_mse: 0.0195\n",
      "Epoch 9/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0937 - mse: 0.0168\n",
      "Epoch 00009: val_loss improved from 0.01655 to 0.01617, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0168 - mae: 0.0937 - mse: 0.0168 - val_loss: 0.0162 - val_mae: 0.0893 - val_mse: 0.0162\n",
      "Epoch 10/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0863 - mse: 0.0147\n",
      "Epoch 00010: val_loss did not improve from 0.01617\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0149 - mae: 0.0868 - mse: 0.0149 - val_loss: 0.0189 - val_mae: 0.1004 - val_mse: 0.0189\n",
      "Epoch 11/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0879 - mse: 0.0150\n",
      "Epoch 00011: val_loss did not improve from 0.01617\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0151 - mae: 0.0881 - mse: 0.0151 - val_loss: 0.0208 - val_mae: 0.1120 - val_mse: 0.0208\n",
      "Epoch 12/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0876 - mse: 0.0151\n",
      "Epoch 00012: val_loss did not improve from 0.01617\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0151 - mae: 0.0878 - mse: 0.0151 - val_loss: 0.0235 - val_mae: 0.1153 - val_mse: 0.0235\n",
      "Epoch 13/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0142 - mae: 0.0852 - mse: 0.0142\n",
      "Epoch 00013: val_loss did not improve from 0.01617\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0141 - mae: 0.0849 - mse: 0.0141 - val_loss: 0.0174 - val_mae: 0.0955 - val_mse: 0.0174\n",
      "Epoch 14/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0824 - mse: 0.0135\n",
      "Epoch 00014: val_loss improved from 0.01617 to 0.01556, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0135 - mae: 0.0824 - mse: 0.0135 - val_loss: 0.0156 - val_mae: 0.0860 - val_mse: 0.0156\n",
      "Epoch 15/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0805 - mse: 0.0128\n",
      "Epoch 00015: val_loss did not improve from 0.01556\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0132 - mae: 0.0809 - mse: 0.0132 - val_loss: 0.0169 - val_mae: 0.0976 - val_mse: 0.0169\n",
      "Epoch 16/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0798 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01556\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0128 - mae: 0.0798 - mse: 0.0128 - val_loss: 0.0174 - val_mae: 0.0882 - val_mse: 0.0174\n",
      "Epoch 17/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0792 - mse: 0.0125\n",
      "Epoch 00017: val_loss did not improve from 0.01556\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0124 - mae: 0.0790 - mse: 0.0124 - val_loss: 0.0162 - val_mae: 0.0873 - val_mse: 0.0162\n",
      "Epoch 18/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0780 - mse: 0.0124\n",
      "Epoch 00018: val_loss improved from 0.01556 to 0.01498, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0124 - mae: 0.0780 - mse: 0.0124 - val_loss: 0.0150 - val_mae: 0.0845 - val_mse: 0.0150\n",
      "Epoch 19/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0780 - mse: 0.0120\n",
      "Epoch 00019: val_loss improved from 0.01498 to 0.01443, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0120 - mae: 0.0780 - mse: 0.0120 - val_loss: 0.0144 - val_mae: 0.0812 - val_mse: 0.0144\n",
      "Epoch 20/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0751 - mse: 0.0113\n",
      "Epoch 00020: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0114 - mae: 0.0752 - mse: 0.0114 - val_loss: 0.0151 - val_mae: 0.0863 - val_mse: 0.0151\n",
      "Epoch 21/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0754 - mse: 0.0114\n",
      "Epoch 00021: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0114 - mae: 0.0754 - mse: 0.0114 - val_loss: 0.0152 - val_mae: 0.0870 - val_mse: 0.0152\n",
      "Epoch 22/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0734 - mse: 0.0109\n",
      "Epoch 00022: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0110 - mae: 0.0737 - mse: 0.0110 - val_loss: 0.0153 - val_mae: 0.0893 - val_mse: 0.0153\n",
      "Epoch 23/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0733 - mse: 0.0109\n",
      "Epoch 00023: val_loss did not improve from 0.01443\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0108 - mae: 0.0733 - mse: 0.0108 - val_loss: 0.0153 - val_mae: 0.0873 - val_mse: 0.0153\n",
      "Epoch 24/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0107 - mae: 0.0728 - mse: 0.0107\n",
      "Epoch 00024: val_loss improved from 0.01443 to 0.01426, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0107 - mae: 0.0728 - mse: 0.0107 - val_loss: 0.0143 - val_mae: 0.0828 - val_mse: 0.0143\n",
      "Epoch 25/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0710 - mse: 0.0102\n",
      "Epoch 00025: val_loss improved from 0.01426 to 0.01365, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0101 - mae: 0.0709 - mse: 0.0101 - val_loss: 0.0137 - val_mae: 0.0800 - val_mse: 0.0137\n",
      "Epoch 26/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0691 - mse: 0.0097\n",
      "Epoch 00026: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0097 - mae: 0.0691 - mse: 0.0097 - val_loss: 0.0139 - val_mae: 0.0810 - val_mse: 0.0139\n",
      "Epoch 27/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0100 - mae: 0.0707 - mse: 0.0100\n",
      "Epoch 00027: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0100 - mae: 0.0708 - mse: 0.0100 - val_loss: 0.0149 - val_mae: 0.0849 - val_mse: 0.0149\n",
      "Epoch 28/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0696 - mse: 0.0098\n",
      "Epoch 00028: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0098 - mae: 0.0695 - mse: 0.0098 - val_loss: 0.0156 - val_mae: 0.0837 - val_mse: 0.0156\n",
      "Epoch 29/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0671 - mse: 0.0094\n",
      "Epoch 00029: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0093 - mae: 0.0671 - mse: 0.0093 - val_loss: 0.0151 - val_mae: 0.0866 - val_mse: 0.0151\n",
      "Epoch 30/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0680 - mse: 0.0093\n",
      "Epoch 00030: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0093 - mae: 0.0680 - mse: 0.0093 - val_loss: 0.0143 - val_mae: 0.0822 - val_mse: 0.0143\n",
      "Epoch 31/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0654 - mse: 0.0088\n",
      "Epoch 00031: val_loss did not improve from 0.01365\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0088 - mae: 0.0654 - mse: 0.0088 - val_loss: 0.0149 - val_mae: 0.0842 - val_mse: 0.0149\n",
      "Epoch 32/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0672 - mse: 0.0091\n",
      "Epoch 00032: val_loss improved from 0.01365 to 0.01359, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0092 - mae: 0.0675 - mse: 0.0092 - val_loss: 0.0136 - val_mae: 0.0786 - val_mse: 0.0136\n",
      "Epoch 33/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0659 - mse: 0.0088\n",
      "Epoch 00033: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0088 - mae: 0.0661 - mse: 0.0088 - val_loss: 0.0160 - val_mae: 0.0929 - val_mse: 0.0160\n",
      "Epoch 34/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0645 - mse: 0.0085\n",
      "Epoch 00034: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0085 - mae: 0.0646 - mse: 0.0085 - val_loss: 0.0145 - val_mae: 0.0875 - val_mse: 0.0145\n",
      "Epoch 35/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0638 - mse: 0.0083\n",
      "Epoch 00035: val_loss improved from 0.01359 to 0.01302, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0082 - mae: 0.0637 - mse: 0.0082 - val_loss: 0.0130 - val_mae: 0.0787 - val_mse: 0.0130\n",
      "Epoch 36/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0653 - mse: 0.0086\n",
      "Epoch 00036: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0086 - mae: 0.0653 - mse: 0.0086 - val_loss: 0.0133 - val_mae: 0.0780 - val_mse: 0.0133\n",
      "Epoch 37/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0630 - mse: 0.0082\n",
      "Epoch 00037: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0081 - mae: 0.0630 - mse: 0.0081 - val_loss: 0.0147 - val_mae: 0.0823 - val_mse: 0.0147\n",
      "Epoch 38/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0626 - mse: 0.0079\n",
      "Epoch 00038: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0079 - mae: 0.0627 - mse: 0.0079 - val_loss: 0.0138 - val_mae: 0.0773 - val_mse: 0.0138\n",
      "Epoch 39/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0633 - mse: 0.0082\n",
      "Epoch 00039: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0082 - mae: 0.0633 - mse: 0.0082 - val_loss: 0.0145 - val_mae: 0.0815 - val_mse: 0.0145\n",
      "Epoch 40/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0606 - mse: 0.0075\n",
      "Epoch 00040: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0075 - mae: 0.0605 - mse: 0.0075 - val_loss: 0.0143 - val_mae: 0.0816 - val_mse: 0.0143\n",
      "Epoch 41/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0619 - mse: 0.0079\n",
      "Epoch 00041: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0078 - mae: 0.0617 - mse: 0.0078 - val_loss: 0.0153 - val_mae: 0.0857 - val_mse: 0.0153\n",
      "Epoch 42/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0604 - mse: 0.0075\n",
      "Epoch 00042: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0075 - mae: 0.0603 - mse: 0.0075 - val_loss: 0.0133 - val_mae: 0.0811 - val_mse: 0.0133\n",
      "Epoch 43/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0601 - mse: 0.0074\n",
      "Epoch 00043: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0074 - mae: 0.0603 - mse: 0.0074 - val_loss: 0.0133 - val_mae: 0.0785 - val_mse: 0.0133\n",
      "Epoch 44/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0583 - mse: 0.0068\n",
      "Epoch 00044: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0068 - mae: 0.0583 - mse: 0.0068 - val_loss: 0.0156 - val_mae: 0.0874 - val_mse: 0.0156\n",
      "Epoch 45/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0599 - mse: 0.0073\n",
      "Epoch 00045: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0073 - mae: 0.0600 - mse: 0.0073 - val_loss: 0.0134 - val_mae: 0.0787 - val_mse: 0.0134\n",
      "Epoch 46/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0586 - mse: 0.0070\n",
      "Epoch 00046: val_loss did not improve from 0.01302\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0070 - mae: 0.0586 - mse: 0.0070 - val_loss: 0.0140 - val_mae: 0.0822 - val_mse: 0.0140\n",
      "Elapsed time during model training:  65.42458820343018\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0467 - mae: 0.1463 - mse: 0.0467\n",
      "Epoch 00001: val_loss improved from inf to 0.02480, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0464,  mae:0.1459,  mse:0.0464,  val_loss:0.0248,  val_mae:0.1110,  val_mse:0.0248,  \n",
      "14926/14926 [==============================] - 2s 147us/sample - loss: 0.0464 - mae: 0.1459 - mse: 0.0464 - val_loss: 0.0248 - val_mae: 0.1110 - val_mse: 0.0248\n",
      "Epoch 2/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0224 - mae: 0.1087 - mse: 0.0224\n",
      "Epoch 00002: val_loss did not improve from 0.02480\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0224 - mae: 0.1088 - mse: 0.0224 - val_loss: 0.0363 - val_mae: 0.1501 - val_mse: 0.0363\n",
      "Epoch 3/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0205 - mae: 0.1037 - mse: 0.0205\n",
      "Epoch 00003: val_loss improved from 0.02480 to 0.01668, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0205 - mae: 0.1036 - mse: 0.0205 - val_loss: 0.0167 - val_mae: 0.0929 - val_mse: 0.0167\n",
      "Epoch 4/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0192 - mae: 0.0997 - mse: 0.0192\n",
      "Epoch 00004: val_loss did not improve from 0.01668\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0192 - mae: 0.0995 - mse: 0.0192 - val_loss: 0.0185 - val_mae: 0.0967 - val_mse: 0.0185\n",
      "Epoch 5/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0977 - mse: 0.0183\n",
      "Epoch 00005: val_loss improved from 0.01668 to 0.01591, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0183 - mae: 0.0977 - mse: 0.0183 - val_loss: 0.0159 - val_mae: 0.0885 - val_mse: 0.0159\n",
      "Epoch 6/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0173 - mae: 0.0940 - mse: 0.0173\n",
      "Epoch 00006: val_loss did not improve from 0.01591\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0172 - mae: 0.0940 - mse: 0.0172 - val_loss: 0.0199 - val_mae: 0.1026 - val_mse: 0.0199\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0898 - mse: 0.0158\n",
      "Epoch 00007: val_loss did not improve from 0.01591\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0162 - mae: 0.0900 - mse: 0.0162 - val_loss: 0.0173 - val_mae: 0.0964 - val_mse: 0.0173\n",
      "Epoch 8/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0938 - mse: 0.0171\n",
      "Epoch 00008: val_loss did not improve from 0.01591\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0170 - mae: 0.0937 - mse: 0.0170 - val_loss: 0.0162 - val_mae: 0.0889 - val_mse: 0.0162\n",
      "Epoch 9/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0895 - mse: 0.0157\n",
      "Epoch 00009: val_loss improved from 0.01591 to 0.01590, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0157 - mae: 0.0895 - mse: 0.0157 - val_loss: 0.0159 - val_mae: 0.0916 - val_mse: 0.0159\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0854 - mse: 0.0148\n",
      "Epoch 00010: val_loss improved from 0.01590 to 0.01567, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0148 - mae: 0.0854 - mse: 0.0148 - val_loss: 0.0157 - val_mae: 0.0851 - val_mse: 0.0157\n",
      "Epoch 11/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0863 - mse: 0.0150\n",
      "Epoch 00011: val_loss did not improve from 0.01567\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0149 - mae: 0.0862 - mse: 0.0149 - val_loss: 0.0173 - val_mae: 0.0884 - val_mse: 0.0173\n",
      "Epoch 12/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0861 - mse: 0.0148\n",
      "Epoch 00012: val_loss improved from 0.01567 to 0.01428, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0147 - mae: 0.0860 - mse: 0.0147 - val_loss: 0.0143 - val_mae: 0.0827 - val_mse: 0.0143\n",
      "Epoch 13/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0831 - mse: 0.0139\n",
      "Epoch 00013: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0140 - mae: 0.0832 - mse: 0.0140 - val_loss: 0.0172 - val_mae: 0.0941 - val_mse: 0.0172\n",
      "Epoch 14/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0828 - mse: 0.0138\n",
      "Epoch 00014: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0138 - mae: 0.0828 - mse: 0.0138 - val_loss: 0.0170 - val_mae: 0.0865 - val_mse: 0.0170\n",
      "Epoch 15/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0822 - mse: 0.0135\n",
      "Epoch 00015: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0135 - mae: 0.0821 - mse: 0.0135 - val_loss: 0.0145 - val_mae: 0.0858 - val_mse: 0.0145\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0799 - mse: 0.0131\n",
      "Epoch 00016: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0131 - mae: 0.0800 - mse: 0.0131 - val_loss: 0.0167 - val_mae: 0.0873 - val_mse: 0.0167\n",
      "Epoch 17/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0787 - mse: 0.0126\n",
      "Epoch 00017: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0125 - mae: 0.0787 - mse: 0.0125 - val_loss: 0.0153 - val_mae: 0.0835 - val_mse: 0.0153\n",
      "Epoch 18/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0781 - mse: 0.0125\n",
      "Epoch 00018: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0125 - mae: 0.0781 - mse: 0.0125 - val_loss: 0.0152 - val_mae: 0.0834 - val_mse: 0.0152\n",
      "Epoch 19/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0764 - mse: 0.0121\n",
      "Epoch 00019: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0120 - mae: 0.0764 - mse: 0.0120 - val_loss: 0.0153 - val_mae: 0.0846 - val_mse: 0.0153\n",
      "Epoch 20/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0122 - mae: 0.0771 - mse: 0.0122\n",
      "Epoch 00020: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0121 - mae: 0.0771 - mse: 0.0121 - val_loss: 0.0147 - val_mae: 0.0831 - val_mse: 0.0147\n",
      "Epoch 21/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0114 - mae: 0.0748 - mse: 0.0114\n",
      "Epoch 00021: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0114 - mae: 0.0748 - mse: 0.0114 - val_loss: 0.0158 - val_mae: 0.0896 - val_mse: 0.0158\n",
      "Epoch 22/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0760 - mse: 0.0115\n",
      "Epoch 00022: val_loss improved from 0.01428 to 0.01393, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0115 - mae: 0.0759 - mse: 0.0115 - val_loss: 0.0139 - val_mae: 0.0790 - val_mse: 0.0139\n",
      "Epoch 23/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0731 - mse: 0.0110\n",
      "Epoch 00023: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0110 - mae: 0.0730 - mse: 0.0110 - val_loss: 0.0150 - val_mae: 0.0853 - val_mse: 0.0150\n",
      "Epoch 24/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0109 - mae: 0.0726 - mse: 0.0109\n",
      "Epoch 00024: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0109 - mae: 0.0726 - mse: 0.0109 - val_loss: 0.0171 - val_mae: 0.0908 - val_mse: 0.0171\n",
      "Epoch 25/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0720 - mse: 0.0107\n",
      "Epoch 00025: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0107 - mae: 0.0721 - mse: 0.0107 - val_loss: 0.0151 - val_mae: 0.0836 - val_mse: 0.0151\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0710 - mse: 0.0104\n",
      "Epoch 00026: val_loss improved from 0.01393 to 0.01386, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0104 - mae: 0.0711 - mse: 0.0104 - val_loss: 0.0139 - val_mae: 0.0808 - val_mse: 0.0139\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0701 - mse: 0.0099\n",
      "Epoch 00027: val_loss did not improve from 0.01386\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0102 - mae: 0.0704 - mse: 0.0102 - val_loss: 0.0173 - val_mae: 0.1020 - val_mse: 0.0173\n",
      "Epoch 28/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0695 - mse: 0.0099\n",
      "Epoch 00028: val_loss improved from 0.01386 to 0.01375, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0099 - mae: 0.0695 - mse: 0.0099 - val_loss: 0.0137 - val_mae: 0.0766 - val_mse: 0.0137\n",
      "Epoch 29/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0686 - mse: 0.0098\n",
      "Epoch 00029: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0098 - mae: 0.0687 - mse: 0.0098 - val_loss: 0.0151 - val_mae: 0.0889 - val_mse: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0689 - mse: 0.0097\n",
      "Epoch 00030: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0097 - mae: 0.0689 - mse: 0.0097 - val_loss: 0.0142 - val_mae: 0.0804 - val_mse: 0.0142\n",
      "Epoch 31/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0685 - mse: 0.0095\n",
      "Epoch 00031: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0094 - mae: 0.0683 - mse: 0.0094 - val_loss: 0.0138 - val_mae: 0.0788 - val_mse: 0.0138\n",
      "Epoch 32/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0672 - mse: 0.0093\n",
      "Epoch 00032: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0160 - val_mae: 0.0819 - val_mse: 0.0160\n",
      "Epoch 33/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0664 - mse: 0.0090\n",
      "Epoch 00033: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0090 - mae: 0.0663 - mse: 0.0090 - val_loss: 0.0146 - val_mae: 0.0791 - val_mse: 0.0146\n",
      "Epoch 34/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0644 - mse: 0.0085\n",
      "Epoch 00034: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0086 - mae: 0.0646 - mse: 0.0086 - val_loss: 0.0148 - val_mae: 0.0834 - val_mse: 0.0148\n",
      "Epoch 35/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0656 - mse: 0.0088\n",
      "Epoch 00035: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0088 - mae: 0.0657 - mse: 0.0088 - val_loss: 0.0164 - val_mae: 0.0899 - val_mse: 0.0164\n",
      "Epoch 36/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0660 - mse: 0.0090\n",
      "Epoch 00036: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0090 - mae: 0.0659 - mse: 0.0090 - val_loss: 0.0139 - val_mae: 0.0791 - val_mse: 0.0139\n",
      "Epoch 37/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0633 - mse: 0.0083\n",
      "Epoch 00037: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0083 - mae: 0.0634 - mse: 0.0083 - val_loss: 0.0148 - val_mae: 0.0847 - val_mse: 0.0148\n",
      "Epoch 38/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0627 - mse: 0.0080\n",
      "Epoch 00038: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0080 - mae: 0.0626 - mse: 0.0080 - val_loss: 0.0141 - val_mae: 0.0799 - val_mse: 0.0141\n",
      "Epoch 39/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0632 - mse: 0.0082\n",
      "Epoch 00039: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0081 - mae: 0.0631 - mse: 0.0081 - val_loss: 0.0148 - val_mae: 0.0855 - val_mse: 0.0148\n",
      "Epoch 40/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0623 - mse: 0.0079\n",
      "Epoch 00040: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0079 - mae: 0.0622 - mse: 0.0079 - val_loss: 0.0141 - val_mae: 0.0811 - val_mse: 0.0141\n",
      "Epoch 41/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0610 - mse: 0.0076\n",
      "Epoch 00041: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0076 - mae: 0.0612 - mse: 0.0076 - val_loss: 0.0138 - val_mae: 0.0778 - val_mse: 0.0138\n",
      "Epoch 42/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0077 - mae: 0.0612 - mse: 0.0077\n",
      "Epoch 00042: val_loss improved from 0.01375 to 0.01351, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0077 - mae: 0.0612 - mse: 0.0077 - val_loss: 0.0135 - val_mae: 0.0795 - val_mse: 0.0135\n",
      "Epoch 43/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0599 - mse: 0.0072\n",
      "Epoch 00043: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0072 - mae: 0.0600 - mse: 0.0072 - val_loss: 0.0143 - val_mae: 0.0866 - val_mse: 0.0143\n",
      "Epoch 44/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0622 - mse: 0.0077\n",
      "Epoch 00044: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0081 - mae: 0.0627 - mse: 0.0081 - val_loss: 0.0170 - val_mae: 0.0934 - val_mse: 0.0170\n",
      "Epoch 45/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0590 - mse: 0.0072\n",
      "Epoch 00045: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0071 - mae: 0.0590 - mse: 0.0071 - val_loss: 0.0139 - val_mae: 0.0787 - val_mse: 0.0139\n",
      "Epoch 46/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0591 - mse: 0.0073\n",
      "Epoch 00046: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0073 - mae: 0.0591 - mse: 0.0073 - val_loss: 0.0144 - val_mae: 0.0775 - val_mse: 0.0144\n",
      "Epoch 47/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0590 - mse: 0.0072\n",
      "Epoch 00047: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0072 - mae: 0.0590 - mse: 0.0072 - val_loss: 0.0149 - val_mae: 0.0826 - val_mse: 0.0149\n",
      "Epoch 48/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0591 - mse: 0.0070\n",
      "Epoch 00048: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0070 - mae: 0.0591 - mse: 0.0070 - val_loss: 0.0137 - val_mae: 0.0774 - val_mse: 0.0137\n",
      "Epoch 49/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0072 - mae: 0.0589 - mse: 0.0072\n",
      "Epoch 00049: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0072 - mae: 0.0589 - mse: 0.0072 - val_loss: 0.0137 - val_mae: 0.0770 - val_mse: 0.0137\n",
      "Epoch 50/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0065 - mae: 0.0568 - mse: 0.0065\n",
      "Epoch 00050: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0065 - mae: 0.0567 - mse: 0.0065 - val_loss: 0.0141 - val_mae: 0.0775 - val_mse: 0.0141\n",
      "Epoch 51/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0577 - mse: 0.0066\n",
      "Epoch 00051: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0066 - mae: 0.0577 - mse: 0.0066 - val_loss: 0.0145 - val_mae: 0.0789 - val_mse: 0.0145\n",
      "Epoch 52/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0559 - mse: 0.0063\n",
      "Epoch 00052: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0063 - mae: 0.0558 - mse: 0.0063 - val_loss: 0.0140 - val_mae: 0.0768 - val_mse: 0.0140\n",
      "Epoch 53/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0577 - mse: 0.0067\n",
      "Epoch 00053: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0067 - mae: 0.0577 - mse: 0.0067 - val_loss: 0.0151 - val_mae: 0.0833 - val_mse: 0.0151\n",
      "Epoch 54/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0561 - mse: 0.0065\n",
      "Epoch 00054: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0065 - mae: 0.0561 - mse: 0.0065 - val_loss: 0.0146 - val_mae: 0.0826 - val_mse: 0.0146\n",
      "Epoch 55/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0559 - mse: 0.0064\n",
      "Epoch 00055: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0064 - mae: 0.0558 - mse: 0.0064 - val_loss: 0.0138 - val_mae: 0.0768 - val_mse: 0.0138\n",
      "Epoch 56/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0057 - mae: 0.0536 - mse: 0.0057\n",
      "Epoch 00056: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0060 - mae: 0.0542 - mse: 0.0060 - val_loss: 0.0158 - val_mae: 0.0844 - val_mse: 0.0158\n",
      "Epoch 57/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0560 - mse: 0.0066\n",
      "Epoch 00057: val_loss did not improve from 0.01351\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0066 - mae: 0.0560 - mse: 0.0066 - val_loss: 0.0145 - val_mae: 0.0808 - val_mse: 0.0145\n",
      "Elapsed time during model training:  79.99616050720215\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0461 - mae: 0.1496 - mse: 0.0461\n",
      "Epoch 00001: val_loss improved from inf to 0.02003, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0459,  mae:0.1492,  mse:0.0459,  val_loss:0.0200,  val_mae:0.1046,  val_mse:0.0200,  \n",
      "14926/14926 [==============================] - 2s 144us/sample - loss: 0.0459 - mae: 0.1492 - mse: 0.0459 - val_loss: 0.0200 - val_mae: 0.1046 - val_mse: 0.0200\n",
      "Epoch 2/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0236 - mae: 0.1132 - mse: 0.0236\n",
      "Epoch 00002: val_loss improved from 0.02003 to 0.01842, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0235 - mae: 0.1129 - mse: 0.0235 - val_loss: 0.0184 - val_mae: 0.0995 - val_mse: 0.0184\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0190 - mae: 0.0989 - mse: 0.0190\n",
      "Epoch 00003: val_loss did not improve from 0.01842\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0190 - mae: 0.0988 - mse: 0.0190 - val_loss: 0.0188 - val_mae: 0.0986 - val_mse: 0.0188\n",
      "Epoch 4/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0197 - mae: 0.1018 - mse: 0.0197\n",
      "Epoch 00004: val_loss did not improve from 0.01842\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0197 - mae: 0.1018 - mse: 0.0197 - val_loss: 0.0187 - val_mae: 0.1016 - val_mse: 0.0187\n",
      "Epoch 5/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0182 - mae: 0.0968 - mse: 0.0182\n",
      "Epoch 00005: val_loss improved from 0.01842 to 0.01826, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0181 - mae: 0.0966 - mse: 0.0181 - val_loss: 0.0183 - val_mae: 0.0987 - val_mse: 0.0183\n",
      "Epoch 6/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0934 - mse: 0.0171\n",
      "Epoch 00006: val_loss improved from 0.01826 to 0.01797, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0172 - mae: 0.0936 - mse: 0.0172 - val_loss: 0.0180 - val_mae: 0.0967 - val_mse: 0.0180\n",
      "Epoch 7/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0946 - mse: 0.0171\n",
      "Epoch 00007: val_loss improved from 0.01797 to 0.01701, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0171 - mae: 0.0944 - mse: 0.0171 - val_loss: 0.0170 - val_mae: 0.0896 - val_mse: 0.0170\n",
      "Epoch 8/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0926 - mse: 0.0166\n",
      "Epoch 00008: val_loss did not improve from 0.01701\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0166 - mae: 0.0927 - mse: 0.0166 - val_loss: 0.0197 - val_mae: 0.1057 - val_mse: 0.0197\n",
      "Epoch 9/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0907 - mse: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.01701\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0160 - mae: 0.0907 - mse: 0.0160 - val_loss: 0.0171 - val_mae: 0.0945 - val_mse: 0.0171\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0868 - mse: 0.0150\n",
      "Epoch 00010: val_loss improved from 0.01701 to 0.01676, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0150 - mae: 0.0868 - mse: 0.0150 - val_loss: 0.0168 - val_mae: 0.0907 - val_mse: 0.0168\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0857 - mse: 0.0146\n",
      "Epoch 00011: val_loss did not improve from 0.01676\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0147 - mae: 0.0857 - mse: 0.0147 - val_loss: 0.0181 - val_mae: 0.0957 - val_mse: 0.0181\n",
      "Epoch 12/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0858 - mse: 0.0145\n",
      "Epoch 00012: val_loss improved from 0.01676 to 0.01639, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0144 - mae: 0.0857 - mse: 0.0144 - val_loss: 0.0164 - val_mae: 0.0879 - val_mse: 0.0164\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0838 - mse: 0.0139\n",
      "Epoch 00013: val_loss did not improve from 0.01639\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0139 - mae: 0.0838 - mse: 0.0139 - val_loss: 0.0169 - val_mae: 0.0918 - val_mse: 0.0169\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0829 - mse: 0.0137\n",
      "Epoch 00014: val_loss improved from 0.01639 to 0.01540, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0137 - mae: 0.0829 - mse: 0.0137 - val_loss: 0.0154 - val_mae: 0.0873 - val_mse: 0.0154\n",
      "Epoch 15/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0825 - mse: 0.0135\n",
      "Epoch 00015: val_loss did not improve from 0.01540\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0135 - mae: 0.0825 - mse: 0.0135 - val_loss: 0.0176 - val_mae: 0.0941 - val_mse: 0.0176\n",
      "Epoch 16/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0131 - mae: 0.0812 - mse: 0.0131\n",
      "Epoch 00016: val_loss improved from 0.01540 to 0.01532, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0131 - mae: 0.0814 - mse: 0.0131 - val_loss: 0.0153 - val_mae: 0.0873 - val_mse: 0.0153\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0796 - mse: 0.0127\n",
      "Epoch 00017: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0126 - mae: 0.0794 - mse: 0.0126 - val_loss: 0.0163 - val_mae: 0.0915 - val_mse: 0.0163\n",
      "Epoch 18/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0777 - mse: 0.0122\n",
      "Epoch 00018: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0123 - mae: 0.0780 - mse: 0.0123 - val_loss: 0.0179 - val_mae: 0.0935 - val_mse: 0.0179\n",
      "Epoch 19/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0773 - mse: 0.0121\n",
      "Epoch 00019: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0121 - mae: 0.0775 - mse: 0.0121 - val_loss: 0.0218 - val_mae: 0.1095 - val_mse: 0.0218\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0772 - mse: 0.0120\n",
      "Epoch 00020: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0119 - mae: 0.0770 - mse: 0.0119 - val_loss: 0.0154 - val_mae: 0.0858 - val_mse: 0.0154\n",
      "Epoch 21/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0759 - mse: 0.0114\n",
      "Epoch 00021: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0114 - mae: 0.0758 - mse: 0.0114 - val_loss: 0.0164 - val_mae: 0.0869 - val_mse: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0745 - mse: 0.0112\n",
      "Epoch 00022: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0112 - mae: 0.0746 - mse: 0.0112 - val_loss: 0.0181 - val_mae: 0.0943 - val_mse: 0.0181\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0107 - mae: 0.0734 - mse: 0.0107\n",
      "Epoch 00023: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0190 - val_mae: 0.1033 - val_mse: 0.0190\n",
      "Epoch 24/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0746 - mse: 0.0109\n",
      "Epoch 00024: val_loss did not improve from 0.01532\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0110 - mae: 0.0746 - mse: 0.0110 - val_loss: 0.0159 - val_mae: 0.0850 - val_mse: 0.0159\n",
      "Elapsed time during model training:  34.435476303100586\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0537 - mae: 0.1595 - mse: 0.0537\n",
      "Epoch 00001: val_loss improved from inf to 0.02480, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0533,  mae:0.1589,  mse:0.0533,  val_loss:0.0248,  val_mae:0.1211,  val_mse:0.0248,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0533 - mae: 0.1589 - mse: 0.0533 - val_loss: 0.0248 - val_mae: 0.1211 - val_mse: 0.0248\n",
      "Epoch 2/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0217 - mae: 0.1068 - mse: 0.0217\n",
      "Epoch 00002: val_loss improved from 0.02480 to 0.02316, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0217 - mae: 0.1067 - mse: 0.0217 - val_loss: 0.0232 - val_mae: 0.1133 - val_mse: 0.0232\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0197 - mae: 0.1012 - mse: 0.0197\n",
      "Epoch 00003: val_loss improved from 0.02316 to 0.01973, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0197 - mae: 0.1014 - mse: 0.0197 - val_loss: 0.0197 - val_mae: 0.1007 - val_mse: 0.0197\n",
      "Epoch 4/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0197 - mae: 0.1017 - mse: 0.0197\n",
      "Epoch 00004: val_loss improved from 0.01973 to 0.01744, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0196 - mae: 0.1015 - mse: 0.0196 - val_loss: 0.0174 - val_mae: 0.0943 - val_mse: 0.0174\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0182 - mae: 0.0968 - mse: 0.0182\n",
      "Epoch 00005: val_loss did not improve from 0.01744\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0181 - mae: 0.0968 - mse: 0.0181 - val_loss: 0.0183 - val_mae: 0.0980 - val_mse: 0.0183\n",
      "Epoch 6/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0171 - mae: 0.0934 - mse: 0.0171\n",
      "Epoch 00006: val_loss improved from 0.01744 to 0.01723, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0171 - mae: 0.0934 - mse: 0.0171 - val_loss: 0.0172 - val_mae: 0.0937 - val_mse: 0.0172\n",
      "Epoch 7/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0916 - mse: 0.0165\n",
      "Epoch 00007: val_loss did not improve from 0.01723\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0166 - mae: 0.0916 - mse: 0.0166 - val_loss: 0.0180 - val_mae: 0.0968 - val_mse: 0.0180\n",
      "Epoch 8/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0894 - mse: 0.0159\n",
      "Epoch 00008: val_loss did not improve from 0.01723\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0159 - mae: 0.0893 - mse: 0.0159 - val_loss: 0.0189 - val_mae: 0.1047 - val_mse: 0.0189\n",
      "Epoch 9/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0901 - mse: 0.0160\n",
      "Epoch 00009: val_loss improved from 0.01723 to 0.01552, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0160 - mae: 0.0900 - mse: 0.0160 - val_loss: 0.0155 - val_mae: 0.0872 - val_mse: 0.0155\n",
      "Epoch 10/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0861 - mse: 0.0151\n",
      "Epoch 00010: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0151 - mae: 0.0862 - mse: 0.0151 - val_loss: 0.0157 - val_mae: 0.0882 - val_mse: 0.0157\n",
      "Epoch 11/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0858 - mse: 0.0148\n",
      "Epoch 00011: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0148 - mae: 0.0858 - mse: 0.0148 - val_loss: 0.0157 - val_mae: 0.0849 - val_mse: 0.0157\n",
      "Epoch 12/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0144 - mae: 0.0840 - mse: 0.0144\n",
      "Epoch 00012: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0144 - mae: 0.0839 - mse: 0.0144 - val_loss: 0.0158 - val_mae: 0.0867 - val_mse: 0.0158\n",
      "Epoch 13/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0845 - mse: 0.0143\n",
      "Epoch 00013: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0144 - mae: 0.0845 - mse: 0.0144 - val_loss: 0.0163 - val_mae: 0.0931 - val_mse: 0.0163\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0834 - mse: 0.0141\n",
      "Epoch 00014: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0140 - mae: 0.0834 - mse: 0.0140 - val_loss: 0.0195 - val_mae: 0.1030 - val_mse: 0.0195\n",
      "Epoch 15/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0820 - mse: 0.0137\n",
      "Epoch 00015: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0137 - mae: 0.0822 - mse: 0.0137 - val_loss: 0.0182 - val_mae: 0.0988 - val_mse: 0.0182\n",
      "Epoch 16/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0805 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0132 - mae: 0.0807 - mse: 0.0132 - val_loss: 0.0175 - val_mae: 0.0994 - val_mse: 0.0175\n",
      "Epoch 17/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0802 - mse: 0.0130\n",
      "Epoch 00017: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0130 - mae: 0.0803 - mse: 0.0130 - val_loss: 0.0169 - val_mae: 0.0904 - val_mse: 0.0169\n",
      "Epoch 18/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0790 - mse: 0.0125\n",
      "Epoch 00018: val_loss did not improve from 0.01552\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0130 - mae: 0.0799 - mse: 0.0130 - val_loss: 0.0164 - val_mae: 0.0911 - val_mse: 0.0164\n",
      "Elapsed time during model training:  26.641403675079346\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0557 - mae: 0.1610 - mse: 0.0557\n",
      "Epoch 00001: val_loss improved from inf to 0.02348, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0548,  mae:0.1596,  mse:0.0548,  val_loss:0.0235,  val_mae:0.1120,  val_mse:0.0235,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0548 - mae: 0.1596 - mse: 0.0548 - val_loss: 0.0235 - val_mae: 0.1120 - val_mse: 0.0235\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0239 - mae: 0.1132 - mse: 0.0239\n",
      "Epoch 00002: val_loss improved from 0.02348 to 0.01859, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0238 - mae: 0.1130 - mse: 0.0238 - val_loss: 0.0186 - val_mae: 0.0986 - val_mse: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0200 - mae: 0.1019 - mse: 0.0200\n",
      "Epoch 00003: val_loss did not improve from 0.01859\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0202 - mae: 0.1026 - mse: 0.0202 - val_loss: 0.0258 - val_mae: 0.1208 - val_mse: 0.0258\n",
      "Epoch 4/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.0988 - mse: 0.0188\n",
      "Epoch 00004: val_loss improved from 0.01859 to 0.01806, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0188 - mae: 0.0987 - mse: 0.0188 - val_loss: 0.0181 - val_mae: 0.0935 - val_mse: 0.0181\n",
      "Epoch 5/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0182 - mae: 0.0965 - mse: 0.0182\n",
      "Epoch 00005: val_loss did not improve from 0.01806\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0183 - mae: 0.0968 - mse: 0.0183 - val_loss: 0.0234 - val_mae: 0.1192 - val_mse: 0.0234\n",
      "Epoch 6/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0956 - mse: 0.0179\n",
      "Epoch 00006: val_loss improved from 0.01806 to 0.01731, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0179 - mae: 0.0955 - mse: 0.0179 - val_loss: 0.0173 - val_mae: 0.0946 - val_mse: 0.0173\n",
      "Epoch 7/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0943 - mse: 0.0172\n",
      "Epoch 00007: val_loss did not improve from 0.01731\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0172 - mae: 0.0943 - mse: 0.0172 - val_loss: 0.0199 - val_mae: 0.1047 - val_mse: 0.0199\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0936 - mse: 0.0170\n",
      "Epoch 00008: val_loss improved from 0.01731 to 0.01476, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0170 - mae: 0.0935 - mse: 0.0170 - val_loss: 0.0148 - val_mae: 0.0825 - val_mse: 0.0148\n",
      "Epoch 9/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0907 - mse: 0.0161\n",
      "Epoch 00009: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0161 - mae: 0.0907 - mse: 0.0161 - val_loss: 0.0177 - val_mae: 0.0968 - val_mse: 0.0177\n",
      "Epoch 10/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0154 - mae: 0.0880 - mse: 0.0154\n",
      "Epoch 00010: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0155 - mae: 0.0882 - mse: 0.0155 - val_loss: 0.0163 - val_mae: 0.0883 - val_mse: 0.0163\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0885 - mse: 0.0156\n",
      "Epoch 00011: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0155 - mae: 0.0883 - mse: 0.0155 - val_loss: 0.0165 - val_mae: 0.0875 - val_mse: 0.0165\n",
      "Epoch 12/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0844 - mse: 0.0144\n",
      "Epoch 00012: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0144 - mae: 0.0845 - mse: 0.0144 - val_loss: 0.0166 - val_mae: 0.0889 - val_mse: 0.0166\n",
      "Epoch 13/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0860 - mse: 0.0148\n",
      "Epoch 00013: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0147 - mae: 0.0859 - mse: 0.0147 - val_loss: 0.0167 - val_mae: 0.0920 - val_mse: 0.0167\n",
      "Epoch 14/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0844 - mse: 0.0141\n",
      "Epoch 00014: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0143 - mae: 0.0849 - mse: 0.0143 - val_loss: 0.0171 - val_mae: 0.0921 - val_mse: 0.0171\n",
      "Epoch 15/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0844 - mse: 0.0141\n",
      "Epoch 00015: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0141 - mae: 0.0846 - mse: 0.0141 - val_loss: 0.0153 - val_mae: 0.0863 - val_mse: 0.0153\n",
      "Epoch 16/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0818 - mse: 0.0133\n",
      "Epoch 00016: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0133 - mae: 0.0820 - mse: 0.0133 - val_loss: 0.0151 - val_mae: 0.0848 - val_mse: 0.0151\n",
      "Epoch 17/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0808 - mse: 0.0132\n",
      "Epoch 00017: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0132 - mae: 0.0809 - mse: 0.0132 - val_loss: 0.0156 - val_mae: 0.0872 - val_mse: 0.0156\n",
      "Epoch 18/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0806 - mse: 0.0130\n",
      "Epoch 00018: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0129 - mae: 0.0804 - mse: 0.0129 - val_loss: 0.0150 - val_mae: 0.0840 - val_mse: 0.0150\n",
      "Epoch 19/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0788 - mse: 0.0125\n",
      "Epoch 00019: val_loss did not improve from 0.01476\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0125 - mae: 0.0788 - mse: 0.0125 - val_loss: 0.0159 - val_mae: 0.0900 - val_mse: 0.0159\n",
      "Elapsed time during model training:  26.066182374954224\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0457 - mae: 0.1473 - mse: 0.0457\n",
      "Epoch 00001: val_loss improved from inf to 0.03536, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0456,  mae:0.1473,  mse:0.0456,  val_loss:0.0354,  val_mae:0.1512,  val_mse:0.0354,  \n",
      "14926/14926 [==============================] - 2s 143us/sample - loss: 0.0456 - mae: 0.1473 - mse: 0.0456 - val_loss: 0.0354 - val_mae: 0.1512 - val_mse: 0.0354\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0244 - mae: 0.1144 - mse: 0.0244\n",
      "Epoch 00002: val_loss improved from 0.03536 to 0.02128, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0244 - mae: 0.1142 - mse: 0.0244 - val_loss: 0.0213 - val_mae: 0.1078 - val_mse: 0.0213\n",
      "Epoch 3/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0210 - mae: 0.1053 - mse: 0.0210\n",
      "Epoch 00003: val_loss did not improve from 0.02128\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0212 - mae: 0.1060 - mse: 0.0212 - val_loss: 0.0222 - val_mae: 0.1041 - val_mse: 0.0222\n",
      "Epoch 4/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1034 - mse: 0.0203\n",
      "Epoch 00004: val_loss improved from 0.02128 to 0.02070, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0201 - mae: 0.1031 - mse: 0.0201 - val_loss: 0.0207 - val_mae: 0.1054 - val_mse: 0.0207\n",
      "Epoch 5/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1009 - mse: 0.0193\n",
      "Epoch 00005: val_loss improved from 0.02070 to 0.01801, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0193 - mae: 0.1008 - mse: 0.0193 - val_loss: 0.0180 - val_mae: 0.0973 - val_mse: 0.0180\n",
      "Epoch 6/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0958 - mse: 0.0178\n",
      "Epoch 00006: val_loss improved from 0.01801 to 0.01603, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 129us/sample - loss: 0.0177 - mae: 0.0957 - mse: 0.0177 - val_loss: 0.0160 - val_mae: 0.0887 - val_mse: 0.0160\n",
      "Epoch 7/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0943 - mse: 0.0172\n",
      "Epoch 00007: val_loss did not improve from 0.01603\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0172 - mae: 0.0943 - mse: 0.0172 - val_loss: 0.0182 - val_mae: 0.0955 - val_mse: 0.0182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0165 - mae: 0.0917 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01603\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0166 - mae: 0.0920 - mse: 0.0166 - val_loss: 0.0162 - val_mae: 0.0883 - val_mse: 0.0162\n",
      "Epoch 9/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0160 - mae: 0.0909 - mse: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.01603\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0160 - mae: 0.0910 - mse: 0.0160 - val_loss: 0.0176 - val_mae: 0.0979 - val_mse: 0.0176\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0155 - mae: 0.0891 - mse: 0.0155\n",
      "Epoch 00010: val_loss did not improve from 0.01603\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0156 - mae: 0.0891 - mse: 0.0156 - val_loss: 0.0166 - val_mae: 0.0936 - val_mse: 0.0166\n",
      "Epoch 11/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0152 - mae: 0.0877 - mse: 0.0152\n",
      "Epoch 00011: val_loss improved from 0.01603 to 0.01469, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0151 - mae: 0.0878 - mse: 0.0151 - val_loss: 0.0147 - val_mae: 0.0845 - val_mse: 0.0147\n",
      "Epoch 12/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0852 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01469\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0145 - mae: 0.0853 - mse: 0.0145 - val_loss: 0.0204 - val_mae: 0.1032 - val_mse: 0.0204\n",
      "Epoch 13/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0853 - mse: 0.0143\n",
      "Epoch 00013: val_loss did not improve from 0.01469\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0143 - mae: 0.0853 - mse: 0.0143 - val_loss: 0.0189 - val_mae: 0.1023 - val_mse: 0.0189\n",
      "Epoch 14/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0815 - mse: 0.0133\n",
      "Epoch 00014: val_loss improved from 0.01469 to 0.01457, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0133 - mae: 0.0815 - mse: 0.0133 - val_loss: 0.0146 - val_mae: 0.0852 - val_mse: 0.0146\n",
      "Epoch 15/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0845 - mse: 0.0139\n",
      "Epoch 00015: val_loss did not improve from 0.01457\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0139 - mae: 0.0845 - mse: 0.0139 - val_loss: 0.0151 - val_mae: 0.0882 - val_mse: 0.0151\n",
      "Epoch 16/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0798 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01457\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0128 - mae: 0.0798 - mse: 0.0128 - val_loss: 0.0182 - val_mae: 0.0999 - val_mse: 0.0182\n",
      "Epoch 17/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0130 - mae: 0.0811 - mse: 0.0130\n",
      "Epoch 00017: val_loss did not improve from 0.01457\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0129 - mae: 0.0810 - mse: 0.0129 - val_loss: 0.0150 - val_mae: 0.0858 - val_mse: 0.0150\n",
      "Epoch 18/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0777 - mse: 0.0122\n",
      "Epoch 00018: val_loss improved from 0.01457 to 0.01403, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0122 - mae: 0.0778 - mse: 0.0122 - val_loss: 0.0140 - val_mae: 0.0801 - val_mse: 0.0140\n",
      "Epoch 19/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0119 - mae: 0.0771 - mse: 0.0119\n",
      "Epoch 00019: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0120 - mae: 0.0771 - mse: 0.0120 - val_loss: 0.0148 - val_mae: 0.0834 - val_mse: 0.0148\n",
      "Epoch 20/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0751 - mse: 0.0111\n",
      "Epoch 00020: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0115 - mae: 0.0754 - mse: 0.0115 - val_loss: 0.0164 - val_mae: 0.0960 - val_mse: 0.0164\n",
      "Epoch 21/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0115 - mae: 0.0762 - mse: 0.0115\n",
      "Epoch 00021: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0115 - mae: 0.0762 - mse: 0.0115 - val_loss: 0.0142 - val_mae: 0.0832 - val_mse: 0.0142\n",
      "Epoch 22/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0767 - mse: 0.0116\n",
      "Epoch 00022: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0116 - mae: 0.0768 - mse: 0.0116 - val_loss: 0.0150 - val_mae: 0.0844 - val_mse: 0.0150\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0714 - mse: 0.0105\n",
      "Epoch 00023: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0105 - mae: 0.0714 - mse: 0.0105 - val_loss: 0.0148 - val_mae: 0.0875 - val_mse: 0.0148\n",
      "Epoch 24/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0763 - mse: 0.0115\n",
      "Epoch 00024: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0114 - mae: 0.0761 - mse: 0.0114 - val_loss: 0.0142 - val_mae: 0.0805 - val_mse: 0.0142\n",
      "Epoch 25/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0100 - mae: 0.0713 - mse: 0.0100\n",
      "Epoch 00025: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0103 - mae: 0.0715 - mse: 0.0103 - val_loss: 0.0167 - val_mae: 0.0939 - val_mse: 0.0167\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0717 - mse: 0.0103\n",
      "Epoch 00026: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0104 - mae: 0.0719 - mse: 0.0104 - val_loss: 0.0149 - val_mae: 0.0822 - val_mse: 0.0149\n",
      "Epoch 27/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0710 - mse: 0.0102\n",
      "Epoch 00027: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0103 - mae: 0.0711 - mse: 0.0103 - val_loss: 0.0164 - val_mae: 0.0947 - val_mse: 0.0164\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0699 - mse: 0.0098\n",
      "Epoch 00028: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0098 - mae: 0.0700 - mse: 0.0098 - val_loss: 0.0143 - val_mae: 0.0829 - val_mse: 0.0143\n",
      "Epoch 29/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0685 - mse: 0.0095\n",
      "Epoch 00029: val_loss improved from 0.01403 to 0.01355, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0095 - mae: 0.0685 - mse: 0.0095 - val_loss: 0.0136 - val_mae: 0.0791 - val_mse: 0.0136\n",
      "Epoch 30/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0694 - mse: 0.0096\n",
      "Epoch 00030: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0096 - mae: 0.0693 - mse: 0.0096 - val_loss: 0.0140 - val_mae: 0.0812 - val_mse: 0.0140\n",
      "Epoch 31/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0673 - mse: 0.0092\n",
      "Epoch 00031: val_loss improved from 0.01355 to 0.01347, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0092 - mae: 0.0674 - mse: 0.0092 - val_loss: 0.0135 - val_mae: 0.0786 - val_mse: 0.0135\n",
      "Epoch 32/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0678 - mse: 0.0093\n",
      "Epoch 00032: val_loss did not improve from 0.01347\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0093 - mae: 0.0678 - mse: 0.0093 - val_loss: 0.0149 - val_mae: 0.0815 - val_mse: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0672 - mse: 0.0091\n",
      "Epoch 00033: val_loss improved from 0.01347 to 0.01334, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0091 - mae: 0.0672 - mse: 0.0091 - val_loss: 0.0133 - val_mae: 0.0784 - val_mse: 0.0133\n",
      "Epoch 34/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0087 - mae: 0.0658 - mse: 0.0087\n",
      "Epoch 00034: val_loss improved from 0.01334 to 0.01326, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0087 - mae: 0.0660 - mse: 0.0087 - val_loss: 0.0133 - val_mae: 0.0763 - val_mse: 0.0133\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0656 - mse: 0.0089\n",
      "Epoch 00035: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0088 - mae: 0.0654 - mse: 0.0088 - val_loss: 0.0144 - val_mae: 0.0826 - val_mse: 0.0144\n",
      "Epoch 36/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0646 - mse: 0.0085\n",
      "Epoch 00036: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0085 - mae: 0.0647 - mse: 0.0085 - val_loss: 0.0147 - val_mae: 0.0854 - val_mse: 0.0147\n",
      "Epoch 37/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0640 - mse: 0.0083\n",
      "Epoch 00037: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0084 - mae: 0.0642 - mse: 0.0084 - val_loss: 0.0173 - val_mae: 0.0968 - val_mse: 0.0173\n",
      "Epoch 38/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0640 - mse: 0.0084\n",
      "Epoch 00038: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0084 - mae: 0.0641 - mse: 0.0084 - val_loss: 0.0146 - val_mae: 0.0861 - val_mse: 0.0146\n",
      "Epoch 39/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0642 - mse: 0.0082\n",
      "Epoch 00039: val_loss improved from 0.01326 to 0.01312, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0082 - mae: 0.0641 - mse: 0.0082 - val_loss: 0.0131 - val_mae: 0.0771 - val_mse: 0.0131\n",
      "Epoch 40/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0078 - mae: 0.0627 - mse: 0.0078\n",
      "Epoch 00040: val_loss did not improve from 0.01312\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0079 - mae: 0.0630 - mse: 0.0079 - val_loss: 0.0153 - val_mae: 0.0884 - val_mse: 0.0153\n",
      "Epoch 41/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0626 - mse: 0.0078\n",
      "Epoch 00041: val_loss did not improve from 0.01312\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0078 - mae: 0.0626 - mse: 0.0078 - val_loss: 0.0141 - val_mae: 0.0842 - val_mse: 0.0141\n",
      "Epoch 42/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0626 - mse: 0.0079\n",
      "Epoch 00042: val_loss did not improve from 0.01312\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0078 - mae: 0.0625 - mse: 0.0078 - val_loss: 0.0139 - val_mae: 0.0780 - val_mse: 0.0139\n",
      "Epoch 43/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0612 - mse: 0.0076\n",
      "Epoch 00043: val_loss improved from 0.01312 to 0.01307, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0076 - mae: 0.0612 - mse: 0.0076 - val_loss: 0.0131 - val_mae: 0.0772 - val_mse: 0.0131\n",
      "Epoch 44/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0595 - mse: 0.0073\n",
      "Epoch 00044: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0073 - mae: 0.0594 - mse: 0.0073 - val_loss: 0.0152 - val_mae: 0.0877 - val_mse: 0.0152\n",
      "Epoch 45/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0606 - mse: 0.0075\n",
      "Epoch 00045: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0075 - mae: 0.0608 - mse: 0.0075 - val_loss: 0.0145 - val_mae: 0.0831 - val_mse: 0.0145\n",
      "Epoch 46/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0588 - mse: 0.0070\n",
      "Epoch 00046: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0071 - mae: 0.0591 - mse: 0.0071 - val_loss: 0.0153 - val_mae: 0.0835 - val_mse: 0.0153\n",
      "Epoch 47/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0614 - mse: 0.0075\n",
      "Epoch 00047: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0075 - mae: 0.0615 - mse: 0.0075 - val_loss: 0.0133 - val_mae: 0.0762 - val_mse: 0.0133\n",
      "Epoch 48/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0597 - mse: 0.0070\n",
      "Epoch 00048: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0070 - mae: 0.0596 - mse: 0.0070 - val_loss: 0.0135 - val_mae: 0.0778 - val_mse: 0.0135\n",
      "Epoch 49/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0068 - mae: 0.0581 - mse: 0.0068\n",
      "Epoch 00049: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0067 - mae: 0.0581 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 50/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0602 - mse: 0.0073\n",
      "Epoch 00050: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0073 - mae: 0.0601 - mse: 0.0073 - val_loss: 0.0133 - val_mae: 0.0768 - val_mse: 0.0133\n",
      "Epoch 51/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0067 - mae: 0.0574 - mse: 0.0067\n",
      "Epoch 00051: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0068 - mae: 0.0578 - mse: 0.0068 - val_loss: 0.0146 - val_mae: 0.0877 - val_mse: 0.0146\n",
      "Epoch 52/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0575 - mse: 0.0068\n",
      "Epoch 00052: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0068 - mae: 0.0575 - mse: 0.0068 - val_loss: 0.0152 - val_mae: 0.0882 - val_mse: 0.0152\n",
      "Epoch 53/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0584 - mse: 0.0068\n",
      "Epoch 00053: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0067 - mae: 0.0584 - mse: 0.0067 - val_loss: 0.0134 - val_mae: 0.0822 - val_mse: 0.0134\n",
      "Epoch 54/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0575 - mse: 0.0066\n",
      "Epoch 00054: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0066 - mae: 0.0576 - mse: 0.0066 - val_loss: 0.0139 - val_mae: 0.0779 - val_mse: 0.0139\n",
      "Epoch 55/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0564 - mse: 0.0062\n",
      "Epoch 00055: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0062 - mae: 0.0564 - mse: 0.0062 - val_loss: 0.0138 - val_mae: 0.0771 - val_mse: 0.0138\n",
      "Elapsed time during model training:  76.67872786521912\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0524 - mae: 0.1530 - mse: 0.0524\n",
      "Epoch 00001: val_loss improved from inf to 0.01999, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0522,  mae:0.1527,  mse:0.0522,  val_loss:0.0200,  val_mae:0.1023,  val_mse:0.0200,  \n",
      "14926/14926 [==============================] - 2s 142us/sample - loss: 0.0522 - mae: 0.1527 - mse: 0.0522 - val_loss: 0.0200 - val_mae: 0.1023 - val_mse: 0.0200\n",
      "Epoch 2/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0230 - mae: 0.1110 - mse: 0.0230\n",
      "Epoch 00002: val_loss did not improve from 0.01999\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0230 - mae: 0.1109 - mse: 0.0230 - val_loss: 0.0203 - val_mae: 0.0994 - val_mse: 0.0203\n",
      "Epoch 3/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0199 - mae: 0.1014 - mse: 0.0199\n",
      "Epoch 00003: val_loss improved from 0.01999 to 0.01684, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0199 - mae: 0.1014 - mse: 0.0199 - val_loss: 0.0168 - val_mae: 0.0939 - val_mse: 0.0168\n",
      "Epoch 4/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0194 - mae: 0.1003 - mse: 0.0194\n",
      "Epoch 00004: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0194 - mae: 0.1004 - mse: 0.0194 - val_loss: 0.0177 - val_mae: 0.0962 - val_mse: 0.0177\n",
      "Epoch 5/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0180 - mae: 0.0962 - mse: 0.0180\n",
      "Epoch 00005: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0180 - mae: 0.0964 - mse: 0.0180 - val_loss: 0.0177 - val_mae: 0.0925 - val_mse: 0.0177\n",
      "Epoch 6/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0181 - mae: 0.0965 - mse: 0.0181\n",
      "Epoch 00006: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0183 - mae: 0.0971 - mse: 0.0183 - val_loss: 0.0289 - val_mae: 0.1287 - val_mse: 0.0289\n",
      "Epoch 7/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0945 - mse: 0.0174\n",
      "Epoch 00007: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0174 - mae: 0.0944 - mse: 0.0174 - val_loss: 0.0172 - val_mae: 0.0932 - val_mse: 0.0172\n",
      "Epoch 8/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0898 - mse: 0.0160\n",
      "Epoch 00008: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0160 - mae: 0.0897 - mse: 0.0160 - val_loss: 0.0211 - val_mae: 0.1151 - val_mse: 0.0211\n",
      "Epoch 9/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0897 - mse: 0.0159\n",
      "Epoch 00009: val_loss did not improve from 0.01684\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0158 - mae: 0.0897 - mse: 0.0158 - val_loss: 0.0169 - val_mae: 0.0902 - val_mse: 0.0169\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0890 - mse: 0.0156\n",
      "Epoch 00010: val_loss improved from 0.01684 to 0.01637, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0157 - mae: 0.0890 - mse: 0.0157 - val_loss: 0.0164 - val_mae: 0.0890 - val_mse: 0.0164\n",
      "Epoch 11/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0868 - mse: 0.0149\n",
      "Epoch 00011: val_loss did not improve from 0.01637\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0149 - mae: 0.0869 - mse: 0.0149 - val_loss: 0.0167 - val_mae: 0.0937 - val_mse: 0.0167\n",
      "Epoch 12/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0842 - mse: 0.0141\n",
      "Epoch 00012: val_loss did not improve from 0.01637\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0144 - mae: 0.0845 - mse: 0.0144 - val_loss: 0.0189 - val_mae: 0.1030 - val_mse: 0.0189\n",
      "Epoch 13/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0142 - mae: 0.0843 - mse: 0.0142\n",
      "Epoch 00013: val_loss did not improve from 0.01637\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0141 - mae: 0.0842 - mse: 0.0141 - val_loss: 0.0168 - val_mae: 0.0947 - val_mse: 0.0168\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0851 - mse: 0.0145\n",
      "Epoch 00014: val_loss improved from 0.01637 to 0.01626, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0144 - mae: 0.0851 - mse: 0.0144 - val_loss: 0.0163 - val_mae: 0.0927 - val_mse: 0.0163\n",
      "Epoch 15/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0136 - mae: 0.0827 - mse: 0.0136\n",
      "Epoch 00015: val_loss improved from 0.01626 to 0.01559, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0136 - mae: 0.0828 - mse: 0.0136 - val_loss: 0.0156 - val_mae: 0.0882 - val_mse: 0.0156\n",
      "Epoch 16/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0817 - mse: 0.0133\n",
      "Epoch 00016: val_loss did not improve from 0.01559\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0132 - mae: 0.0816 - mse: 0.0132 - val_loss: 0.0181 - val_mae: 0.0993 - val_mse: 0.0181\n",
      "Epoch 17/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0124 - mae: 0.0784 - mse: 0.0124\n",
      "Epoch 00017: val_loss did not improve from 0.01559\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0123 - mae: 0.0785 - mse: 0.0123 - val_loss: 0.0191 - val_mae: 0.1026 - val_mse: 0.0191\n",
      "Epoch 18/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0783 - mse: 0.0125\n",
      "Epoch 00018: val_loss improved from 0.01559 to 0.01516, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0124 - mae: 0.0782 - mse: 0.0124 - val_loss: 0.0152 - val_mae: 0.0863 - val_mse: 0.0152\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0779 - mse: 0.0123\n",
      "Epoch 00019: val_loss improved from 0.01516 to 0.01470, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0122 - mae: 0.0779 - mse: 0.0122 - val_loss: 0.0147 - val_mae: 0.0868 - val_mse: 0.0147\n",
      "Epoch 20/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0767 - mse: 0.0119\n",
      "Epoch 00020: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0118 - mae: 0.0765 - mse: 0.0118 - val_loss: 0.0157 - val_mae: 0.0843 - val_mse: 0.0157\n",
      "Epoch 21/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0765 - mse: 0.0119\n",
      "Epoch 00021: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0119 - mae: 0.0767 - mse: 0.0119 - val_loss: 0.0190 - val_mae: 0.1009 - val_mse: 0.0190\n",
      "Epoch 22/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0758 - mse: 0.0116\n",
      "Epoch 00022: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0116 - mae: 0.0759 - mse: 0.0116 - val_loss: 0.0164 - val_mae: 0.0926 - val_mse: 0.0164\n",
      "Epoch 23/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0739 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0111 - mae: 0.0738 - mse: 0.0111 - val_loss: 0.0149 - val_mae: 0.0830 - val_mse: 0.0149\n",
      "Epoch 24/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0740 - mse: 0.0112\n",
      "Epoch 00024: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0152 - val_mae: 0.0848 - val_mse: 0.0152\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0742 - mse: 0.0112\n",
      "Epoch 00025: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0112 - mae: 0.0743 - mse: 0.0112 - val_loss: 0.0150 - val_mae: 0.0844 - val_mse: 0.0150\n",
      "Epoch 26/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0724 - mse: 0.0107\n",
      "Epoch 00026: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0107 - mae: 0.0724 - mse: 0.0107 - val_loss: 0.0150 - val_mae: 0.0857 - val_mse: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0709 - mse: 0.0103\n",
      "Epoch 00027: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0103 - mae: 0.0709 - mse: 0.0103 - val_loss: 0.0155 - val_mae: 0.0845 - val_mse: 0.0155\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0714 - mse: 0.0103\n",
      "Epoch 00028: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0103 - mae: 0.0713 - mse: 0.0103 - val_loss: 0.0165 - val_mae: 0.0895 - val_mse: 0.0165\n",
      "Elapsed time during model training:  38.45309543609619\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0484 - mae: 0.1485 - mse: 0.0484\n",
      "Epoch 00001: val_loss improved from inf to 0.02154, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0481,  mae:0.1481,  mse:0.0481,  val_loss:0.0215,  val_mae:0.1106,  val_mse:0.0215,  \n",
      "14926/14926 [==============================] - 2s 138us/sample - loss: 0.0481 - mae: 0.1481 - mse: 0.0481 - val_loss: 0.0215 - val_mae: 0.1106 - val_mse: 0.0215\n",
      "Epoch 2/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1092 - mse: 0.0221\n",
      "Epoch 00002: val_loss did not improve from 0.02154\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0222 - mae: 0.1093 - mse: 0.0222 - val_loss: 0.0258 - val_mae: 0.1238 - val_mse: 0.0258\n",
      "Epoch 3/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0209 - mae: 0.1052 - mse: 0.0209\n",
      "Epoch 00003: val_loss improved from 0.02154 to 0.01839, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0209 - mae: 0.1052 - mse: 0.0209 - val_loss: 0.0184 - val_mae: 0.0976 - val_mse: 0.0184\n",
      "Epoch 4/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0190 - mae: 0.0999 - mse: 0.0190\n",
      "Epoch 00004: val_loss improved from 0.01839 to 0.01616, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0189 - mae: 0.0995 - mse: 0.0189 - val_loss: 0.0162 - val_mae: 0.0888 - val_mse: 0.0162\n",
      "Epoch 5/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0949 - mse: 0.0174\n",
      "Epoch 00005: val_loss did not improve from 0.01616\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0174 - mae: 0.0950 - mse: 0.0174 - val_loss: 0.0168 - val_mae: 0.0946 - val_mse: 0.0168\n",
      "Epoch 6/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0943 - mse: 0.0172\n",
      "Epoch 00006: val_loss did not improve from 0.01616\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0171 - mae: 0.0943 - mse: 0.0171 - val_loss: 0.0187 - val_mae: 0.1006 - val_mse: 0.0187\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0903 - mse: 0.0162\n",
      "Epoch 00007: val_loss improved from 0.01616 to 0.01595, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0162 - mae: 0.0905 - mse: 0.0162 - val_loss: 0.0160 - val_mae: 0.0885 - val_mse: 0.0160\n",
      "Epoch 8/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0876 - mse: 0.0151\n",
      "Epoch 00008: val_loss did not improve from 0.01595\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0151 - mae: 0.0875 - mse: 0.0151 - val_loss: 0.0175 - val_mae: 0.0932 - val_mse: 0.0175\n",
      "Epoch 9/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0891 - mse: 0.0154\n",
      "Epoch 00009: val_loss improved from 0.01595 to 0.01589, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0153 - mae: 0.0889 - mse: 0.0153 - val_loss: 0.0159 - val_mae: 0.0849 - val_mse: 0.0159\n",
      "Epoch 10/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0842 - mse: 0.0142\n",
      "Epoch 00010: val_loss did not improve from 0.01589\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0143 - mae: 0.0844 - mse: 0.0143 - val_loss: 0.0173 - val_mae: 0.0912 - val_mse: 0.0173\n",
      "Epoch 11/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0844 - mse: 0.0141\n",
      "Epoch 00011: val_loss did not improve from 0.01589\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0142 - mae: 0.0845 - mse: 0.0142 - val_loss: 0.0197 - val_mae: 0.1045 - val_mse: 0.0197\n",
      "Epoch 12/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0815 - mse: 0.0135\n",
      "Epoch 00012: val_loss did not improve from 0.01589\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0136 - mae: 0.0815 - mse: 0.0136 - val_loss: 0.0172 - val_mae: 0.0952 - val_mse: 0.0172\n",
      "Epoch 13/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0808 - mse: 0.0130\n",
      "Epoch 00013: val_loss did not improve from 0.01589\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0130 - mae: 0.0808 - mse: 0.0130 - val_loss: 0.0168 - val_mae: 0.0859 - val_mse: 0.0168\n",
      "Epoch 14/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0819 - mse: 0.0132\n",
      "Epoch 00014: val_loss did not improve from 0.01589\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0132 - mae: 0.0820 - mse: 0.0132 - val_loss: 0.0172 - val_mae: 0.0928 - val_mse: 0.0172\n",
      "Epoch 15/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0795 - mse: 0.0125\n",
      "Epoch 00015: val_loss improved from 0.01589 to 0.01513, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0124 - mae: 0.0795 - mse: 0.0124 - val_loss: 0.0151 - val_mae: 0.0874 - val_mse: 0.0151\n",
      "Epoch 16/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0775 - mse: 0.0120\n",
      "Epoch 00016: val_loss did not improve from 0.01513\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0120 - mae: 0.0775 - mse: 0.0120 - val_loss: 0.0160 - val_mae: 0.0897 - val_mse: 0.0160\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0751 - mse: 0.0114\n",
      "Epoch 00017: val_loss improved from 0.01513 to 0.01427, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0114 - mae: 0.0752 - mse: 0.0114 - val_loss: 0.0143 - val_mae: 0.0804 - val_mse: 0.0143\n",
      "Epoch 18/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0116 - mae: 0.0760 - mse: 0.0116\n",
      "Epoch 00018: val_loss did not improve from 0.01427\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0116 - mae: 0.0760 - mse: 0.0116 - val_loss: 0.0148 - val_mae: 0.0837 - val_mse: 0.0148\n",
      "Epoch 19/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0731 - mse: 0.0109\n",
      "Epoch 00019: val_loss improved from 0.01427 to 0.01367, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0137 - val_mae: 0.0799 - val_mse: 0.0137\n",
      "Epoch 20/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0730 - mse: 0.0108\n",
      "Epoch 00020: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0109 - mae: 0.0734 - mse: 0.0109 - val_loss: 0.0151 - val_mae: 0.0845 - val_mse: 0.0151\n",
      "Epoch 21/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0715 - mse: 0.0103\n",
      "Epoch 00021: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0103 - mae: 0.0717 - mse: 0.0103 - val_loss: 0.0172 - val_mae: 0.0914 - val_mse: 0.0172\n",
      "Epoch 22/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0712 - mse: 0.0103\n",
      "Epoch 00022: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0103 - mae: 0.0712 - mse: 0.0103 - val_loss: 0.0151 - val_mae: 0.0820 - val_mse: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0683 - mse: 0.0096\n",
      "Epoch 00023: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0095 - mae: 0.0682 - mse: 0.0095 - val_loss: 0.0151 - val_mae: 0.0831 - val_mse: 0.0151\n",
      "Epoch 24/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0688 - mse: 0.0096\n",
      "Epoch 00024: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0096 - mae: 0.0687 - mse: 0.0096 - val_loss: 0.0153 - val_mae: 0.0897 - val_mse: 0.0153\n",
      "Epoch 25/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0665 - mse: 0.0092\n",
      "Epoch 00025: val_loss did not improve from 0.01367\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0092 - mae: 0.0666 - mse: 0.0092 - val_loss: 0.0156 - val_mae: 0.0854 - val_mse: 0.0156\n",
      "Epoch 26/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0661 - mse: 0.0090\n",
      "Epoch 00026: val_loss improved from 0.01367 to 0.01337, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0091 - mae: 0.0663 - mse: 0.0091 - val_loss: 0.0134 - val_mae: 0.0807 - val_mse: 0.0134\n",
      "Epoch 27/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0680 - mse: 0.0092\n",
      "Epoch 00027: val_loss did not improve from 0.01337\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0092 - mae: 0.0681 - mse: 0.0092 - val_loss: 0.0165 - val_mae: 0.0955 - val_mse: 0.0165\n",
      "Epoch 28/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0661 - mse: 0.0089\n",
      "Epoch 00028: val_loss did not improve from 0.01337\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0089 - mae: 0.0662 - mse: 0.0089 - val_loss: 0.0168 - val_mae: 0.0890 - val_mse: 0.0168\n",
      "Epoch 29/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0635 - mse: 0.0083\n",
      "Epoch 00029: val_loss did not improve from 0.01337\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0083 - mae: 0.0635 - mse: 0.0083 - val_loss: 0.0140 - val_mae: 0.0804 - val_mse: 0.0140\n",
      "Epoch 30/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0085 - mae: 0.0645 - mse: 0.0085\n",
      "Epoch 00030: val_loss did not improve from 0.01337\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0085 - mae: 0.0647 - mse: 0.0085 - val_loss: 0.0145 - val_mae: 0.0811 - val_mse: 0.0145\n",
      "Epoch 31/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0617 - mse: 0.0079\n",
      "Epoch 00031: val_loss improved from 0.01337 to 0.01294, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0079 - mae: 0.0616 - mse: 0.0079 - val_loss: 0.0129 - val_mae: 0.0752 - val_mse: 0.0129\n",
      "Epoch 32/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0603 - mse: 0.0075\n",
      "Epoch 00032: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0075 - mae: 0.0603 - mse: 0.0075 - val_loss: 0.0137 - val_mae: 0.0780 - val_mse: 0.0137\n",
      "Epoch 33/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0630 - mse: 0.0081\n",
      "Epoch 00033: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0081 - mae: 0.0631 - mse: 0.0081 - val_loss: 0.0141 - val_mae: 0.0802 - val_mse: 0.0141\n",
      "Epoch 34/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0608 - mse: 0.0075\n",
      "Epoch 00034: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0075 - mae: 0.0608 - mse: 0.0075 - val_loss: 0.0139 - val_mae: 0.0791 - val_mse: 0.0139\n",
      "Epoch 35/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00035: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0073 - mae: 0.0600 - mse: 0.0073 - val_loss: 0.0130 - val_mae: 0.0765 - val_mse: 0.0130\n",
      "Epoch 36/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0606 - mse: 0.0074\n",
      "Epoch 00036: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0074 - mae: 0.0606 - mse: 0.0074 - val_loss: 0.0133 - val_mae: 0.0766 - val_mse: 0.0133\n",
      "Epoch 37/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0590 - mse: 0.0071\n",
      "Epoch 00037: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0071 - mae: 0.0592 - mse: 0.0071 - val_loss: 0.0135 - val_mae: 0.0791 - val_mse: 0.0135\n",
      "Epoch 38/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0586 - mse: 0.0069\n",
      "Epoch 00038: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0069 - mae: 0.0587 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0800 - val_mse: 0.0139\n",
      "Epoch 39/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0067 - mae: 0.0571 - mse: 0.0067\n",
      "Epoch 00039: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0066 - mae: 0.0571 - mse: 0.0066 - val_loss: 0.0136 - val_mae: 0.0771 - val_mse: 0.0136\n",
      "Epoch 40/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0561 - mse: 0.0063\n",
      "Epoch 00040: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0063 - mae: 0.0561 - mse: 0.0063 - val_loss: 0.0139 - val_mae: 0.0804 - val_mse: 0.0139\n",
      "Epoch 41/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0561 - mse: 0.0065\n",
      "Epoch 00041: val_loss did not improve from 0.01294\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0066 - mae: 0.0561 - mse: 0.0066 - val_loss: 0.0140 - val_mae: 0.0798 - val_mse: 0.0140\n",
      "Epoch 42/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0555 - mse: 0.0063\n",
      "Epoch 00042: val_loss improved from 0.01294 to 0.01284, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0062 - mae: 0.0554 - mse: 0.0062 - val_loss: 0.0128 - val_mae: 0.0765 - val_mse: 0.0128\n",
      "Epoch 43/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0555 - mse: 0.0061\n",
      "Epoch 00043: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0061 - mae: 0.0554 - mse: 0.0061 - val_loss: 0.0134 - val_mae: 0.0764 - val_mse: 0.0134\n",
      "Epoch 44/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0544 - mse: 0.0059\n",
      "Epoch 00044: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0059 - mae: 0.0544 - mse: 0.0059 - val_loss: 0.0135 - val_mae: 0.0795 - val_mse: 0.0135\n",
      "Epoch 45/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0531 - mse: 0.0056\n",
      "Epoch 00045: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0056 - mae: 0.0531 - mse: 0.0056 - val_loss: 0.0138 - val_mae: 0.0790 - val_mse: 0.0138\n",
      "Epoch 46/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0542 - mse: 0.0061\n",
      "Epoch 00046: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0061 - mae: 0.0542 - mse: 0.0061 - val_loss: 0.0138 - val_mae: 0.0825 - val_mse: 0.0138\n",
      "Epoch 47/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0546 - mse: 0.0061\n",
      "Epoch 00047: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0062 - mae: 0.0546 - mse: 0.0062 - val_loss: 0.0133 - val_mae: 0.0780 - val_mse: 0.0133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0516 - mse: 0.0054\n",
      "Epoch 00048: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0054 - mae: 0.0516 - mse: 0.0054 - val_loss: 0.0139 - val_mae: 0.0781 - val_mse: 0.0139\n",
      "Epoch 49/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0537 - mse: 0.0058\n",
      "Epoch 00049: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0058 - mae: 0.0536 - mse: 0.0058 - val_loss: 0.0138 - val_mae: 0.0765 - val_mse: 0.0138\n",
      "Epoch 50/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0050 - mae: 0.0498 - mse: 0.0050\n",
      "Epoch 00050: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0049 - mae: 0.0498 - mse: 0.0049 - val_loss: 0.0142 - val_mae: 0.0821 - val_mse: 0.0142\n",
      "Epoch 51/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0515 - mse: 0.0053\n",
      "Epoch 00051: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0053 - mae: 0.0515 - mse: 0.0053 - val_loss: 0.0144 - val_mae: 0.0788 - val_mse: 0.0144\n",
      "Epoch 52/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0050 - mae: 0.0502 - mse: 0.0050\n",
      "Epoch 00052: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0050 - mae: 0.0503 - mse: 0.0050 - val_loss: 0.0145 - val_mae: 0.0808 - val_mse: 0.0145\n",
      "Epoch 53/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0508 - mse: 0.0052\n",
      "Epoch 00053: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0052 - mae: 0.0508 - mse: 0.0052 - val_loss: 0.0132 - val_mae: 0.0770 - val_mse: 0.0132\n",
      "Elapsed time during model training:  75.61364459991455\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0435 - mae: 0.1461 - mse: 0.0435\n",
      "Epoch 00001: val_loss improved from inf to 0.02757, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0435,  mae:0.1459,  mse:0.0435,  val_loss:0.0276,  val_mae:0.1281,  val_mse:0.0276,  \n",
      "14926/14926 [==============================] - 2s 147us/sample - loss: 0.0435 - mae: 0.1459 - mse: 0.0435 - val_loss: 0.0276 - val_mae: 0.1281 - val_mse: 0.0276\n",
      "Epoch 2/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0230 - mae: 0.1114 - mse: 0.0230\n",
      "Epoch 00002: val_loss improved from 0.02757 to 0.01856, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0228 - mae: 0.1108 - mse: 0.0228 - val_loss: 0.0186 - val_mae: 0.0965 - val_mse: 0.0186\n",
      "Epoch 3/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0196 - mae: 0.1015 - mse: 0.0196\n",
      "Epoch 00003: val_loss did not improve from 0.01856\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0195 - mae: 0.1014 - mse: 0.0195 - val_loss: 0.0208 - val_mae: 0.1067 - val_mse: 0.0208\n",
      "Epoch 4/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0953 - mse: 0.0179\n",
      "Epoch 00004: val_loss improved from 0.01856 to 0.01570, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0179 - mae: 0.0954 - mse: 0.0179 - val_loss: 0.0157 - val_mae: 0.0883 - val_mse: 0.0157\n",
      "Epoch 5/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0962 - mse: 0.0179\n",
      "Epoch 00005: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0181 - mae: 0.0965 - mse: 0.0181 - val_loss: 0.0310 - val_mae: 0.1312 - val_mse: 0.0310\n",
      "Epoch 6/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0939 - mse: 0.0170\n",
      "Epoch 00006: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0169 - mae: 0.0938 - mse: 0.0169 - val_loss: 0.0159 - val_mae: 0.0889 - val_mse: 0.0159\n",
      "Epoch 7/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0905 - mse: 0.0161\n",
      "Epoch 00007: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0161 - mae: 0.0905 - mse: 0.0161 - val_loss: 0.0163 - val_mae: 0.0895 - val_mse: 0.0163\n",
      "Epoch 8/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0891 - mse: 0.0153\n",
      "Epoch 00008: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0158 - mae: 0.0897 - mse: 0.0158 - val_loss: 0.0201 - val_mae: 0.1065 - val_mse: 0.0201\n",
      "Epoch 9/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0876 - mse: 0.0151\n",
      "Epoch 00009: val_loss improved from 0.01570 to 0.01489, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0151 - mae: 0.0874 - mse: 0.0151 - val_loss: 0.0149 - val_mae: 0.0845 - val_mse: 0.0149\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0839 - mse: 0.0141\n",
      "Epoch 00010: val_loss improved from 0.01489 to 0.01420, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0140 - mae: 0.0838 - mse: 0.0140 - val_loss: 0.0142 - val_mae: 0.0823 - val_mse: 0.0142\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0833 - mse: 0.0139\n",
      "Epoch 00011: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0139 - mae: 0.0832 - mse: 0.0139 - val_loss: 0.0151 - val_mae: 0.0875 - val_mse: 0.0151\n",
      "Epoch 12/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0835 - mse: 0.0138\n",
      "Epoch 00012: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0138 - mae: 0.0837 - mse: 0.0138 - val_loss: 0.0230 - val_mae: 0.1175 - val_mse: 0.0230\n",
      "Epoch 13/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0820 - mse: 0.0135\n",
      "Epoch 00013: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0135 - mae: 0.0819 - mse: 0.0135 - val_loss: 0.0144 - val_mae: 0.0831 - val_mse: 0.0144\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0785 - mse: 0.0125\n",
      "Epoch 00014: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0124 - mae: 0.0784 - mse: 0.0124 - val_loss: 0.0156 - val_mae: 0.0874 - val_mse: 0.0156\n",
      "Epoch 15/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0127 - mae: 0.0802 - mse: 0.0127\n",
      "Epoch 00015: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0126 - mae: 0.0799 - mse: 0.0126 - val_loss: 0.0169 - val_mae: 0.0925 - val_mse: 0.0169\n",
      "Epoch 16/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0786 - mse: 0.0123\n",
      "Epoch 00016: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0124 - mae: 0.0789 - mse: 0.0124 - val_loss: 0.0180 - val_mae: 0.0951 - val_mse: 0.0180\n",
      "Epoch 17/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0764 - mse: 0.0118\n",
      "Epoch 00017: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0118 - mae: 0.0765 - mse: 0.0118 - val_loss: 0.0146 - val_mae: 0.0833 - val_mse: 0.0146\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0751 - mse: 0.0115\n",
      "Epoch 00018: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0115 - mae: 0.0751 - mse: 0.0115 - val_loss: 0.0145 - val_mae: 0.0851 - val_mse: 0.0145\n",
      "Epoch 19/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0752 - mse: 0.0114\n",
      "Epoch 00019: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0113 - mae: 0.0751 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0799 - val_mse: 0.0148\n",
      "Epoch 20/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0750 - mse: 0.0111\n",
      "Epoch 00020: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0111 - mae: 0.0750 - mse: 0.0111 - val_loss: 0.0148 - val_mae: 0.0830 - val_mse: 0.0148\n",
      "Epoch 21/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0711 - mse: 0.0103\n",
      "Epoch 00021: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0103 - mae: 0.0711 - mse: 0.0103 - val_loss: 0.0143 - val_mae: 0.0818 - val_mse: 0.0143\n",
      "Epoch 22/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0706 - mse: 0.0101\n",
      "Epoch 00022: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0706 - mse: 0.0101 - val_loss: 0.0145 - val_mae: 0.0829 - val_mse: 0.0145\n",
      "Elapsed time during model training:  31.740365028381348\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0426 - mae: 0.1433 - mse: 0.0426\n",
      "Epoch 00001: val_loss improved from inf to 0.02555, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0424,  mae:0.1431,  mse:0.0424,  val_loss:0.0255,  val_mae:0.1203,  val_mse:0.0255,  \n",
      "14926/14926 [==============================] - 3s 174us/sample - loss: 0.0424 - mae: 0.1431 - mse: 0.0424 - val_loss: 0.0255 - val_mae: 0.1203 - val_mse: 0.0255\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1077 - mse: 0.0216\n",
      "Epoch 00002: val_loss improved from 0.02555 to 0.02096, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0216 - mae: 0.1076 - mse: 0.0216 - val_loss: 0.0210 - val_mae: 0.1077 - val_mse: 0.0210\n",
      "Epoch 3/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0196 - mae: 0.1013 - mse: 0.0196\n",
      "Epoch 00003: val_loss improved from 0.02096 to 0.01664, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0198 - mae: 0.1017 - mse: 0.0198 - val_loss: 0.0166 - val_mae: 0.0925 - val_mse: 0.0166\n",
      "Epoch 4/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0183 - mae: 0.0969 - mse: 0.0183\n",
      "Epoch 00004: val_loss did not improve from 0.01664\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0183 - mae: 0.0971 - mse: 0.0183 - val_loss: 0.0249 - val_mae: 0.1163 - val_mse: 0.0249\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0974 - mse: 0.0183\n",
      "Epoch 00005: val_loss did not improve from 0.01664\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0182 - mae: 0.0972 - mse: 0.0182 - val_loss: 0.0172 - val_mae: 0.0928 - val_mse: 0.0172\n",
      "Epoch 6/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0168 - mae: 0.0923 - mse: 0.0168\n",
      "Epoch 00006: val_loss did not improve from 0.01664\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0168 - mae: 0.0923 - mse: 0.0168 - val_loss: 0.0184 - val_mae: 0.0984 - val_mse: 0.0184\n",
      "Epoch 7/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0163 - mae: 0.0915 - mse: 0.0163\n",
      "Epoch 00007: val_loss improved from 0.01664 to 0.01627, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0162 - mae: 0.0914 - mse: 0.0162 - val_loss: 0.0163 - val_mae: 0.0891 - val_mse: 0.0163\n",
      "Epoch 8/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0894 - mse: 0.0152\n",
      "Epoch 00008: val_loss did not improve from 0.01627\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0155 - mae: 0.0893 - mse: 0.0155 - val_loss: 0.0187 - val_mae: 0.0995 - val_mse: 0.0187\n",
      "Epoch 9/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0149 - mae: 0.0867 - mse: 0.0149\n",
      "Epoch 00009: val_loss did not improve from 0.01627\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0149 - mae: 0.0866 - mse: 0.0149 - val_loss: 0.0185 - val_mae: 0.0978 - val_mse: 0.0185\n",
      "Epoch 10/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0836 - mse: 0.0141\n",
      "Epoch 00010: val_loss did not improve from 0.01627\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0141 - mae: 0.0836 - mse: 0.0141 - val_loss: 0.0197 - val_mae: 0.0978 - val_mse: 0.0197\n",
      "Epoch 11/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0144 - mae: 0.0855 - mse: 0.0144\n",
      "Epoch 00011: val_loss improved from 0.01627 to 0.01451, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0144 - mae: 0.0855 - mse: 0.0144 - val_loss: 0.0145 - val_mae: 0.0837 - val_mse: 0.0145\n",
      "Epoch 12/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0836 - mse: 0.0139\n",
      "Epoch 00012: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0139 - mae: 0.0837 - mse: 0.0139 - val_loss: 0.0200 - val_mae: 0.1034 - val_mse: 0.0200\n",
      "Epoch 13/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0827 - mse: 0.0136\n",
      "Epoch 00013: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0135 - mae: 0.0824 - mse: 0.0135 - val_loss: 0.0156 - val_mae: 0.0855 - val_mse: 0.0156\n",
      "Epoch 14/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0817 - mse: 0.0133\n",
      "Epoch 00014: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0132 - mae: 0.0816 - mse: 0.0132 - val_loss: 0.0158 - val_mae: 0.0885 - val_mse: 0.0158\n",
      "Epoch 15/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0788 - mse: 0.0125\n",
      "Epoch 00015: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0126 - mae: 0.0788 - mse: 0.0126 - val_loss: 0.0195 - val_mae: 0.1090 - val_mse: 0.0195\n",
      "Epoch 16/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0126 - mae: 0.0794 - mse: 0.0126\n",
      "Epoch 00016: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0126 - mae: 0.0794 - mse: 0.0126 - val_loss: 0.0165 - val_mae: 0.0878 - val_mse: 0.0165\n",
      "Epoch 17/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0778 - mse: 0.0122\n",
      "Epoch 00017: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0122 - mae: 0.0777 - mse: 0.0122 - val_loss: 0.0146 - val_mae: 0.0835 - val_mse: 0.0146\n",
      "Epoch 18/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0754 - mse: 0.0116\n",
      "Epoch 00018: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0115 - mae: 0.0754 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0846 - val_mse: 0.0150\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0748 - mse: 0.0112\n",
      "Epoch 00019: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0112 - mae: 0.0747 - mse: 0.0112 - val_loss: 0.0160 - val_mae: 0.0888 - val_mse: 0.0160\n",
      "Epoch 20/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0718 - mse: 0.0106\n",
      "Epoch 00020: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0107 - mae: 0.0719 - mse: 0.0107 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 21/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0694 - mse: 0.0101\n",
      "Epoch 00021: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0102 - mae: 0.0699 - mse: 0.0102 - val_loss: 0.0164 - val_mae: 0.0910 - val_mse: 0.0164\n",
      "Epoch 22/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0742 - mse: 0.0111\n",
      "Epoch 00022: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0110 - mae: 0.0740 - mse: 0.0110 - val_loss: 0.0154 - val_mae: 0.0893 - val_mse: 0.0154\n",
      "Epoch 23/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0704 - mse: 0.0101\n",
      "Epoch 00023: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0101 - mae: 0.0705 - mse: 0.0101 - val_loss: 0.0147 - val_mae: 0.0866 - val_mse: 0.0147\n",
      "Epoch 24/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0713 - mse: 0.0103\n",
      "Epoch 00024: val_loss improved from 0.01451 to 0.01442, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0104 - mae: 0.0715 - mse: 0.0104 - val_loss: 0.0144 - val_mae: 0.0833 - val_mse: 0.0144\n",
      "Epoch 25/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0686 - mse: 0.0096\n",
      "Epoch 00025: val_loss improved from 0.01442 to 0.01327, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0095 - mae: 0.0684 - mse: 0.0095 - val_loss: 0.0133 - val_mae: 0.0779 - val_mse: 0.0133\n",
      "Epoch 26/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0665 - mse: 0.0092\n",
      "Epoch 00026: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0092 - mae: 0.0666 - mse: 0.0092 - val_loss: 0.0149 - val_mae: 0.0862 - val_mse: 0.0149\n",
      "Epoch 27/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0684 - mse: 0.0095\n",
      "Epoch 00027: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0095 - mae: 0.0685 - mse: 0.0095 - val_loss: 0.0144 - val_mae: 0.0816 - val_mse: 0.0144\n",
      "Epoch 28/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0672 - mse: 0.0092\n",
      "Epoch 00028: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0153 - val_mae: 0.0829 - val_mse: 0.0153\n",
      "Epoch 29/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0663 - mse: 0.0088\n",
      "Epoch 00029: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0088 - mae: 0.0662 - mse: 0.0088 - val_loss: 0.0136 - val_mae: 0.0790 - val_mse: 0.0136\n",
      "Epoch 30/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0640 - mse: 0.0084\n",
      "Epoch 00030: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0084 - mae: 0.0643 - mse: 0.0084 - val_loss: 0.0145 - val_mae: 0.0835 - val_mse: 0.0145\n",
      "Epoch 31/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0651 - mse: 0.0087\n",
      "Epoch 00031: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0087 - mae: 0.0651 - mse: 0.0087 - val_loss: 0.0139 - val_mae: 0.0811 - val_mse: 0.0139\n",
      "Epoch 32/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0648 - mse: 0.0086\n",
      "Epoch 00032: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0085 - mae: 0.0649 - mse: 0.0085 - val_loss: 0.0175 - val_mae: 0.0970 - val_mse: 0.0175\n",
      "Epoch 33/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0634 - mse: 0.0082\n",
      "Epoch 00033: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0082 - mae: 0.0634 - mse: 0.0082 - val_loss: 0.0143 - val_mae: 0.0807 - val_mse: 0.0143\n",
      "Epoch 34/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0619 - mse: 0.0079\n",
      "Epoch 00034: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0079 - mae: 0.0621 - mse: 0.0079 - val_loss: 0.0140 - val_mae: 0.0795 - val_mse: 0.0140\n",
      "Epoch 35/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0622 - mse: 0.0079\n",
      "Epoch 00035: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0080 - mae: 0.0624 - mse: 0.0080 - val_loss: 0.0142 - val_mae: 0.0819 - val_mse: 0.0142\n",
      "Epoch 36/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0594 - mse: 0.0072\n",
      "Epoch 00036: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0073 - mae: 0.0595 - mse: 0.0073 - val_loss: 0.0134 - val_mae: 0.0774 - val_mse: 0.0134\n",
      "Epoch 37/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0611 - mse: 0.0077\n",
      "Epoch 00037: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0077 - mae: 0.0611 - mse: 0.0077 - val_loss: 0.0139 - val_mae: 0.0784 - val_mse: 0.0139\n",
      "Epoch 38/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0595 - mse: 0.0071\n",
      "Epoch 00038: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0135 - val_mae: 0.0770 - val_mse: 0.0135\n",
      "Epoch 39/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0073 - mae: 0.0599 - mse: 0.0073\n",
      "Epoch 00039: val_loss did not improve from 0.01327\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0073 - mae: 0.0599 - mse: 0.0073 - val_loss: 0.0146 - val_mae: 0.0833 - val_mse: 0.0146\n",
      "Elapsed time during model training:  53.78520894050598\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0461 - mae: 0.1453 - mse: 0.0461\n",
      "Epoch 00001: val_loss improved from inf to 0.01995, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0453,  mae:0.1440,  mse:0.0453,  val_loss:0.0199,  val_mae:0.1023,  val_mse:0.0199,  \n",
      "14926/14926 [==============================] - 2s 151us/sample - loss: 0.0453 - mae: 0.1440 - mse: 0.0453 - val_loss: 0.0199 - val_mae: 0.1023 - val_mse: 0.0199\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0221 - mae: 0.1079 - mse: 0.0221\n",
      "Epoch 00002: val_loss improved from 0.01995 to 0.01789, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0220 - mae: 0.1077 - mse: 0.0220 - val_loss: 0.0179 - val_mae: 0.0956 - val_mse: 0.0179\n",
      "Epoch 3/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1032 - mse: 0.0202\n",
      "Epoch 00003: val_loss did not improve from 0.01789\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0203 - mae: 0.1035 - mse: 0.0203 - val_loss: 0.0381 - val_mae: 0.1563 - val_mse: 0.0381\n",
      "Epoch 4/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0189 - mae: 0.0998 - mse: 0.0189\n",
      "Epoch 00004: val_loss improved from 0.01789 to 0.01725, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0188 - mae: 0.0996 - mse: 0.0188 - val_loss: 0.0173 - val_mae: 0.0952 - val_mse: 0.0173\n",
      "Epoch 5/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0175 - mae: 0.0955 - mse: 0.0175\n",
      "Epoch 00005: val_loss improved from 0.01725 to 0.01639, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0175 - mae: 0.0955 - mse: 0.0175 - val_loss: 0.0164 - val_mae: 0.0903 - val_mse: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0937 - mse: 0.0170\n",
      "Epoch 00006: val_loss did not improve from 0.01639\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0170 - mae: 0.0937 - mse: 0.0170 - val_loss: 0.0165 - val_mae: 0.0911 - val_mse: 0.0165\n",
      "Epoch 7/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0890 - mse: 0.0157\n",
      "Epoch 00007: val_loss improved from 0.01639 to 0.01546, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0156 - mae: 0.0888 - mse: 0.0156 - val_loss: 0.0155 - val_mae: 0.0872 - val_mse: 0.0155\n",
      "Epoch 8/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0879 - mse: 0.0154\n",
      "Epoch 00008: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0153 - mae: 0.0878 - mse: 0.0153 - val_loss: 0.0159 - val_mae: 0.0867 - val_mse: 0.0159\n",
      "Epoch 9/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0146 - mae: 0.0862 - mse: 0.0146\n",
      "Epoch 00009: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0145 - mae: 0.0858 - mse: 0.0145 - val_loss: 0.0160 - val_mae: 0.0932 - val_mse: 0.0160\n",
      "Epoch 10/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0140 - mae: 0.0837 - mse: 0.0140\n",
      "Epoch 00010: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0139 - mae: 0.0835 - mse: 0.0139 - val_loss: 0.0155 - val_mae: 0.0884 - val_mse: 0.0155\n",
      "Epoch 11/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0845 - mse: 0.0141\n",
      "Epoch 00011: val_loss improved from 0.01546 to 0.01492, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0140 - mae: 0.0843 - mse: 0.0140 - val_loss: 0.0149 - val_mae: 0.0908 - val_mse: 0.0149\n",
      "Epoch 12/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0817 - mse: 0.0132\n",
      "Epoch 00012: val_loss improved from 0.01492 to 0.01451, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0132 - mae: 0.0817 - mse: 0.0132 - val_loss: 0.0145 - val_mae: 0.0841 - val_mse: 0.0145\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0811 - mse: 0.0130\n",
      "Epoch 00013: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0130 - mae: 0.0811 - mse: 0.0130 - val_loss: 0.0147 - val_mae: 0.0819 - val_mse: 0.0147\n",
      "Epoch 14/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0787 - mse: 0.0124\n",
      "Epoch 00014: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0124 - mae: 0.0787 - mse: 0.0124 - val_loss: 0.0162 - val_mae: 0.0888 - val_mse: 0.0162\n",
      "Epoch 15/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0765 - mse: 0.0118\n",
      "Epoch 00015: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0118 - mae: 0.0765 - mse: 0.0118 - val_loss: 0.0200 - val_mae: 0.1022 - val_mse: 0.0200\n",
      "Epoch 16/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0117 - mae: 0.0761 - mse: 0.0117\n",
      "Epoch 00016: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0766 - mse: 0.0117 - val_loss: 0.0158 - val_mae: 0.0877 - val_mse: 0.0158\n",
      "Epoch 17/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0741 - mse: 0.0112\n",
      "Epoch 00017: val_loss did not improve from 0.01451\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0112 - mae: 0.0741 - mse: 0.0112 - val_loss: 0.0151 - val_mae: 0.0854 - val_mse: 0.0151\n",
      "Epoch 18/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0745 - mse: 0.0111\n",
      "Epoch 00018: val_loss improved from 0.01451 to 0.01406, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0111 - mae: 0.0743 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0814 - val_mse: 0.0141\n",
      "Epoch 19/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0736 - mse: 0.0108\n",
      "Epoch 00019: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0108 - mae: 0.0735 - mse: 0.0108 - val_loss: 0.0158 - val_mae: 0.0869 - val_mse: 0.0158\n",
      "Epoch 20/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0707 - mse: 0.0103\n",
      "Epoch 00020: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0103 - mae: 0.0707 - mse: 0.0103 - val_loss: 0.0142 - val_mae: 0.0819 - val_mse: 0.0142\n",
      "Epoch 21/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0709 - mse: 0.0102\n",
      "Epoch 00021: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0102 - mae: 0.0712 - mse: 0.0102 - val_loss: 0.0171 - val_mae: 0.0859 - val_mse: 0.0171\n",
      "Epoch 22/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0692 - mse: 0.0098\n",
      "Epoch 00022: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0098 - mae: 0.0692 - mse: 0.0098 - val_loss: 0.0144 - val_mae: 0.0814 - val_mse: 0.0144\n",
      "Epoch 23/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0679 - mse: 0.0095\n",
      "Epoch 00023: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0095 - mae: 0.0681 - mse: 0.0095 - val_loss: 0.0154 - val_mae: 0.0881 - val_mse: 0.0154\n",
      "Epoch 24/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0695 - mse: 0.0096\n",
      "Epoch 00024: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0096 - mae: 0.0695 - mse: 0.0096 - val_loss: 0.0145 - val_mae: 0.0802 - val_mse: 0.0145\n",
      "Epoch 25/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0664 - mse: 0.0089\n",
      "Epoch 00025: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0089 - mae: 0.0667 - mse: 0.0089 - val_loss: 0.0152 - val_mae: 0.0867 - val_mse: 0.0152\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0673 - mse: 0.0091\n",
      "Epoch 00026: val_loss did not improve from 0.01406\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0090 - mae: 0.0673 - mse: 0.0090 - val_loss: 0.0143 - val_mae: 0.0821 - val_mse: 0.0143\n",
      "Epoch 27/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0647 - mse: 0.0086\n",
      "Epoch 00027: val_loss improved from 0.01406 to 0.01331, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0086 - mae: 0.0647 - mse: 0.0086 - val_loss: 0.0133 - val_mae: 0.0807 - val_mse: 0.0133\n",
      "Epoch 28/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0662 - mse: 0.0089\n",
      "Epoch 00028: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0089 - mae: 0.0664 - mse: 0.0089 - val_loss: 0.0146 - val_mae: 0.0862 - val_mse: 0.0146\n",
      "Epoch 29/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0637 - mse: 0.0083\n",
      "Epoch 00029: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0083 - mae: 0.0636 - mse: 0.0083 - val_loss: 0.0141 - val_mae: 0.0801 - val_mse: 0.0141\n",
      "Epoch 30/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0633 - mse: 0.0081\n",
      "Epoch 00030: val_loss improved from 0.01331 to 0.01310, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0081 - mae: 0.0633 - mse: 0.0081 - val_loss: 0.0131 - val_mae: 0.0777 - val_mse: 0.0131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0640 - mse: 0.0082\n",
      "Epoch 00031: val_loss did not improve from 0.01310\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0082 - mae: 0.0638 - mse: 0.0082 - val_loss: 0.0146 - val_mae: 0.0829 - val_mse: 0.0146\n",
      "Epoch 32/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0641 - mse: 0.0083\n",
      "Epoch 00032: val_loss improved from 0.01310 to 0.01307, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0083 - mae: 0.0639 - mse: 0.0083 - val_loss: 0.0131 - val_mae: 0.0754 - val_mse: 0.0131\n",
      "Epoch 33/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0072 - mae: 0.0593 - mse: 0.0072\n",
      "Epoch 00033: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0072 - mae: 0.0594 - mse: 0.0072 - val_loss: 0.0133 - val_mae: 0.0755 - val_mse: 0.0133\n",
      "Epoch 34/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0608 - mse: 0.0074\n",
      "Epoch 00034: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0074 - mae: 0.0608 - mse: 0.0074 - val_loss: 0.0142 - val_mae: 0.0811 - val_mse: 0.0142\n",
      "Epoch 35/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0611 - mse: 0.0075\n",
      "Epoch 00035: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0075 - mae: 0.0611 - mse: 0.0075 - val_loss: 0.0159 - val_mae: 0.0889 - val_mse: 0.0159\n",
      "Epoch 36/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0582 - mse: 0.0069\n",
      "Epoch 00036: val_loss did not improve from 0.01307\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0069 - mae: 0.0583 - mse: 0.0069 - val_loss: 0.0137 - val_mae: 0.0818 - val_mse: 0.0137\n",
      "Epoch 37/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00037: val_loss improved from 0.01307 to 0.01305, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0072 - mae: 0.0598 - mse: 0.0072 - val_loss: 0.0131 - val_mae: 0.0746 - val_mse: 0.0131\n",
      "Epoch 38/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0574 - mse: 0.0067\n",
      "Epoch 00038: val_loss did not improve from 0.01305\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0068 - mae: 0.0575 - mse: 0.0068 - val_loss: 0.0149 - val_mae: 0.0824 - val_mse: 0.0149\n",
      "Epoch 39/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0584 - mse: 0.0069\n",
      "Epoch 00039: val_loss did not improve from 0.01305\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0069 - mae: 0.0585 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0802 - val_mse: 0.0139\n",
      "Epoch 40/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0568 - mse: 0.0065\n",
      "Epoch 00040: val_loss improved from 0.01305 to 0.01277, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0065 - mae: 0.0568 - mse: 0.0065 - val_loss: 0.0128 - val_mae: 0.0748 - val_mse: 0.0128\n",
      "Epoch 41/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0558 - mse: 0.0064\n",
      "Epoch 00041: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0064 - mae: 0.0559 - mse: 0.0064 - val_loss: 0.0145 - val_mae: 0.0792 - val_mse: 0.0145\n",
      "Epoch 42/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0063 - mae: 0.0557 - mse: 0.0063\n",
      "Epoch 00042: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0063 - mae: 0.0556 - mse: 0.0063 - val_loss: 0.0151 - val_mae: 0.0859 - val_mse: 0.0151\n",
      "Epoch 43/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0564 - mse: 0.0063\n",
      "Epoch 00043: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0063 - mae: 0.0564 - mse: 0.0063 - val_loss: 0.0133 - val_mae: 0.0757 - val_mse: 0.0133\n",
      "Epoch 44/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0547 - mse: 0.0060\n",
      "Epoch 00044: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0060 - mae: 0.0548 - mse: 0.0060 - val_loss: 0.0132 - val_mae: 0.0746 - val_mse: 0.0132\n",
      "Epoch 45/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0531 - mse: 0.0056\n",
      "Epoch 00045: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0056 - mae: 0.0531 - mse: 0.0056 - val_loss: 0.0135 - val_mae: 0.0777 - val_mse: 0.0135\n",
      "Epoch 46/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0532 - mse: 0.0058\n",
      "Epoch 00046: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0058 - mae: 0.0532 - mse: 0.0058 - val_loss: 0.0150 - val_mae: 0.0820 - val_mse: 0.0150\n",
      "Epoch 47/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0538 - mse: 0.0058\n",
      "Epoch 00047: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0058 - mae: 0.0537 - mse: 0.0058 - val_loss: 0.0133 - val_mae: 0.0761 - val_mse: 0.0133\n",
      "Epoch 48/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0533 - mse: 0.0058\n",
      "Epoch 00048: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 2s 126us/sample - loss: 0.0058 - mae: 0.0533 - mse: 0.0058 - val_loss: 0.0140 - val_mae: 0.0785 - val_mse: 0.0140\n",
      "Epoch 49/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0513 - mse: 0.0052\n",
      "Epoch 00049: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0052 - mae: 0.0513 - mse: 0.0052 - val_loss: 0.0139 - val_mae: 0.0782 - val_mse: 0.0139\n",
      "Epoch 50/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0524 - mse: 0.0054\n",
      "Epoch 00050: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0054 - mae: 0.0524 - mse: 0.0054 - val_loss: 0.0163 - val_mae: 0.0816 - val_mse: 0.0163\n",
      "Epoch 51/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0053 - mae: 0.0511 - mse: 0.0053\n",
      "Epoch 00051: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0053 - mae: 0.0513 - mse: 0.0053 - val_loss: 0.0151 - val_mae: 0.0824 - val_mse: 0.0151\n",
      "Epoch 52/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0504 - mse: 0.0051\n",
      "Epoch 00052: val_loss did not improve from 0.01277\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0051 - mae: 0.0503 - mse: 0.0051 - val_loss: 0.0135 - val_mae: 0.0785 - val_mse: 0.0135\n",
      "Elapsed time during model training:  74.6416380405426\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0454 - mae: 0.1465 - mse: 0.0454\n",
      "Epoch 00001: val_loss improved from inf to 0.02537, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0453,  mae:0.1464,  mse:0.0453,  val_loss:0.0254,  val_mae:0.1107,  val_mse:0.0254,  \n",
      "14926/14926 [==============================] - 2s 141us/sample - loss: 0.0453 - mae: 0.1464 - mse: 0.0453 - val_loss: 0.0254 - val_mae: 0.1107 - val_mse: 0.0254\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0222 - mae: 0.1092 - mse: 0.0222\n",
      "Epoch 00002: val_loss improved from 0.02537 to 0.02097, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0221 - mae: 0.1092 - mse: 0.0221 - val_loss: 0.0210 - val_mae: 0.1120 - val_mse: 0.0210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1027 - mse: 0.0203\n",
      "Epoch 00003: val_loss did not improve from 0.02097\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0203 - mae: 0.1028 - mse: 0.0203 - val_loss: 0.0214 - val_mae: 0.1109 - val_mse: 0.0214\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0182 - mae: 0.0976 - mse: 0.0182\n",
      "Epoch 00004: val_loss improved from 0.02097 to 0.01654, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0183 - mae: 0.0979 - mse: 0.0183 - val_loss: 0.0165 - val_mae: 0.0902 - val_mse: 0.0165\n",
      "Epoch 5/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0960 - mse: 0.0178\n",
      "Epoch 00005: val_loss did not improve from 0.01654\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0178 - mae: 0.0959 - mse: 0.0178 - val_loss: 0.0174 - val_mae: 0.0931 - val_mse: 0.0174\n",
      "Epoch 6/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0926 - mse: 0.0167\n",
      "Epoch 00006: val_loss did not improve from 0.01654\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0167 - mae: 0.0927 - mse: 0.0167 - val_loss: 0.0220 - val_mae: 0.1141 - val_mse: 0.0220\n",
      "Epoch 7/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0920 - mse: 0.0165\n",
      "Epoch 00007: val_loss did not improve from 0.01654\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0166 - mae: 0.0922 - mse: 0.0166 - val_loss: 0.0193 - val_mae: 0.0998 - val_mse: 0.0193\n",
      "Epoch 8/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0915 - mse: 0.0161\n",
      "Epoch 00008: val_loss improved from 0.01654 to 0.01550, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0161 - mae: 0.0915 - mse: 0.0161 - val_loss: 0.0155 - val_mae: 0.0874 - val_mse: 0.0155\n",
      "Epoch 9/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0859 - mse: 0.0145\n",
      "Epoch 00009: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0146 - mae: 0.0861 - mse: 0.0146 - val_loss: 0.0166 - val_mae: 0.0922 - val_mse: 0.0166\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0865 - mse: 0.0146\n",
      "Epoch 00010: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0145 - mae: 0.0865 - mse: 0.0145 - val_loss: 0.0168 - val_mae: 0.0934 - val_mse: 0.0168\n",
      "Epoch 11/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0870 - mse: 0.0147\n",
      "Epoch 00011: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0147 - mae: 0.0870 - mse: 0.0147 - val_loss: 0.0206 - val_mae: 0.1082 - val_mse: 0.0206\n",
      "Epoch 12/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0843 - mse: 0.0141\n",
      "Epoch 00012: val_loss did not improve from 0.01550\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0141 - mae: 0.0842 - mse: 0.0141 - val_loss: 0.0158 - val_mae: 0.0862 - val_mse: 0.0158\n",
      "Epoch 13/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0801 - mse: 0.0129\n",
      "Epoch 00013: val_loss improved from 0.01550 to 0.01497, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0129 - mae: 0.0800 - mse: 0.0129 - val_loss: 0.0150 - val_mae: 0.0852 - val_mse: 0.0150\n",
      "Epoch 14/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0818 - mse: 0.0132\n",
      "Epoch 00014: val_loss did not improve from 0.01497\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0132 - mae: 0.0818 - mse: 0.0132 - val_loss: 0.0162 - val_mae: 0.0906 - val_mse: 0.0162\n",
      "Epoch 15/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0776 - mse: 0.0120\n",
      "Epoch 00015: val_loss did not improve from 0.01497\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0121 - mae: 0.0777 - mse: 0.0121 - val_loss: 0.0162 - val_mae: 0.0874 - val_mse: 0.0162\n",
      "Epoch 16/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0786 - mse: 0.0123\n",
      "Epoch 00016: val_loss improved from 0.01497 to 0.01492, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0123 - mae: 0.0785 - mse: 0.0123 - val_loss: 0.0149 - val_mae: 0.0863 - val_mse: 0.0149\n",
      "Epoch 17/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0749 - mse: 0.0114\n",
      "Epoch 00017: val_loss improved from 0.01492 to 0.01439, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0114 - mae: 0.0750 - mse: 0.0114 - val_loss: 0.0144 - val_mae: 0.0827 - val_mse: 0.0144\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0763 - mse: 0.0116\n",
      "Epoch 00018: val_loss did not improve from 0.01439\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0115 - mae: 0.0762 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0840 - val_mse: 0.0150\n",
      "Epoch 19/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0741 - mse: 0.0111\n",
      "Epoch 00019: val_loss did not improve from 0.01439\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0111 - mae: 0.0742 - mse: 0.0111 - val_loss: 0.0153 - val_mae: 0.0888 - val_mse: 0.0153\n",
      "Epoch 20/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0109 - mae: 0.0737 - mse: 0.0109\n",
      "Epoch 00020: val_loss improved from 0.01439 to 0.01435, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0109 - mae: 0.0736 - mse: 0.0109 - val_loss: 0.0144 - val_mae: 0.0826 - val_mse: 0.0144\n",
      "Epoch 21/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0724 - mse: 0.0106\n",
      "Epoch 00021: val_loss did not improve from 0.01435\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0106 - mae: 0.0725 - mse: 0.0106 - val_loss: 0.0151 - val_mae: 0.0906 - val_mse: 0.0151\n",
      "Epoch 22/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0707 - mse: 0.0101\n",
      "Epoch 00022: val_loss improved from 0.01435 to 0.01369, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0137 - val_mae: 0.0794 - val_mse: 0.0137\n",
      "Epoch 23/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0702 - mse: 0.0099\n",
      "Epoch 00023: val_loss improved from 0.01369 to 0.01331, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0099 - mae: 0.0702 - mse: 0.0099 - val_loss: 0.0133 - val_mae: 0.0776 - val_mse: 0.0133\n",
      "Epoch 24/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0681 - mse: 0.0093\n",
      "Epoch 00024: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0093 - mae: 0.0681 - mse: 0.0093 - val_loss: 0.0139 - val_mae: 0.0821 - val_mse: 0.0139\n",
      "Epoch 25/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0681 - mse: 0.0094\n",
      "Epoch 00025: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0094 - mae: 0.0681 - mse: 0.0094 - val_loss: 0.0149 - val_mae: 0.0852 - val_mse: 0.0149\n",
      "Epoch 26/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0665 - mse: 0.0091\n",
      "Epoch 00026: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0091 - mae: 0.0664 - mse: 0.0091 - val_loss: 0.0151 - val_mae: 0.0806 - val_mse: 0.0151\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0659 - mse: 0.0088\n",
      "Epoch 00027: val_loss did not improve from 0.01331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0088 - mae: 0.0657 - mse: 0.0088 - val_loss: 0.0141 - val_mae: 0.0796 - val_mse: 0.0141\n",
      "Epoch 28/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0647 - mse: 0.0086\n",
      "Epoch 00028: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0085 - mae: 0.0646 - mse: 0.0085 - val_loss: 0.0134 - val_mae: 0.0779 - val_mse: 0.0134\n",
      "Epoch 29/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0658 - mse: 0.0085\n",
      "Epoch 00029: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0664 - mse: 0.0089 - val_loss: 0.0153 - val_mae: 0.0858 - val_mse: 0.0153\n",
      "Epoch 30/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0641 - mse: 0.0083\n",
      "Epoch 00030: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0082 - mae: 0.0641 - mse: 0.0082 - val_loss: 0.0136 - val_mae: 0.0769 - val_mse: 0.0136\n",
      "Epoch 31/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0625 - mse: 0.0079\n",
      "Epoch 00031: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0079 - mae: 0.0625 - mse: 0.0079 - val_loss: 0.0138 - val_mae: 0.0794 - val_mse: 0.0138\n",
      "Epoch 32/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0642 - mse: 0.0084\n",
      "Epoch 00032: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0083 - mae: 0.0642 - mse: 0.0083 - val_loss: 0.0142 - val_mae: 0.0832 - val_mse: 0.0142\n",
      "Epoch 33/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0604 - mse: 0.0074\n",
      "Epoch 00033: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0074 - mae: 0.0605 - mse: 0.0074 - val_loss: 0.0140 - val_mae: 0.0831 - val_mse: 0.0140\n",
      "Epoch 34/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0606 - mse: 0.0074\n",
      "Epoch 00034: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0074 - mae: 0.0605 - mse: 0.0074 - val_loss: 0.0135 - val_mae: 0.0811 - val_mse: 0.0135\n",
      "Elapsed time during model training:  48.35979175567627\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0457 - mae: 0.1480 - mse: 0.0457\n",
      "Epoch 00001: val_loss improved from inf to 0.01943, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0447,  mae:0.1464,  mse:0.0447,  val_loss:0.0194,  val_mae:0.1008,  val_mse:0.0194,  \n",
      "14926/14926 [==============================] - 2s 148us/sample - loss: 0.0447 - mae: 0.1464 - mse: 0.0447 - val_loss: 0.0194 - val_mae: 0.1008 - val_mse: 0.0194\n",
      "Epoch 2/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0232 - mae: 0.1118 - mse: 0.0232\n",
      "Epoch 00002: val_loss did not improve from 0.01943\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0232 - mae: 0.1120 - mse: 0.0232 - val_loss: 0.0209 - val_mae: 0.1023 - val_mse: 0.0209\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1037 - mse: 0.0203\n",
      "Epoch 00003: val_loss did not improve from 0.01943\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0203 - mae: 0.1036 - mse: 0.0203 - val_loss: 0.0204 - val_mae: 0.1076 - val_mse: 0.0204\n",
      "Epoch 4/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0190 - mae: 0.0991 - mse: 0.0190\n",
      "Epoch 00004: val_loss improved from 0.01943 to 0.01688, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0190 - mae: 0.0990 - mse: 0.0190 - val_loss: 0.0169 - val_mae: 0.0934 - val_mse: 0.0169\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0970 - mse: 0.0183\n",
      "Epoch 00005: val_loss did not improve from 0.01688\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0182 - mae: 0.0968 - mse: 0.0182 - val_loss: 0.0191 - val_mae: 0.0977 - val_mse: 0.0191\n",
      "Epoch 6/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0176 - mae: 0.0956 - mse: 0.0176\n",
      "Epoch 00006: val_loss did not improve from 0.01688\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0176 - mae: 0.0956 - mse: 0.0176 - val_loss: 0.0194 - val_mae: 0.0991 - val_mse: 0.0194\n",
      "Epoch 7/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0944 - mse: 0.0172\n",
      "Epoch 00007: val_loss did not improve from 0.01688\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0172 - mae: 0.0944 - mse: 0.0172 - val_loss: 0.0193 - val_mae: 0.0959 - val_mse: 0.0193\n",
      "Epoch 8/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0901 - mse: 0.0159\n",
      "Epoch 00008: val_loss did not improve from 0.01688\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0160 - mae: 0.0902 - mse: 0.0160 - val_loss: 0.0179 - val_mae: 0.0996 - val_mse: 0.0179\n",
      "Epoch 9/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0903 - mse: 0.0158\n",
      "Epoch 00009: val_loss did not improve from 0.01688\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0158 - mae: 0.0902 - mse: 0.0158 - val_loss: 0.0179 - val_mae: 0.0955 - val_mse: 0.0179\n",
      "Epoch 10/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0871 - mse: 0.0149\n",
      "Epoch 00010: val_loss improved from 0.01688 to 0.01570, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0149 - mae: 0.0871 - mse: 0.0149 - val_loss: 0.0157 - val_mae: 0.0849 - val_mse: 0.0157\n",
      "Epoch 11/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0879 - mse: 0.0151\n",
      "Epoch 00011: val_loss did not improve from 0.01570\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0150 - mae: 0.0879 - mse: 0.0150 - val_loss: 0.0163 - val_mae: 0.0896 - val_mse: 0.0163\n",
      "Epoch 12/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0850 - mse: 0.0142\n",
      "Epoch 00012: val_loss improved from 0.01570 to 0.01452, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0142 - mae: 0.0849 - mse: 0.0142 - val_loss: 0.0145 - val_mae: 0.0826 - val_mse: 0.0145\n",
      "Epoch 13/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0836 - mse: 0.0138\n",
      "Epoch 00013: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0138 - mae: 0.0836 - mse: 0.0138 - val_loss: 0.0150 - val_mae: 0.0887 - val_mse: 0.0150\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0820 - mse: 0.0133\n",
      "Epoch 00014: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0133 - mae: 0.0820 - mse: 0.0133 - val_loss: 0.0149 - val_mae: 0.0840 - val_mse: 0.0149\n",
      "Epoch 15/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0803 - mse: 0.0129\n",
      "Epoch 00015: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0129 - mae: 0.0804 - mse: 0.0129 - val_loss: 0.0153 - val_mae: 0.0865 - val_mse: 0.0153\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0787 - mse: 0.0126\n",
      "Epoch 00016: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0126 - mae: 0.0788 - mse: 0.0126 - val_loss: 0.0148 - val_mae: 0.0842 - val_mse: 0.0148\n",
      "Epoch 17/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0124 - mae: 0.0784 - mse: 0.0124\n",
      "Epoch 00017: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0124 - mae: 0.0784 - mse: 0.0124 - val_loss: 0.0174 - val_mae: 0.0882 - val_mse: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0123 - mae: 0.0785 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0122 - mae: 0.0782 - mse: 0.0122 - val_loss: 0.0156 - val_mae: 0.0918 - val_mse: 0.0156\n",
      "Epoch 19/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0762 - mse: 0.0118\n",
      "Epoch 00019: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0118 - mae: 0.0762 - mse: 0.0118 - val_loss: 0.0163 - val_mae: 0.0911 - val_mse: 0.0163\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0755 - mse: 0.0115\n",
      "Epoch 00020: val_loss improved from 0.01452 to 0.01421, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0113 - mae: 0.0752 - mse: 0.0113 - val_loss: 0.0142 - val_mae: 0.0790 - val_mse: 0.0142\n",
      "Epoch 21/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0742 - mse: 0.0112\n",
      "Epoch 00021: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0112 - mae: 0.0743 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0879 - val_mse: 0.0154\n",
      "Epoch 22/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0750 - mse: 0.0111\n",
      "Epoch 00022: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0111 - mae: 0.0750 - mse: 0.0111 - val_loss: 0.0151 - val_mae: 0.0868 - val_mse: 0.0151\n",
      "Epoch 23/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0727 - mse: 0.0106\n",
      "Epoch 00023: val_loss improved from 0.01421 to 0.01405, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0106 - mae: 0.0726 - mse: 0.0106 - val_loss: 0.0141 - val_mae: 0.0811 - val_mse: 0.0141\n",
      "Epoch 24/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0717 - mse: 0.0104\n",
      "Epoch 00024: val_loss did not improve from 0.01405\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0104 - mae: 0.0718 - mse: 0.0104 - val_loss: 0.0161 - val_mae: 0.0934 - val_mse: 0.0161\n",
      "Epoch 25/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0098 - mae: 0.0704 - mse: 0.0098\n",
      "Epoch 00025: val_loss did not improve from 0.01405\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0169 - val_mae: 0.0887 - val_mse: 0.0169\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0704 - mse: 0.0097\n",
      "Epoch 00026: val_loss did not improve from 0.01405\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0162 - val_mae: 0.0941 - val_mse: 0.0162\n",
      "Epoch 27/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0097 - mae: 0.0698 - mse: 0.0097\n",
      "Epoch 00027: val_loss did not improve from 0.01405\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0097 - mae: 0.0698 - mse: 0.0097 - val_loss: 0.0150 - val_mae: 0.0819 - val_mse: 0.0150\n",
      "Epoch 28/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0680 - mse: 0.0094\n",
      "Epoch 00028: val_loss improved from 0.01405 to 0.01398, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0094 - mae: 0.0680 - mse: 0.0094 - val_loss: 0.0140 - val_mae: 0.0789 - val_mse: 0.0140\n",
      "Epoch 29/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0676 - mse: 0.0093\n",
      "Epoch 00029: val_loss improved from 0.01398 to 0.01354, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0093 - mae: 0.0676 - mse: 0.0093 - val_loss: 0.0135 - val_mae: 0.0797 - val_mse: 0.0135\n",
      "Epoch 30/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00030: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0089 - mae: 0.0661 - mse: 0.0089 - val_loss: 0.0156 - val_mae: 0.0871 - val_mse: 0.0156\n",
      "Epoch 31/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0646 - mse: 0.0085\n",
      "Epoch 00031: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0085 - mae: 0.0647 - mse: 0.0085 - val_loss: 0.0143 - val_mae: 0.0777 - val_mse: 0.0143\n",
      "Epoch 32/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0665 - mse: 0.0089\n",
      "Epoch 00032: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0138 - val_mae: 0.0796 - val_mse: 0.0138\n",
      "Epoch 33/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0656 - mse: 0.0087\n",
      "Epoch 00033: val_loss improved from 0.01354 to 0.01323, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0087 - mae: 0.0656 - mse: 0.0087 - val_loss: 0.0132 - val_mae: 0.0786 - val_mse: 0.0132\n",
      "Epoch 34/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0658 - mse: 0.0087\n",
      "Epoch 00034: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0086 - mae: 0.0657 - mse: 0.0086 - val_loss: 0.0145 - val_mae: 0.0800 - val_mse: 0.0145\n",
      "Epoch 35/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0639 - mse: 0.0082\n",
      "Epoch 00035: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0082 - mae: 0.0641 - mse: 0.0082 - val_loss: 0.0142 - val_mae: 0.0789 - val_mse: 0.0142\n",
      "Epoch 36/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0642 - mse: 0.0083\n",
      "Epoch 00036: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0082 - mae: 0.0642 - mse: 0.0082 - val_loss: 0.0147 - val_mae: 0.0839 - val_mse: 0.0147\n",
      "Epoch 37/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0626 - mse: 0.0076\n",
      "Epoch 00037: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0079 - mae: 0.0627 - mse: 0.0079 - val_loss: 0.0162 - val_mae: 0.0928 - val_mse: 0.0162\n",
      "Epoch 38/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0618 - mse: 0.0078\n",
      "Epoch 00038: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0078 - mae: 0.0618 - mse: 0.0078 - val_loss: 0.0140 - val_mae: 0.0801 - val_mse: 0.0140\n",
      "Epoch 39/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0613 - mse: 0.0076\n",
      "Epoch 00039: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0076 - mae: 0.0612 - mse: 0.0076 - val_loss: 0.0142 - val_mae: 0.0790 - val_mse: 0.0142\n",
      "Epoch 40/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0625 - mse: 0.0079\n",
      "Epoch 00040: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0079 - mae: 0.0627 - mse: 0.0079 - val_loss: 0.0154 - val_mae: 0.0845 - val_mse: 0.0154\n",
      "Epoch 41/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0609 - mse: 0.0075\n",
      "Epoch 00041: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0075 - mae: 0.0610 - mse: 0.0075 - val_loss: 0.0140 - val_mae: 0.0795 - val_mse: 0.0140\n",
      "Epoch 42/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0602 - mse: 0.0073\n",
      "Epoch 00042: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0074 - mae: 0.0602 - mse: 0.0074 - val_loss: 0.0137 - val_mae: 0.0780 - val_mse: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0587 - mse: 0.0069\n",
      "Epoch 00043: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0069 - mae: 0.0587 - mse: 0.0069 - val_loss: 0.0167 - val_mae: 0.0919 - val_mse: 0.0167\n",
      "Epoch 44/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0587 - mse: 0.0069\n",
      "Epoch 00044: val_loss did not improve from 0.01323\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0070 - mae: 0.0588 - mse: 0.0070 - val_loss: 0.0146 - val_mae: 0.0844 - val_mse: 0.0146\n",
      "Elapsed time during model training:  66.3153703212738\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0443 - mae: 0.1469 - mse: 0.0443\n",
      "Epoch 00001: val_loss improved from inf to 0.02539, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0442,  mae:0.1467,  mse:0.0442,  val_loss:0.0254,  val_mae:0.1190,  val_mse:0.0254,  \n",
      "14926/14926 [==============================] - 2s 146us/sample - loss: 0.0442 - mae: 0.1467 - mse: 0.0442 - val_loss: 0.0254 - val_mae: 0.1190 - val_mse: 0.0254\n",
      "Epoch 2/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0232 - mae: 0.1119 - mse: 0.0232\n",
      "Epoch 00002: val_loss improved from 0.02539 to 0.02244, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0230 - mae: 0.1116 - mse: 0.0230 - val_loss: 0.0224 - val_mae: 0.1164 - val_mse: 0.0224\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1035 - mse: 0.0202\n",
      "Epoch 00003: val_loss improved from 0.02244 to 0.02088, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0203 - mae: 0.1034 - mse: 0.0203 - val_loss: 0.0209 - val_mae: 0.1048 - val_mse: 0.0209\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0979 - mse: 0.0184\n",
      "Epoch 00004: val_loss did not improve from 0.02088\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0184 - mae: 0.0979 - mse: 0.0184 - val_loss: 0.0211 - val_mae: 0.1021 - val_mse: 0.0211\n",
      "Epoch 5/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0974 - mse: 0.0184\n",
      "Epoch 00005: val_loss improved from 0.02088 to 0.01725, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 125us/sample - loss: 0.0184 - mae: 0.0974 - mse: 0.0184 - val_loss: 0.0173 - val_mae: 0.0941 - val_mse: 0.0173\n",
      "Epoch 6/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0169 - mae: 0.0938 - mse: 0.0169\n",
      "Epoch 00006: val_loss improved from 0.01725 to 0.01633, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0168 - mae: 0.0936 - mse: 0.0168 - val_loss: 0.0163 - val_mae: 0.0906 - val_mse: 0.0163\n",
      "Epoch 7/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0912 - mse: 0.0162\n",
      "Epoch 00007: val_loss did not improve from 0.01633\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0162 - mae: 0.0912 - mse: 0.0162 - val_loss: 0.0167 - val_mae: 0.0913 - val_mse: 0.0167\n",
      "Epoch 8/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0905 - mse: 0.0160\n",
      "Epoch 00008: val_loss did not improve from 0.01633\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0159 - mae: 0.0904 - mse: 0.0159 - val_loss: 0.0198 - val_mae: 0.1068 - val_mse: 0.0198\n",
      "Epoch 9/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0857 - mse: 0.0145\n",
      "Epoch 00009: val_loss did not improve from 0.01633\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0148 - mae: 0.0868 - mse: 0.0148 - val_loss: 0.0213 - val_mae: 0.1072 - val_mse: 0.0213\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0880 - mse: 0.0154\n",
      "Epoch 00010: val_loss did not improve from 0.01633\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0154 - mae: 0.0880 - mse: 0.0154 - val_loss: 0.0193 - val_mae: 0.1025 - val_mse: 0.0193\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0831 - mse: 0.0139\n",
      "Epoch 00011: val_loss improved from 0.01633 to 0.01403, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0139 - mae: 0.0831 - mse: 0.0139 - val_loss: 0.0140 - val_mae: 0.0819 - val_mse: 0.0140\n",
      "Epoch 12/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0836 - mse: 0.0137\n",
      "Epoch 00012: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0137 - mae: 0.0835 - mse: 0.0137 - val_loss: 0.0166 - val_mae: 0.0868 - val_mse: 0.0166\n",
      "Epoch 13/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0831 - mse: 0.0136\n",
      "Epoch 00013: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0136 - mae: 0.0832 - mse: 0.0136 - val_loss: 0.0174 - val_mae: 0.0943 - val_mse: 0.0174\n",
      "Epoch 14/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0807 - mse: 0.0130\n",
      "Epoch 00014: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0130 - mae: 0.0807 - mse: 0.0130 - val_loss: 0.0177 - val_mae: 0.0958 - val_mse: 0.0177\n",
      "Epoch 15/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0835 - mse: 0.0135\n",
      "Epoch 00015: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0135 - mae: 0.0834 - mse: 0.0135 - val_loss: 0.0158 - val_mae: 0.0871 - val_mse: 0.0158\n",
      "Epoch 16/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0778 - mse: 0.0122\n",
      "Epoch 00016: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0122 - mae: 0.0779 - mse: 0.0122 - val_loss: 0.0162 - val_mae: 0.0879 - val_mse: 0.0162\n",
      "Epoch 17/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0759 - mse: 0.0118\n",
      "Epoch 00017: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0117 - mae: 0.0758 - mse: 0.0117 - val_loss: 0.0168 - val_mae: 0.0929 - val_mse: 0.0168\n",
      "Epoch 18/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0772 - mse: 0.0118\n",
      "Epoch 00018: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0118 - mae: 0.0772 - mse: 0.0118 - val_loss: 0.0149 - val_mae: 0.0869 - val_mse: 0.0149\n",
      "Epoch 19/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0750 - mse: 0.0113\n",
      "Epoch 00019: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0113 - mae: 0.0750 - mse: 0.0113 - val_loss: 0.0167 - val_mae: 0.0879 - val_mse: 0.0167\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0746 - mse: 0.0113\n",
      "Epoch 00020: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0113 - mae: 0.0748 - mse: 0.0113 - val_loss: 0.0145 - val_mae: 0.0846 - val_mse: 0.0145\n",
      "Epoch 21/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0107 - mae: 0.0724 - mse: 0.0107\n",
      "Epoch 00021: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0107 - mae: 0.0726 - mse: 0.0107 - val_loss: 0.0147 - val_mae: 0.0859 - val_mse: 0.0147\n",
      "Epoch 22/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0707 - mse: 0.0100\n",
      "Epoch 00022: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0100 - mae: 0.0705 - mse: 0.0100 - val_loss: 0.0150 - val_mae: 0.0830 - val_mse: 0.0150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0711 - mse: 0.0103\n",
      "Epoch 00023: val_loss did not improve from 0.01403\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0103 - mae: 0.0709 - mse: 0.0103 - val_loss: 0.0155 - val_mae: 0.0825 - val_mse: 0.0155\n",
      "Elapsed time during model training:  34.80256938934326\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0453 - mae: 0.1501 - mse: 0.0453\n",
      "Epoch 00001: val_loss improved from inf to 0.01990, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0452,  mae:0.1501,  mse:0.0452,  val_loss:0.0199,  val_mae:0.1036,  val_mse:0.0199,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0452 - mae: 0.1501 - mse: 0.0452 - val_loss: 0.0199 - val_mae: 0.1036 - val_mse: 0.0199\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0217 - mae: 0.1067 - mse: 0.0217\n",
      "Epoch 00002: val_loss improved from 0.01990 to 0.01704, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0217 - mae: 0.1066 - mse: 0.0217 - val_loss: 0.0170 - val_mae: 0.0942 - val_mse: 0.0170\n",
      "Epoch 3/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0215 - mae: 0.1073 - mse: 0.0215\n",
      "Epoch 00003: val_loss did not improve from 0.01704\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0215 - mae: 0.1071 - mse: 0.0215 - val_loss: 0.0179 - val_mae: 0.0953 - val_mse: 0.0179\n",
      "Epoch 4/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.0994 - mse: 0.0191\n",
      "Epoch 00004: val_loss did not improve from 0.01704\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0191 - mae: 0.0995 - mse: 0.0191 - val_loss: 0.0174 - val_mae: 0.0966 - val_mse: 0.0174\n",
      "Epoch 5/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0977 - mse: 0.0183\n",
      "Epoch 00005: val_loss did not improve from 0.01704\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0183 - mae: 0.0977 - mse: 0.0183 - val_loss: 0.0239 - val_mae: 0.1140 - val_mse: 0.0239\n",
      "Epoch 6/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0974 - mse: 0.0181\n",
      "Epoch 00006: val_loss did not improve from 0.01704\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0181 - mae: 0.0975 - mse: 0.0181 - val_loss: 0.0216 - val_mae: 0.1067 - val_mse: 0.0216\n",
      "Epoch 7/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0921 - mse: 0.0166\n",
      "Epoch 00007: val_loss did not improve from 0.01704\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0166 - mae: 0.0922 - mse: 0.0166 - val_loss: 0.0173 - val_mae: 0.0948 - val_mse: 0.0173\n",
      "Epoch 8/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0893 - mse: 0.0158\n",
      "Epoch 00008: val_loss improved from 0.01704 to 0.01502, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0159 - mae: 0.0895 - mse: 0.0159 - val_loss: 0.0150 - val_mae: 0.0861 - val_mse: 0.0150\n",
      "Epoch 9/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0159 - mae: 0.0902 - mse: 0.0159\n",
      "Epoch 00009: val_loss did not improve from 0.01502\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0159 - mae: 0.0902 - mse: 0.0159 - val_loss: 0.0178 - val_mae: 0.0929 - val_mse: 0.0178\n",
      "Epoch 10/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0894 - mse: 0.0156\n",
      "Epoch 00010: val_loss did not improve from 0.01502\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0155 - mae: 0.0893 - mse: 0.0155 - val_loss: 0.0167 - val_mae: 0.0939 - val_mse: 0.0167\n",
      "Epoch 11/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0151 - mae: 0.0884 - mse: 0.0151\n",
      "Epoch 00011: val_loss improved from 0.01502 to 0.01493, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0151 - mae: 0.0883 - mse: 0.0151 - val_loss: 0.0149 - val_mae: 0.0839 - val_mse: 0.0149\n",
      "Epoch 12/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0144 - mae: 0.0861 - mse: 0.0144\n",
      "Epoch 00012: val_loss did not improve from 0.01493\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0146 - mae: 0.0864 - mse: 0.0146 - val_loss: 0.0179 - val_mae: 0.0945 - val_mse: 0.0179\n",
      "Epoch 13/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0827 - mse: 0.0136\n",
      "Epoch 00013: val_loss did not improve from 0.01493\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0136 - mae: 0.0828 - mse: 0.0136 - val_loss: 0.0174 - val_mae: 0.0968 - val_mse: 0.0174\n",
      "Epoch 14/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0831 - mse: 0.0136\n",
      "Epoch 00014: val_loss did not improve from 0.01493\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0136 - mae: 0.0830 - mse: 0.0136 - val_loss: 0.0215 - val_mae: 0.1103 - val_mse: 0.0215\n",
      "Epoch 15/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0827 - mse: 0.0136\n",
      "Epoch 00015: val_loss did not improve from 0.01493\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0136 - mae: 0.0827 - mse: 0.0136 - val_loss: 0.0166 - val_mae: 0.0888 - val_mse: 0.0166\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0806 - mse: 0.0130\n",
      "Epoch 00016: val_loss improved from 0.01493 to 0.01404, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0130 - mae: 0.0806 - mse: 0.0130 - val_loss: 0.0140 - val_mae: 0.0811 - val_mse: 0.0140\n",
      "Epoch 17/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0795 - mse: 0.0126\n",
      "Epoch 00017: val_loss did not improve from 0.01404\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0126 - mae: 0.0797 - mse: 0.0126 - val_loss: 0.0144 - val_mae: 0.0830 - val_mse: 0.0144\n",
      "Epoch 18/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0779 - mse: 0.0124\n",
      "Epoch 00018: val_loss did not improve from 0.01404\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0124 - mae: 0.0782 - mse: 0.0124 - val_loss: 0.0151 - val_mae: 0.0833 - val_mse: 0.0151\n",
      "Epoch 19/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0767 - mse: 0.0119\n",
      "Epoch 00019: val_loss did not improve from 0.01404\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0119 - mae: 0.0766 - mse: 0.0119 - val_loss: 0.0141 - val_mae: 0.0819 - val_mse: 0.0141\n",
      "Epoch 20/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0750 - mse: 0.0115\n",
      "Epoch 00020: val_loss did not improve from 0.01404\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0115 - mae: 0.0750 - mse: 0.0115 - val_loss: 0.0150 - val_mae: 0.0850 - val_mse: 0.0150\n",
      "Epoch 21/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0752 - mse: 0.0116\n",
      "Epoch 00021: val_loss did not improve from 0.01404\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0116 - mae: 0.0751 - mse: 0.0116 - val_loss: 0.0162 - val_mae: 0.0887 - val_mse: 0.0162\n",
      "Epoch 22/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0758 - mse: 0.0116\n",
      "Epoch 00022: val_loss improved from 0.01404 to 0.01336, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0116 - mae: 0.0756 - mse: 0.0116 - val_loss: 0.0134 - val_mae: 0.0767 - val_mse: 0.0134\n",
      "Epoch 23/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0726 - mse: 0.0108\n",
      "Epoch 00023: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0108 - mae: 0.0725 - mse: 0.0108 - val_loss: 0.0149 - val_mae: 0.0806 - val_mse: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0107 - mae: 0.0725 - mse: 0.0107\n",
      "Epoch 00024: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0107 - mae: 0.0727 - mse: 0.0107 - val_loss: 0.0158 - val_mae: 0.0887 - val_mse: 0.0158\n",
      "Epoch 25/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0106 - mae: 0.0720 - mse: 0.0106\n",
      "Epoch 00025: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0107 - mae: 0.0722 - mse: 0.0107 - val_loss: 0.0141 - val_mae: 0.0800 - val_mse: 0.0141\n",
      "Epoch 26/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0708 - mse: 0.0103\n",
      "Epoch 00026: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0103 - mae: 0.0708 - mse: 0.0103 - val_loss: 0.0148 - val_mae: 0.0823 - val_mse: 0.0148\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0709 - mse: 0.0101\n",
      "Epoch 00027: val_loss improved from 0.01336 to 0.01324, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0709 - mse: 0.0101 - val_loss: 0.0132 - val_mae: 0.0772 - val_mse: 0.0132\n",
      "Epoch 28/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0681 - mse: 0.0094\n",
      "Epoch 00028: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0094 - mae: 0.0681 - mse: 0.0094 - val_loss: 0.0138 - val_mae: 0.0789 - val_mse: 0.0138\n",
      "Epoch 29/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0686 - mse: 0.0096\n",
      "Epoch 00029: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0095 - mae: 0.0684 - mse: 0.0095 - val_loss: 0.0138 - val_mae: 0.0776 - val_mse: 0.0138\n",
      "Epoch 30/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0694 - mse: 0.0099\n",
      "Epoch 00030: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0099 - mae: 0.0694 - mse: 0.0099 - val_loss: 0.0139 - val_mae: 0.0793 - val_mse: 0.0139\n",
      "Epoch 31/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0692 - mse: 0.0097\n",
      "Epoch 00031: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0096 - mae: 0.0692 - mse: 0.0096 - val_loss: 0.0136 - val_mae: 0.0802 - val_mse: 0.0136\n",
      "Epoch 32/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0657 - mse: 0.0090\n",
      "Epoch 00032: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0090 - mae: 0.0658 - mse: 0.0090 - val_loss: 0.0138 - val_mae: 0.0790 - val_mse: 0.0138\n",
      "Epoch 33/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0656 - mse: 0.0084\n",
      "Epoch 00033: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0149 - val_mae: 0.0866 - val_mse: 0.0149\n",
      "Epoch 34/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0657 - mse: 0.0088\n",
      "Epoch 00034: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0088 - mae: 0.0657 - mse: 0.0088 - val_loss: 0.0135 - val_mae: 0.0773 - val_mse: 0.0135\n",
      "Epoch 35/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0644 - mse: 0.0085\n",
      "Epoch 00035: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0085 - mae: 0.0645 - mse: 0.0085 - val_loss: 0.0146 - val_mae: 0.0837 - val_mse: 0.0146\n",
      "Epoch 36/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0657 - mse: 0.0086\n",
      "Epoch 00036: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0086 - mae: 0.0657 - mse: 0.0086 - val_loss: 0.0140 - val_mae: 0.0796 - val_mse: 0.0140\n",
      "Epoch 37/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0626 - mse: 0.0080\n",
      "Epoch 00037: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0080 - mae: 0.0626 - mse: 0.0080 - val_loss: 0.0135 - val_mae: 0.0792 - val_mse: 0.0135\n",
      "Epoch 38/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0626 - mse: 0.0080\n",
      "Epoch 00038: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0080 - mae: 0.0626 - mse: 0.0080 - val_loss: 0.0133 - val_mae: 0.0791 - val_mse: 0.0133\n",
      "Epoch 39/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0629 - mse: 0.0080\n",
      "Epoch 00039: val_loss did not improve from 0.01324\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0080 - mae: 0.0628 - mse: 0.0080 - val_loss: 0.0152 - val_mae: 0.0836 - val_mse: 0.0152\n",
      "Elapsed time during model training:  53.864581823349\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0480 - mae: 0.1485 - mse: 0.0480\n",
      "Epoch 00001: val_loss improved from inf to 0.02043, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0476,  mae:0.1479,  mse:0.0476,  val_loss:0.0204,  val_mae:0.1041,  val_mse:0.0204,  \n",
      "14926/14926 [==============================] - 2s 143us/sample - loss: 0.0476 - mae: 0.1479 - mse: 0.0476 - val_loss: 0.0204 - val_mae: 0.1041 - val_mse: 0.0204\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0218 - mae: 0.1077 - mse: 0.0218\n",
      "Epoch 00002: val_loss improved from 0.02043 to 0.01916, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0217 - mae: 0.1075 - mse: 0.0217 - val_loss: 0.0192 - val_mae: 0.0997 - val_mse: 0.0192\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1035 - mse: 0.0202\n",
      "Epoch 00003: val_loss improved from 0.01916 to 0.01832, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0201 - mae: 0.1034 - mse: 0.0201 - val_loss: 0.0183 - val_mae: 0.0999 - val_mse: 0.0183\n",
      "Epoch 4/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0987 - mse: 0.0187\n",
      "Epoch 00004: val_loss improved from 0.01832 to 0.01805, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0186 - mae: 0.0986 - mse: 0.0186 - val_loss: 0.0181 - val_mae: 0.0947 - val_mse: 0.0181\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0177 - mae: 0.0956 - mse: 0.0177\n",
      "Epoch 00005: val_loss improved from 0.01805 to 0.01799, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0177 - mae: 0.0956 - mse: 0.0177 - val_loss: 0.0180 - val_mae: 0.0980 - val_mse: 0.0180\n",
      "Epoch 6/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0906 - mse: 0.0161\n",
      "Epoch 00006: val_loss improved from 0.01799 to 0.01789, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0160 - mae: 0.0906 - mse: 0.0160 - val_loss: 0.0179 - val_mae: 0.0982 - val_mse: 0.0179\n",
      "Epoch 7/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0910 - mse: 0.0162\n",
      "Epoch 00007: val_loss did not improve from 0.01789\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0162 - mae: 0.0910 - mse: 0.0162 - val_loss: 0.0242 - val_mae: 0.1218 - val_mse: 0.0242\n",
      "Epoch 8/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0897 - mse: 0.0158\n",
      "Epoch 00008: val_loss did not improve from 0.01789\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0159 - mae: 0.0899 - mse: 0.0159 - val_loss: 0.0194 - val_mae: 0.1051 - val_mse: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0147 - mae: 0.0865 - mse: 0.0147\n",
      "Epoch 00009: val_loss improved from 0.01789 to 0.01605, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0149 - mae: 0.0870 - mse: 0.0149 - val_loss: 0.0160 - val_mae: 0.0907 - val_mse: 0.0160\n",
      "Epoch 10/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0847 - mse: 0.0141\n",
      "Epoch 00010: val_loss did not improve from 0.01605\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0144 - mae: 0.0848 - mse: 0.0144 - val_loss: 0.0171 - val_mae: 0.1007 - val_mse: 0.0171\n",
      "Epoch 11/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0837 - mse: 0.0138\n",
      "Epoch 00011: val_loss improved from 0.01605 to 0.01590, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0138 - mae: 0.0837 - mse: 0.0138 - val_loss: 0.0159 - val_mae: 0.0884 - val_mse: 0.0159\n",
      "Epoch 12/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0138 - mae: 0.0836 - mse: 0.0138\n",
      "Epoch 00012: val_loss improved from 0.01590 to 0.01539, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0138 - mae: 0.0836 - mse: 0.0138 - val_loss: 0.0154 - val_mae: 0.0827 - val_mse: 0.0154\n",
      "Epoch 13/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0821 - mse: 0.0135\n",
      "Epoch 00013: val_loss improved from 0.01539 to 0.01500, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0135 - mae: 0.0820 - mse: 0.0135 - val_loss: 0.0150 - val_mae: 0.0869 - val_mse: 0.0150\n",
      "Epoch 14/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0781 - mse: 0.0125\n",
      "Epoch 00014: val_loss did not improve from 0.01500\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0125 - mae: 0.0782 - mse: 0.0125 - val_loss: 0.0200 - val_mae: 0.1046 - val_mse: 0.0200\n",
      "Epoch 15/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0800 - mse: 0.0128\n",
      "Epoch 00015: val_loss improved from 0.01500 to 0.01498, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0127 - mae: 0.0800 - mse: 0.0127 - val_loss: 0.0150 - val_mae: 0.0852 - val_mse: 0.0150\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0771 - mse: 0.0119\n",
      "Epoch 00016: val_loss did not improve from 0.01498\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0119 - mae: 0.0772 - mse: 0.0119 - val_loss: 0.0167 - val_mae: 0.0906 - val_mse: 0.0167\n",
      "Epoch 17/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0766 - mse: 0.0120\n",
      "Epoch 00017: val_loss did not improve from 0.01498\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0119 - mae: 0.0765 - mse: 0.0119 - val_loss: 0.0158 - val_mae: 0.0883 - val_mse: 0.0158\n",
      "Epoch 18/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0741 - mse: 0.0111\n",
      "Epoch 00018: val_loss improved from 0.01498 to 0.01374, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0137 - val_mae: 0.0793 - val_mse: 0.0137\n",
      "Epoch 19/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0750 - mse: 0.0112\n",
      "Epoch 00019: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0113 - mae: 0.0752 - mse: 0.0113 - val_loss: 0.0156 - val_mae: 0.0902 - val_mse: 0.0156\n",
      "Epoch 20/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00020: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0105 - mae: 0.0718 - mse: 0.0105 - val_loss: 0.0151 - val_mae: 0.0808 - val_mse: 0.0151\n",
      "Epoch 21/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0705 - mse: 0.0102\n",
      "Epoch 00021: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0102 - mae: 0.0706 - mse: 0.0102 - val_loss: 0.0140 - val_mae: 0.0794 - val_mse: 0.0140\n",
      "Epoch 22/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0719 - mse: 0.0104\n",
      "Epoch 00022: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0104 - mae: 0.0719 - mse: 0.0104 - val_loss: 0.0149 - val_mae: 0.0883 - val_mse: 0.0149\n",
      "Epoch 23/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0706 - mse: 0.0102\n",
      "Epoch 00023: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0102 - mae: 0.0706 - mse: 0.0102 - val_loss: 0.0152 - val_mae: 0.0859 - val_mse: 0.0152\n",
      "Epoch 24/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0675 - mse: 0.0094\n",
      "Epoch 00024: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0095 - mae: 0.0677 - mse: 0.0095 - val_loss: 0.0142 - val_mae: 0.0843 - val_mse: 0.0142\n",
      "Epoch 25/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0674 - mse: 0.0086\n",
      "Epoch 00025: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0094 - mae: 0.0680 - mse: 0.0094 - val_loss: 0.0182 - val_mae: 0.1014 - val_mse: 0.0182\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0683 - mse: 0.0093\n",
      "Epoch 00026: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0093 - mae: 0.0684 - mse: 0.0093 - val_loss: 0.0148 - val_mae: 0.0877 - val_mse: 0.0148\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00027: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0089 - mae: 0.0661 - mse: 0.0089 - val_loss: 0.0150 - val_mae: 0.0884 - val_mse: 0.0150\n",
      "Epoch 28/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0668 - mse: 0.0090\n",
      "Epoch 00028: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0090 - mae: 0.0668 - mse: 0.0090 - val_loss: 0.0149 - val_mae: 0.0880 - val_mse: 0.0149\n",
      "Epoch 29/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0647 - mse: 0.0086\n",
      "Epoch 00029: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0085 - mae: 0.0648 - mse: 0.0085 - val_loss: 0.0146 - val_mae: 0.0828 - val_mse: 0.0146\n",
      "Epoch 30/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0651 - mse: 0.0086\n",
      "Epoch 00030: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0087 - mae: 0.0652 - mse: 0.0087 - val_loss: 0.0140 - val_mae: 0.0810 - val_mse: 0.0140\n",
      "Elapsed time during model training:  43.30793738365173\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0465 - mae: 0.1490 - mse: 0.0465\n",
      "Epoch 00001: val_loss improved from inf to 0.02055, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0465,  mae:0.1490,  mse:0.0465,  val_loss:0.0205,  val_mae:0.1072,  val_mse:0.0205,  \n",
      "14926/14926 [==============================] - 2s 142us/sample - loss: 0.0465 - mae: 0.1490 - mse: 0.0465 - val_loss: 0.0205 - val_mae: 0.1072 - val_mse: 0.0205\n",
      "Epoch 2/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0242 - mae: 0.1149 - mse: 0.0242\n",
      "Epoch 00002: val_loss improved from 0.02055 to 0.01858, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0242 - mae: 0.1148 - mse: 0.0242 - val_loss: 0.0186 - val_mae: 0.0969 - val_mse: 0.0186\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1032 - mse: 0.0202\n",
      "Epoch 00003: val_loss did not improve from 0.01858\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0202 - mae: 0.1033 - mse: 0.0202 - val_loss: 0.0221 - val_mae: 0.1152 - val_mse: 0.0221\n",
      "Epoch 4/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0195 - mae: 0.1016 - mse: 0.0195\n",
      "Epoch 00004: val_loss improved from 0.01858 to 0.01682, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0195 - mae: 0.1016 - mse: 0.0195 - val_loss: 0.0168 - val_mae: 0.0911 - val_mse: 0.0168\n",
      "Epoch 5/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0188 - mae: 0.0997 - mse: 0.0188\n",
      "Epoch 00005: val_loss improved from 0.01682 to 0.01621, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0186 - mae: 0.0991 - mse: 0.0186 - val_loss: 0.0162 - val_mae: 0.0872 - val_mse: 0.0162\n",
      "Epoch 6/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0971 - mse: 0.0181\n",
      "Epoch 00006: val_loss improved from 0.01621 to 0.01586, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0181 - mae: 0.0970 - mse: 0.0181 - val_loss: 0.0159 - val_mae: 0.0898 - val_mse: 0.0159\n",
      "Epoch 7/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0165 - mae: 0.0921 - mse: 0.0165\n",
      "Epoch 00007: val_loss did not improve from 0.01586\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0166 - mae: 0.0925 - mse: 0.0166 - val_loss: 0.0180 - val_mae: 0.0986 - val_mse: 0.0180\n",
      "Epoch 8/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0913 - mse: 0.0161\n",
      "Epoch 00008: val_loss did not improve from 0.01586\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0161 - mae: 0.0912 - mse: 0.0161 - val_loss: 0.0186 - val_mae: 0.0969 - val_mse: 0.0186\n",
      "Epoch 9/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0893 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01586\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0156 - mae: 0.0893 - mse: 0.0156 - val_loss: 0.0166 - val_mae: 0.0889 - val_mse: 0.0166\n",
      "Epoch 10/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0874 - mse: 0.0151\n",
      "Epoch 00010: val_loss did not improve from 0.01586\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0151 - mae: 0.0875 - mse: 0.0151 - val_loss: 0.0185 - val_mae: 0.0967 - val_mse: 0.0185\n",
      "Epoch 11/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0855 - mse: 0.0145\n",
      "Epoch 00011: val_loss did not improve from 0.01586\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0145 - mae: 0.0858 - mse: 0.0145 - val_loss: 0.0194 - val_mae: 0.1063 - val_mse: 0.0194\n",
      "Epoch 12/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0843 - mse: 0.0140\n",
      "Epoch 00012: val_loss improved from 0.01586 to 0.01481, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0139 - mae: 0.0843 - mse: 0.0139 - val_loss: 0.0148 - val_mae: 0.0830 - val_mse: 0.0148\n",
      "Epoch 13/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0848 - mse: 0.0141\n",
      "Epoch 00013: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0141 - mae: 0.0848 - mse: 0.0141 - val_loss: 0.0157 - val_mae: 0.0884 - val_mse: 0.0157\n",
      "Epoch 14/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0846 - mse: 0.0140\n",
      "Epoch 00014: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0140 - mae: 0.0847 - mse: 0.0140 - val_loss: 0.0156 - val_mae: 0.0895 - val_mse: 0.0156\n",
      "Epoch 15/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0798 - mse: 0.0127\n",
      "Epoch 00015: val_loss improved from 0.01481 to 0.01408, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0126 - mae: 0.0797 - mse: 0.0126 - val_loss: 0.0141 - val_mae: 0.0810 - val_mse: 0.0141\n",
      "Epoch 16/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0788 - mse: 0.0125\n",
      "Epoch 00016: val_loss did not improve from 0.01408\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0125 - mae: 0.0787 - mse: 0.0125 - val_loss: 0.0196 - val_mae: 0.0999 - val_mse: 0.0196\n",
      "Epoch 17/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0805 - mse: 0.0127\n",
      "Epoch 00017: val_loss did not improve from 0.01408\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0127 - mae: 0.0806 - mse: 0.0127 - val_loss: 0.0149 - val_mae: 0.0849 - val_mse: 0.0149\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0775 - mse: 0.0120\n",
      "Epoch 00018: val_loss improved from 0.01408 to 0.01402, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0120 - mae: 0.0774 - mse: 0.0120 - val_loss: 0.0140 - val_mae: 0.0820 - val_mse: 0.0140\n",
      "Epoch 19/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0759 - mse: 0.0116\n",
      "Epoch 00019: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0116 - mae: 0.0759 - mse: 0.0116 - val_loss: 0.0171 - val_mae: 0.0965 - val_mse: 0.0171\n",
      "Epoch 20/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0746 - mse: 0.0112\n",
      "Epoch 00020: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0111 - mae: 0.0745 - mse: 0.0111 - val_loss: 0.0144 - val_mae: 0.0817 - val_mse: 0.0144\n",
      "Epoch 21/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0737 - mse: 0.0110\n",
      "Epoch 00021: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0110 - mae: 0.0737 - mse: 0.0110 - val_loss: 0.0146 - val_mae: 0.0821 - val_mse: 0.0146\n",
      "Epoch 22/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0727 - mse: 0.0106\n",
      "Epoch 00022: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0106 - mae: 0.0726 - mse: 0.0106 - val_loss: 0.0148 - val_mae: 0.0839 - val_mse: 0.0148\n",
      "Epoch 23/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0734 - mse: 0.0107\n",
      "Epoch 00023: val_loss did not improve from 0.01402\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0107 - mae: 0.0734 - mse: 0.0107 - val_loss: 0.0230 - val_mae: 0.1140 - val_mse: 0.0230\n",
      "Epoch 24/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0104 - mae: 0.0720 - mse: 0.0104\n",
      "Epoch 00024: val_loss improved from 0.01402 to 0.01399, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0103 - mae: 0.0718 - mse: 0.0103 - val_loss: 0.0140 - val_mae: 0.0803 - val_mse: 0.0140\n",
      "Epoch 25/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0693 - mse: 0.0097\n",
      "Epoch 00025: val_loss did not improve from 0.01399\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0097 - mae: 0.0693 - mse: 0.0097 - val_loss: 0.0153 - val_mae: 0.0911 - val_mse: 0.0153\n",
      "Epoch 26/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0712 - mse: 0.0101\n",
      "Epoch 00026: val_loss improved from 0.01399 to 0.01346, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0712 - mse: 0.0101 - val_loss: 0.0135 - val_mae: 0.0792 - val_mse: 0.0135\n",
      "Epoch 27/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0692 - mse: 0.0096\n",
      "Epoch 00027: val_loss did not improve from 0.01346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0095 - mae: 0.0691 - mse: 0.0095 - val_loss: 0.0161 - val_mae: 0.0898 - val_mse: 0.0161\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0684 - mse: 0.0094\n",
      "Epoch 00028: val_loss did not improve from 0.01346\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0093 - mae: 0.0683 - mse: 0.0093 - val_loss: 0.0141 - val_mae: 0.0829 - val_mse: 0.0141\n",
      "Epoch 29/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0093 - mae: 0.0686 - mse: 0.0093\n",
      "Epoch 00029: val_loss improved from 0.01346 to 0.01336, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0093 - mae: 0.0685 - mse: 0.0093 - val_loss: 0.0134 - val_mae: 0.0801 - val_mse: 0.0134\n",
      "Epoch 30/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0670 - mse: 0.0090\n",
      "Epoch 00030: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0090 - mae: 0.0670 - mse: 0.0090 - val_loss: 0.0146 - val_mae: 0.0831 - val_mse: 0.0146\n",
      "Epoch 31/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0087 - mae: 0.0669 - mse: 0.0087\n",
      "Epoch 00031: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0090 - mae: 0.0671 - mse: 0.0090 - val_loss: 0.0170 - val_mae: 0.1002 - val_mse: 0.0170\n",
      "Epoch 32/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0657 - mse: 0.0086\n",
      "Epoch 00032: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0086 - mae: 0.0658 - mse: 0.0086 - val_loss: 0.0158 - val_mae: 0.0915 - val_mse: 0.0158\n",
      "Epoch 33/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0085 - mae: 0.0646 - mse: 0.0085\n",
      "Epoch 00033: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0085 - mae: 0.0647 - mse: 0.0085 - val_loss: 0.0141 - val_mae: 0.0800 - val_mse: 0.0141\n",
      "Epoch 34/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0658 - mse: 0.0086\n",
      "Epoch 00034: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0086 - mae: 0.0657 - mse: 0.0086 - val_loss: 0.0149 - val_mae: 0.0846 - val_mse: 0.0149\n",
      "Epoch 35/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0634 - mse: 0.0081\n",
      "Epoch 00035: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0081 - mae: 0.0634 - mse: 0.0081 - val_loss: 0.0141 - val_mae: 0.0827 - val_mse: 0.0141\n",
      "Epoch 36/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0629 - mse: 0.0080\n",
      "Epoch 00036: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0080 - mae: 0.0630 - mse: 0.0080 - val_loss: 0.0148 - val_mae: 0.0846 - val_mse: 0.0148\n",
      "Epoch 37/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0632 - mse: 0.0080\n",
      "Epoch 00037: val_loss improved from 0.01336 to 0.01309, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0080 - mae: 0.0632 - mse: 0.0080 - val_loss: 0.0131 - val_mae: 0.0776 - val_mse: 0.0131\n",
      "Epoch 38/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0619 - mse: 0.0076\n",
      "Epoch 00038: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0076 - mae: 0.0619 - mse: 0.0076 - val_loss: 0.0142 - val_mae: 0.0797 - val_mse: 0.0142\n",
      "Epoch 39/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0613 - mse: 0.0075\n",
      "Epoch 00039: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0075 - mae: 0.0613 - mse: 0.0075 - val_loss: 0.0136 - val_mae: 0.0780 - val_mse: 0.0136\n",
      "Epoch 40/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0603 - mse: 0.0072\n",
      "Epoch 00040: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0073 - mae: 0.0606 - mse: 0.0073 - val_loss: 0.0157 - val_mae: 0.0861 - val_mse: 0.0157\n",
      "Epoch 41/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0596 - mse: 0.0072\n",
      "Epoch 00041: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0072 - mae: 0.0597 - mse: 0.0072 - val_loss: 0.0146 - val_mae: 0.0882 - val_mse: 0.0146\n",
      "Epoch 42/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0593 - mse: 0.0071\n",
      "Epoch 00042: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0070 - mae: 0.0593 - mse: 0.0070 - val_loss: 0.0140 - val_mae: 0.0774 - val_mse: 0.0140\n",
      "Epoch 43/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0606 - mse: 0.0074\n",
      "Epoch 00043: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0074 - mae: 0.0608 - mse: 0.0074 - val_loss: 0.0141 - val_mae: 0.0801 - val_mse: 0.0141\n",
      "Epoch 44/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0069 - mae: 0.0586 - mse: 0.0069\n",
      "Epoch 00044: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0069 - mae: 0.0588 - mse: 0.0069 - val_loss: 0.0149 - val_mae: 0.0826 - val_mse: 0.0149\n",
      "Epoch 45/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0580 - mse: 0.0068\n",
      "Epoch 00045: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0068 - mae: 0.0580 - mse: 0.0068 - val_loss: 0.0151 - val_mae: 0.0829 - val_mse: 0.0151\n",
      "Elapsed time during model training:  63.754210233688354\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0418 - mae: 0.1425 - mse: 0.0418\n",
      "Epoch 00001: val_loss improved from inf to 0.02666, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0422,  mae:0.1426,  mse:0.0422,  val_loss:0.0267,  val_mae:0.1256,  val_mse:0.0267,  \n",
      "14926/14926 [==============================] - 2s 144us/sample - loss: 0.0422 - mae: 0.1426 - mse: 0.0422 - val_loss: 0.0267 - val_mae: 0.1256 - val_mse: 0.0267\n",
      "Epoch 2/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0223 - mae: 0.1097 - mse: 0.0223\n",
      "Epoch 00002: val_loss improved from 0.02666 to 0.02339, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0224 - mae: 0.1097 - mse: 0.0224 - val_loss: 0.0234 - val_mae: 0.1199 - val_mse: 0.0234\n",
      "Epoch 3/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0202 - mae: 0.1031 - mse: 0.0202\n",
      "Epoch 00003: val_loss improved from 0.02339 to 0.01917, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0204 - mae: 0.1034 - mse: 0.0204 - val_loss: 0.0192 - val_mae: 0.0980 - val_mse: 0.0192\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0990 - mse: 0.0187\n",
      "Epoch 00004: val_loss improved from 0.01917 to 0.01893, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0186 - mae: 0.0990 - mse: 0.0186 - val_loss: 0.0189 - val_mae: 0.0956 - val_mse: 0.0189\n",
      "Epoch 5/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0177 - mae: 0.0957 - mse: 0.0177\n",
      "Epoch 00005: val_loss improved from 0.01893 to 0.01601, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0176 - mae: 0.0956 - mse: 0.0176 - val_loss: 0.0160 - val_mae: 0.0886 - val_mse: 0.0160\n",
      "Epoch 6/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0891 - mse: 0.0158\n",
      "Epoch 00006: val_loss did not improve from 0.01601\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0158 - mae: 0.0891 - mse: 0.0158 - val_loss: 0.0192 - val_mae: 0.0988 - val_mse: 0.0192\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0905 - mse: 0.0162\n",
      "Epoch 00007: val_loss improved from 0.01601 to 0.01521, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0161 - mae: 0.0903 - mse: 0.0161 - val_loss: 0.0152 - val_mae: 0.0860 - val_mse: 0.0152\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0902 - mse: 0.0158\n",
      "Epoch 00008: val_loss did not improve from 0.01521\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0158 - mae: 0.0901 - mse: 0.0158 - val_loss: 0.0196 - val_mae: 0.1100 - val_mse: 0.0196\n",
      "Epoch 9/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0866 - mse: 0.0147\n",
      "Epoch 00009: val_loss did not improve from 0.01521\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0148 - mae: 0.0868 - mse: 0.0148 - val_loss: 0.0160 - val_mae: 0.0888 - val_mse: 0.0160\n",
      "Epoch 10/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0866 - mse: 0.0146\n",
      "Epoch 00010: val_loss improved from 0.01521 to 0.01514, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0146 - mae: 0.0865 - mse: 0.0146 - val_loss: 0.0151 - val_mae: 0.0877 - val_mse: 0.0151\n",
      "Epoch 11/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0140 - mae: 0.0854 - mse: 0.0140\n",
      "Epoch 00011: val_loss did not improve from 0.01514\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0144 - mae: 0.0855 - mse: 0.0144 - val_loss: 0.0167 - val_mae: 0.0921 - val_mse: 0.0167\n",
      "Epoch 12/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0813 - mse: 0.0135\n",
      "Epoch 00012: val_loss improved from 0.01514 to 0.01470, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0133 - mae: 0.0812 - mse: 0.0133 - val_loss: 0.0147 - val_mae: 0.0852 - val_mse: 0.0147\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0799 - mse: 0.0127\n",
      "Epoch 00013: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0127 - mae: 0.0799 - mse: 0.0127 - val_loss: 0.0159 - val_mae: 0.0907 - val_mse: 0.0159\n",
      "Epoch 14/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0119 - mae: 0.0766 - mse: 0.0119\n",
      "Epoch 00014: val_loss did not improve from 0.01470\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0119 - mae: 0.0766 - mse: 0.0119 - val_loss: 0.0221 - val_mae: 0.1096 - val_mse: 0.0221\n",
      "Epoch 15/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0802 - mse: 0.0125\n",
      "Epoch 00015: val_loss improved from 0.01470 to 0.01417, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0125 - mae: 0.0802 - mse: 0.0125 - val_loss: 0.0142 - val_mae: 0.0803 - val_mse: 0.0142\n",
      "Epoch 16/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0761 - mse: 0.0116\n",
      "Epoch 00016: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0117 - mae: 0.0763 - mse: 0.0117 - val_loss: 0.0154 - val_mae: 0.0903 - val_mse: 0.0154\n",
      "Epoch 17/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0777 - mse: 0.0121\n",
      "Epoch 00017: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0121 - mae: 0.0778 - mse: 0.0121 - val_loss: 0.0182 - val_mae: 0.0962 - val_mse: 0.0182\n",
      "Epoch 18/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0732 - mse: 0.0109\n",
      "Epoch 00018: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0166 - val_mae: 0.0958 - val_mse: 0.0166\n",
      "Epoch 19/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0729 - mse: 0.0107\n",
      "Epoch 00019: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0107 - mae: 0.0730 - mse: 0.0107 - val_loss: 0.0144 - val_mae: 0.0816 - val_mse: 0.0144\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0719 - mse: 0.0104\n",
      "Epoch 00020: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0105 - mae: 0.0724 - mse: 0.0105 - val_loss: 0.0163 - val_mae: 0.0954 - val_mse: 0.0163\n",
      "Epoch 21/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0715 - mse: 0.0102\n",
      "Epoch 00021: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0102 - mae: 0.0715 - mse: 0.0102 - val_loss: 0.0155 - val_mae: 0.0847 - val_mse: 0.0155\n",
      "Epoch 22/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0700 - mse: 0.0100\n",
      "Epoch 00022: val_loss did not improve from 0.01417\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0100 - mae: 0.0701 - mse: 0.0100 - val_loss: 0.0147 - val_mae: 0.0856 - val_mse: 0.0147\n",
      "Epoch 23/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0095 - mae: 0.0681 - mse: 0.0095\n",
      "Epoch 00023: val_loss improved from 0.01417 to 0.01384, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0096 - mae: 0.0683 - mse: 0.0096 - val_loss: 0.0138 - val_mae: 0.0816 - val_mse: 0.0138\n",
      "Epoch 24/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0093 - mae: 0.0675 - mse: 0.0093\n",
      "Epoch 00024: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0094 - mae: 0.0679 - mse: 0.0094 - val_loss: 0.0156 - val_mae: 0.0827 - val_mse: 0.0156\n",
      "Epoch 25/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0682 - mse: 0.0094\n",
      "Epoch 00025: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0094 - mae: 0.0682 - mse: 0.0094 - val_loss: 0.0143 - val_mae: 0.0851 - val_mse: 0.0143\n",
      "Epoch 26/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00026: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0661 - mse: 0.0089 - val_loss: 0.0141 - val_mae: 0.0806 - val_mse: 0.0141\n",
      "Epoch 27/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0651 - mse: 0.0086\n",
      "Epoch 00027: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0086 - mae: 0.0651 - mse: 0.0086 - val_loss: 0.0149 - val_mae: 0.0822 - val_mse: 0.0149\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0673 - mse: 0.0091\n",
      "Epoch 00028: val_loss did not improve from 0.01384\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0091 - mae: 0.0675 - mse: 0.0091 - val_loss: 0.0154 - val_mae: 0.0885 - val_mse: 0.0154\n",
      "Epoch 29/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0637 - mse: 0.0082\n",
      "Epoch 00029: val_loss improved from 0.01384 to 0.01370, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0137 - val_mae: 0.0792 - val_mse: 0.0137\n",
      "Epoch 30/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0652 - mse: 0.0084\n",
      "Epoch 00030: val_loss did not improve from 0.01370\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0084 - mae: 0.0650 - mse: 0.0084 - val_loss: 0.0137 - val_mae: 0.0777 - val_mse: 0.0137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0625 - mse: 0.0077\n",
      "Epoch 00031: val_loss did not improve from 0.01370\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0081 - mae: 0.0627 - mse: 0.0081 - val_loss: 0.0151 - val_mae: 0.0853 - val_mse: 0.0151\n",
      "Epoch 32/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0621 - mse: 0.0078\n",
      "Epoch 00032: val_loss did not improve from 0.01370\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0078 - mae: 0.0621 - mse: 0.0078 - val_loss: 0.0145 - val_mae: 0.0817 - val_mse: 0.0145\n",
      "Epoch 33/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0621 - mse: 0.0079\n",
      "Epoch 00033: val_loss did not improve from 0.01370\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0079 - mae: 0.0623 - mse: 0.0079 - val_loss: 0.0165 - val_mae: 0.0939 - val_mse: 0.0165\n",
      "Epoch 34/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0604 - mse: 0.0074\n",
      "Epoch 00034: val_loss did not improve from 0.01370\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0074 - mae: 0.0605 - mse: 0.0074 - val_loss: 0.0150 - val_mae: 0.0861 - val_mse: 0.0150\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0589 - mse: 0.0070\n",
      "Epoch 00035: val_loss improved from 0.01370 to 0.01359, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0070 - mae: 0.0591 - mse: 0.0070 - val_loss: 0.0136 - val_mae: 0.0781 - val_mse: 0.0136\n",
      "Epoch 36/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0604 - mse: 0.0075\n",
      "Epoch 00036: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0075 - mae: 0.0605 - mse: 0.0075 - val_loss: 0.0147 - val_mae: 0.0831 - val_mse: 0.0147\n",
      "Epoch 37/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0069 - mae: 0.0581 - mse: 0.0069\n",
      "Epoch 00037: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0070 - mae: 0.0584 - mse: 0.0070 - val_loss: 0.0163 - val_mae: 0.0884 - val_mse: 0.0163\n",
      "Epoch 38/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0579 - mse: 0.0068\n",
      "Epoch 00038: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0069 - mae: 0.0581 - mse: 0.0069 - val_loss: 0.0149 - val_mae: 0.0852 - val_mse: 0.0149\n",
      "Epoch 39/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0566 - mse: 0.0067\n",
      "Epoch 00039: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0067 - mae: 0.0568 - mse: 0.0067 - val_loss: 0.0148 - val_mae: 0.0832 - val_mse: 0.0148\n",
      "Epoch 40/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0068 - mae: 0.0582 - mse: 0.0068\n",
      "Epoch 00040: val_loss improved from 0.01359 to 0.01273, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0067 - mae: 0.0579 - mse: 0.0067 - val_loss: 0.0127 - val_mae: 0.0750 - val_mse: 0.0127\n",
      "Epoch 41/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0062 - mae: 0.0550 - mse: 0.0062\n",
      "Epoch 00041: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0062 - mae: 0.0551 - mse: 0.0062 - val_loss: 0.0135 - val_mae: 0.0778 - val_mse: 0.0135\n",
      "Epoch 42/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0546 - mse: 0.0062\n",
      "Epoch 00042: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0062 - mae: 0.0546 - mse: 0.0062 - val_loss: 0.0142 - val_mae: 0.0806 - val_mse: 0.0142\n",
      "Epoch 43/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0556 - mse: 0.0063\n",
      "Epoch 00043: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0063 - mae: 0.0555 - mse: 0.0063 - val_loss: 0.0146 - val_mae: 0.0799 - val_mse: 0.0146\n",
      "Epoch 44/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0062 - mae: 0.0551 - mse: 0.0062\n",
      "Epoch 00044: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0063 - mae: 0.0555 - mse: 0.0063 - val_loss: 0.0146 - val_mae: 0.0804 - val_mse: 0.0146\n",
      "Epoch 45/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0544 - mse: 0.0061\n",
      "Epoch 00045: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0061 - mae: 0.0545 - mse: 0.0061 - val_loss: 0.0145 - val_mae: 0.0848 - val_mse: 0.0145\n",
      "Epoch 46/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0516 - mse: 0.0052\n",
      "Epoch 00046: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0054 - mae: 0.0518 - mse: 0.0054 - val_loss: 0.0173 - val_mae: 0.0941 - val_mse: 0.0173\n",
      "Epoch 47/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0557 - mse: 0.0062\n",
      "Epoch 00047: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0062 - mae: 0.0555 - mse: 0.0062 - val_loss: 0.0149 - val_mae: 0.0823 - val_mse: 0.0149\n",
      "Epoch 48/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0529 - mse: 0.0058\n",
      "Epoch 00048: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0058 - mae: 0.0528 - mse: 0.0058 - val_loss: 0.0137 - val_mae: 0.0783 - val_mse: 0.0137\n",
      "Epoch 49/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0500 - mse: 0.0053\n",
      "Epoch 00049: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0053 - mae: 0.0500 - mse: 0.0053 - val_loss: 0.0154 - val_mae: 0.0832 - val_mse: 0.0154\n",
      "Epoch 50/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0507 - mse: 0.0051\n",
      "Epoch 00050: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0053 - mae: 0.0510 - mse: 0.0053 - val_loss: 0.0160 - val_mae: 0.0851 - val_mse: 0.0160\n",
      "Epoch 51/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0504 - mse: 0.0052\n",
      "Epoch 00051: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0052 - mae: 0.0504 - mse: 0.0052 - val_loss: 0.0159 - val_mae: 0.0859 - val_mse: 0.0159\n",
      "Epoch 52/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0049 - mae: 0.0496 - mse: 0.0049\n",
      "Epoch 00052: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0051 - mae: 0.0499 - mse: 0.0051 - val_loss: 0.0153 - val_mae: 0.0911 - val_mse: 0.0153\n",
      "Epoch 53/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0498 - mse: 0.0051\n",
      "Epoch 00053: val_loss did not improve from 0.01273\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0051 - mae: 0.0499 - mse: 0.0051 - val_loss: 0.0141 - val_mae: 0.0775 - val_mse: 0.0141\n",
      "Elapsed time during model training:  75.44514060020447\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0487 - mae: 0.1521 - mse: 0.0487\n",
      "Epoch 00001: val_loss improved from inf to 0.02557, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0480,  mae:0.1508,  mse:0.0480,  val_loss:0.0256,  val_mae:0.1158,  val_mse:0.0256,  \n",
      "14926/14926 [==============================] - 2s 139us/sample - loss: 0.0480 - mae: 0.1508 - mse: 0.0480 - val_loss: 0.0256 - val_mae: 0.1158 - val_mse: 0.0256\n",
      "Epoch 2/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0234 - mae: 0.1128 - mse: 0.0234\n",
      "Epoch 00002: val_loss improved from 0.02557 to 0.01923, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0234 - mae: 0.1128 - mse: 0.0234 - val_loss: 0.0192 - val_mae: 0.1030 - val_mse: 0.0192\n",
      "Epoch 3/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0211 - mae: 0.1058 - mse: 0.0211\n",
      "Epoch 00003: val_loss did not improve from 0.01923\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0211 - mae: 0.1058 - mse: 0.0211 - val_loss: 0.0224 - val_mae: 0.1137 - val_mse: 0.0224\n",
      "Epoch 4/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0196 - mae: 0.1014 - mse: 0.0196\n",
      "Epoch 00004: val_loss improved from 0.01923 to 0.01846, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0195 - mae: 0.1009 - mse: 0.0195 - val_loss: 0.0185 - val_mae: 0.1015 - val_mse: 0.0185\n",
      "Epoch 5/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.0991 - mse: 0.0188\n",
      "Epoch 00005: val_loss did not improve from 0.01846\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0188 - mae: 0.0991 - mse: 0.0188 - val_loss: 0.0252 - val_mae: 0.1258 - val_mse: 0.0252\n",
      "Epoch 6/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0184 - mae: 0.0983 - mse: 0.0184\n",
      "Epoch 00006: val_loss improved from 0.01846 to 0.01717, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0183 - mae: 0.0981 - mse: 0.0183 - val_loss: 0.0172 - val_mae: 0.0909 - val_mse: 0.0172\n",
      "Epoch 7/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0173 - mae: 0.0942 - mse: 0.0173\n",
      "Epoch 00007: val_loss improved from 0.01717 to 0.01636, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0172 - mae: 0.0941 - mse: 0.0172 - val_loss: 0.0164 - val_mae: 0.0906 - val_mse: 0.0164\n",
      "Epoch 8/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0166 - mae: 0.0918 - mse: 0.0166\n",
      "Epoch 00008: val_loss did not improve from 0.01636\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0166 - mae: 0.0919 - mse: 0.0166 - val_loss: 0.0164 - val_mae: 0.0899 - val_mse: 0.0164\n",
      "Epoch 9/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0897 - mse: 0.0154\n",
      "Epoch 00009: val_loss did not improve from 0.01636\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0156 - mae: 0.0898 - mse: 0.0156 - val_loss: 0.0208 - val_mae: 0.1118 - val_mse: 0.0208\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0865 - mse: 0.0147\n",
      "Epoch 00010: val_loss did not improve from 0.01636\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0147 - mae: 0.0866 - mse: 0.0147 - val_loss: 0.0171 - val_mae: 0.0977 - val_mse: 0.0171\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0867 - mse: 0.0148\n",
      "Epoch 00011: val_loss improved from 0.01636 to 0.01607, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0148 - mae: 0.0867 - mse: 0.0148 - val_loss: 0.0161 - val_mae: 0.0895 - val_mse: 0.0161\n",
      "Epoch 12/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0857 - mse: 0.0145\n",
      "Epoch 00012: val_loss did not improve from 0.01607\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0145 - mae: 0.0857 - mse: 0.0145 - val_loss: 0.0182 - val_mae: 0.1007 - val_mse: 0.0182\n",
      "Epoch 13/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0863 - mse: 0.0145\n",
      "Epoch 00013: val_loss improved from 0.01607 to 0.01545, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0145 - mae: 0.0862 - mse: 0.0145 - val_loss: 0.0154 - val_mae: 0.0886 - val_mse: 0.0154\n",
      "Epoch 14/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0824 - mse: 0.0135\n",
      "Epoch 00014: val_loss improved from 0.01545 to 0.01394, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0135 - mae: 0.0823 - mse: 0.0135 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 15/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0816 - mse: 0.0133\n",
      "Epoch 00015: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0132 - mae: 0.0815 - mse: 0.0132 - val_loss: 0.0147 - val_mae: 0.0838 - val_mse: 0.0147\n",
      "Epoch 16/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0125 - mae: 0.0789 - mse: 0.0125\n",
      "Epoch 00016: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0125 - mae: 0.0792 - mse: 0.0125 - val_loss: 0.0157 - val_mae: 0.0925 - val_mse: 0.0157\n",
      "Epoch 17/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0803 - mse: 0.0129\n",
      "Epoch 00017: val_loss improved from 0.01394 to 0.01385, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0128 - mae: 0.0802 - mse: 0.0128 - val_loss: 0.0139 - val_mae: 0.0803 - val_mse: 0.0139\n",
      "Epoch 18/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0787 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0123 - mae: 0.0787 - mse: 0.0123 - val_loss: 0.0158 - val_mae: 0.0906 - val_mse: 0.0158\n",
      "Epoch 19/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0775 - mse: 0.0120\n",
      "Epoch 00019: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0121 - mae: 0.0777 - mse: 0.0121 - val_loss: 0.0163 - val_mae: 0.0959 - val_mse: 0.0163\n",
      "Epoch 20/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0754 - mse: 0.0113\n",
      "Epoch 00020: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0113 - mae: 0.0752 - mse: 0.0113 - val_loss: 0.0158 - val_mae: 0.0889 - val_mse: 0.0158\n",
      "Epoch 21/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0758 - mse: 0.0116\n",
      "Epoch 00021: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0116 - mae: 0.0759 - mse: 0.0116 - val_loss: 0.0154 - val_mae: 0.0892 - val_mse: 0.0154\n",
      "Epoch 22/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0728 - mse: 0.0105\n",
      "Epoch 00022: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0108 - mae: 0.0729 - mse: 0.0108 - val_loss: 0.0163 - val_mae: 0.0927 - val_mse: 0.0163\n",
      "Epoch 23/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0115 - mae: 0.0756 - mse: 0.0115\n",
      "Epoch 00023: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0114 - mae: 0.0754 - mse: 0.0114 - val_loss: 0.0151 - val_mae: 0.0874 - val_mse: 0.0151\n",
      "Epoch 24/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0714 - mse: 0.0104\n",
      "Epoch 00024: val_loss did not improve from 0.01385\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0104 - mae: 0.0715 - mse: 0.0104 - val_loss: 0.0147 - val_mae: 0.0837 - val_mse: 0.0147\n",
      "Epoch 25/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0714 - mse: 0.0103\n",
      "Epoch 00025: val_loss improved from 0.01385 to 0.01349, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0102 - mae: 0.0712 - mse: 0.0102 - val_loss: 0.0135 - val_mae: 0.0780 - val_mse: 0.0135\n",
      "Epoch 26/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0709 - mse: 0.0103\n",
      "Epoch 00026: val_loss improved from 0.01349 to 0.01300, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0102 - mae: 0.0707 - mse: 0.0102 - val_loss: 0.0130 - val_mae: 0.0759 - val_mse: 0.0130\n",
      "Epoch 27/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0693 - mse: 0.0098\n",
      "Epoch 00027: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0133 - val_mae: 0.0796 - val_mse: 0.0133\n",
      "Epoch 28/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0701 - mse: 0.0099\n",
      "Epoch 00028: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0099 - mae: 0.0700 - mse: 0.0099 - val_loss: 0.0140 - val_mae: 0.0809 - val_mse: 0.0140\n",
      "Epoch 29/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0688 - mse: 0.0095\n",
      "Epoch 00029: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0095 - mae: 0.0688 - mse: 0.0095 - val_loss: 0.0166 - val_mae: 0.0957 - val_mse: 0.0166\n",
      "Epoch 30/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0694 - mse: 0.0097\n",
      "Epoch 00030: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0098 - mae: 0.0696 - mse: 0.0098 - val_loss: 0.0149 - val_mae: 0.0870 - val_mse: 0.0149\n",
      "Epoch 31/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0668 - mse: 0.0091\n",
      "Epoch 00031: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0091 - mae: 0.0668 - mse: 0.0091 - val_loss: 0.0142 - val_mae: 0.0820 - val_mse: 0.0142\n",
      "Epoch 32/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0671 - mse: 0.0091\n",
      "Epoch 00032: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0091 - mae: 0.0671 - mse: 0.0091 - val_loss: 0.0142 - val_mae: 0.0810 - val_mse: 0.0142\n",
      "Epoch 33/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0655 - mse: 0.0087\n",
      "Epoch 00033: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0087 - mae: 0.0655 - mse: 0.0087 - val_loss: 0.0153 - val_mae: 0.0838 - val_mse: 0.0153\n",
      "Epoch 34/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0667 - mse: 0.0089\n",
      "Epoch 00034: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0089 - mae: 0.0667 - mse: 0.0089 - val_loss: 0.0142 - val_mae: 0.0806 - val_mse: 0.0142\n",
      "Epoch 35/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0645 - mse: 0.0084\n",
      "Epoch 00035: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0084 - mae: 0.0646 - mse: 0.0084 - val_loss: 0.0148 - val_mae: 0.0871 - val_mse: 0.0148\n",
      "Epoch 36/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0655 - mse: 0.0086\n",
      "Epoch 00036: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0086 - mae: 0.0655 - mse: 0.0086 - val_loss: 0.0137 - val_mae: 0.0777 - val_mse: 0.0137\n",
      "Epoch 37/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0630 - mse: 0.0081\n",
      "Epoch 00037: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0081 - mae: 0.0630 - mse: 0.0081 - val_loss: 0.0136 - val_mae: 0.0798 - val_mse: 0.0136\n",
      "Epoch 38/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0630 - mse: 0.0080\n",
      "Epoch 00038: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0080 - mae: 0.0631 - mse: 0.0080 - val_loss: 0.0148 - val_mae: 0.0877 - val_mse: 0.0148\n",
      "Epoch 39/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0081 - mae: 0.0631 - mse: 0.0081\n",
      "Epoch 00039: val_loss did not improve from 0.01300\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0081 - mae: 0.0631 - mse: 0.0081 - val_loss: 0.0132 - val_mae: 0.0767 - val_mse: 0.0132\n",
      "Elapsed time during model training:  55.312903881073\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0466 - mae: 0.1513 - mse: 0.0466\n",
      "Epoch 00001: val_loss improved from inf to 0.02441, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0460,  mae:0.1504,  mse:0.0460,  val_loss:0.0244,  val_mae:0.1129,  val_mse:0.0244,  \n",
      "14926/14926 [==============================] - 2s 140us/sample - loss: 0.0460 - mae: 0.1504 - mse: 0.0460 - val_loss: 0.0244 - val_mae: 0.1129 - val_mse: 0.0244\n",
      "Epoch 2/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0219 - mae: 0.1084 - mse: 0.0219\n",
      "Epoch 00002: val_loss improved from 0.02441 to 0.02193, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0219 - mae: 0.1085 - mse: 0.0219 - val_loss: 0.0219 - val_mae: 0.1105 - val_mse: 0.0219\n",
      "Epoch 3/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0218 - mae: 0.1088 - mse: 0.0218\n",
      "Epoch 00003: val_loss improved from 0.02193 to 0.01966, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0218 - mae: 0.1086 - mse: 0.0218 - val_loss: 0.0197 - val_mae: 0.1042 - val_mse: 0.0197\n",
      "Epoch 4/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0188 - mae: 0.0988 - mse: 0.0188\n",
      "Epoch 00004: val_loss improved from 0.01966 to 0.01945, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0189 - mae: 0.0988 - mse: 0.0189 - val_loss: 0.0194 - val_mae: 0.1034 - val_mse: 0.0194\n",
      "Epoch 5/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0977 - mse: 0.0181\n",
      "Epoch 00005: val_loss did not improve from 0.01945\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0185 - mae: 0.0979 - mse: 0.0185 - val_loss: 0.0318 - val_mae: 0.1439 - val_mse: 0.0318\n",
      "Epoch 6/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0185 - mae: 0.0992 - mse: 0.0185\n",
      "Epoch 00006: val_loss improved from 0.01945 to 0.01725, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0185 - mae: 0.0991 - mse: 0.0185 - val_loss: 0.0173 - val_mae: 0.0976 - val_mse: 0.0173\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0942 - mse: 0.0170\n",
      "Epoch 00007: val_loss did not improve from 0.01725\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0171 - mae: 0.0944 - mse: 0.0171 - val_loss: 0.0175 - val_mae: 0.0956 - val_mse: 0.0175\n",
      "Epoch 8/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0921 - mse: 0.0164\n",
      "Epoch 00008: val_loss did not improve from 0.01725\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0166 - mae: 0.0926 - mse: 0.0166 - val_loss: 0.0195 - val_mae: 0.1040 - val_mse: 0.0195\n",
      "Epoch 9/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0923 - mse: 0.0164\n",
      "Epoch 00009: val_loss did not improve from 0.01725\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0164 - mae: 0.0923 - mse: 0.0164 - val_loss: 0.0196 - val_mae: 0.1020 - val_mse: 0.0196\n",
      "Epoch 10/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0155 - mae: 0.0897 - mse: 0.0155\n",
      "Epoch 00010: val_loss improved from 0.01725 to 0.01681, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0155 - mae: 0.0897 - mse: 0.0155 - val_loss: 0.0168 - val_mae: 0.0920 - val_mse: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0864 - mse: 0.0148\n",
      "Epoch 00011: val_loss did not improve from 0.01681\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0148 - mae: 0.0865 - mse: 0.0148 - val_loss: 0.0168 - val_mae: 0.0914 - val_mse: 0.0168\n",
      "Epoch 12/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0844 - mse: 0.0141\n",
      "Epoch 00012: val_loss improved from 0.01681 to 0.01680, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0140 - mae: 0.0841 - mse: 0.0140 - val_loss: 0.0168 - val_mae: 0.0930 - val_mse: 0.0168\n",
      "Epoch 13/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.0824 - mse: 0.0137\n",
      "Epoch 00013: val_loss did not improve from 0.01680\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0137 - mae: 0.0825 - mse: 0.0137 - val_loss: 0.0214 - val_mae: 0.1049 - val_mse: 0.0214\n",
      "Epoch 14/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0834 - mse: 0.0137\n",
      "Epoch 00014: val_loss improved from 0.01680 to 0.01431, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0137 - mae: 0.0834 - mse: 0.0137 - val_loss: 0.0143 - val_mae: 0.0819 - val_mse: 0.0143\n",
      "Epoch 15/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0824 - mse: 0.0135\n",
      "Epoch 00015: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0135 - mae: 0.0825 - mse: 0.0135 - val_loss: 0.0158 - val_mae: 0.0907 - val_mse: 0.0158\n",
      "Epoch 16/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0127 - mae: 0.0798 - mse: 0.0127\n",
      "Epoch 00016: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0127 - mae: 0.0797 - mse: 0.0127 - val_loss: 0.0146 - val_mae: 0.0831 - val_mse: 0.0146\n",
      "Epoch 17/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0789 - mse: 0.0125\n",
      "Epoch 00017: val_loss improved from 0.01431 to 0.01409, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0125 - mae: 0.0789 - mse: 0.0125 - val_loss: 0.0141 - val_mae: 0.0808 - val_mse: 0.0141\n",
      "Epoch 18/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0784 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01409\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0123 - mae: 0.0784 - mse: 0.0123 - val_loss: 0.0147 - val_mae: 0.0834 - val_mse: 0.0147\n",
      "Epoch 19/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0120 - mae: 0.0775 - mse: 0.0120\n",
      "Epoch 00019: val_loss did not improve from 0.01409\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0120 - mae: 0.0775 - mse: 0.0120 - val_loss: 0.0146 - val_mae: 0.0797 - val_mse: 0.0146\n",
      "Epoch 20/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0754 - mse: 0.0115\n",
      "Epoch 00020: val_loss did not improve from 0.01409\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0115 - mae: 0.0754 - mse: 0.0115 - val_loss: 0.0151 - val_mae: 0.0881 - val_mse: 0.0151\n",
      "Epoch 21/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0760 - mse: 0.0116\n",
      "Epoch 00021: val_loss did not improve from 0.01409\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0116 - mae: 0.0761 - mse: 0.0116 - val_loss: 0.0163 - val_mae: 0.0945 - val_mse: 0.0163\n",
      "Epoch 22/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0745 - mse: 0.0112\n",
      "Epoch 00022: val_loss did not improve from 0.01409\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0112 - mae: 0.0747 - mse: 0.0112 - val_loss: 0.0184 - val_mae: 0.1005 - val_mse: 0.0184\n",
      "Epoch 23/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0726 - mse: 0.0108\n",
      "Epoch 00023: val_loss improved from 0.01409 to 0.01393, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0108 - mae: 0.0726 - mse: 0.0108 - val_loss: 0.0139 - val_mae: 0.0816 - val_mse: 0.0139\n",
      "Epoch 24/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0699 - mse: 0.0101\n",
      "Epoch 00024: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0101 - mae: 0.0700 - mse: 0.0101 - val_loss: 0.0145 - val_mae: 0.0836 - val_mse: 0.0145\n",
      "Epoch 25/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00025: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0105 - mae: 0.0717 - mse: 0.0105 - val_loss: 0.0148 - val_mae: 0.0843 - val_mse: 0.0148\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0693 - mse: 0.0098\n",
      "Epoch 00026: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0154 - val_mae: 0.0820 - val_mse: 0.0154\n",
      "Epoch 27/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0100 - mae: 0.0700 - mse: 0.0100\n",
      "Epoch 00027: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0100 - mae: 0.0699 - mse: 0.0100 - val_loss: 0.0141 - val_mae: 0.0805 - val_mse: 0.0141\n",
      "Epoch 28/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0691 - mse: 0.0100\n",
      "Epoch 00028: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0099 - mae: 0.0689 - mse: 0.0099 - val_loss: 0.0148 - val_mae: 0.0845 - val_mse: 0.0148\n",
      "Epoch 29/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0682 - mse: 0.0095\n",
      "Epoch 00029: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0095 - mae: 0.0682 - mse: 0.0095 - val_loss: 0.0172 - val_mae: 0.0938 - val_mse: 0.0172\n",
      "Epoch 30/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0094 - mae: 0.0675 - mse: 0.0094\n",
      "Epoch 00030: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0093 - mae: 0.0675 - mse: 0.0093 - val_loss: 0.0147 - val_mae: 0.0844 - val_mse: 0.0147\n",
      "Epoch 31/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0090 - mae: 0.0667 - mse: 0.0090\n",
      "Epoch 00031: val_loss improved from 0.01393 to 0.01375, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0090 - mae: 0.0669 - mse: 0.0090 - val_loss: 0.0137 - val_mae: 0.0798 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0660 - mse: 0.0091\n",
      "Epoch 00032: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0091 - mae: 0.0661 - mse: 0.0091 - val_loss: 0.0145 - val_mae: 0.0836 - val_mse: 0.0145\n",
      "Epoch 33/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0650 - mse: 0.0087\n",
      "Epoch 00033: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0087 - mae: 0.0651 - mse: 0.0087 - val_loss: 0.0156 - val_mae: 0.0862 - val_mse: 0.0156\n",
      "Epoch 34/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0087 - mae: 0.0652 - mse: 0.0087\n",
      "Epoch 00034: val_loss did not improve from 0.01375\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0086 - mae: 0.0651 - mse: 0.0086 - val_loss: 0.0141 - val_mae: 0.0800 - val_mse: 0.0141\n",
      "Epoch 35/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0637 - mse: 0.0083\n",
      "Epoch 00035: val_loss improved from 0.01375 to 0.01303, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0083 - mae: 0.0636 - mse: 0.0083 - val_loss: 0.0130 - val_mae: 0.0786 - val_mse: 0.0130\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0638 - mse: 0.0083\n",
      "Epoch 00036: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0083 - mae: 0.0638 - mse: 0.0083 - val_loss: 0.0137 - val_mae: 0.0778 - val_mse: 0.0137\n",
      "Epoch 37/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0625 - mse: 0.0082\n",
      "Epoch 00037: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 2s 126us/sample - loss: 0.0081 - mae: 0.0623 - mse: 0.0081 - val_loss: 0.0148 - val_mae: 0.0855 - val_mse: 0.0148\n",
      "Epoch 38/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0617 - mse: 0.0077\n",
      "Epoch 00038: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0077 - mae: 0.0617 - mse: 0.0077 - val_loss: 0.0137 - val_mae: 0.0792 - val_mse: 0.0137\n",
      "Epoch 39/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0621 - mse: 0.0080\n",
      "Epoch 00039: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0079 - mae: 0.0619 - mse: 0.0079 - val_loss: 0.0162 - val_mae: 0.0835 - val_mse: 0.0162\n",
      "Epoch 40/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0078 - mae: 0.0620 - mse: 0.0078\n",
      "Epoch 00040: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0078 - mae: 0.0621 - mse: 0.0078 - val_loss: 0.0152 - val_mae: 0.0843 - val_mse: 0.0152\n",
      "Epoch 41/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0595 - mse: 0.0074\n",
      "Epoch 00041: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0074 - mae: 0.0595 - mse: 0.0074 - val_loss: 0.0144 - val_mae: 0.0799 - val_mse: 0.0144\n",
      "Epoch 42/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0597 - mse: 0.0074\n",
      "Epoch 00042: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0073 - mae: 0.0597 - mse: 0.0073 - val_loss: 0.0135 - val_mae: 0.0777 - val_mse: 0.0135\n",
      "Epoch 43/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0571 - mse: 0.0068\n",
      "Epoch 00043: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0068 - mae: 0.0573 - mse: 0.0068 - val_loss: 0.0148 - val_mae: 0.0872 - val_mse: 0.0148\n",
      "Epoch 44/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0592 - mse: 0.0071\n",
      "Epoch 00044: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0132 - val_mae: 0.0769 - val_mse: 0.0132\n",
      "Epoch 45/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0588 - mse: 0.0070\n",
      "Epoch 00045: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0070 - mae: 0.0586 - mse: 0.0070 - val_loss: 0.0137 - val_mae: 0.0780 - val_mse: 0.0137\n",
      "Epoch 46/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0582 - mse: 0.0068\n",
      "Epoch 00046: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0068 - mae: 0.0583 - mse: 0.0068 - val_loss: 0.0138 - val_mae: 0.0800 - val_mse: 0.0138\n",
      "Epoch 47/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0602 - mse: 0.0074\n",
      "Epoch 00047: val_loss did not improve from 0.01303\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0074 - mae: 0.0602 - mse: 0.0074 - val_loss: 0.0134 - val_mae: 0.0803 - val_mse: 0.0134\n",
      "Elapsed time during model training:  68.4038610458374\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0432 - mae: 0.1471 - mse: 0.0432\n",
      "Epoch 00001: val_loss improved from inf to 0.03225, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0426,  mae:0.1460,  mse:0.0426,  val_loss:0.0323,  val_mae:0.1335,  val_mse:0.0323,  \n",
      "14926/14926 [==============================] - 2s 139us/sample - loss: 0.0426 - mae: 0.1460 - mse: 0.0426 - val_loss: 0.0323 - val_mae: 0.1335 - val_mse: 0.0323\n",
      "Epoch 2/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0240 - mae: 0.1134 - mse: 0.0240\n",
      "Epoch 00002: val_loss improved from 0.03225 to 0.02235, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0240 - mae: 0.1135 - mse: 0.0240 - val_loss: 0.0223 - val_mae: 0.1175 - val_mse: 0.0223\n",
      "Epoch 3/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0203 - mae: 0.1032 - mse: 0.0203\n",
      "Epoch 00003: val_loss improved from 0.02235 to 0.01983, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0203 - mae: 0.1031 - mse: 0.0203 - val_loss: 0.0198 - val_mae: 0.1024 - val_mse: 0.0198\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0205 - mae: 0.1046 - mse: 0.0205\n",
      "Epoch 00004: val_loss improved from 0.01983 to 0.01776, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0204 - mae: 0.1043 - mse: 0.0204 - val_loss: 0.0178 - val_mae: 0.0966 - val_mse: 0.0178\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1003 - mse: 0.0191\n",
      "Epoch 00005: val_loss did not improve from 0.01776\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0190 - mae: 0.1000 - mse: 0.0190 - val_loss: 0.0308 - val_mae: 0.1318 - val_mse: 0.0308\n",
      "Epoch 6/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0180 - mae: 0.0967 - mse: 0.0180\n",
      "Epoch 00006: val_loss did not improve from 0.01776\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0180 - mae: 0.0968 - mse: 0.0180 - val_loss: 0.0180 - val_mae: 0.0985 - val_mse: 0.0180\n",
      "Epoch 7/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0171 - mae: 0.0939 - mse: 0.0171\n",
      "Epoch 00007: val_loss did not improve from 0.01776\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0170 - mae: 0.0937 - mse: 0.0170 - val_loss: 0.0178 - val_mae: 0.0953 - val_mse: 0.0178\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0894 - mse: 0.0158\n",
      "Epoch 00008: val_loss improved from 0.01776 to 0.01614, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0158 - mae: 0.0893 - mse: 0.0158 - val_loss: 0.0161 - val_mae: 0.0895 - val_mse: 0.0161\n",
      "Epoch 9/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0160 - mae: 0.0914 - mse: 0.0160\n",
      "Epoch 00009: val_loss did not improve from 0.01614\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0163 - mae: 0.0914 - mse: 0.0163 - val_loss: 0.0181 - val_mae: 0.1018 - val_mse: 0.0181\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0880 - mse: 0.0151\n",
      "Epoch 00010: val_loss did not improve from 0.01614\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0151 - mae: 0.0880 - mse: 0.0151 - val_loss: 0.0198 - val_mae: 0.1037 - val_mse: 0.0198\n",
      "Epoch 11/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0877 - mse: 0.0150\n",
      "Epoch 00011: val_loss did not improve from 0.01614\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0150 - mae: 0.0877 - mse: 0.0150 - val_loss: 0.0165 - val_mae: 0.0870 - val_mse: 0.0165\n",
      "Epoch 12/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0844 - mse: 0.0142\n",
      "Epoch 00012: val_loss did not improve from 0.01614\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0142 - mae: 0.0846 - mse: 0.0142 - val_loss: 0.0176 - val_mae: 0.0929 - val_mse: 0.0176\n",
      "Epoch 13/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0856 - mse: 0.0144\n",
      "Epoch 00013: val_loss improved from 0.01614 to 0.01600, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0143 - mae: 0.0855 - mse: 0.0143 - val_loss: 0.0160 - val_mae: 0.0906 - val_mse: 0.0160\n",
      "Epoch 14/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.0830 - mse: 0.0137\n",
      "Epoch 00014: val_loss improved from 0.01600 to 0.01510, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0138 - mae: 0.0833 - mse: 0.0138 - val_loss: 0.0151 - val_mae: 0.0873 - val_mse: 0.0151\n",
      "Epoch 15/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0793 - mse: 0.0127\n",
      "Epoch 00015: val_loss did not improve from 0.01510\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0127 - mae: 0.0794 - mse: 0.0127 - val_loss: 0.0163 - val_mae: 0.0914 - val_mse: 0.0163\n",
      "Epoch 16/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0808 - mse: 0.0129\n",
      "Epoch 00016: val_loss did not improve from 0.01510\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0129 - mae: 0.0808 - mse: 0.0129 - val_loss: 0.0152 - val_mae: 0.0855 - val_mse: 0.0152\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0806 - mse: 0.0128\n",
      "Epoch 00017: val_loss did not improve from 0.01510\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0128 - mae: 0.0805 - mse: 0.0128 - val_loss: 0.0156 - val_mae: 0.0893 - val_mse: 0.0156\n",
      "Epoch 18/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0767 - mse: 0.0119\n",
      "Epoch 00018: val_loss improved from 0.01510 to 0.01501, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0119 - mae: 0.0767 - mse: 0.0119 - val_loss: 0.0150 - val_mae: 0.0828 - val_mse: 0.0150\n",
      "Epoch 19/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0119 - mae: 0.0772 - mse: 0.0119\n",
      "Epoch 00019: val_loss did not improve from 0.01501\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0119 - mae: 0.0776 - mse: 0.0119 - val_loss: 0.0196 - val_mae: 0.1036 - val_mse: 0.0196\n",
      "Epoch 20/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0771 - mse: 0.0118\n",
      "Epoch 00020: val_loss improved from 0.01501 to 0.01426, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0118 - mae: 0.0770 - mse: 0.0118 - val_loss: 0.0143 - val_mae: 0.0820 - val_mse: 0.0143\n",
      "Epoch 21/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0114 - mae: 0.0753 - mse: 0.0114\n",
      "Epoch 00021: val_loss did not improve from 0.01426\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0113 - mae: 0.0752 - mse: 0.0113 - val_loss: 0.0148 - val_mae: 0.0839 - val_mse: 0.0148\n",
      "Epoch 22/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0741 - mse: 0.0111\n",
      "Epoch 00022: val_loss improved from 0.01426 to 0.01376, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0111 - mae: 0.0741 - mse: 0.0111 - val_loss: 0.0138 - val_mae: 0.0808 - val_mse: 0.0138\n",
      "Epoch 23/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0731 - mse: 0.0108\n",
      "Epoch 00023: val_loss improved from 0.01376 to 0.01364, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0107 - mae: 0.0731 - mse: 0.0107 - val_loss: 0.0136 - val_mae: 0.0784 - val_mse: 0.0136\n",
      "Epoch 24/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0714 - mse: 0.0103\n",
      "Epoch 00024: val_loss did not improve from 0.01364\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0103 - mae: 0.0715 - mse: 0.0103 - val_loss: 0.0165 - val_mae: 0.0949 - val_mse: 0.0165\n",
      "Epoch 25/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0726 - mse: 0.0105\n",
      "Epoch 00025: val_loss did not improve from 0.01364\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0105 - mae: 0.0727 - mse: 0.0105 - val_loss: 0.0140 - val_mae: 0.0807 - val_mse: 0.0140\n",
      "Epoch 26/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0099 - mae: 0.0696 - mse: 0.0099\n",
      "Epoch 00026: val_loss did not improve from 0.01364\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0099 - mae: 0.0700 - mse: 0.0099 - val_loss: 0.0149 - val_mae: 0.0859 - val_mse: 0.0149\n",
      "Epoch 27/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0706 - mse: 0.0099\n",
      "Epoch 00027: val_loss did not improve from 0.01364\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0099 - mae: 0.0706 - mse: 0.0099 - val_loss: 0.0163 - val_mae: 0.0852 - val_mse: 0.0163\n",
      "Epoch 28/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0706 - mse: 0.0101\n",
      "Epoch 00028: val_loss improved from 0.01364 to 0.01335, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0706 - mse: 0.0101 - val_loss: 0.0134 - val_mae: 0.0787 - val_mse: 0.0134\n",
      "Epoch 29/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0666 - mse: 0.0092\n",
      "Epoch 00029: val_loss did not improve from 0.01335\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0091 - mae: 0.0667 - mse: 0.0091 - val_loss: 0.0155 - val_mae: 0.0871 - val_mse: 0.0155\n",
      "Epoch 30/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0671 - mse: 0.0090\n",
      "Epoch 00030: val_loss did not improve from 0.01335\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0090 - mae: 0.0671 - mse: 0.0090 - val_loss: 0.0144 - val_mae: 0.0791 - val_mse: 0.0144\n",
      "Epoch 31/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0685 - mse: 0.0093\n",
      "Epoch 00031: val_loss did not improve from 0.01335\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0093 - mae: 0.0685 - mse: 0.0093 - val_loss: 0.0140 - val_mae: 0.0803 - val_mse: 0.0140\n",
      "Epoch 32/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0665 - mse: 0.0089\n",
      "Epoch 00032: val_loss did not improve from 0.01335\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0135 - val_mae: 0.0794 - val_mse: 0.0135\n",
      "Epoch 33/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00033: val_loss improved from 0.01335 to 0.01322, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0092 - mae: 0.0675 - mse: 0.0092 - val_loss: 0.0132 - val_mae: 0.0768 - val_mse: 0.0132\n",
      "Epoch 34/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0640 - mse: 0.0081\n",
      "Epoch 00034: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0084 - mae: 0.0643 - mse: 0.0084 - val_loss: 0.0144 - val_mae: 0.0875 - val_mse: 0.0144\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0632 - mse: 0.0081\n",
      "Epoch 00035: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0080 - mae: 0.0632 - mse: 0.0080 - val_loss: 0.0144 - val_mae: 0.0835 - val_mse: 0.0144\n",
      "Epoch 36/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0642 - mse: 0.0083\n",
      "Epoch 00036: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0083 - mae: 0.0642 - mse: 0.0083 - val_loss: 0.0136 - val_mae: 0.0775 - val_mse: 0.0136\n",
      "Epoch 37/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0629 - mse: 0.0080\n",
      "Epoch 00037: val_loss did not improve from 0.01322\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0080 - mae: 0.0629 - mse: 0.0080 - val_loss: 0.0137 - val_mae: 0.0807 - val_mse: 0.0137\n",
      "Epoch 38/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0622 - mse: 0.0078\n",
      "Epoch 00038: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0079 - mae: 0.0625 - mse: 0.0079 - val_loss: 0.0147 - val_mae: 0.0849 - val_mse: 0.0147\n",
      "Epoch 39/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0610 - mse: 0.0074\n",
      "Epoch 00039: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0074 - mae: 0.0611 - mse: 0.0074 - val_loss: 0.0144 - val_mae: 0.0820 - val_mse: 0.0144\n",
      "Epoch 40/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0607 - mse: 0.0076\n",
      "Epoch 00040: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0076 - mae: 0.0609 - mse: 0.0076 - val_loss: 0.0138 - val_mae: 0.0826 - val_mse: 0.0138\n",
      "Epoch 41/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0624 - mse: 0.0077\n",
      "Epoch 00041: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0077 - mae: 0.0626 - mse: 0.0077 - val_loss: 0.0154 - val_mae: 0.0842 - val_mse: 0.0154\n",
      "Epoch 42/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0592 - mse: 0.0071\n",
      "Epoch 00042: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0071 - mae: 0.0592 - mse: 0.0071 - val_loss: 0.0156 - val_mae: 0.0843 - val_mse: 0.0156\n",
      "Epoch 43/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0603 - mse: 0.0073\n",
      "Epoch 00043: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0073 - mae: 0.0605 - mse: 0.0073 - val_loss: 0.0152 - val_mae: 0.0852 - val_mse: 0.0152\n",
      "Epoch 44/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0073 - mae: 0.0604 - mse: 0.0073\n",
      "Epoch 00044: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0073 - mae: 0.0606 - mse: 0.0073 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 45/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0598 - mse: 0.0071\n",
      "Epoch 00045: val_loss did not improve from 0.01322\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0071 - mae: 0.0598 - mse: 0.0071 - val_loss: 0.0153 - val_mae: 0.0812 - val_mse: 0.0153\n",
      "Elapsed time during model training:  66.23178052902222\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0455 - mae: 0.1451 - mse: 0.0455\n",
      "Epoch 00001: val_loss improved from inf to 0.02286, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0453,  mae:0.1447,  mse:0.0453,  val_loss:0.0229,  val_mae:0.1105,  val_mse:0.0229,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0453 - mae: 0.1447 - mse: 0.0453 - val_loss: 0.0229 - val_mae: 0.1105 - val_mse: 0.0229\n",
      "Epoch 2/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0218 - mae: 0.1079 - mse: 0.0218\n",
      "Epoch 00002: val_loss did not improve from 0.02286\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0221 - mae: 0.1079 - mse: 0.0221 - val_loss: 0.0301 - val_mae: 0.1354 - val_mse: 0.0301\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0196 - mae: 0.1022 - mse: 0.0196\n",
      "Epoch 00003: val_loss improved from 0.02286 to 0.02073, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0197 - mae: 0.1022 - mse: 0.0197 - val_loss: 0.0207 - val_mae: 0.0979 - val_mse: 0.0207\n",
      "Epoch 4/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0983 - mse: 0.0184\n",
      "Epoch 00004: val_loss improved from 0.02073 to 0.01839, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0185 - mae: 0.0985 - mse: 0.0185 - val_loss: 0.0184 - val_mae: 0.0953 - val_mse: 0.0184\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0949 - mse: 0.0174\n",
      "Epoch 00005: val_loss improved from 0.01839 to 0.01667, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0175 - mae: 0.0950 - mse: 0.0175 - val_loss: 0.0167 - val_mae: 0.0902 - val_mse: 0.0167\n",
      "Epoch 6/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0169 - mae: 0.0932 - mse: 0.0169\n",
      "Epoch 00006: val_loss did not improve from 0.01667\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0169 - mae: 0.0933 - mse: 0.0169 - val_loss: 0.0171 - val_mae: 0.0934 - val_mse: 0.0171\n",
      "Epoch 7/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0920 - mse: 0.0167\n",
      "Epoch 00007: val_loss did not improve from 0.01667\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0166 - mae: 0.0921 - mse: 0.0166 - val_loss: 0.0225 - val_mae: 0.1116 - val_mse: 0.0225\n",
      "Epoch 8/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0867 - mse: 0.0149\n",
      "Epoch 00008: val_loss improved from 0.01667 to 0.01649, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0149 - mae: 0.0864 - mse: 0.0149 - val_loss: 0.0165 - val_mae: 0.0867 - val_mse: 0.0165\n",
      "Epoch 9/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0835 - mse: 0.0142\n",
      "Epoch 00009: val_loss did not improve from 0.01649\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0142 - mae: 0.0836 - mse: 0.0142 - val_loss: 0.0188 - val_mae: 0.1059 - val_mse: 0.0188\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0844 - mse: 0.0142\n",
      "Epoch 00010: val_loss improved from 0.01649 to 0.01635, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0142 - mae: 0.0844 - mse: 0.0142 - val_loss: 0.0164 - val_mae: 0.0891 - val_mse: 0.0164\n",
      "Epoch 11/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0835 - mse: 0.0137\n",
      "Epoch 00011: val_loss improved from 0.01635 to 0.01452, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0137 - mae: 0.0834 - mse: 0.0137 - val_loss: 0.0145 - val_mae: 0.0813 - val_mse: 0.0145\n",
      "Epoch 12/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0823 - mse: 0.0135\n",
      "Epoch 00012: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0135 - mae: 0.0825 - mse: 0.0135 - val_loss: 0.0172 - val_mae: 0.0912 - val_mse: 0.0172\n",
      "Epoch 13/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0817 - mse: 0.0133\n",
      "Epoch 00013: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0134 - mae: 0.0819 - mse: 0.0134 - val_loss: 0.0166 - val_mae: 0.0921 - val_mse: 0.0166\n",
      "Epoch 14/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0781 - mse: 0.0123\n",
      "Epoch 00014: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0123 - mae: 0.0780 - mse: 0.0123 - val_loss: 0.0153 - val_mae: 0.0865 - val_mse: 0.0153\n",
      "Epoch 15/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0772 - mse: 0.0121\n",
      "Epoch 00015: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0121 - mae: 0.0772 - mse: 0.0121 - val_loss: 0.0151 - val_mae: 0.0830 - val_mse: 0.0151\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0762 - mse: 0.0117\n",
      "Epoch 00016: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0152 - val_mae: 0.0862 - val_mse: 0.0152\n",
      "Epoch 17/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0112 - mae: 0.0755 - mse: 0.0112\n",
      "Epoch 00017: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0116 - mae: 0.0759 - mse: 0.0116 - val_loss: 0.0187 - val_mae: 0.1051 - val_mse: 0.0187\n",
      "Epoch 18/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0758 - mse: 0.0115\n",
      "Epoch 00018: val_loss did not improve from 0.01452\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0115 - mae: 0.0759 - mse: 0.0115 - val_loss: 0.0152 - val_mae: 0.0883 - val_mse: 0.0152\n",
      "Epoch 19/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0109 - mae: 0.0734 - mse: 0.0109\n",
      "Epoch 00019: val_loss improved from 0.01452 to 0.01396, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0109 - mae: 0.0733 - mse: 0.0109 - val_loss: 0.0140 - val_mae: 0.0798 - val_mse: 0.0140\n",
      "Epoch 20/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0720 - mse: 0.0104\n",
      "Epoch 00020: val_loss did not improve from 0.01396\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0104 - mae: 0.0720 - mse: 0.0104 - val_loss: 0.0177 - val_mae: 0.0928 - val_mse: 0.0177\n",
      "Epoch 21/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0692 - mse: 0.0099\n",
      "Epoch 00021: val_loss did not improve from 0.01396\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0100 - mae: 0.0693 - mse: 0.0100 - val_loss: 0.0148 - val_mae: 0.0865 - val_mse: 0.0148\n",
      "Epoch 22/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0711 - mse: 0.0102\n",
      "Epoch 00022: val_loss improved from 0.01396 to 0.01394, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0102 - mae: 0.0710 - mse: 0.0102 - val_loss: 0.0139 - val_mae: 0.0819 - val_mse: 0.0139\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0097 - mae: 0.0693 - mse: 0.0097\n",
      "Epoch 00023: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0097 - mae: 0.0696 - mse: 0.0097 - val_loss: 0.0141 - val_mae: 0.0806 - val_mse: 0.0141\n",
      "Epoch 24/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0683 - mse: 0.0096\n",
      "Epoch 00024: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0096 - mae: 0.0686 - mse: 0.0096 - val_loss: 0.0177 - val_mae: 0.0959 - val_mse: 0.0177\n",
      "Epoch 25/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0683 - mse: 0.0095\n",
      "Epoch 00025: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0095 - mae: 0.0684 - mse: 0.0095 - val_loss: 0.0164 - val_mae: 0.0909 - val_mse: 0.0164\n",
      "Epoch 26/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0668 - mse: 0.0090\n",
      "Epoch 00026: val_loss improved from 0.01394 to 0.01390, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0090 - mae: 0.0668 - mse: 0.0090 - val_loss: 0.0139 - val_mae: 0.0784 - val_mse: 0.0139\n",
      "Epoch 27/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0659 - mse: 0.0089\n",
      "Epoch 00027: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0090 - mae: 0.0660 - mse: 0.0090 - val_loss: 0.0160 - val_mae: 0.0870 - val_mse: 0.0160\n",
      "Epoch 28/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0658 - mse: 0.0087\n",
      "Epoch 00028: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0087 - mae: 0.0658 - mse: 0.0087 - val_loss: 0.0148 - val_mae: 0.0820 - val_mse: 0.0148\n",
      "Epoch 29/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0645 - mse: 0.0085\n",
      "Epoch 00029: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0086 - mae: 0.0646 - mse: 0.0086 - val_loss: 0.0160 - val_mae: 0.0858 - val_mse: 0.0160\n",
      "Epoch 30/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0644 - mse: 0.0087\n",
      "Epoch 00030: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0087 - mae: 0.0645 - mse: 0.0087 - val_loss: 0.0147 - val_mae: 0.0873 - val_mse: 0.0147\n",
      "Epoch 31/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0605 - mse: 0.0077\n",
      "Epoch 00031: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0077 - mae: 0.0605 - mse: 0.0077 - val_loss: 0.0139 - val_mae: 0.0798 - val_mse: 0.0139\n",
      "Epoch 32/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0636 - mse: 0.0082\n",
      "Epoch 00032: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0082 - mae: 0.0634 - mse: 0.0082 - val_loss: 0.0142 - val_mae: 0.0805 - val_mse: 0.0142\n",
      "Epoch 33/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0608 - mse: 0.0076\n",
      "Epoch 00033: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0076 - mae: 0.0610 - mse: 0.0076 - val_loss: 0.0144 - val_mae: 0.0812 - val_mse: 0.0144\n",
      "Epoch 34/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0600 - mse: 0.0073\n",
      "Epoch 00034: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0073 - mae: 0.0599 - mse: 0.0073 - val_loss: 0.0146 - val_mae: 0.0799 - val_mse: 0.0146\n",
      "Epoch 35/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0599 - mse: 0.0073\n",
      "Epoch 00035: val_loss improved from 0.01390 to 0.01334, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0073 - mae: 0.0599 - mse: 0.0073 - val_loss: 0.0133 - val_mae: 0.0769 - val_mse: 0.0133\n",
      "Epoch 36/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0074 - mae: 0.0600 - mse: 0.0074\n",
      "Epoch 00036: val_loss improved from 0.01334 to 0.01274, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0074 - mae: 0.0598 - mse: 0.0074 - val_loss: 0.0127 - val_mae: 0.0744 - val_mse: 0.0127\n",
      "Epoch 37/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0572 - mse: 0.0069\n",
      "Epoch 00037: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0069 - mae: 0.0571 - mse: 0.0069 - val_loss: 0.0143 - val_mae: 0.0820 - val_mse: 0.0143\n",
      "Epoch 38/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0564 - mse: 0.0066\n",
      "Epoch 00038: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0066 - mae: 0.0565 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0790 - val_mse: 0.0134\n",
      "Epoch 39/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0575 - mse: 0.0067\n",
      "Epoch 00039: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0066 - mae: 0.0574 - mse: 0.0066 - val_loss: 0.0134 - val_mae: 0.0763 - val_mse: 0.0134\n",
      "Epoch 40/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0557 - mse: 0.0063\n",
      "Epoch 00040: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0063 - mae: 0.0558 - mse: 0.0063 - val_loss: 0.0161 - val_mae: 0.0913 - val_mse: 0.0161\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0556 - mse: 0.0064\n",
      "Epoch 00041: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0063 - mae: 0.0555 - mse: 0.0063 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 42/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0064 - mae: 0.0556 - mse: 0.0064\n",
      "Epoch 00042: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0064 - mae: 0.0556 - mse: 0.0064 - val_loss: 0.0149 - val_mae: 0.0797 - val_mse: 0.0149\n",
      "Epoch 43/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0549 - mse: 0.0062\n",
      "Epoch 00043: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0061 - mae: 0.0549 - mse: 0.0061 - val_loss: 0.0134 - val_mae: 0.0758 - val_mse: 0.0134\n",
      "Epoch 44/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0536 - mse: 0.0060\n",
      "Epoch 00044: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0060 - mae: 0.0536 - mse: 0.0060 - val_loss: 0.0148 - val_mae: 0.0831 - val_mse: 0.0148\n",
      "Epoch 45/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0534 - mse: 0.0059\n",
      "Epoch 00045: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0059 - mae: 0.0532 - mse: 0.0059 - val_loss: 0.0140 - val_mae: 0.0768 - val_mse: 0.0140\n",
      "Epoch 46/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0534 - mse: 0.0059\n",
      "Epoch 00046: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0059 - mae: 0.0534 - mse: 0.0059 - val_loss: 0.0148 - val_mae: 0.0809 - val_mse: 0.0148\n",
      "Epoch 47/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0540 - mse: 0.0062\n",
      "Epoch 00047: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0062 - mae: 0.0541 - mse: 0.0062 - val_loss: 0.0145 - val_mae: 0.0825 - val_mse: 0.0145\n",
      "Epoch 48/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0523 - mse: 0.0056\n",
      "Epoch 00048: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0056 - mae: 0.0523 - mse: 0.0056 - val_loss: 0.0133 - val_mae: 0.0767 - val_mse: 0.0133\n",
      "Epoch 49/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0050 - mae: 0.0495 - mse: 0.0050\n",
      "Epoch 00049: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0051 - mae: 0.0497 - mse: 0.0051 - val_loss: 0.0146 - val_mae: 0.0796 - val_mse: 0.0146\n",
      "Epoch 50/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0500 - mse: 0.0052\n",
      "Epoch 00050: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0051 - mae: 0.0500 - mse: 0.0051 - val_loss: 0.0150 - val_mae: 0.0807 - val_mse: 0.0150\n",
      "Epoch 51/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0508 - mse: 0.0054\n",
      "Epoch 00051: val_loss did not improve from 0.01274\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0053 - mae: 0.0507 - mse: 0.0053 - val_loss: 0.0135 - val_mae: 0.0761 - val_mse: 0.0135\n",
      "Elapsed time during model training:  74.87120032310486\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0461 - mae: 0.1511 - mse: 0.0461\n",
      "Epoch 00001: val_loss improved from inf to 0.02061, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0461,  mae:0.1510,  mse:0.0461,  val_loss:0.0206,  val_mae:0.1039,  val_mse:0.0206,  \n",
      "14926/14926 [==============================] - 2s 144us/sample - loss: 0.0461 - mae: 0.1510 - mse: 0.0461 - val_loss: 0.0206 - val_mae: 0.1039 - val_mse: 0.0206\n",
      "Epoch 2/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0220 - mae: 0.1088 - mse: 0.0220\n",
      "Epoch 00002: val_loss improved from 0.02061 to 0.01944, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0219 - mae: 0.1086 - mse: 0.0219 - val_loss: 0.0194 - val_mae: 0.1054 - val_mse: 0.0194\n",
      "Epoch 3/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0212 - mae: 0.1064 - mse: 0.0212\n",
      "Epoch 00003: val_loss did not improve from 0.01944\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0213 - mae: 0.1064 - mse: 0.0213 - val_loss: 0.0225 - val_mae: 0.1173 - val_mse: 0.0225\n",
      "Epoch 4/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0186 - mae: 0.0981 - mse: 0.0186\n",
      "Epoch 00004: val_loss improved from 0.01944 to 0.01870, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0185 - mae: 0.0979 - mse: 0.0185 - val_loss: 0.0187 - val_mae: 0.0993 - val_mse: 0.0187\n",
      "Epoch 5/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0967 - mse: 0.0181\n",
      "Epoch 00005: val_loss improved from 0.01870 to 0.01860, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 125us/sample - loss: 0.0180 - mae: 0.0965 - mse: 0.0180 - val_loss: 0.0186 - val_mae: 0.0993 - val_mse: 0.0186\n",
      "Epoch 6/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0175 - mae: 0.0956 - mse: 0.0175\n",
      "Epoch 00006: val_loss did not improve from 0.01860\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0175 - mae: 0.0953 - mse: 0.0175 - val_loss: 0.0189 - val_mae: 0.1047 - val_mse: 0.0189\n",
      "Epoch 7/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0163 - mae: 0.0915 - mse: 0.0163\n",
      "Epoch 00007: val_loss improved from 0.01860 to 0.01560, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0163 - mae: 0.0913 - mse: 0.0163 - val_loss: 0.0156 - val_mae: 0.0878 - val_mse: 0.0156\n",
      "Epoch 8/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0161 - mae: 0.0916 - mse: 0.0161\n",
      "Epoch 00008: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0163 - mae: 0.0922 - mse: 0.0163 - val_loss: 0.0197 - val_mae: 0.1057 - val_mse: 0.0197\n",
      "Epoch 9/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0159 - mae: 0.0904 - mse: 0.0159\n",
      "Epoch 00009: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0159 - mae: 0.0901 - mse: 0.0159 - val_loss: 0.0170 - val_mae: 0.0949 - val_mse: 0.0170\n",
      "Epoch 10/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0861 - mse: 0.0145\n",
      "Epoch 00010: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0146 - mae: 0.0863 - mse: 0.0146 - val_loss: 0.0207 - val_mae: 0.1116 - val_mse: 0.0207\n",
      "Epoch 11/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0852 - mse: 0.0141\n",
      "Epoch 00011: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0144 - mae: 0.0853 - mse: 0.0144 - val_loss: 0.0190 - val_mae: 0.1066 - val_mse: 0.0190\n",
      "Epoch 12/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0840 - mse: 0.0139\n",
      "Epoch 00012: val_loss improved from 0.01560 to 0.01428, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0139 - mae: 0.0839 - mse: 0.0139 - val_loss: 0.0143 - val_mae: 0.0807 - val_mse: 0.0143\n",
      "Epoch 13/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0832 - mse: 0.0135\n",
      "Epoch 00013: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0136 - mae: 0.0834 - mse: 0.0136 - val_loss: 0.0160 - val_mae: 0.0895 - val_mse: 0.0160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0795 - mse: 0.0127\n",
      "Epoch 00014: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0128 - mae: 0.0798 - mse: 0.0128 - val_loss: 0.0199 - val_mae: 0.1124 - val_mse: 0.0199\n",
      "Epoch 15/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0129 - mae: 0.0806 - mse: 0.0129\n",
      "Epoch 00015: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0129 - mae: 0.0805 - mse: 0.0129 - val_loss: 0.0166 - val_mae: 0.0926 - val_mse: 0.0166\n",
      "Epoch 16/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0786 - mse: 0.0125\n",
      "Epoch 00016: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0124 - mae: 0.0786 - mse: 0.0124 - val_loss: 0.0162 - val_mae: 0.0910 - val_mse: 0.0162\n",
      "Epoch 17/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0760 - mse: 0.0116\n",
      "Epoch 00017: val_loss did not improve from 0.01428\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0116 - mae: 0.0759 - mse: 0.0116 - val_loss: 0.0149 - val_mae: 0.0869 - val_mse: 0.0149\n",
      "Epoch 18/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0782 - mse: 0.0120\n",
      "Epoch 00018: val_loss improved from 0.01428 to 0.01382, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0120 - mae: 0.0782 - mse: 0.0120 - val_loss: 0.0138 - val_mae: 0.0804 - val_mse: 0.0138\n",
      "Epoch 19/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0756 - mse: 0.0115\n",
      "Epoch 00019: val_loss did not improve from 0.01382\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0114 - mae: 0.0756 - mse: 0.0114 - val_loss: 0.0154 - val_mae: 0.0903 - val_mse: 0.0154\n",
      "Epoch 20/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0750 - mse: 0.0114\n",
      "Epoch 00020: val_loss did not improve from 0.01382\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0113 - mae: 0.0747 - mse: 0.0113 - val_loss: 0.0154 - val_mae: 0.0864 - val_mse: 0.0154\n",
      "Epoch 21/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0733 - mse: 0.0108\n",
      "Epoch 00021: val_loss did not improve from 0.01382\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0108 - mae: 0.0732 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0823 - val_mse: 0.0141\n",
      "Epoch 22/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0102 - mae: 0.0709 - mse: 0.0102\n",
      "Epoch 00022: val_loss did not improve from 0.01382\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0102 - mae: 0.0708 - mse: 0.0102 - val_loss: 0.0140 - val_mae: 0.0803 - val_mse: 0.0140\n",
      "Epoch 23/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0698 - mse: 0.0099\n",
      "Epoch 00023: val_loss improved from 0.01382 to 0.01350, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0099 - mae: 0.0697 - mse: 0.0099 - val_loss: 0.0135 - val_mae: 0.0781 - val_mse: 0.0135\n",
      "Epoch 24/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0713 - mse: 0.0101\n",
      "Epoch 00024: val_loss did not improve from 0.01350\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0101 - mae: 0.0714 - mse: 0.0101 - val_loss: 0.0161 - val_mae: 0.0890 - val_mse: 0.0161\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0684 - mse: 0.0097\n",
      "Epoch 00025: val_loss did not improve from 0.01350\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0097 - mae: 0.0684 - mse: 0.0097 - val_loss: 0.0153 - val_mae: 0.0891 - val_mse: 0.0153\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0687 - mse: 0.0095\n",
      "Epoch 00026: val_loss did not improve from 0.01350\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0095 - mae: 0.0688 - mse: 0.0095 - val_loss: 0.0150 - val_mae: 0.0903 - val_mse: 0.0150\n",
      "Epoch 27/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0668 - mse: 0.0089\n",
      "Epoch 00027: val_loss did not improve from 0.01350\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0090 - mae: 0.0669 - mse: 0.0090 - val_loss: 0.0156 - val_mae: 0.0927 - val_mse: 0.0156\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0667 - mse: 0.0090\n",
      "Epoch 00028: val_loss did not improve from 0.01350\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0090 - mae: 0.0667 - mse: 0.0090 - val_loss: 0.0137 - val_mae: 0.0813 - val_mse: 0.0137\n",
      "Epoch 29/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0640 - mse: 0.0084\n",
      "Epoch 00029: val_loss improved from 0.01350 to 0.01293, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0084 - mae: 0.0640 - mse: 0.0084 - val_loss: 0.0129 - val_mae: 0.0765 - val_mse: 0.0129\n",
      "Epoch 30/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0644 - mse: 0.0084\n",
      "Epoch 00030: val_loss improved from 0.01293 to 0.01266, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0084 - mae: 0.0644 - mse: 0.0084 - val_loss: 0.0127 - val_mae: 0.0748 - val_mse: 0.0127\n",
      "Epoch 31/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0650 - mse: 0.0085\n",
      "Epoch 00031: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0085 - mae: 0.0650 - mse: 0.0085 - val_loss: 0.0137 - val_mae: 0.0798 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0643 - mse: 0.0083\n",
      "Epoch 00032: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0082 - mae: 0.0642 - mse: 0.0082 - val_loss: 0.0131 - val_mae: 0.0767 - val_mse: 0.0131\n",
      "Epoch 33/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0624 - mse: 0.0079\n",
      "Epoch 00033: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0079 - mae: 0.0624 - mse: 0.0079 - val_loss: 0.0133 - val_mae: 0.0772 - val_mse: 0.0133\n",
      "Epoch 34/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0611 - mse: 0.0077\n",
      "Epoch 00034: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0077 - mae: 0.0611 - mse: 0.0077 - val_loss: 0.0139 - val_mae: 0.0790 - val_mse: 0.0139\n",
      "Epoch 35/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0620 - mse: 0.0077\n",
      "Epoch 00035: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0077 - mae: 0.0620 - mse: 0.0077 - val_loss: 0.0138 - val_mae: 0.0792 - val_mse: 0.0138\n",
      "Epoch 36/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0608 - mse: 0.0076\n",
      "Epoch 00036: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0075 - mae: 0.0607 - mse: 0.0075 - val_loss: 0.0142 - val_mae: 0.0803 - val_mse: 0.0142\n",
      "Epoch 37/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0606 - mse: 0.0074\n",
      "Epoch 00037: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0074 - mae: 0.0606 - mse: 0.0074 - val_loss: 0.0137 - val_mae: 0.0805 - val_mse: 0.0137\n",
      "Epoch 38/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0072 - mae: 0.0589 - mse: 0.0072\n",
      "Epoch 00038: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0071 - mae: 0.0586 - mse: 0.0071 - val_loss: 0.0138 - val_mae: 0.0759 - val_mse: 0.0138\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0591 - mse: 0.0071\n",
      "Epoch 00039: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0151 - val_mae: 0.0854 - val_mse: 0.0151\n",
      "Epoch 40/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0066 - mae: 0.0565 - mse: 0.0066\n",
      "Epoch 00040: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0066 - mae: 0.0566 - mse: 0.0066 - val_loss: 0.0135 - val_mae: 0.0769 - val_mse: 0.0135\n",
      "Epoch 41/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0591 - mse: 0.0070\n",
      "Epoch 00041: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0070 - mae: 0.0590 - mse: 0.0070 - val_loss: 0.0131 - val_mae: 0.0744 - val_mse: 0.0131\n",
      "Epoch 42/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0576 - mse: 0.0068\n",
      "Epoch 00042: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0069 - mae: 0.0578 - mse: 0.0069 - val_loss: 0.0140 - val_mae: 0.0784 - val_mse: 0.0140\n",
      "Epoch 43/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0567 - mse: 0.0066\n",
      "Epoch 00043: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0066 - mae: 0.0567 - mse: 0.0066 - val_loss: 0.0133 - val_mae: 0.0754 - val_mse: 0.0133\n",
      "Epoch 44/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0567 - mse: 0.0065\n",
      "Epoch 00044: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0065 - mae: 0.0568 - mse: 0.0065 - val_loss: 0.0142 - val_mae: 0.0800 - val_mse: 0.0142\n",
      "Epoch 45/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0549 - mse: 0.0061\n",
      "Epoch 00045: val_loss did not improve from 0.01266\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0061 - mae: 0.0551 - mse: 0.0061 - val_loss: 0.0138 - val_mae: 0.0794 - val_mse: 0.0138\n",
      "Elapsed time during model training:  63.648977756500244\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0457 - mae: 0.1488 - mse: 0.0457\n",
      "Epoch 00001: val_loss improved from inf to 0.02254, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0454,  mae:0.1486,  mse:0.0454,  val_loss:0.0225,  val_mae:0.1145,  val_mse:0.0225,  \n",
      "14926/14926 [==============================] - 2s 148us/sample - loss: 0.0454 - mae: 0.1486 - mse: 0.0454 - val_loss: 0.0225 - val_mae: 0.1145 - val_mse: 0.0225\n",
      "Epoch 2/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1071 - mse: 0.0216\n",
      "Epoch 00002: val_loss improved from 0.02254 to 0.01973, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 126us/sample - loss: 0.0217 - mae: 0.1073 - mse: 0.0217 - val_loss: 0.0197 - val_mae: 0.1005 - val_mse: 0.0197\n",
      "Epoch 3/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0204 - mae: 0.1031 - mse: 0.0204\n",
      "Epoch 00003: val_loss improved from 0.01973 to 0.01786, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0203 - mae: 0.1029 - mse: 0.0203 - val_loss: 0.0179 - val_mae: 0.0977 - val_mse: 0.0179\n",
      "Epoch 4/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0981 - mse: 0.0183\n",
      "Epoch 00004: val_loss did not improve from 0.01786\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0184 - mae: 0.0983 - mse: 0.0184 - val_loss: 0.0244 - val_mae: 0.1205 - val_mse: 0.0244\n",
      "Epoch 5/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0963 - mse: 0.0178\n",
      "Epoch 00005: val_loss did not improve from 0.01786\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0178 - mae: 0.0963 - mse: 0.0178 - val_loss: 0.0211 - val_mae: 0.1037 - val_mse: 0.0211\n",
      "Epoch 6/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0935 - mse: 0.0171\n",
      "Epoch 00006: val_loss did not improve from 0.01786\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0171 - mae: 0.0935 - mse: 0.0171 - val_loss: 0.0202 - val_mae: 0.1096 - val_mse: 0.0202\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0900 - mse: 0.0160\n",
      "Epoch 00007: val_loss improved from 0.01786 to 0.01744, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0160 - mae: 0.0900 - mse: 0.0160 - val_loss: 0.0174 - val_mae: 0.0943 - val_mse: 0.0174\n",
      "Epoch 8/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0871 - mse: 0.0148\n",
      "Epoch 00008: val_loss did not improve from 0.01744\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0152 - mae: 0.0875 - mse: 0.0152 - val_loss: 0.0192 - val_mae: 0.1076 - val_mse: 0.0192\n",
      "Epoch 9/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0886 - mse: 0.0153\n",
      "Epoch 00009: val_loss did not improve from 0.01744\n",
      "14926/14926 [==============================] - 2s 125us/sample - loss: 0.0153 - mae: 0.0886 - mse: 0.0153 - val_loss: 0.0207 - val_mae: 0.1066 - val_mse: 0.0207\n",
      "Epoch 10/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0859 - mse: 0.0146\n",
      "Epoch 00010: val_loss improved from 0.01744 to 0.01407, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0145 - mae: 0.0857 - mse: 0.0145 - val_loss: 0.0141 - val_mae: 0.0801 - val_mse: 0.0141\n",
      "Epoch 11/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0138 - mae: 0.0850 - mse: 0.0138\n",
      "Epoch 00011: val_loss did not improve from 0.01407\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0142 - mae: 0.0852 - mse: 0.0142 - val_loss: 0.0214 - val_mae: 0.1091 - val_mse: 0.0214\n",
      "Epoch 12/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0135 - mae: 0.0828 - mse: 0.0135\n",
      "Epoch 00012: val_loss did not improve from 0.01407\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0135 - mae: 0.0827 - mse: 0.0135 - val_loss: 0.0160 - val_mae: 0.0918 - val_mse: 0.0160\n",
      "Epoch 13/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0788 - mse: 0.0126\n",
      "Epoch 00013: val_loss did not improve from 0.01407\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0126 - mae: 0.0789 - mse: 0.0126 - val_loss: 0.0178 - val_mae: 0.0899 - val_mse: 0.0178\n",
      "Epoch 14/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0810 - mse: 0.0130\n",
      "Epoch 00014: val_loss did not improve from 0.01407\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0130 - mae: 0.0809 - mse: 0.0130 - val_loss: 0.0154 - val_mae: 0.0857 - val_mse: 0.0154\n",
      "Epoch 15/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0767 - mse: 0.0121\n",
      "Epoch 00015: val_loss did not improve from 0.01407\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0121 - mae: 0.0767 - mse: 0.0121 - val_loss: 0.0155 - val_mae: 0.0858 - val_mse: 0.0155\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0763 - mse: 0.0117\n",
      "Epoch 00016: val_loss improved from 0.01407 to 0.01349, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0135 - val_mae: 0.0780 - val_mse: 0.0135\n",
      "Epoch 17/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0736 - mse: 0.0111\n",
      "Epoch 00017: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0111 - mae: 0.0736 - mse: 0.0111 - val_loss: 0.0141 - val_mae: 0.0826 - val_mse: 0.0141\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0752 - mse: 0.0113\n",
      "Epoch 00018: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0113 - mae: 0.0753 - mse: 0.0113 - val_loss: 0.0155 - val_mae: 0.0869 - val_mse: 0.0155\n",
      "Epoch 19/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0744 - mse: 0.0110\n",
      "Epoch 00019: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0110 - mae: 0.0744 - mse: 0.0110 - val_loss: 0.0148 - val_mae: 0.0852 - val_mse: 0.0148\n",
      "Epoch 20/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0709 - mse: 0.0100\n",
      "Epoch 00020: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0103 - mae: 0.0711 - mse: 0.0103 - val_loss: 0.0182 - val_mae: 0.1031 - val_mse: 0.0182\n",
      "Epoch 21/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0102 - mae: 0.0714 - mse: 0.0102\n",
      "Epoch 00021: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0102 - mae: 0.0714 - mse: 0.0102 - val_loss: 0.0142 - val_mae: 0.0785 - val_mse: 0.0142\n",
      "Epoch 22/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0698 - mse: 0.0100\n",
      "Epoch 00022: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0099 - mae: 0.0695 - mse: 0.0099 - val_loss: 0.0140 - val_mae: 0.0799 - val_mse: 0.0140\n",
      "Epoch 23/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0689 - mse: 0.0096\n",
      "Epoch 00023: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0096 - mae: 0.0689 - mse: 0.0096 - val_loss: 0.0146 - val_mae: 0.0848 - val_mse: 0.0146\n",
      "Epoch 24/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0670 - mse: 0.0092\n",
      "Epoch 00024: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0092 - mae: 0.0673 - mse: 0.0092 - val_loss: 0.0160 - val_mae: 0.0908 - val_mse: 0.0160\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0671 - mse: 0.0092\n",
      "Epoch 00025: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0149 - val_mae: 0.0825 - val_mse: 0.0149\n",
      "Epoch 26/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0664 - mse: 0.0089\n",
      "Epoch 00026: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0157 - val_mae: 0.0944 - val_mse: 0.0157\n",
      "Epoch 27/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0655 - mse: 0.0088\n",
      "Epoch 00027: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0087 - mae: 0.0654 - mse: 0.0087 - val_loss: 0.0153 - val_mae: 0.0844 - val_mse: 0.0153\n",
      "Epoch 28/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0640 - mse: 0.0083\n",
      "Epoch 00028: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0084 - mae: 0.0646 - mse: 0.0084 - val_loss: 0.0155 - val_mae: 0.0865 - val_mse: 0.0155\n",
      "Epoch 29/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0640 - mse: 0.0082\n",
      "Epoch 00029: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0082 - mae: 0.0640 - mse: 0.0082 - val_loss: 0.0156 - val_mae: 0.0872 - val_mse: 0.0156\n",
      "Epoch 30/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0620 - mse: 0.0079\n",
      "Epoch 00030: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0079 - mae: 0.0620 - mse: 0.0079 - val_loss: 0.0136 - val_mae: 0.0799 - val_mse: 0.0136\n",
      "Epoch 31/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0622 - mse: 0.0079\n",
      "Epoch 00031: val_loss did not improve from 0.01349\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0079 - mae: 0.0621 - mse: 0.0079 - val_loss: 0.0141 - val_mae: 0.0819 - val_mse: 0.0141\n",
      "Elapsed time during model training:  46.707627296447754\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0446 - mae: 0.1466 - mse: 0.0446\n",
      "Epoch 00001: val_loss improved from inf to 0.02943, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0445,  mae:0.1466,  mse:0.0445,  val_loss:0.0294,  val_mae:0.1192,  val_mse:0.0294,  \n",
      "14926/14926 [==============================] - 2s 142us/sample - loss: 0.0445 - mae: 0.1466 - mse: 0.0445 - val_loss: 0.0294 - val_mae: 0.1192 - val_mse: 0.0294\n",
      "Epoch 2/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0217 - mae: 0.1071 - mse: 0.0217\n",
      "Epoch 00002: val_loss improved from 0.02943 to 0.01834, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0217 - mae: 0.1071 - mse: 0.0217 - val_loss: 0.0183 - val_mae: 0.0998 - val_mse: 0.0183\n",
      "Epoch 3/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0204 - mae: 0.1039 - mse: 0.0204\n",
      "Epoch 00003: val_loss improved from 0.01834 to 0.01733, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0205 - mae: 0.1040 - mse: 0.0205 - val_loss: 0.0173 - val_mae: 0.0930 - val_mse: 0.0173\n",
      "Epoch 4/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0187 - mae: 0.0984 - mse: 0.0187\n",
      "Epoch 00004: val_loss improved from 0.01733 to 0.01699, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0186 - mae: 0.0984 - mse: 0.0186 - val_loss: 0.0170 - val_mae: 0.0946 - val_mse: 0.0170\n",
      "Epoch 5/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0949 - mse: 0.0174\n",
      "Epoch 00005: val_loss did not improve from 0.01699\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0174 - mae: 0.0948 - mse: 0.0174 - val_loss: 0.0217 - val_mae: 0.1038 - val_mse: 0.0217\n",
      "Epoch 6/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0173 - mae: 0.0943 - mse: 0.0173\n",
      "Epoch 00006: val_loss did not improve from 0.01699\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0172 - mae: 0.0941 - mse: 0.0172 - val_loss: 0.0174 - val_mae: 0.0961 - val_mse: 0.0174\n",
      "Epoch 7/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0157 - mae: 0.0890 - mse: 0.0157\n",
      "Epoch 00007: val_loss improved from 0.01699 to 0.01582, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0156 - mae: 0.0887 - mse: 0.0156 - val_loss: 0.0158 - val_mae: 0.0885 - val_mse: 0.0158\n",
      "Epoch 8/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0155 - mae: 0.0885 - mse: 0.0155\n",
      "Epoch 00008: val_loss improved from 0.01582 to 0.01546, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0154 - mae: 0.0884 - mse: 0.0154 - val_loss: 0.0155 - val_mae: 0.0865 - val_mse: 0.0155\n",
      "Epoch 9/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0151 - mae: 0.0880 - mse: 0.0151\n",
      "Epoch 00009: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0151 - mae: 0.0880 - mse: 0.0151 - val_loss: 0.0176 - val_mae: 0.0986 - val_mse: 0.0176\n",
      "Epoch 10/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0149 - mae: 0.0873 - mse: 0.0149\n",
      "Epoch 00010: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0149 - mae: 0.0871 - mse: 0.0149 - val_loss: 0.0167 - val_mae: 0.0907 - val_mse: 0.0167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0138 - mae: 0.0826 - mse: 0.0138\n",
      "Epoch 00011: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0139 - mae: 0.0832 - mse: 0.0139 - val_loss: 0.0176 - val_mae: 0.0982 - val_mse: 0.0176\n",
      "Epoch 12/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0801 - mse: 0.0130\n",
      "Epoch 00012: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0130 - mae: 0.0801 - mse: 0.0130 - val_loss: 0.0157 - val_mae: 0.0876 - val_mse: 0.0157\n",
      "Epoch 13/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0800 - mse: 0.0128\n",
      "Epoch 00013: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0128 - mae: 0.0801 - mse: 0.0128 - val_loss: 0.0175 - val_mae: 0.0917 - val_mse: 0.0175\n",
      "Epoch 14/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0793 - mse: 0.0126\n",
      "Epoch 00014: val_loss improved from 0.01546 to 0.01423, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0126 - mae: 0.0792 - mse: 0.0126 - val_loss: 0.0142 - val_mae: 0.0816 - val_mse: 0.0142\n",
      "Epoch 15/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0125 - mae: 0.0794 - mse: 0.0125\n",
      "Epoch 00015: val_loss did not improve from 0.01423\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0125 - mae: 0.0793 - mse: 0.0125 - val_loss: 0.0148 - val_mae: 0.0853 - val_mse: 0.0148\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0759 - mse: 0.0118\n",
      "Epoch 00016: val_loss did not improve from 0.01423\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0118 - mae: 0.0759 - mse: 0.0118 - val_loss: 0.0161 - val_mae: 0.0885 - val_mse: 0.0161\n",
      "Epoch 17/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0782 - mse: 0.0121\n",
      "Epoch 00017: val_loss did not improve from 0.01423\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0122 - mae: 0.0785 - mse: 0.0122 - val_loss: 0.0184 - val_mae: 0.0983 - val_mse: 0.0184\n",
      "Epoch 18/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0739 - mse: 0.0111\n",
      "Epoch 00018: val_loss did not improve from 0.01423\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0160 - val_mae: 0.0886 - val_mse: 0.0160\n",
      "Epoch 19/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0110 - mae: 0.0735 - mse: 0.0110\n",
      "Epoch 00019: val_loss did not improve from 0.01423\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0111 - mae: 0.0737 - mse: 0.0111 - val_loss: 0.0169 - val_mae: 0.0982 - val_mse: 0.0169\n",
      "Epoch 20/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0106 - mae: 0.0721 - mse: 0.0106\n",
      "Epoch 00020: val_loss improved from 0.01423 to 0.01342, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0106 - mae: 0.0722 - mse: 0.0106 - val_loss: 0.0134 - val_mae: 0.0787 - val_mse: 0.0134\n",
      "Epoch 21/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0714 - mse: 0.0104\n",
      "Epoch 00021: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0104 - mae: 0.0718 - mse: 0.0104 - val_loss: 0.0192 - val_mae: 0.1023 - val_mse: 0.0192\n",
      "Epoch 22/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0706 - mse: 0.0101\n",
      "Epoch 00022: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0102 - mae: 0.0707 - mse: 0.0102 - val_loss: 0.0139 - val_mae: 0.0809 - val_mse: 0.0139\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0687 - mse: 0.0097\n",
      "Epoch 00023: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0097 - mae: 0.0686 - mse: 0.0097 - val_loss: 0.0137 - val_mae: 0.0770 - val_mse: 0.0137\n",
      "Epoch 24/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0688 - mse: 0.0097\n",
      "Epoch 00024: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0097 - mae: 0.0691 - mse: 0.0097 - val_loss: 0.0143 - val_mae: 0.0785 - val_mse: 0.0143\n",
      "Epoch 25/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0690 - mse: 0.0095\n",
      "Epoch 00025: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0095 - mae: 0.0689 - mse: 0.0095 - val_loss: 0.0151 - val_mae: 0.0834 - val_mse: 0.0151\n",
      "Epoch 26/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0659 - mse: 0.0088\n",
      "Epoch 00026: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0152 - val_mae: 0.0838 - val_mse: 0.0152\n",
      "Epoch 27/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0648 - mse: 0.0085\n",
      "Epoch 00027: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0086 - mae: 0.0650 - mse: 0.0086 - val_loss: 0.0157 - val_mae: 0.0889 - val_mse: 0.0157\n",
      "Epoch 28/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0664 - mse: 0.0089\n",
      "Epoch 00028: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0137 - val_mae: 0.0791 - val_mse: 0.0137\n",
      "Epoch 29/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0643 - mse: 0.0083\n",
      "Epoch 00029: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0084 - mae: 0.0643 - mse: 0.0084 - val_loss: 0.0146 - val_mae: 0.0811 - val_mse: 0.0146\n",
      "Epoch 30/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0086 - mae: 0.0644 - mse: 0.0086\n",
      "Epoch 00030: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0086 - mae: 0.0646 - mse: 0.0086 - val_loss: 0.0158 - val_mae: 0.0899 - val_mse: 0.0158\n",
      "Epoch 31/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0621 - mse: 0.0077\n",
      "Epoch 00031: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0077 - mae: 0.0620 - mse: 0.0077 - val_loss: 0.0136 - val_mae: 0.0794 - val_mse: 0.0136\n",
      "Epoch 32/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0627 - mse: 0.0079\n",
      "Epoch 00032: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0079 - mae: 0.0627 - mse: 0.0079 - val_loss: 0.0149 - val_mae: 0.0791 - val_mse: 0.0149\n",
      "Epoch 33/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0617 - mse: 0.0078\n",
      "Epoch 00033: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0078 - mae: 0.0619 - mse: 0.0078 - val_loss: 0.0137 - val_mae: 0.0778 - val_mse: 0.0137\n",
      "Epoch 34/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0607 - mse: 0.0075\n",
      "Epoch 00034: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0075 - mae: 0.0607 - mse: 0.0075 - val_loss: 0.0138 - val_mae: 0.0792 - val_mse: 0.0138\n",
      "Epoch 35/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0072 - mae: 0.0597 - mse: 0.0072\n",
      "Epoch 00035: val_loss did not improve from 0.01342\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0072 - mae: 0.0598 - mse: 0.0072 - val_loss: 0.0141 - val_mae: 0.0812 - val_mse: 0.0141\n",
      "Elapsed time during model training:  50.65756130218506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0456 - mae: 0.1473 - mse: 0.0456\n",
      "Epoch 00001: val_loss improved from inf to 0.02390, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0456,  mae:0.1473,  mse:0.0456,  val_loss:0.0239,  val_mae:0.1166,  val_mse:0.0239,  \n",
      "14926/14926 [==============================] - 2s 143us/sample - loss: 0.0456 - mae: 0.1473 - mse: 0.0456 - val_loss: 0.0239 - val_mae: 0.1166 - val_mse: 0.0239\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0222 - mae: 0.1090 - mse: 0.0222\n",
      "Epoch 00002: val_loss improved from 0.02390 to 0.02324, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0222 - mae: 0.1090 - mse: 0.0222 - val_loss: 0.0232 - val_mae: 0.1125 - val_mse: 0.0232\n",
      "Epoch 3/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1031 - mse: 0.0201\n",
      "Epoch 00003: val_loss improved from 0.02324 to 0.01871, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0200 - mae: 0.1029 - mse: 0.0200 - val_loss: 0.0187 - val_mae: 0.0929 - val_mse: 0.0187\n",
      "Epoch 4/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0183 - mae: 0.0970 - mse: 0.0183\n",
      "Epoch 00004: val_loss improved from 0.01871 to 0.01628, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0183 - mae: 0.0970 - mse: 0.0183 - val_loss: 0.0163 - val_mae: 0.0901 - val_mse: 0.0163\n",
      "Epoch 5/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0934 - mse: 0.0170\n",
      "Epoch 00005: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0170 - mae: 0.0934 - mse: 0.0170 - val_loss: 0.0173 - val_mae: 0.0910 - val_mse: 0.0173\n",
      "Epoch 6/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0932 - mse: 0.0170\n",
      "Epoch 00006: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0170 - mae: 0.0932 - mse: 0.0170 - val_loss: 0.0191 - val_mae: 0.0992 - val_mse: 0.0191\n",
      "Epoch 7/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0927 - mse: 0.0167\n",
      "Epoch 00007: val_loss did not improve from 0.01628\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0167 - mae: 0.0926 - mse: 0.0167 - val_loss: 0.0194 - val_mae: 0.0998 - val_mse: 0.0194\n",
      "Epoch 8/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0169 - mae: 0.0937 - mse: 0.0169\n",
      "Epoch 00008: val_loss improved from 0.01628 to 0.01575, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0169 - mae: 0.0937 - mse: 0.0169 - val_loss: 0.0157 - val_mae: 0.0896 - val_mse: 0.0157\n",
      "Epoch 9/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0147 - mae: 0.0859 - mse: 0.0147\n",
      "Epoch 00009: val_loss did not improve from 0.01575\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0147 - mae: 0.0858 - mse: 0.0147 - val_loss: 0.0195 - val_mae: 0.1025 - val_mse: 0.0195\n",
      "Epoch 10/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0849 - mse: 0.0145\n",
      "Epoch 00010: val_loss improved from 0.01575 to 0.01442, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0144 - mae: 0.0847 - mse: 0.0144 - val_loss: 0.0144 - val_mae: 0.0812 - val_mse: 0.0144\n",
      "Epoch 11/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.0830 - mse: 0.0137\n",
      "Epoch 00011: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0137 - mae: 0.0828 - mse: 0.0137 - val_loss: 0.0151 - val_mae: 0.0856 - val_mse: 0.0151\n",
      "Epoch 12/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0131 - mae: 0.0812 - mse: 0.0131\n",
      "Epoch 00012: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0132 - mae: 0.0814 - mse: 0.0132 - val_loss: 0.0162 - val_mae: 0.0935 - val_mse: 0.0162\n",
      "Epoch 13/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0132 - mae: 0.0809 - mse: 0.0132\n",
      "Epoch 00013: val_loss did not improve from 0.01442\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0131 - mae: 0.0804 - mse: 0.0131 - val_loss: 0.0169 - val_mae: 0.0858 - val_mse: 0.0169\n",
      "Epoch 14/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0129 - mae: 0.0801 - mse: 0.0129\n",
      "Epoch 00014: val_loss improved from 0.01442 to 0.01398, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0129 - mae: 0.0801 - mse: 0.0129 - val_loss: 0.0140 - val_mae: 0.0823 - val_mse: 0.0140\n",
      "Epoch 15/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0792 - mse: 0.0124\n",
      "Epoch 00015: val_loss did not improve from 0.01398\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0124 - mae: 0.0793 - mse: 0.0124 - val_loss: 0.0178 - val_mae: 0.0950 - val_mse: 0.0178\n",
      "Epoch 16/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0761 - mse: 0.0116\n",
      "Epoch 00016: val_loss improved from 0.01398 to 0.01393, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0116 - mae: 0.0761 - mse: 0.0116 - val_loss: 0.0139 - val_mae: 0.0826 - val_mse: 0.0139\n",
      "Epoch 17/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0755 - mse: 0.0115\n",
      "Epoch 00017: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0115 - mae: 0.0755 - mse: 0.0115 - val_loss: 0.0147 - val_mae: 0.0812 - val_mse: 0.0147\n",
      "Epoch 18/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0766 - mse: 0.0117\n",
      "Epoch 00018: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0117 - mae: 0.0766 - mse: 0.0117 - val_loss: 0.0140 - val_mae: 0.0788 - val_mse: 0.0140\n",
      "Epoch 19/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0731 - mse: 0.0108\n",
      "Epoch 00019: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0109 - mae: 0.0734 - mse: 0.0109 - val_loss: 0.0152 - val_mae: 0.0815 - val_mse: 0.0152\n",
      "Epoch 20/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0745 - mse: 0.0111\n",
      "Epoch 00020: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0111 - mae: 0.0744 - mse: 0.0111 - val_loss: 0.0144 - val_mae: 0.0856 - val_mse: 0.0144\n",
      "Epoch 21/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0703 - mse: 0.0103\n",
      "Epoch 00021: val_loss did not improve from 0.01393\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0103 - mae: 0.0705 - mse: 0.0103 - val_loss: 0.0146 - val_mae: 0.0847 - val_mse: 0.0146\n",
      "Epoch 22/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0699 - mse: 0.0101\n",
      "Epoch 00022: val_loss improved from 0.01393 to 0.01358, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0100 - mae: 0.0699 - mse: 0.0100 - val_loss: 0.0136 - val_mae: 0.0789 - val_mse: 0.0136\n",
      "Epoch 23/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0682 - mse: 0.0097\n",
      "Epoch 00023: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0097 - mae: 0.0682 - mse: 0.0097 - val_loss: 0.0152 - val_mae: 0.0864 - val_mse: 0.0152\n",
      "Epoch 24/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0682 - mse: 0.0094\n",
      "Epoch 00024: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0094 - mae: 0.0681 - mse: 0.0094 - val_loss: 0.0152 - val_mae: 0.0829 - val_mse: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0671 - mse: 0.0092\n",
      "Epoch 00025: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0092 - mae: 0.0671 - mse: 0.0092 - val_loss: 0.0159 - val_mae: 0.0896 - val_mse: 0.0159\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0664 - mse: 0.0090\n",
      "Epoch 00026: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0091 - mae: 0.0664 - mse: 0.0091 - val_loss: 0.0136 - val_mae: 0.0800 - val_mse: 0.0136\n",
      "Epoch 27/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0668 - mse: 0.0091\n",
      "Epoch 00027: val_loss improved from 0.01358 to 0.01334, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0090 - mae: 0.0668 - mse: 0.0090 - val_loss: 0.0133 - val_mae: 0.0758 - val_mse: 0.0133\n",
      "Epoch 28/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0628 - mse: 0.0082\n",
      "Epoch 00028: val_loss did not improve from 0.01334\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0082 - mae: 0.0629 - mse: 0.0082 - val_loss: 0.0149 - val_mae: 0.0825 - val_mse: 0.0149\n",
      "Epoch 29/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0654 - mse: 0.0087\n",
      "Epoch 00029: val_loss did not improve from 0.01334\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0087 - mae: 0.0654 - mse: 0.0087 - val_loss: 0.0135 - val_mae: 0.0794 - val_mse: 0.0135\n",
      "Epoch 30/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0638 - mse: 0.0082\n",
      "Epoch 00030: val_loss did not improve from 0.01334\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0082 - mae: 0.0639 - mse: 0.0082 - val_loss: 0.0149 - val_mae: 0.0850 - val_mse: 0.0149\n",
      "Epoch 31/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0644 - mse: 0.0084\n",
      "Epoch 00031: val_loss did not improve from 0.01334\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0084 - mae: 0.0644 - mse: 0.0084 - val_loss: 0.0137 - val_mae: 0.0773 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0619 - mse: 0.0079\n",
      "Epoch 00032: val_loss improved from 0.01334 to 0.01301, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0078 - mae: 0.0619 - mse: 0.0078 - val_loss: 0.0130 - val_mae: 0.0757 - val_mse: 0.0130\n",
      "Epoch 33/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0623 - mse: 0.0079\n",
      "Epoch 00033: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0079 - mae: 0.0623 - mse: 0.0079 - val_loss: 0.0139 - val_mae: 0.0810 - val_mse: 0.0139\n",
      "Epoch 34/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0605 - mse: 0.0072\n",
      "Epoch 00034: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0077 - mae: 0.0609 - mse: 0.0077 - val_loss: 0.0170 - val_mae: 0.1004 - val_mse: 0.0170\n",
      "Epoch 35/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0601 - mse: 0.0074\n",
      "Epoch 00035: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0074 - mae: 0.0601 - mse: 0.0074 - val_loss: 0.0149 - val_mae: 0.0828 - val_mse: 0.0149\n",
      "Epoch 36/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0584 - mse: 0.0070\n",
      "Epoch 00036: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0070 - mae: 0.0585 - mse: 0.0070 - val_loss: 0.0152 - val_mae: 0.0832 - val_mse: 0.0152\n",
      "Epoch 37/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0577 - mse: 0.0069\n",
      "Epoch 00037: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0069 - mae: 0.0579 - mse: 0.0069 - val_loss: 0.0161 - val_mae: 0.0843 - val_mse: 0.0161\n",
      "Epoch 38/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0592 - mse: 0.0070\n",
      "Epoch 00038: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0072 - mae: 0.0592 - mse: 0.0072 - val_loss: 0.0144 - val_mae: 0.0786 - val_mse: 0.0144\n",
      "Epoch 39/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0570 - mse: 0.0067\n",
      "Epoch 00039: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0067 - mae: 0.0570 - mse: 0.0067 - val_loss: 0.0136 - val_mae: 0.0776 - val_mse: 0.0136\n",
      "Epoch 40/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0580 - mse: 0.0068\n",
      "Epoch 00040: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0069 - mae: 0.0582 - mse: 0.0069 - val_loss: 0.0149 - val_mae: 0.0843 - val_mse: 0.0149\n",
      "Epoch 41/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0064 - mae: 0.0560 - mse: 0.0064\n",
      "Epoch 00041: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0064 - mae: 0.0560 - mse: 0.0064 - val_loss: 0.0150 - val_mae: 0.0781 - val_mse: 0.0150\n",
      "Epoch 42/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0550 - mse: 0.0063\n",
      "Epoch 00042: val_loss did not improve from 0.01301\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0063 - mae: 0.0550 - mse: 0.0063 - val_loss: 0.0164 - val_mae: 0.0904 - val_mse: 0.0164\n",
      "Epoch 43/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0551 - mse: 0.0062\n",
      "Epoch 00043: val_loss improved from 0.01301 to 0.01272, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0062 - mae: 0.0551 - mse: 0.0062 - val_loss: 0.0127 - val_mae: 0.0738 - val_mse: 0.0127\n",
      "Epoch 44/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0528 - mse: 0.0058\n",
      "Epoch 00044: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0058 - mae: 0.0528 - mse: 0.0058 - val_loss: 0.0141 - val_mae: 0.0767 - val_mse: 0.0141\n",
      "Epoch 45/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0060 - mae: 0.0540 - mse: 0.0060\n",
      "Epoch 00045: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0059 - mae: 0.0540 - mse: 0.0059 - val_loss: 0.0134 - val_mae: 0.0761 - val_mse: 0.0134\n",
      "Epoch 46/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0509 - mse: 0.0053\n",
      "Epoch 00046: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0053 - mae: 0.0509 - mse: 0.0053 - val_loss: 0.0134 - val_mae: 0.0743 - val_mse: 0.0134\n",
      "Epoch 47/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0537 - mse: 0.0059\n",
      "Epoch 00047: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0060 - mae: 0.0538 - mse: 0.0060 - val_loss: 0.0152 - val_mae: 0.0849 - val_mse: 0.0152\n",
      "Epoch 48/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0518 - mse: 0.0054\n",
      "Epoch 00048: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0054 - mae: 0.0518 - mse: 0.0054 - val_loss: 0.0157 - val_mae: 0.0917 - val_mse: 0.0157\n",
      "Epoch 49/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0513 - mse: 0.0053\n",
      "Epoch 00049: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0053 - mae: 0.0513 - mse: 0.0053 - val_loss: 0.0145 - val_mae: 0.0795 - val_mse: 0.0145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0055 - mae: 0.0513 - mse: 0.0055\n",
      "Epoch 00050: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0055 - mae: 0.0514 - mse: 0.0055 - val_loss: 0.0137 - val_mae: 0.0757 - val_mse: 0.0137\n",
      "Epoch 51/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0504 - mse: 0.0053\n",
      "Epoch 00051: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0054 - mae: 0.0505 - mse: 0.0054 - val_loss: 0.0137 - val_mae: 0.0774 - val_mse: 0.0137\n",
      "Epoch 52/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0051 - mae: 0.0495 - mse: 0.0051\n",
      "Epoch 00052: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0050 - mae: 0.0496 - mse: 0.0050 - val_loss: 0.0142 - val_mae: 0.0777 - val_mse: 0.0142\n",
      "Epoch 53/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0052 - mae: 0.0510 - mse: 0.0052\n",
      "Epoch 00053: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0052 - mae: 0.0511 - mse: 0.0052 - val_loss: 0.0134 - val_mae: 0.0756 - val_mse: 0.0134\n",
      "Epoch 54/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0050 - mae: 0.0494 - mse: 0.0050\n",
      "Epoch 00054: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0050 - mae: 0.0495 - mse: 0.0050 - val_loss: 0.0137 - val_mae: 0.0756 - val_mse: 0.0137\n",
      "Epoch 55/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0047 - mae: 0.0472 - mse: 0.0047\n",
      "Epoch 00055: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0047 - mae: 0.0472 - mse: 0.0047 - val_loss: 0.0141 - val_mae: 0.0793 - val_mse: 0.0141\n",
      "Epoch 56/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0045 - mae: 0.0467 - mse: 0.0045\n",
      "Epoch 00056: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0045 - mae: 0.0469 - mse: 0.0045 - val_loss: 0.0157 - val_mae: 0.0794 - val_mse: 0.0157\n",
      "Epoch 57/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0511 - mse: 0.0053\n",
      "Epoch 00057: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0053 - mae: 0.0511 - mse: 0.0053 - val_loss: 0.0142 - val_mae: 0.0790 - val_mse: 0.0142\n",
      "Epoch 58/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0475 - mse: 0.0046\n",
      "Epoch 00058: val_loss did not improve from 0.01272\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0046 - mae: 0.0476 - mse: 0.0046 - val_loss: 0.0145 - val_mae: 0.0782 - val_mse: 0.0145\n",
      "Elapsed time during model training:  83.52811694145203\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0444 - mae: 0.1435 - mse: 0.0444\n",
      "Epoch 00001: val_loss improved from inf to 0.02085, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0444,  mae:0.1435,  mse:0.0444,  val_loss:0.0208,  val_mae:0.1030,  val_mse:0.0208,  \n",
      "14926/14926 [==============================] - 2s 146us/sample - loss: 0.0444 - mae: 0.1435 - mse: 0.0444 - val_loss: 0.0208 - val_mae: 0.1030 - val_mse: 0.0208\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0225 - mae: 0.1094 - mse: 0.0225\n",
      "Epoch 00002: val_loss improved from 0.02085 to 0.02080, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0224 - mae: 0.1094 - mse: 0.0224 - val_loss: 0.0208 - val_mae: 0.1056 - val_mse: 0.0208\n",
      "Epoch 3/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0192 - mae: 0.1001 - mse: 0.0192\n",
      "Epoch 00003: val_loss improved from 0.02080 to 0.01752, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0192 - mae: 0.1002 - mse: 0.0192 - val_loss: 0.0175 - val_mae: 0.0944 - val_mse: 0.0175\n",
      "Epoch 4/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0185 - mae: 0.0984 - mse: 0.0185\n",
      "Epoch 00004: val_loss did not improve from 0.01752\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0185 - mae: 0.0984 - mse: 0.0185 - val_loss: 0.0325 - val_mae: 0.1422 - val_mse: 0.0325\n",
      "Epoch 5/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0177 - mae: 0.0964 - mse: 0.0177\n",
      "Epoch 00005: val_loss did not improve from 0.01752\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0178 - mae: 0.0965 - mse: 0.0178 - val_loss: 0.0196 - val_mae: 0.1038 - val_mse: 0.0196\n",
      "Epoch 6/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0175 - mae: 0.0953 - mse: 0.0175\n",
      "Epoch 00006: val_loss improved from 0.01752 to 0.01599, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0175 - mae: 0.0953 - mse: 0.0175 - val_loss: 0.0160 - val_mae: 0.0916 - val_mse: 0.0160\n",
      "Epoch 7/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0156 - mae: 0.0884 - mse: 0.0156\n",
      "Epoch 00007: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0156 - mae: 0.0884 - mse: 0.0156 - val_loss: 0.0186 - val_mae: 0.1022 - val_mse: 0.0186\n",
      "Epoch 8/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0884 - mse: 0.0153\n",
      "Epoch 00008: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0153 - mae: 0.0884 - mse: 0.0153 - val_loss: 0.0170 - val_mae: 0.0930 - val_mse: 0.0170\n",
      "Epoch 9/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0836 - mse: 0.0137\n",
      "Epoch 00009: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0141 - mae: 0.0839 - mse: 0.0141 - val_loss: 0.0252 - val_mae: 0.1243 - val_mse: 0.0252\n",
      "Epoch 10/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0152 - mae: 0.0887 - mse: 0.0152\n",
      "Epoch 00010: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0152 - mae: 0.0887 - mse: 0.0152 - val_loss: 0.0168 - val_mae: 0.0934 - val_mse: 0.0168\n",
      "Epoch 11/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0132 - mae: 0.0814 - mse: 0.0132\n",
      "Epoch 00011: val_loss did not improve from 0.01599\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0132 - mae: 0.0815 - mse: 0.0132 - val_loss: 0.0161 - val_mae: 0.0925 - val_mse: 0.0161\n",
      "Epoch 12/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0137 - mae: 0.0830 - mse: 0.0137\n",
      "Epoch 00012: val_loss improved from 0.01599 to 0.01553, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0136 - mae: 0.0829 - mse: 0.0136 - val_loss: 0.0155 - val_mae: 0.0878 - val_mse: 0.0155\n",
      "Epoch 13/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0797 - mse: 0.0127\n",
      "Epoch 00013: val_loss improved from 0.01553 to 0.01542, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0127 - mae: 0.0798 - mse: 0.0127 - val_loss: 0.0154 - val_mae: 0.0831 - val_mse: 0.0154\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0793 - mse: 0.0126\n",
      "Epoch 00014: val_loss improved from 0.01542 to 0.01463, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0127 - mae: 0.0796 - mse: 0.0127 - val_loss: 0.0146 - val_mae: 0.0837 - val_mse: 0.0146\n",
      "Epoch 15/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0787 - mse: 0.0123\n",
      "Epoch 00015: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0122 - mae: 0.0786 - mse: 0.0122 - val_loss: 0.0152 - val_mae: 0.0869 - val_mse: 0.0152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0116 - mae: 0.0758 - mse: 0.0116\n",
      "Epoch 00016: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0116 - mae: 0.0760 - mse: 0.0116 - val_loss: 0.0156 - val_mae: 0.0923 - val_mse: 0.0156\n",
      "Epoch 17/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0748 - mse: 0.0113\n",
      "Epoch 00017: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0112 - mae: 0.0747 - mse: 0.0112 - val_loss: 0.0151 - val_mae: 0.0873 - val_mse: 0.0151\n",
      "Epoch 18/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0759 - mse: 0.0115\n",
      "Epoch 00018: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0115 - mae: 0.0761 - mse: 0.0115 - val_loss: 0.0160 - val_mae: 0.0917 - val_mse: 0.0160\n",
      "Epoch 19/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0746 - mse: 0.0110\n",
      "Epoch 00019: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0110 - mae: 0.0747 - mse: 0.0110 - val_loss: 0.0186 - val_mae: 0.1022 - val_mse: 0.0186\n",
      "Epoch 20/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0718 - mse: 0.0105\n",
      "Epoch 00020: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0105 - mae: 0.0718 - mse: 0.0105 - val_loss: 0.0154 - val_mae: 0.0874 - val_mse: 0.0154\n",
      "Epoch 21/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0706 - mse: 0.0101\n",
      "Epoch 00021: val_loss improved from 0.01463 to 0.01434, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0143 - val_mae: 0.0860 - val_mse: 0.0143\n",
      "Epoch 22/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0703 - mse: 0.0099\n",
      "Epoch 00022: val_loss improved from 0.01434 to 0.01399, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0099 - mae: 0.0703 - mse: 0.0099 - val_loss: 0.0140 - val_mae: 0.0798 - val_mse: 0.0140\n",
      "Epoch 23/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0690 - mse: 0.0099\n",
      "Epoch 00023: val_loss improved from 0.01399 to 0.01326, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0099 - mae: 0.0689 - mse: 0.0099 - val_loss: 0.0133 - val_mae: 0.0781 - val_mse: 0.0133\n",
      "Epoch 24/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0682 - mse: 0.0095\n",
      "Epoch 00024: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0095 - mae: 0.0682 - mse: 0.0095 - val_loss: 0.0149 - val_mae: 0.0837 - val_mse: 0.0149\n",
      "Epoch 25/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0667 - mse: 0.0091\n",
      "Epoch 00025: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0091 - mae: 0.0665 - mse: 0.0091 - val_loss: 0.0159 - val_mae: 0.0911 - val_mse: 0.0159\n",
      "Epoch 26/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0665 - mse: 0.0089\n",
      "Epoch 00026: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0089 - mae: 0.0665 - mse: 0.0089 - val_loss: 0.0147 - val_mae: 0.0840 - val_mse: 0.0147\n",
      "Epoch 27/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0673 - mse: 0.0091\n",
      "Epoch 00027: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0091 - mae: 0.0673 - mse: 0.0091 - val_loss: 0.0148 - val_mae: 0.0857 - val_mse: 0.0148\n",
      "Epoch 28/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0631 - mse: 0.0079\n",
      "Epoch 00028: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0082 - mae: 0.0634 - mse: 0.0082 - val_loss: 0.0136 - val_mae: 0.0797 - val_mse: 0.0136\n",
      "Epoch 29/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0080 - mae: 0.0626 - mse: 0.0080\n",
      "Epoch 00029: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0080 - mae: 0.0628 - mse: 0.0080 - val_loss: 0.0150 - val_mae: 0.0843 - val_mse: 0.0150\n",
      "Epoch 30/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0634 - mse: 0.0081\n",
      "Epoch 00030: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0081 - mae: 0.0633 - mse: 0.0081 - val_loss: 0.0147 - val_mae: 0.0827 - val_mse: 0.0147\n",
      "Epoch 31/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0623 - mse: 0.0079\n",
      "Epoch 00031: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0079 - mae: 0.0624 - mse: 0.0079 - val_loss: 0.0144 - val_mae: 0.0830 - val_mse: 0.0144\n",
      "Epoch 32/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0616 - mse: 0.0077\n",
      "Epoch 00032: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0076 - mae: 0.0616 - mse: 0.0076 - val_loss: 0.0145 - val_mae: 0.0828 - val_mse: 0.0145\n",
      "Epoch 33/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0610 - mse: 0.0076\n",
      "Epoch 00033: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0076 - mae: 0.0611 - mse: 0.0076 - val_loss: 0.0159 - val_mae: 0.0880 - val_mse: 0.0159\n",
      "Epoch 34/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0584 - mse: 0.0070\n",
      "Epoch 00034: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0070 - mae: 0.0584 - mse: 0.0070 - val_loss: 0.0141 - val_mae: 0.0807 - val_mse: 0.0141\n",
      "Epoch 35/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0587 - mse: 0.0070\n",
      "Epoch 00035: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0070 - mae: 0.0588 - mse: 0.0070 - val_loss: 0.0158 - val_mae: 0.0884 - val_mse: 0.0158\n",
      "Epoch 36/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0593 - mse: 0.0071\n",
      "Epoch 00036: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0144 - val_mae: 0.0790 - val_mse: 0.0144\n",
      "Epoch 37/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0583 - mse: 0.0070\n",
      "Epoch 00037: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0069 - mae: 0.0582 - mse: 0.0069 - val_loss: 0.0146 - val_mae: 0.0830 - val_mse: 0.0146\n",
      "Epoch 38/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0576 - mse: 0.0068\n",
      "Epoch 00038: val_loss did not improve from 0.01326\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0067 - mae: 0.0577 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0784 - val_mse: 0.0145\n",
      "Elapsed time during model training:  56.06405758857727\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0633 - mae: 0.1657 - mse: 0.0633\n",
      "Epoch 00001: val_loss improved from inf to 0.02107, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0620,  mae:0.1640,  mse:0.0620,  val_loss:0.0211,  val_mae:0.1082,  val_mse:0.0211,  \n",
      "14926/14926 [==============================] - 2s 130us/sample - loss: 0.0620 - mae: 0.1640 - mse: 0.0620 - val_loss: 0.0211 - val_mae: 0.1082 - val_mse: 0.0211\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1067 - mse: 0.0216\n",
      "Epoch 00002: val_loss improved from 0.02107 to 0.01921, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0216 - mae: 0.1066 - mse: 0.0216 - val_loss: 0.0192 - val_mae: 0.1009 - val_mse: 0.0192\n",
      "Epoch 3/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0189 - mae: 0.0978 - mse: 0.0189\n",
      "Epoch 00003: val_loss improved from 0.01921 to 0.01893, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0189 - mae: 0.0978 - mse: 0.0189 - val_loss: 0.0189 - val_mae: 0.1018 - val_mse: 0.0189\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0181 - mae: 0.0961 - mse: 0.0181\n",
      "Epoch 00004: val_loss improved from 0.01893 to 0.01783, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0181 - mae: 0.0960 - mse: 0.0181 - val_loss: 0.0178 - val_mae: 0.0955 - val_mse: 0.0178\n",
      "Epoch 5/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0933 - mse: 0.0171\n",
      "Epoch 00005: val_loss did not improve from 0.01783\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0172 - mae: 0.0934 - mse: 0.0172 - val_loss: 0.0179 - val_mae: 0.0945 - val_mse: 0.0179\n",
      "Epoch 6/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0904 - mse: 0.0164\n",
      "Epoch 00006: val_loss improved from 0.01783 to 0.01622, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0164 - mae: 0.0903 - mse: 0.0164 - val_loss: 0.0162 - val_mae: 0.0887 - val_mse: 0.0162\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0894 - mse: 0.0160\n",
      "Epoch 00007: val_loss did not improve from 0.01622\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0161 - mae: 0.0895 - mse: 0.0161 - val_loss: 0.0225 - val_mae: 0.1105 - val_mse: 0.0225\n",
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.0889 - mse: 0.0156\n",
      "Epoch 00008: val_loss did not improve from 0.01622\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0157 - mae: 0.0892 - mse: 0.0157 - val_loss: 0.0176 - val_mae: 0.0933 - val_mse: 0.0176\n",
      "Elapsed time during model training:  12.468416452407837\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0426 - mae: 0.1450 - mse: 0.0426\n",
      "Epoch 00001: val_loss improved from inf to 0.03579, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0424,  mae:0.1446,  mse:0.0424,  val_loss:0.0358,  val_mae:0.1447,  val_mse:0.0358,  \n",
      "14926/14926 [==============================] - 2s 137us/sample - loss: 0.0424 - mae: 0.1446 - mse: 0.0424 - val_loss: 0.0358 - val_mae: 0.1447 - val_mse: 0.0358\n",
      "Epoch 2/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0238 - mae: 0.1138 - mse: 0.0238\n",
      "Epoch 00002: val_loss improved from 0.03579 to 0.02027, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 109us/sample - loss: 0.0238 - mae: 0.1137 - mse: 0.0238 - val_loss: 0.0203 - val_mae: 0.1098 - val_mse: 0.0203\n",
      "Epoch 3/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0211 - mae: 0.1065 - mse: 0.0211\n",
      "Epoch 00003: val_loss improved from 0.02027 to 0.01971, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0210 - mae: 0.1061 - mse: 0.0210 - val_loss: 0.0197 - val_mae: 0.1030 - val_mse: 0.0197\n",
      "Epoch 4/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0201 - mae: 0.1040 - mse: 0.0201\n",
      "Epoch 00004: val_loss improved from 0.01971 to 0.01819, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0201 - mae: 0.1039 - mse: 0.0201 - val_loss: 0.0182 - val_mae: 0.0988 - val_mse: 0.0182\n",
      "Epoch 5/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0189 - mae: 0.0997 - mse: 0.0189\n",
      "Epoch 00005: val_loss did not improve from 0.01819\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0188 - mae: 0.0998 - mse: 0.0188 - val_loss: 0.0201 - val_mae: 0.1031 - val_mse: 0.0201\n",
      "Epoch 6/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0976 - mse: 0.0179\n",
      "Epoch 00006: val_loss improved from 0.01819 to 0.01765, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0180 - mae: 0.0976 - mse: 0.0180 - val_loss: 0.0177 - val_mae: 0.0940 - val_mse: 0.0177\n",
      "Epoch 7/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0926 - mse: 0.0167\n",
      "Epoch 00007: val_loss improved from 0.01765 to 0.01546, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0166 - mae: 0.0924 - mse: 0.0166 - val_loss: 0.0155 - val_mae: 0.0856 - val_mse: 0.0155\n",
      "Epoch 8/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0939 - mse: 0.0171\n",
      "Epoch 00008: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0171 - mae: 0.0942 - mse: 0.0171 - val_loss: 0.0229 - val_mae: 0.1144 - val_mse: 0.0229\n",
      "Epoch 9/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0920 - mse: 0.0162\n",
      "Epoch 00009: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0162 - mae: 0.0920 - mse: 0.0162 - val_loss: 0.0163 - val_mae: 0.0928 - val_mse: 0.0163\n",
      "Epoch 10/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0899 - mse: 0.0157\n",
      "Epoch 00010: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0157 - mae: 0.0899 - mse: 0.0157 - val_loss: 0.0173 - val_mae: 0.0930 - val_mse: 0.0173\n",
      "Epoch 11/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0155 - mae: 0.0891 - mse: 0.0155\n",
      "Epoch 00011: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0154 - mae: 0.0890 - mse: 0.0154 - val_loss: 0.0182 - val_mae: 0.1026 - val_mse: 0.0182\n",
      "Epoch 12/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0861 - mse: 0.0143\n",
      "Epoch 00012: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0147 - mae: 0.0863 - mse: 0.0147 - val_loss: 0.0183 - val_mae: 0.1007 - val_mse: 0.0183\n",
      "Epoch 13/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0138 - mae: 0.0839 - mse: 0.0138\n",
      "Epoch 00013: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0138 - mae: 0.0839 - mse: 0.0138 - val_loss: 0.0164 - val_mae: 0.0894 - val_mse: 0.0164\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0841 - mse: 0.0140\n",
      "Epoch 00014: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0140 - mae: 0.0842 - mse: 0.0140 - val_loss: 0.0165 - val_mae: 0.0901 - val_mse: 0.0165\n",
      "Epoch 15/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0139 - mae: 0.0846 - mse: 0.0139\n",
      "Epoch 00015: val_loss did not improve from 0.01546\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0138 - mae: 0.0844 - mse: 0.0138 - val_loss: 0.0156 - val_mae: 0.0856 - val_mse: 0.0156\n",
      "Epoch 16/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0815 - mse: 0.0132\n",
      "Epoch 00016: val_loss improved from 0.01546 to 0.01501, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0131 - mae: 0.0812 - mse: 0.0131 - val_loss: 0.0150 - val_mae: 0.0827 - val_mse: 0.0150\n",
      "Epoch 17/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0129 - mae: 0.0811 - mse: 0.0129\n",
      "Epoch 00017: val_loss did not improve from 0.01501\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0129 - mae: 0.0810 - mse: 0.0129 - val_loss: 0.0182 - val_mae: 0.0953 - val_mse: 0.0182\n",
      "Epoch 18/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0822 - mse: 0.0133\n",
      "Epoch 00018: val_loss did not improve from 0.01501\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0133 - mae: 0.0821 - mse: 0.0133 - val_loss: 0.0204 - val_mae: 0.1101 - val_mse: 0.0204\n",
      "Epoch 19/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0782 - mse: 0.0122\n",
      "Epoch 00019: val_loss did not improve from 0.01501\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0122 - mae: 0.0783 - mse: 0.0122 - val_loss: 0.0182 - val_mae: 0.0939 - val_mse: 0.0182\n",
      "Epoch 20/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0768 - mse: 0.0116\n",
      "Epoch 00020: val_loss did not improve from 0.01501\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0119 - mae: 0.0769 - mse: 0.0119 - val_loss: 0.0187 - val_mae: 0.1030 - val_mse: 0.0187\n",
      "Epoch 21/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0768 - mse: 0.0117\n",
      "Epoch 00021: val_loss improved from 0.01501 to 0.01486, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0117 - mae: 0.0768 - mse: 0.0117 - val_loss: 0.0149 - val_mae: 0.0848 - val_mse: 0.0149\n",
      "Epoch 22/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0116 - mae: 0.0771 - mse: 0.0116\n",
      "Epoch 00022: val_loss did not improve from 0.01486\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0116 - mae: 0.0770 - mse: 0.0116 - val_loss: 0.0153 - val_mae: 0.0901 - val_mse: 0.0153\n",
      "Epoch 23/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0111 - mae: 0.0750 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01486\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0111 - mae: 0.0751 - mse: 0.0111 - val_loss: 0.0160 - val_mae: 0.0882 - val_mse: 0.0160\n",
      "Epoch 24/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0730 - mse: 0.0107\n",
      "Epoch 00024: val_loss improved from 0.01486 to 0.01469, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0108 - mae: 0.0731 - mse: 0.0108 - val_loss: 0.0147 - val_mae: 0.0852 - val_mse: 0.0147\n",
      "Epoch 25/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0723 - mse: 0.0106\n",
      "Epoch 00025: val_loss did not improve from 0.01469\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0106 - mae: 0.0725 - mse: 0.0106 - val_loss: 0.0163 - val_mae: 0.0888 - val_mse: 0.0163\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0728 - mse: 0.0106\n",
      "Epoch 00026: val_loss did not improve from 0.01469\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0106 - mae: 0.0728 - mse: 0.0106 - val_loss: 0.0154 - val_mae: 0.0848 - val_mse: 0.0154\n",
      "Epoch 27/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0104 - mae: 0.0722 - mse: 0.0104\n",
      "Epoch 00027: val_loss improved from 0.01469 to 0.01463, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0104 - mae: 0.0720 - mse: 0.0104 - val_loss: 0.0146 - val_mae: 0.0829 - val_mse: 0.0146\n",
      "Epoch 28/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0685 - mse: 0.0096\n",
      "Epoch 00028: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0096 - mae: 0.0686 - mse: 0.0096 - val_loss: 0.0148 - val_mae: 0.0847 - val_mse: 0.0148\n",
      "Epoch 29/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0705 - mse: 0.0101\n",
      "Epoch 00029: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0705 - mse: 0.0101 - val_loss: 0.0148 - val_mae: 0.0829 - val_mse: 0.0148\n",
      "Epoch 30/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0703 - mse: 0.0100\n",
      "Epoch 00030: val_loss did not improve from 0.01463\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0100 - mae: 0.0703 - mse: 0.0100 - val_loss: 0.0148 - val_mae: 0.0850 - val_mse: 0.0148\n",
      "Epoch 31/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0702 - mse: 0.0098\n",
      "Epoch 00031: val_loss improved from 0.01463 to 0.01433, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0098 - mae: 0.0702 - mse: 0.0098 - val_loss: 0.0143 - val_mae: 0.0823 - val_mse: 0.0143\n",
      "Epoch 32/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0675 - mse: 0.0089\n",
      "Epoch 00032: val_loss did not improve from 0.01433\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0092 - mae: 0.0678 - mse: 0.0092 - val_loss: 0.0152 - val_mae: 0.0859 - val_mse: 0.0152\n",
      "Epoch 33/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0669 - mse: 0.0089\n",
      "Epoch 00033: val_loss did not improve from 0.01433\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0090 - mae: 0.0670 - mse: 0.0090 - val_loss: 0.0154 - val_mae: 0.0842 - val_mse: 0.0154\n",
      "Epoch 34/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0670 - mse: 0.0090\n",
      "Epoch 00034: val_loss improved from 0.01433 to 0.01423, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0090 - mae: 0.0670 - mse: 0.0090 - val_loss: 0.0142 - val_mae: 0.0824 - val_mse: 0.0142\n",
      "Epoch 35/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0681 - mse: 0.0091\n",
      "Epoch 00035: val_loss improved from 0.01423 to 0.01403, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0091 - mae: 0.0681 - mse: 0.0091 - val_loss: 0.0140 - val_mae: 0.0794 - val_mse: 0.0140\n",
      "Epoch 36/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0641 - mse: 0.0084\n",
      "Epoch 00036: val_loss improved from 0.01403 to 0.01337, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0084 - mae: 0.0641 - mse: 0.0084 - val_loss: 0.0134 - val_mae: 0.0767 - val_mse: 0.0134\n",
      "Epoch 37/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0648 - mse: 0.0085\n",
      "Epoch 00037: val_loss improved from 0.01337 to 0.01331, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0085 - mae: 0.0647 - mse: 0.0085 - val_loss: 0.0133 - val_mae: 0.0767 - val_mse: 0.0133\n",
      "Epoch 38/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0646 - mse: 0.0084\n",
      "Epoch 00038: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0084 - mae: 0.0646 - mse: 0.0084 - val_loss: 0.0145 - val_mae: 0.0840 - val_mse: 0.0145\n",
      "Epoch 39/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0644 - mse: 0.0084\n",
      "Epoch 00039: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0084 - mae: 0.0644 - mse: 0.0084 - val_loss: 0.0141 - val_mae: 0.0808 - val_mse: 0.0141\n",
      "Epoch 40/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0078 - mae: 0.0621 - mse: 0.0078\n",
      "Epoch 00040: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0078 - mae: 0.0623 - mse: 0.0078 - val_loss: 0.0143 - val_mae: 0.0809 - val_mse: 0.0143\n",
      "Epoch 41/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0638 - mse: 0.0082\n",
      "Epoch 00041: val_loss did not improve from 0.01331\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0140 - val_mae: 0.0815 - val_mse: 0.0140\n",
      "Epoch 42/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0625 - mse: 0.0078\n",
      "Epoch 00042: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0079 - mae: 0.0625 - mse: 0.0079 - val_loss: 0.0143 - val_mae: 0.0837 - val_mse: 0.0143\n",
      "Epoch 43/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0609 - mse: 0.0075\n",
      "Epoch 00043: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0075 - mae: 0.0611 - mse: 0.0075 - val_loss: 0.0148 - val_mae: 0.0812 - val_mse: 0.0148\n",
      "Epoch 44/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0605 - mse: 0.0073\n",
      "Epoch 00044: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0073 - mae: 0.0604 - mse: 0.0073 - val_loss: 0.0152 - val_mae: 0.0861 - val_mse: 0.0152\n",
      "Epoch 45/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0619 - mse: 0.0076\n",
      "Epoch 00045: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0076 - mae: 0.0617 - mse: 0.0076 - val_loss: 0.0141 - val_mae: 0.0801 - val_mse: 0.0141\n",
      "Epoch 46/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0606 - mse: 0.0073\n",
      "Epoch 00046: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0073 - mae: 0.0606 - mse: 0.0073 - val_loss: 0.0148 - val_mae: 0.0832 - val_mse: 0.0148\n",
      "Epoch 47/1000\n",
      "14208/14926 [===========================>..] - ETA: 0s - loss: 0.0071 - mae: 0.0600 - mse: 0.0071\n",
      "Epoch 00047: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0071 - mae: 0.0600 - mse: 0.0071 - val_loss: 0.0148 - val_mae: 0.0828 - val_mse: 0.0148\n",
      "Epoch 48/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0601 - mse: 0.0071\n",
      "Epoch 00048: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0071 - mae: 0.0600 - mse: 0.0071 - val_loss: 0.0147 - val_mae: 0.0829 - val_mse: 0.0147\n",
      "Epoch 49/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0573 - mse: 0.0063\n",
      "Epoch 00049: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0066 - mae: 0.0578 - mse: 0.0066 - val_loss: 0.0148 - val_mae: 0.0842 - val_mse: 0.0148\n",
      "Epoch 50/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0603 - mse: 0.0072\n",
      "Epoch 00050: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0072 - mae: 0.0603 - mse: 0.0072 - val_loss: 0.0151 - val_mae: 0.0849 - val_mse: 0.0151\n",
      "Epoch 51/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0579 - mse: 0.0066\n",
      "Epoch 00051: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0066 - mae: 0.0580 - mse: 0.0066 - val_loss: 0.0173 - val_mae: 0.0932 - val_mse: 0.0173\n",
      "Epoch 52/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0604 - mse: 0.0073\n",
      "Epoch 00052: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0073 - mae: 0.0604 - mse: 0.0073 - val_loss: 0.0146 - val_mae: 0.0809 - val_mse: 0.0146\n",
      "Elapsed time during model training:  73.29143381118774\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0434 - mae: 0.1474 - mse: 0.0434\n",
      "Epoch 00001: val_loss improved from inf to 0.02845, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0433,  mae:0.1473,  mse:0.0433,  val_loss:0.0285,  val_mae:0.1273,  val_mse:0.0285,  \n",
      "14926/14926 [==============================] - 2s 146us/sample - loss: 0.0433 - mae: 0.1473 - mse: 0.0433 - val_loss: 0.0285 - val_mae: 0.1273 - val_mse: 0.0285\n",
      "Epoch 2/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0248 - mae: 0.1168 - mse: 0.0248\n",
      "Epoch 00002: val_loss improved from 0.02845 to 0.02124, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0247 - mae: 0.1167 - mse: 0.0247 - val_loss: 0.0212 - val_mae: 0.1117 - val_mse: 0.0212\n",
      "Epoch 3/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0208 - mae: 0.1056 - mse: 0.0208\n",
      "Epoch 00003: val_loss improved from 0.02124 to 0.01853, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0207 - mae: 0.1054 - mse: 0.0207 - val_loss: 0.0185 - val_mae: 0.1005 - val_mse: 0.0185\n",
      "Epoch 4/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0197 - mae: 0.1030 - mse: 0.0197\n",
      "Epoch 00004: val_loss did not improve from 0.01853\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0200 - mae: 0.1030 - mse: 0.0200 - val_loss: 0.0212 - val_mae: 0.1096 - val_mse: 0.0212\n",
      "Epoch 5/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1002 - mse: 0.0191\n",
      "Epoch 00005: val_loss did not improve from 0.01853\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0191 - mae: 0.1001 - mse: 0.0191 - val_loss: 0.0193 - val_mae: 0.1046 - val_mse: 0.0193\n",
      "Epoch 6/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0177 - mae: 0.0958 - mse: 0.0177\n",
      "Epoch 00006: val_loss did not improve from 0.01853\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0178 - mae: 0.0960 - mse: 0.0178 - val_loss: 0.0207 - val_mae: 0.1093 - val_mse: 0.0207\n",
      "Epoch 7/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0174 - mae: 0.0956 - mse: 0.0174\n",
      "Epoch 00007: val_loss did not improve from 0.01853\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0174 - mae: 0.0955 - mse: 0.0174 - val_loss: 0.0251 - val_mae: 0.1232 - val_mse: 0.0251\n",
      "Epoch 8/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0168 - mae: 0.0926 - mse: 0.0168\n",
      "Epoch 00008: val_loss improved from 0.01853 to 0.01779, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0168 - mae: 0.0928 - mse: 0.0168 - val_loss: 0.0178 - val_mae: 0.0968 - val_mse: 0.0178\n",
      "Epoch 9/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0158 - mae: 0.0900 - mse: 0.0158\n",
      "Epoch 00009: val_loss improved from 0.01779 to 0.01606, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0158 - mae: 0.0900 - mse: 0.0158 - val_loss: 0.0161 - val_mae: 0.0909 - val_mse: 0.0161\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0891 - mse: 0.0154\n",
      "Epoch 00010: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0154 - mae: 0.0892 - mse: 0.0154 - val_loss: 0.0178 - val_mae: 0.1017 - val_mse: 0.0178\n",
      "Epoch 11/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0154 - mae: 0.0887 - mse: 0.0154\n",
      "Epoch 00011: val_loss did not improve from 0.01606\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0153 - mae: 0.0885 - mse: 0.0153 - val_loss: 0.0167 - val_mae: 0.0927 - val_mse: 0.0167\n",
      "Epoch 12/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0852 - mse: 0.0143\n",
      "Epoch 00012: val_loss improved from 0.01606 to 0.01456, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0143 - mae: 0.0851 - mse: 0.0143 - val_loss: 0.0146 - val_mae: 0.0840 - val_mse: 0.0146\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0141 - mae: 0.0848 - mse: 0.0141\n",
      "Epoch 00013: val_loss did not improve from 0.01456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0141 - mae: 0.0848 - mse: 0.0141 - val_loss: 0.0191 - val_mae: 0.1048 - val_mse: 0.0191\n",
      "Epoch 14/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0139 - mae: 0.0836 - mse: 0.0139\n",
      "Epoch 00014: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0140 - mae: 0.0837 - mse: 0.0140 - val_loss: 0.0153 - val_mae: 0.0902 - val_mse: 0.0153\n",
      "Epoch 15/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0826 - mse: 0.0133\n",
      "Epoch 00015: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0133 - mae: 0.0825 - mse: 0.0133 - val_loss: 0.0148 - val_mae: 0.0852 - val_mse: 0.0148\n",
      "Epoch 16/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0799 - mse: 0.0130\n",
      "Epoch 00016: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0129 - mae: 0.0796 - mse: 0.0129 - val_loss: 0.0159 - val_mae: 0.0860 - val_mse: 0.0159\n",
      "Epoch 17/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0813 - mse: 0.0130\n",
      "Epoch 00017: val_loss improved from 0.01456 to 0.01437, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0129 - mae: 0.0812 - mse: 0.0129 - val_loss: 0.0144 - val_mae: 0.0855 - val_mse: 0.0144\n",
      "Epoch 18/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0780 - mse: 0.0123\n",
      "Epoch 00018: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0124 - mae: 0.0787 - mse: 0.0124 - val_loss: 0.0172 - val_mae: 0.0992 - val_mse: 0.0172\n",
      "Epoch 19/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0787 - mse: 0.0124\n",
      "Epoch 00019: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0124 - mae: 0.0787 - mse: 0.0124 - val_loss: 0.0158 - val_mae: 0.0890 - val_mse: 0.0158\n",
      "Epoch 20/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0779 - mse: 0.0121\n",
      "Epoch 00020: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0121 - mae: 0.0779 - mse: 0.0121 - val_loss: 0.0145 - val_mae: 0.0826 - val_mse: 0.0145\n",
      "Epoch 21/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0115 - mae: 0.0758 - mse: 0.0115\n",
      "Epoch 00021: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0114 - mae: 0.0757 - mse: 0.0114 - val_loss: 0.0154 - val_mae: 0.0905 - val_mse: 0.0154\n",
      "Epoch 22/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0729 - mse: 0.0105\n",
      "Epoch 00022: val_loss did not improve from 0.01437\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0109 - mae: 0.0734 - mse: 0.0109 - val_loss: 0.0161 - val_mae: 0.0933 - val_mse: 0.0161\n",
      "Epoch 23/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0757 - mse: 0.0114\n",
      "Epoch 00023: val_loss improved from 0.01437 to 0.01418, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0114 - mae: 0.0758 - mse: 0.0114 - val_loss: 0.0142 - val_mae: 0.0824 - val_mse: 0.0142\n",
      "Epoch 24/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0735 - mse: 0.0108\n",
      "Epoch 00024: val_loss improved from 0.01418 to 0.01394, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0108 - mae: 0.0734 - mse: 0.0108 - val_loss: 0.0139 - val_mae: 0.0794 - val_mse: 0.0139\n",
      "Epoch 25/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0747 - mse: 0.0111\n",
      "Epoch 00025: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0111 - mae: 0.0747 - mse: 0.0111 - val_loss: 0.0146 - val_mae: 0.0823 - val_mse: 0.0146\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0710 - mse: 0.0103\n",
      "Epoch 00026: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0103 - mae: 0.0710 - mse: 0.0103 - val_loss: 0.0140 - val_mae: 0.0799 - val_mse: 0.0140\n",
      "Epoch 27/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0103 - mae: 0.0713 - mse: 0.0103\n",
      "Epoch 00027: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0102 - mae: 0.0712 - mse: 0.0102 - val_loss: 0.0147 - val_mae: 0.0808 - val_mse: 0.0147\n",
      "Epoch 28/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0706 - mse: 0.0098\n",
      "Epoch 00028: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0101 - mae: 0.0706 - mse: 0.0101 - val_loss: 0.0148 - val_mae: 0.0888 - val_mse: 0.0148\n",
      "Epoch 29/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0690 - mse: 0.0097\n",
      "Epoch 00029: val_loss did not improve from 0.01394\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0097 - mae: 0.0691 - mse: 0.0097 - val_loss: 0.0148 - val_mae: 0.0844 - val_mse: 0.0148\n",
      "Epoch 30/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0665 - mse: 0.0091\n",
      "Epoch 00030: val_loss improved from 0.01394 to 0.01374, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0091 - mae: 0.0668 - mse: 0.0091 - val_loss: 0.0137 - val_mae: 0.0792 - val_mse: 0.0137\n",
      "Epoch 31/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0677 - mse: 0.0092\n",
      "Epoch 00031: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0092 - mae: 0.0678 - mse: 0.0092 - val_loss: 0.0176 - val_mae: 0.0975 - val_mse: 0.0176\n",
      "Epoch 32/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0687 - mse: 0.0091\n",
      "Epoch 00032: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0094 - mae: 0.0689 - mse: 0.0094 - val_loss: 0.0182 - val_mae: 0.0980 - val_mse: 0.0182\n",
      "Epoch 33/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0672 - mse: 0.0089\n",
      "Epoch 00033: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0092 - mae: 0.0673 - mse: 0.0092 - val_loss: 0.0147 - val_mae: 0.0866 - val_mse: 0.0147\n",
      "Epoch 34/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0679 - mse: 0.0092\n",
      "Epoch 00034: val_loss improved from 0.01374 to 0.01374, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0092 - mae: 0.0680 - mse: 0.0092 - val_loss: 0.0137 - val_mae: 0.0787 - val_mse: 0.0137\n",
      "Epoch 35/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0664 - mse: 0.0089\n",
      "Epoch 00035: val_loss did not improve from 0.01374\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0089 - mae: 0.0664 - mse: 0.0089 - val_loss: 0.0140 - val_mae: 0.0816 - val_mse: 0.0140\n",
      "Epoch 36/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0649 - mse: 0.0085\n",
      "Epoch 00036: val_loss improved from 0.01374 to 0.01338, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0085 - mae: 0.0649 - mse: 0.0085 - val_loss: 0.0134 - val_mae: 0.0773 - val_mse: 0.0134\n",
      "Epoch 37/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0650 - mse: 0.0084\n",
      "Epoch 00037: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0084 - mae: 0.0649 - mse: 0.0084 - val_loss: 0.0156 - val_mae: 0.0838 - val_mse: 0.0156\n",
      "Epoch 38/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0083 - mae: 0.0643 - mse: 0.0083\n",
      "Epoch 00038: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0083 - mae: 0.0646 - mse: 0.0083 - val_loss: 0.0142 - val_mae: 0.0818 - val_mse: 0.0142\n",
      "Epoch 39/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0651 - mse: 0.0085\n",
      "Epoch 00039: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0085 - mae: 0.0650 - mse: 0.0085 - val_loss: 0.0135 - val_mae: 0.0770 - val_mse: 0.0135\n",
      "Epoch 40/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0616 - mse: 0.0076\n",
      "Epoch 00040: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0077 - mae: 0.0618 - mse: 0.0077 - val_loss: 0.0163 - val_mae: 0.0913 - val_mse: 0.0163\n",
      "Epoch 41/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0608 - mse: 0.0072\n",
      "Epoch 00041: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0075 - mae: 0.0611 - mse: 0.0075 - val_loss: 0.0159 - val_mae: 0.0874 - val_mse: 0.0159\n",
      "Epoch 42/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0639 - mse: 0.0081\n",
      "Epoch 00042: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0081 - mae: 0.0639 - mse: 0.0081 - val_loss: 0.0139 - val_mae: 0.0781 - val_mse: 0.0139\n",
      "Epoch 43/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0607 - mse: 0.0075\n",
      "Epoch 00043: val_loss did not improve from 0.01338\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0075 - mae: 0.0607 - mse: 0.0075 - val_loss: 0.0139 - val_mae: 0.0803 - val_mse: 0.0139\n",
      "Epoch 44/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0604 - mse: 0.0074\n",
      "Epoch 00044: val_loss improved from 0.01338 to 0.01316, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 107us/sample - loss: 0.0074 - mae: 0.0604 - mse: 0.0074 - val_loss: 0.0132 - val_mae: 0.0774 - val_mse: 0.0132\n",
      "Epoch 45/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0608 - mse: 0.0073\n",
      "Epoch 00045: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0073 - mae: 0.0610 - mse: 0.0073 - val_loss: 0.0148 - val_mae: 0.0815 - val_mse: 0.0148\n",
      "Epoch 46/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0600 - mse: 0.0074\n",
      "Epoch 00046: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0073 - mae: 0.0601 - mse: 0.0073 - val_loss: 0.0148 - val_mae: 0.0850 - val_mse: 0.0148\n",
      "Epoch 47/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0609 - mse: 0.0073\n",
      "Epoch 00047: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0073 - mae: 0.0610 - mse: 0.0073 - val_loss: 0.0142 - val_mae: 0.0812 - val_mse: 0.0142\n",
      "Epoch 48/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0596 - mse: 0.0071\n",
      "Epoch 00048: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0073 - mae: 0.0597 - mse: 0.0073 - val_loss: 0.0150 - val_mae: 0.0866 - val_mse: 0.0150\n",
      "Epoch 49/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0596 - mse: 0.0073\n",
      "Epoch 00049: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0073 - mae: 0.0596 - mse: 0.0073 - val_loss: 0.0145 - val_mae: 0.0796 - val_mse: 0.0145\n",
      "Epoch 50/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0601 - mse: 0.0073\n",
      "Epoch 00050: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0072 - mae: 0.0600 - mse: 0.0072 - val_loss: 0.0149 - val_mae: 0.0830 - val_mse: 0.0149\n",
      "Epoch 51/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0583 - mse: 0.0069\n",
      "Epoch 00051: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0069 - mae: 0.0583 - mse: 0.0069 - val_loss: 0.0139 - val_mae: 0.0781 - val_mse: 0.0139\n",
      "Epoch 52/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0574 - mse: 0.0067\n",
      "Epoch 00052: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0067 - mae: 0.0574 - mse: 0.0067 - val_loss: 0.0137 - val_mae: 0.0801 - val_mse: 0.0137\n",
      "Epoch 53/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0564 - mse: 0.0064\n",
      "Epoch 00053: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0064 - mae: 0.0565 - mse: 0.0064 - val_loss: 0.0136 - val_mae: 0.0803 - val_mse: 0.0136\n",
      "Epoch 54/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0571 - mse: 0.0065\n",
      "Epoch 00054: val_loss improved from 0.01316 to 0.01315, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0065 - mae: 0.0571 - mse: 0.0065 - val_loss: 0.0132 - val_mae: 0.0758 - val_mse: 0.0132\n",
      "Epoch 55/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0587 - mse: 0.0068\n",
      "Epoch 00055: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0068 - mae: 0.0587 - mse: 0.0068 - val_loss: 0.0136 - val_mae: 0.0778 - val_mse: 0.0136\n",
      "Epoch 56/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0553 - mse: 0.0063\n",
      "Epoch 00056: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0063 - mae: 0.0553 - mse: 0.0063 - val_loss: 0.0149 - val_mae: 0.0813 - val_mse: 0.0149\n",
      "Epoch 57/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0562 - mse: 0.0063\n",
      "Epoch 00057: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0063 - mae: 0.0562 - mse: 0.0063 - val_loss: 0.0133 - val_mae: 0.0780 - val_mse: 0.0133\n",
      "Epoch 58/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0059 - mae: 0.0543 - mse: 0.0059\n",
      "Epoch 00058: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0059 - mae: 0.0544 - mse: 0.0059 - val_loss: 0.0140 - val_mae: 0.0772 - val_mse: 0.0140\n",
      "Epoch 59/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0554 - mse: 0.0063\n",
      "Epoch 00059: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0063 - mae: 0.0553 - mse: 0.0063 - val_loss: 0.0141 - val_mae: 0.0833 - val_mse: 0.0141\n",
      "Epoch 60/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0548 - mse: 0.0060\n",
      "Epoch 00060: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0060 - mae: 0.0548 - mse: 0.0060 - val_loss: 0.0139 - val_mae: 0.0776 - val_mse: 0.0139\n",
      "Epoch 61/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0059 - mae: 0.0541 - mse: 0.0059\n",
      "Epoch 00061: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0059 - mae: 0.0542 - mse: 0.0059 - val_loss: 0.0139 - val_mae: 0.0782 - val_mse: 0.0139\n",
      "Epoch 62/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0055 - mae: 0.0526 - mse: 0.0055\n",
      "Epoch 00062: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0054 - mae: 0.0525 - mse: 0.0054 - val_loss: 0.0132 - val_mae: 0.0755 - val_mse: 0.0132\n",
      "Epoch 63/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0528 - mse: 0.0056\n",
      "Epoch 00063: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0056 - mae: 0.0528 - mse: 0.0056 - val_loss: 0.0133 - val_mae: 0.0760 - val_mse: 0.0133\n",
      "Epoch 64/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0537 - mse: 0.0057\n",
      "Epoch 00064: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0057 - mae: 0.0536 - mse: 0.0057 - val_loss: 0.0140 - val_mae: 0.0776 - val_mse: 0.0140\n",
      "Epoch 65/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0528 - mse: 0.0056\n",
      "Epoch 00065: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0056 - mae: 0.0530 - mse: 0.0056 - val_loss: 0.0136 - val_mae: 0.0785 - val_mse: 0.0136\n",
      "Epoch 66/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0053 - mae: 0.0521 - mse: 0.0053\n",
      "Epoch 00066: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0054 - mae: 0.0523 - mse: 0.0054 - val_loss: 0.0188 - val_mae: 0.0924 - val_mse: 0.0188\n",
      "Epoch 67/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0055 - mae: 0.0531 - mse: 0.0055\n",
      "Epoch 00067: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0056 - mae: 0.0532 - mse: 0.0056 - val_loss: 0.0157 - val_mae: 0.0831 - val_mse: 0.0157\n",
      "Elapsed time during model training:  96.04995656013489\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0424 - mae: 0.1417 - mse: 0.0424\n",
      "Epoch 00001: val_loss improved from inf to 0.01990, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0424,  mae:0.1417,  mse:0.0424,  val_loss:0.0199,  val_mae:0.1029,  val_mse:0.0199,  \n",
      "14926/14926 [==============================] - 2s 148us/sample - loss: 0.0424 - mae: 0.1417 - mse: 0.0424 - val_loss: 0.0199 - val_mae: 0.1029 - val_mse: 0.0199\n",
      "Epoch 2/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0233 - mae: 0.1115 - mse: 0.0233\n",
      "Epoch 00002: val_loss did not improve from 0.01990\n",
      "14926/14926 [==============================] - 2s 116us/sample - loss: 0.0233 - mae: 0.1115 - mse: 0.0233 - val_loss: 0.0241 - val_mae: 0.1092 - val_mse: 0.0241\n",
      "Epoch 3/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0206 - mae: 0.1042 - mse: 0.0206\n",
      "Epoch 00003: val_loss did not improve from 0.01990\n",
      "14926/14926 [==============================] - 2s 108us/sample - loss: 0.0206 - mae: 0.1041 - mse: 0.0206 - val_loss: 0.0201 - val_mae: 0.1079 - val_mse: 0.0201\n",
      "Epoch 4/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0179 - mae: 0.0969 - mse: 0.0179\n",
      "Epoch 00004: val_loss did not improve from 0.01990\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0183 - mae: 0.0972 - mse: 0.0183 - val_loss: 0.0231 - val_mae: 0.1121 - val_mse: 0.0231\n",
      "Epoch 5/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0199 - mae: 0.1026 - mse: 0.0199\n",
      "Epoch 00005: val_loss improved from 0.01990 to 0.01886, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0198 - mae: 0.1021 - mse: 0.0198 - val_loss: 0.0189 - val_mae: 0.1006 - val_mse: 0.0189\n",
      "Epoch 6/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0177 - mae: 0.0961 - mse: 0.0177\n",
      "Epoch 00006: val_loss improved from 0.01886 to 0.01608, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0176 - mae: 0.0960 - mse: 0.0176 - val_loss: 0.0161 - val_mae: 0.0885 - val_mse: 0.0161\n",
      "Epoch 7/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0170 - mae: 0.0934 - mse: 0.0170\n",
      "Epoch 00007: val_loss did not improve from 0.01608\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0169 - mae: 0.0932 - mse: 0.0169 - val_loss: 0.0191 - val_mae: 0.1017 - val_mse: 0.0191\n",
      "Epoch 8/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0899 - mse: 0.0160\n",
      "Epoch 00008: val_loss did not improve from 0.01608\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0160 - mae: 0.0898 - mse: 0.0160 - val_loss: 0.0169 - val_mae: 0.0969 - val_mse: 0.0169\n",
      "Epoch 9/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0876 - mse: 0.0153\n",
      "Epoch 00009: val_loss did not improve from 0.01608\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0153 - mae: 0.0876 - mse: 0.0153 - val_loss: 0.0171 - val_mae: 0.0937 - val_mse: 0.0171\n",
      "Epoch 10/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0153 - mae: 0.0884 - mse: 0.0153\n",
      "Epoch 00010: val_loss did not improve from 0.01608\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0153 - mae: 0.0885 - mse: 0.0153 - val_loss: 0.0164 - val_mae: 0.0934 - val_mse: 0.0164\n",
      "Epoch 11/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0143 - mae: 0.0847 - mse: 0.0143\n",
      "Epoch 00011: val_loss improved from 0.01608 to 0.01560, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0143 - mae: 0.0847 - mse: 0.0143 - val_loss: 0.0156 - val_mae: 0.0877 - val_mse: 0.0156\n",
      "Epoch 12/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0853 - mse: 0.0144\n",
      "Epoch 00012: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0143 - mae: 0.0852 - mse: 0.0143 - val_loss: 0.0162 - val_mae: 0.0929 - val_mse: 0.0162\n",
      "Epoch 13/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0145 - mae: 0.0864 - mse: 0.0145\n",
      "Epoch 00013: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0145 - mae: 0.0864 - mse: 0.0145 - val_loss: 0.0171 - val_mae: 0.0950 - val_mse: 0.0171\n",
      "Epoch 14/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0810 - mse: 0.0132\n",
      "Epoch 00014: val_loss did not improve from 0.01560\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0132 - mae: 0.0810 - mse: 0.0132 - val_loss: 0.0186 - val_mae: 0.1028 - val_mse: 0.0186\n",
      "Epoch 15/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0132 - mae: 0.0813 - mse: 0.0132\n",
      "Epoch 00015: val_loss improved from 0.01560 to 0.01415, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0132 - mae: 0.0813 - mse: 0.0132 - val_loss: 0.0142 - val_mae: 0.0814 - val_mse: 0.0142\n",
      "Epoch 16/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0793 - mse: 0.0128\n",
      "Epoch 00016: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0128 - mae: 0.0793 - mse: 0.0128 - val_loss: 0.0156 - val_mae: 0.0868 - val_mse: 0.0156\n",
      "Epoch 17/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0811 - mse: 0.0131\n",
      "Epoch 00017: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0130 - mae: 0.0809 - mse: 0.0130 - val_loss: 0.0152 - val_mae: 0.0882 - val_mse: 0.0152\n",
      "Epoch 18/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0121 - mae: 0.0776 - mse: 0.0121\n",
      "Epoch 00018: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0121 - mae: 0.0777 - mse: 0.0121 - val_loss: 0.0158 - val_mae: 0.0884 - val_mse: 0.0158\n",
      "Epoch 19/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0764 - mse: 0.0119\n",
      "Epoch 00019: val_loss improved from 0.01415 to 0.01401, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0119 - mae: 0.0764 - mse: 0.0119 - val_loss: 0.0140 - val_mae: 0.0833 - val_mse: 0.0140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0114 - mae: 0.0754 - mse: 0.0114\n",
      "Epoch 00020: val_loss did not improve from 0.01401\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0115 - mae: 0.0757 - mse: 0.0115 - val_loss: 0.0168 - val_mae: 0.0950 - val_mse: 0.0168\n",
      "Epoch 21/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0746 - mse: 0.0112\n",
      "Epoch 00021: val_loss did not improve from 0.01401\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0112 - mae: 0.0746 - mse: 0.0112 - val_loss: 0.0161 - val_mae: 0.0881 - val_mse: 0.0161\n",
      "Epoch 22/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0112 - mae: 0.0744 - mse: 0.0112\n",
      "Epoch 00022: val_loss improved from 0.01401 to 0.01358, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0111 - mae: 0.0742 - mse: 0.0111 - val_loss: 0.0136 - val_mae: 0.0798 - val_mse: 0.0136\n",
      "Epoch 23/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0748 - mse: 0.0111\n",
      "Epoch 00023: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0112 - mae: 0.0750 - mse: 0.0112 - val_loss: 0.0148 - val_mae: 0.0846 - val_mse: 0.0148\n",
      "Epoch 24/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0110 - mae: 0.0741 - mse: 0.0110\n",
      "Epoch 00024: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0110 - mae: 0.0740 - mse: 0.0110 - val_loss: 0.0139 - val_mae: 0.0800 - val_mse: 0.0139\n",
      "Epoch 25/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0700 - mse: 0.0101\n",
      "Epoch 00025: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0702 - mse: 0.0101 - val_loss: 0.0152 - val_mae: 0.0852 - val_mse: 0.0152\n",
      "Epoch 26/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0695 - mse: 0.0096\n",
      "Epoch 00026: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0100 - mae: 0.0701 - mse: 0.0100 - val_loss: 0.0205 - val_mae: 0.1084 - val_mse: 0.0205\n",
      "Epoch 27/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0701 - mse: 0.0101\n",
      "Epoch 00027: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0100 - mae: 0.0700 - mse: 0.0100 - val_loss: 0.0152 - val_mae: 0.0815 - val_mse: 0.0152\n",
      "Epoch 28/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0697 - mse: 0.0099\n",
      "Epoch 00028: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0099 - mae: 0.0698 - mse: 0.0099 - val_loss: 0.0164 - val_mae: 0.0907 - val_mse: 0.0164\n",
      "Epoch 29/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0684 - mse: 0.0094\n",
      "Epoch 00029: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0094 - mae: 0.0682 - mse: 0.0094 - val_loss: 0.0145 - val_mae: 0.0805 - val_mse: 0.0145\n",
      "Epoch 30/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0673 - mse: 0.0092\n",
      "Epoch 00030: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0092 - mae: 0.0673 - mse: 0.0092 - val_loss: 0.0166 - val_mae: 0.0943 - val_mse: 0.0166\n",
      "Epoch 31/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0670 - mse: 0.0092\n",
      "Epoch 00031: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0092 - mae: 0.0670 - mse: 0.0092 - val_loss: 0.0145 - val_mae: 0.0826 - val_mse: 0.0145\n",
      "Epoch 32/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0679 - mse: 0.0094\n",
      "Epoch 00032: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0093 - mae: 0.0679 - mse: 0.0093 - val_loss: 0.0185 - val_mae: 0.0984 - val_mse: 0.0185\n",
      "Epoch 33/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0672 - mse: 0.0091\n",
      "Epoch 00033: val_loss did not improve from 0.01358\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0092 - mae: 0.0674 - mse: 0.0092 - val_loss: 0.0148 - val_mae: 0.0842 - val_mse: 0.0148\n",
      "Elapsed time during model training:  48.369587421417236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0435 - mae: 0.1435 - mse: 0.0435\n",
      "Epoch 00001: val_loss improved from inf to 0.02112, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0430,  mae:0.1428,  mse:0.0430,  val_loss:0.0211,  val_mae:0.1077,  val_mse:0.0211,  \n",
      "14926/14926 [==============================] - 2s 145us/sample - loss: 0.0430 - mae: 0.1428 - mse: 0.0430 - val_loss: 0.0211 - val_mae: 0.1077 - val_mse: 0.0211\n",
      "Epoch 2/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0218 - mae: 0.1075 - mse: 0.0218\n",
      "Epoch 00002: val_loss did not improve from 0.02112\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0218 - mae: 0.1077 - mse: 0.0218 - val_loss: 0.0220 - val_mae: 0.1054 - val_mse: 0.0220\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1004 - mse: 0.0191\n",
      "Epoch 00003: val_loss did not improve from 0.02112\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0193 - mae: 0.1005 - mse: 0.0193 - val_loss: 0.0219 - val_mae: 0.1106 - val_mse: 0.0219\n",
      "Epoch 4/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0184 - mae: 0.0991 - mse: 0.0184\n",
      "Epoch 00004: val_loss did not improve from 0.02112\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0185 - mae: 0.0996 - mse: 0.0185 - val_loss: 0.0302 - val_mae: 0.1312 - val_mse: 0.0302\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0177 - mae: 0.0954 - mse: 0.0177\n",
      "Epoch 00005: val_loss improved from 0.02112 to 0.01616, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0178 - mae: 0.0954 - mse: 0.0178 - val_loss: 0.0162 - val_mae: 0.0882 - val_mse: 0.0162\n",
      "Epoch 6/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0907 - mse: 0.0161\n",
      "Epoch 00006: val_loss improved from 0.01616 to 0.01596, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0161 - mae: 0.0907 - mse: 0.0161 - val_loss: 0.0160 - val_mae: 0.0879 - val_mse: 0.0160\n",
      "Epoch 7/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0907 - mse: 0.0161\n",
      "Epoch 00007: val_loss did not improve from 0.01596\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0161 - mae: 0.0907 - mse: 0.0161 - val_loss: 0.0255 - val_mae: 0.1259 - val_mse: 0.0255\n",
      "Epoch 8/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0901 - mse: 0.0157\n",
      "Epoch 00008: val_loss did not improve from 0.01596\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0157 - mae: 0.0900 - mse: 0.0157 - val_loss: 0.0175 - val_mae: 0.0944 - val_mse: 0.0175\n",
      "Epoch 9/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0864 - mse: 0.0148\n",
      "Epoch 00009: val_loss did not improve from 0.01596\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0149 - mae: 0.0867 - mse: 0.0149 - val_loss: 0.0172 - val_mae: 0.0904 - val_mse: 0.0172\n",
      "Epoch 10/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0144 - mae: 0.0869 - mse: 0.0144\n",
      "Epoch 00010: val_loss improved from 0.01596 to 0.01561, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0148 - mae: 0.0871 - mse: 0.0148 - val_loss: 0.0156 - val_mae: 0.0906 - val_mse: 0.0156\n",
      "Epoch 11/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0847 - mse: 0.0142\n",
      "Epoch 00011: val_loss did not improve from 0.01561\n",
      "14926/14926 [==============================] - 2s 126us/sample - loss: 0.0142 - mae: 0.0847 - mse: 0.0142 - val_loss: 0.0158 - val_mae: 0.0887 - val_mse: 0.0158\n",
      "Epoch 12/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0831 - mse: 0.0137\n",
      "Epoch 00012: val_loss improved from 0.01561 to 0.01480, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0136 - mae: 0.0828 - mse: 0.0136 - val_loss: 0.0148 - val_mae: 0.0839 - val_mse: 0.0148\n",
      "Epoch 13/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0128 - mae: 0.0800 - mse: 0.0128\n",
      "Epoch 00013: val_loss did not improve from 0.01480\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0127 - mae: 0.0800 - mse: 0.0127 - val_loss: 0.0170 - val_mae: 0.0928 - val_mse: 0.0170\n",
      "Epoch 14/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0122 - mae: 0.0771 - mse: 0.0122\n",
      "Epoch 00014: val_loss did not improve from 0.01480\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0121 - mae: 0.0771 - mse: 0.0121 - val_loss: 0.0173 - val_mae: 0.0963 - val_mse: 0.0173\n",
      "Epoch 15/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0789 - mse: 0.0123\n",
      "Epoch 00015: val_loss did not improve from 0.01480\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0123 - mae: 0.0788 - mse: 0.0123 - val_loss: 0.0180 - val_mae: 0.0978 - val_mse: 0.0180\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0118 - mae: 0.0764 - mse: 0.0118\n",
      "Epoch 00016: val_loss improved from 0.01480 to 0.01455, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0119 - mae: 0.0766 - mse: 0.0119 - val_loss: 0.0146 - val_mae: 0.0882 - val_mse: 0.0146\n",
      "Epoch 17/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0759 - mse: 0.0117\n",
      "Epoch 00017: val_loss improved from 0.01455 to 0.01418, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0118 - mae: 0.0761 - mse: 0.0118 - val_loss: 0.0142 - val_mae: 0.0829 - val_mse: 0.0142\n",
      "Epoch 18/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0115 - mae: 0.0759 - mse: 0.0115\n",
      "Epoch 00018: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0115 - mae: 0.0759 - mse: 0.0115 - val_loss: 0.0149 - val_mae: 0.0841 - val_mse: 0.0149\n",
      "Epoch 19/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0734 - mse: 0.0105\n",
      "Epoch 00019: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0108 - mae: 0.0735 - mse: 0.0108 - val_loss: 0.0147 - val_mae: 0.0835 - val_mse: 0.0147\n",
      "Epoch 20/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0713 - mse: 0.0104\n",
      "Epoch 00020: val_loss did not improve from 0.01418\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0103 - mae: 0.0713 - mse: 0.0103 - val_loss: 0.0208 - val_mae: 0.1077 - val_mse: 0.0208\n",
      "Epoch 21/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0724 - mse: 0.0104\n",
      "Epoch 00021: val_loss improved from 0.01418 to 0.01395, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0104 - mae: 0.0723 - mse: 0.0104 - val_loss: 0.0140 - val_mae: 0.0781 - val_mse: 0.0140\n",
      "Epoch 22/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0693 - mse: 0.0098\n",
      "Epoch 00022: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0098 - mae: 0.0693 - mse: 0.0098 - val_loss: 0.0142 - val_mae: 0.0782 - val_mse: 0.0142\n",
      "Epoch 23/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0689 - mse: 0.0098\n",
      "Epoch 00023: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0097 - mae: 0.0689 - mse: 0.0097 - val_loss: 0.0153 - val_mae: 0.0860 - val_mse: 0.0153\n",
      "Epoch 24/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0701 - mse: 0.0098\n",
      "Epoch 00024: val_loss did not improve from 0.01395\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0098 - mae: 0.0702 - mse: 0.0098 - val_loss: 0.0159 - val_mae: 0.0916 - val_mse: 0.0159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0661 - mse: 0.0089\n",
      "Epoch 00025: val_loss improved from 0.01395 to 0.01354, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0089 - mae: 0.0662 - mse: 0.0089 - val_loss: 0.0135 - val_mae: 0.0811 - val_mse: 0.0135\n",
      "Epoch 26/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0665 - mse: 0.0089\n",
      "Epoch 00026: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0088 - mae: 0.0666 - mse: 0.0088 - val_loss: 0.0146 - val_mae: 0.0839 - val_mse: 0.0146\n",
      "Epoch 27/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0652 - mse: 0.0087\n",
      "Epoch 00027: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0087 - mae: 0.0654 - mse: 0.0087 - val_loss: 0.0154 - val_mae: 0.0822 - val_mse: 0.0154\n",
      "Epoch 28/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0650 - mse: 0.0087\n",
      "Epoch 00028: val_loss improved from 0.01354 to 0.01341, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0086 - mae: 0.0649 - mse: 0.0086 - val_loss: 0.0134 - val_mae: 0.0787 - val_mse: 0.0134\n",
      "Epoch 29/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0640 - mse: 0.0083\n",
      "Epoch 00029: val_loss improved from 0.01341 to 0.01309, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0083 - mae: 0.0640 - mse: 0.0083 - val_loss: 0.0131 - val_mae: 0.0760 - val_mse: 0.0131\n",
      "Epoch 30/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0618 - mse: 0.0078\n",
      "Epoch 00030: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0078 - mae: 0.0618 - mse: 0.0078 - val_loss: 0.0156 - val_mae: 0.0905 - val_mse: 0.0156\n",
      "Epoch 31/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0636 - mse: 0.0083\n",
      "Epoch 00031: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0083 - mae: 0.0636 - mse: 0.0083 - val_loss: 0.0133 - val_mae: 0.0781 - val_mse: 0.0133\n",
      "Epoch 32/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0612 - mse: 0.0077\n",
      "Epoch 00032: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0077 - mae: 0.0612 - mse: 0.0077 - val_loss: 0.0137 - val_mae: 0.0792 - val_mse: 0.0137\n",
      "Epoch 33/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0598 - mse: 0.0073\n",
      "Epoch 00033: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0073 - mae: 0.0598 - mse: 0.0073 - val_loss: 0.0139 - val_mae: 0.0800 - val_mse: 0.0139\n",
      "Epoch 34/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0599 - mse: 0.0074\n",
      "Epoch 00034: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0074 - mae: 0.0598 - mse: 0.0074 - val_loss: 0.0136 - val_mae: 0.0775 - val_mse: 0.0136\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0581 - mse: 0.0068\n",
      "Epoch 00035: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0070 - mae: 0.0584 - mse: 0.0070 - val_loss: 0.0150 - val_mae: 0.0905 - val_mse: 0.0150\n",
      "Epoch 36/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0586 - mse: 0.0069\n",
      "Epoch 00036: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0069 - mae: 0.0585 - mse: 0.0069 - val_loss: 0.0147 - val_mae: 0.0842 - val_mse: 0.0147\n",
      "Epoch 37/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0577 - mse: 0.0069\n",
      "Epoch 00037: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0069 - mae: 0.0579 - mse: 0.0069 - val_loss: 0.0162 - val_mae: 0.0890 - val_mse: 0.0162\n",
      "Epoch 38/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0578 - mse: 0.0068\n",
      "Epoch 00038: val_loss did not improve from 0.01309\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0068 - mae: 0.0578 - mse: 0.0068 - val_loss: 0.0142 - val_mae: 0.0831 - val_mse: 0.0142\n",
      "Epoch 39/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0561 - mse: 0.0064\n",
      "Epoch 00039: val_loss improved from 0.01309 to 0.01289, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0063 - mae: 0.0560 - mse: 0.0063 - val_loss: 0.0129 - val_mae: 0.0754 - val_mse: 0.0129\n",
      "Epoch 40/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0545 - mse: 0.0061\n",
      "Epoch 00040: val_loss did not improve from 0.01289\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0061 - mae: 0.0545 - mse: 0.0061 - val_loss: 0.0142 - val_mae: 0.0766 - val_mse: 0.0142\n",
      "Epoch 41/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0063 - mae: 0.0557 - mse: 0.0063\n",
      "Epoch 00041: val_loss did not improve from 0.01289\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0063 - mae: 0.0558 - mse: 0.0063 - val_loss: 0.0130 - val_mae: 0.0758 - val_mse: 0.0130\n",
      "Epoch 42/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0547 - mse: 0.0060\n",
      "Epoch 00042: val_loss improved from 0.01289 to 0.01254, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0060 - mae: 0.0547 - mse: 0.0060 - val_loss: 0.0125 - val_mae: 0.0748 - val_mse: 0.0125\n",
      "Epoch 43/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0059 - mae: 0.0538 - mse: 0.0059\n",
      "Epoch 00043: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0059 - mae: 0.0538 - mse: 0.0059 - val_loss: 0.0148 - val_mae: 0.0840 - val_mse: 0.0148\n",
      "Epoch 44/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0545 - mse: 0.0061\n",
      "Epoch 00044: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0061 - mae: 0.0545 - mse: 0.0061 - val_loss: 0.0137 - val_mae: 0.0789 - val_mse: 0.0137\n",
      "Epoch 45/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0525 - mse: 0.0056\n",
      "Epoch 00045: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0056 - mae: 0.0524 - mse: 0.0056 - val_loss: 0.0138 - val_mae: 0.0783 - val_mse: 0.0138\n",
      "Epoch 46/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0519 - mse: 0.0054\n",
      "Epoch 00046: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0054 - mae: 0.0518 - mse: 0.0054 - val_loss: 0.0132 - val_mae: 0.0755 - val_mse: 0.0132\n",
      "Epoch 47/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0508 - mse: 0.0052\n",
      "Epoch 00047: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 2s 118us/sample - loss: 0.0052 - mae: 0.0509 - mse: 0.0052 - val_loss: 0.0135 - val_mae: 0.0788 - val_mse: 0.0135\n",
      "Epoch 48/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0502 - mse: 0.0051\n",
      "Epoch 00048: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0053 - mae: 0.0505 - mse: 0.0053 - val_loss: 0.0152 - val_mae: 0.0828 - val_mse: 0.0152\n",
      "Epoch 49/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0514 - mse: 0.0054\n",
      "Epoch 00049: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0054 - mae: 0.0514 - mse: 0.0054 - val_loss: 0.0143 - val_mae: 0.0801 - val_mse: 0.0143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0505 - mse: 0.0051\n",
      "Epoch 00050: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0051 - mae: 0.0507 - mse: 0.0051 - val_loss: 0.0138 - val_mae: 0.0784 - val_mse: 0.0138\n",
      "Epoch 51/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0047 - mae: 0.0491 - mse: 0.0047\n",
      "Epoch 00051: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0047 - mae: 0.0491 - mse: 0.0047 - val_loss: 0.0134 - val_mae: 0.0760 - val_mse: 0.0134\n",
      "Epoch 52/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0049 - mae: 0.0490 - mse: 0.0049\n",
      "Epoch 00052: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0049 - mae: 0.0490 - mse: 0.0049 - val_loss: 0.0136 - val_mae: 0.0790 - val_mse: 0.0136\n",
      "Epoch 53/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0486 - mse: 0.0046\n",
      "Epoch 00053: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0046 - mae: 0.0486 - mse: 0.0046 - val_loss: 0.0136 - val_mae: 0.0779 - val_mse: 0.0136\n",
      "Epoch 54/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0049 - mae: 0.0486 - mse: 0.0049\n",
      "Epoch 00054: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0049 - mae: 0.0486 - mse: 0.0049 - val_loss: 0.0130 - val_mae: 0.0768 - val_mse: 0.0130\n",
      "Epoch 55/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0043 - mae: 0.0469 - mse: 0.0043\n",
      "Epoch 00055: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0046 - mae: 0.0470 - mse: 0.0046 - val_loss: 0.0150 - val_mae: 0.0902 - val_mse: 0.0150\n",
      "Epoch 56/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0043 - mae: 0.0467 - mse: 0.0043\n",
      "Epoch 00056: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0043 - mae: 0.0467 - mse: 0.0043 - val_loss: 0.0148 - val_mae: 0.0831 - val_mse: 0.0148\n",
      "Epoch 57/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0484 - mse: 0.0046\n",
      "Epoch 00057: val_loss did not improve from 0.01254\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0046 - mae: 0.0483 - mse: 0.0046 - val_loss: 0.0140 - val_mae: 0.0777 - val_mse: 0.0140\n",
      "Elapsed time during model training:  85.64888596534729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0444 - mae: 0.1462 - mse: 0.0444\n",
      "Epoch 00001: val_loss improved from inf to 0.01937, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0440,  mae:0.1455,  mse:0.0440,  val_loss:0.0194,  val_mae:0.1019,  val_mse:0.0194,  \n",
      "14926/14926 [==============================] - 2s 140us/sample - loss: 0.0440 - mae: 0.1455 - mse: 0.0440 - val_loss: 0.0194 - val_mae: 0.1019 - val_mse: 0.0194\n",
      "Epoch 2/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0218 - mae: 0.1077 - mse: 0.0218\n",
      "Epoch 00002: val_loss improved from 0.01937 to 0.01883, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0218 - mae: 0.1077 - mse: 0.0218 - val_loss: 0.0188 - val_mae: 0.0999 - val_mse: 0.0188\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0193 - mae: 0.1008 - mse: 0.0193\n",
      "Epoch 00003: val_loss improved from 0.01883 to 0.01805, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0193 - mae: 0.1008 - mse: 0.0193 - val_loss: 0.0180 - val_mae: 0.0971 - val_mse: 0.0180\n",
      "Epoch 4/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0188 - mae: 0.0988 - mse: 0.0188\n",
      "Epoch 00004: val_loss improved from 0.01805 to 0.01678, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0187 - mae: 0.0987 - mse: 0.0187 - val_loss: 0.0168 - val_mae: 0.0931 - val_mse: 0.0168\n",
      "Epoch 5/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0937 - mse: 0.0171\n",
      "Epoch 00005: val_loss did not improve from 0.01678\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0171 - mae: 0.0938 - mse: 0.0171 - val_loss: 0.0216 - val_mae: 0.1073 - val_mse: 0.0216\n",
      "Epoch 6/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0946 - mse: 0.0171\n",
      "Epoch 00006: val_loss did not improve from 0.01678\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0170 - mae: 0.0944 - mse: 0.0170 - val_loss: 0.0218 - val_mae: 0.1081 - val_mse: 0.0218\n",
      "Epoch 7/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0162 - mae: 0.0912 - mse: 0.0162\n",
      "Epoch 00007: val_loss did not improve from 0.01678\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0163 - mae: 0.0915 - mse: 0.0163 - val_loss: 0.0192 - val_mae: 0.0979 - val_mse: 0.0192\n",
      "Epoch 8/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0150 - mae: 0.0872 - mse: 0.0150\n",
      "Epoch 00008: val_loss improved from 0.01678 to 0.01482, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0150 - mae: 0.0873 - mse: 0.0150 - val_loss: 0.0148 - val_mae: 0.0832 - val_mse: 0.0148\n",
      "Epoch 9/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0148 - mae: 0.0867 - mse: 0.0148\n",
      "Epoch 00009: val_loss improved from 0.01482 to 0.01456, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0147 - mae: 0.0866 - mse: 0.0147 - val_loss: 0.0146 - val_mae: 0.0828 - val_mse: 0.0146\n",
      "Epoch 10/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0847 - mse: 0.0143\n",
      "Epoch 00010: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0143 - mae: 0.0847 - mse: 0.0143 - val_loss: 0.0152 - val_mae: 0.0866 - val_mse: 0.0152\n",
      "Epoch 11/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0143 - mae: 0.0856 - mse: 0.0143\n",
      "Epoch 00011: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0142 - mae: 0.0856 - mse: 0.0142 - val_loss: 0.0153 - val_mae: 0.0857 - val_mse: 0.0153\n",
      "Epoch 12/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0831 - mse: 0.0137\n",
      "Epoch 00012: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0137 - mae: 0.0832 - mse: 0.0137 - val_loss: 0.0157 - val_mae: 0.0903 - val_mse: 0.0157\n",
      "Epoch 13/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0816 - mse: 0.0131\n",
      "Epoch 00013: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0130 - mae: 0.0815 - mse: 0.0130 - val_loss: 0.0163 - val_mae: 0.0919 - val_mse: 0.0163\n",
      "Epoch 14/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0126 - mae: 0.0792 - mse: 0.0126\n",
      "Epoch 00014: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0126 - mae: 0.0792 - mse: 0.0126 - val_loss: 0.0156 - val_mae: 0.0855 - val_mse: 0.0156\n",
      "Epoch 15/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0772 - mse: 0.0120\n",
      "Epoch 00015: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0119 - mae: 0.0772 - mse: 0.0119 - val_loss: 0.0148 - val_mae: 0.0836 - val_mse: 0.0148\n",
      "Epoch 16/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0775 - mse: 0.0119\n",
      "Epoch 00016: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0119 - mae: 0.0775 - mse: 0.0119 - val_loss: 0.0160 - val_mae: 0.0886 - val_mse: 0.0160\n",
      "Epoch 17/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0747 - mse: 0.0112\n",
      "Epoch 00017: val_loss did not improve from 0.01456\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0112 - mae: 0.0747 - mse: 0.0112 - val_loss: 0.0162 - val_mae: 0.0920 - val_mse: 0.0162\n",
      "Epoch 18/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0114 - mae: 0.0751 - mse: 0.0114\n",
      "Epoch 00018: val_loss improved from 0.01456 to 0.01354, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0113 - mae: 0.0750 - mse: 0.0113 - val_loss: 0.0135 - val_mae: 0.0792 - val_mse: 0.0135\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0108 - mae: 0.0732 - mse: 0.0108\n",
      "Epoch 00019: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0108 - mae: 0.0732 - mse: 0.0108 - val_loss: 0.0141 - val_mae: 0.0830 - val_mse: 0.0141\n",
      "Epoch 20/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0735 - mse: 0.0107\n",
      "Epoch 00020: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0107 - mae: 0.0735 - mse: 0.0107 - val_loss: 0.0151 - val_mae: 0.0899 - val_mse: 0.0151\n",
      "Epoch 21/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0101 - mae: 0.0711 - mse: 0.0101\n",
      "Epoch 00021: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0101 - mae: 0.0710 - mse: 0.0101 - val_loss: 0.0139 - val_mae: 0.0793 - val_mse: 0.0139\n",
      "Epoch 22/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0716 - mse: 0.0101\n",
      "Epoch 00022: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0102 - mae: 0.0716 - mse: 0.0102 - val_loss: 0.0189 - val_mae: 0.1011 - val_mse: 0.0189\n",
      "Epoch 23/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0104 - mae: 0.0719 - mse: 0.0104\n",
      "Epoch 00023: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0104 - mae: 0.0718 - mse: 0.0104 - val_loss: 0.0161 - val_mae: 0.0854 - val_mse: 0.0161\n",
      "Epoch 24/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0093 - mae: 0.0681 - mse: 0.0093\n",
      "Epoch 00024: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0093 - mae: 0.0680 - mse: 0.0093 - val_loss: 0.0151 - val_mae: 0.0831 - val_mse: 0.0151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0671 - mse: 0.0092\n",
      "Epoch 00025: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0092 - mae: 0.0671 - mse: 0.0092 - val_loss: 0.0143 - val_mae: 0.0818 - val_mse: 0.0143\n",
      "Epoch 26/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0652 - mse: 0.0084\n",
      "Epoch 00026: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0088 - mae: 0.0657 - mse: 0.0088 - val_loss: 0.0156 - val_mae: 0.0885 - val_mse: 0.0156\n",
      "Epoch 27/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0089 - mae: 0.0660 - mse: 0.0089\n",
      "Epoch 00027: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0090 - mae: 0.0667 - mse: 0.0090 - val_loss: 0.0151 - val_mae: 0.0894 - val_mse: 0.0151\n",
      "Epoch 28/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0648 - mse: 0.0085\n",
      "Epoch 00028: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 2s 105us/sample - loss: 0.0085 - mae: 0.0648 - mse: 0.0085 - val_loss: 0.0143 - val_mae: 0.0866 - val_mse: 0.0143\n",
      "Epoch 29/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0627 - mse: 0.0081\n",
      "Epoch 00029: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0081 - mae: 0.0628 - mse: 0.0081 - val_loss: 0.0138 - val_mae: 0.0767 - val_mse: 0.0138\n",
      "Epoch 30/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0639 - mse: 0.0083\n",
      "Epoch 00030: val_loss did not improve from 0.01354\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0083 - mae: 0.0639 - mse: 0.0083 - val_loss: 0.0135 - val_mae: 0.0791 - val_mse: 0.0135\n",
      "Epoch 31/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0635 - mse: 0.0082\n",
      "Epoch 00031: val_loss improved from 0.01354 to 0.01352, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 125us/sample - loss: 0.0082 - mae: 0.0636 - mse: 0.0082 - val_loss: 0.0135 - val_mae: 0.0773 - val_mse: 0.0135\n",
      "Epoch 32/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0605 - mse: 0.0075\n",
      "Epoch 00032: val_loss did not improve from 0.01352\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0075 - mae: 0.0606 - mse: 0.0075 - val_loss: 0.0144 - val_mae: 0.0839 - val_mse: 0.0144\n",
      "Epoch 33/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0076 - mae: 0.0615 - mse: 0.0076\n",
      "Epoch 00033: val_loss did not improve from 0.01352\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0075 - mae: 0.0613 - mse: 0.0075 - val_loss: 0.0139 - val_mae: 0.0804 - val_mse: 0.0139\n",
      "Epoch 34/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0605 - mse: 0.0074\n",
      "Epoch 00034: val_loss improved from 0.01352 to 0.01316, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0074 - mae: 0.0606 - mse: 0.0074 - val_loss: 0.0132 - val_mae: 0.0761 - val_mse: 0.0132\n",
      "Epoch 35/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0594 - mse: 0.0072\n",
      "Epoch 00035: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0072 - mae: 0.0594 - mse: 0.0072 - val_loss: 0.0139 - val_mae: 0.0833 - val_mse: 0.0139\n",
      "Epoch 36/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0597 - mse: 0.0072\n",
      "Epoch 00036: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0072 - mae: 0.0598 - mse: 0.0072 - val_loss: 0.0138 - val_mae: 0.0802 - val_mse: 0.0138\n",
      "Epoch 37/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0075 - mae: 0.0609 - mse: 0.0075\n",
      "Epoch 00037: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0074 - mae: 0.0608 - mse: 0.0074 - val_loss: 0.0132 - val_mae: 0.0759 - val_mse: 0.0132\n",
      "Epoch 38/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0562 - mse: 0.0066\n",
      "Epoch 00038: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0066 - mae: 0.0563 - mse: 0.0066 - val_loss: 0.0145 - val_mae: 0.0813 - val_mse: 0.0145\n",
      "Epoch 39/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0570 - mse: 0.0067\n",
      "Epoch 00039: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0067 - mae: 0.0570 - mse: 0.0067 - val_loss: 0.0146 - val_mae: 0.0832 - val_mse: 0.0146\n",
      "Epoch 40/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0065 - mae: 0.0572 - mse: 0.0065\n",
      "Epoch 00040: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0064 - mae: 0.0569 - mse: 0.0064 - val_loss: 0.0139 - val_mae: 0.0805 - val_mse: 0.0139\n",
      "Epoch 41/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0553 - mse: 0.0063\n",
      "Epoch 00041: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0063 - mae: 0.0553 - mse: 0.0063 - val_loss: 0.0133 - val_mae: 0.0764 - val_mse: 0.0133\n",
      "Epoch 42/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0558 - mse: 0.0063\n",
      "Epoch 00042: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 2s 101us/sample - loss: 0.0063 - mae: 0.0558 - mse: 0.0063 - val_loss: 0.0147 - val_mae: 0.0815 - val_mse: 0.0147\n",
      "Epoch 43/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0062 - mae: 0.0546 - mse: 0.0062\n",
      "Epoch 00043: val_loss did not improve from 0.01316\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0062 - mae: 0.0548 - mse: 0.0062 - val_loss: 0.0146 - val_mae: 0.0813 - val_mse: 0.0146\n",
      "Epoch 44/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0059 - mae: 0.0535 - mse: 0.0059\n",
      "Epoch 00044: val_loss improved from 0.01316 to 0.01284, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0059 - mae: 0.0537 - mse: 0.0059 - val_loss: 0.0128 - val_mae: 0.0743 - val_mse: 0.0128\n",
      "Epoch 45/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0541 - mse: 0.0060\n",
      "Epoch 00045: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0060 - mae: 0.0545 - mse: 0.0060 - val_loss: 0.0148 - val_mae: 0.0882 - val_mse: 0.0148\n",
      "Epoch 46/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0058 - mae: 0.0531 - mse: 0.0058\n",
      "Epoch 00046: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0058 - mae: 0.0531 - mse: 0.0058 - val_loss: 0.0136 - val_mae: 0.0793 - val_mse: 0.0136\n",
      "Epoch 47/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0511 - mse: 0.0054\n",
      "Epoch 00047: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0054 - mae: 0.0512 - mse: 0.0054 - val_loss: 0.0147 - val_mae: 0.0821 - val_mse: 0.0147\n",
      "Epoch 48/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0053 - mae: 0.0519 - mse: 0.0053\n",
      "Epoch 00048: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0053 - mae: 0.0518 - mse: 0.0053 - val_loss: 0.0139 - val_mae: 0.0803 - val_mse: 0.0139\n",
      "Epoch 49/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0516 - mse: 0.0054\n",
      "Epoch 00049: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0054 - mae: 0.0516 - mse: 0.0054 - val_loss: 0.0153 - val_mae: 0.0862 - val_mse: 0.0153\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0052 - mae: 0.0507 - mse: 0.0052\n",
      "Epoch 00050: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0052 - mae: 0.0507 - mse: 0.0052 - val_loss: 0.0141 - val_mae: 0.0795 - val_mse: 0.0141\n",
      "Epoch 51/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0053 - mae: 0.0514 - mse: 0.0053\n",
      "Epoch 00051: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0053 - mae: 0.0516 - mse: 0.0053 - val_loss: 0.0137 - val_mae: 0.0792 - val_mse: 0.0137\n",
      "Epoch 52/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0051 - mae: 0.0499 - mse: 0.0051\n",
      "Epoch 00052: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0051 - mae: 0.0499 - mse: 0.0051 - val_loss: 0.0134 - val_mae: 0.0780 - val_mse: 0.0134\n",
      "Epoch 53/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0473 - mse: 0.0046\n",
      "Epoch 00053: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0046 - mae: 0.0473 - mse: 0.0046 - val_loss: 0.0134 - val_mae: 0.0760 - val_mse: 0.0134\n",
      "Epoch 54/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0050 - mae: 0.0492 - mse: 0.0050\n",
      "Epoch 00054: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0050 - mae: 0.0495 - mse: 0.0050 - val_loss: 0.0148 - val_mae: 0.0855 - val_mse: 0.0148\n",
      "Epoch 55/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0046 - mae: 0.0480 - mse: 0.0046\n",
      "Epoch 00055: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0046 - mae: 0.0481 - mse: 0.0046 - val_loss: 0.0169 - val_mae: 0.0919 - val_mse: 0.0169\n",
      "Epoch 56/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0047 - mae: 0.0482 - mse: 0.0047\n",
      "Epoch 00056: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0047 - mae: 0.0483 - mse: 0.0047 - val_loss: 0.0136 - val_mae: 0.0788 - val_mse: 0.0136\n",
      "Epoch 57/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0047 - mae: 0.0476 - mse: 0.0047\n",
      "Epoch 00057: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0047 - mae: 0.0475 - mse: 0.0047 - val_loss: 0.0134 - val_mae: 0.0768 - val_mse: 0.0134\n",
      "Epoch 58/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0042 - mae: 0.0449 - mse: 0.0042\n",
      "Epoch 00058: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0042 - mae: 0.0449 - mse: 0.0042 - val_loss: 0.0133 - val_mae: 0.0754 - val_mse: 0.0133\n",
      "Epoch 59/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0042 - mae: 0.0459 - mse: 0.0042\n",
      "Epoch 00059: val_loss did not improve from 0.01284\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0042 - mae: 0.0460 - mse: 0.0042 - val_loss: 0.0138 - val_mae: 0.0754 - val_mse: 0.0138\n",
      "Elapsed time during model training:  85.3166766166687\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0460 - mae: 0.1499 - mse: 0.0460\n",
      "Epoch 00001: val_loss improved from inf to 0.02193, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0454,  mae:0.1490,  mse:0.0454,  val_loss:0.0219,  val_mae:0.1102,  val_mse:0.0219,  \n",
      "14926/14926 [==============================] - 2s 146us/sample - loss: 0.0454 - mae: 0.1490 - mse: 0.0454 - val_loss: 0.0219 - val_mae: 0.1102 - val_mse: 0.0219\n",
      "Epoch 2/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0220 - mae: 0.1086 - mse: 0.0220\n",
      "Epoch 00002: val_loss did not improve from 0.02193\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0220 - mae: 0.1086 - mse: 0.0220 - val_loss: 0.0229 - val_mae: 0.1140 - val_mse: 0.0229\n",
      "Epoch 3/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0200 - mae: 0.1027 - mse: 0.0200\n",
      "Epoch 00003: val_loss did not improve from 0.02193\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0200 - mae: 0.1027 - mse: 0.0200 - val_loss: 0.0309 - val_mae: 0.1335 - val_mse: 0.0309\n",
      "Epoch 4/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0194 - mae: 0.1006 - mse: 0.0194\n",
      "Epoch 00004: val_loss improved from 0.02193 to 0.01655, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0193 - mae: 0.1003 - mse: 0.0193 - val_loss: 0.0165 - val_mae: 0.0903 - val_mse: 0.0165\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0191 - mae: 0.1001 - mse: 0.0191\n",
      "Epoch 00005: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0191 - mae: 0.0999 - mse: 0.0191 - val_loss: 0.0168 - val_mae: 0.0946 - val_mse: 0.0168\n",
      "Epoch 6/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0174 - mae: 0.0950 - mse: 0.0174\n",
      "Epoch 00006: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0173 - mae: 0.0949 - mse: 0.0173 - val_loss: 0.0172 - val_mae: 0.0977 - val_mse: 0.0172\n",
      "Epoch 7/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0172 - mae: 0.0950 - mse: 0.0172\n",
      "Epoch 00007: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0172 - mae: 0.0951 - mse: 0.0172 - val_loss: 0.0186 - val_mae: 0.0996 - val_mse: 0.0186\n",
      "Epoch 8/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0915 - mse: 0.0165\n",
      "Epoch 00008: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0165 - mae: 0.0915 - mse: 0.0165 - val_loss: 0.0187 - val_mae: 0.0983 - val_mse: 0.0187\n",
      "Epoch 9/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0908 - mse: 0.0161\n",
      "Epoch 00009: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0161 - mae: 0.0908 - mse: 0.0161 - val_loss: 0.0176 - val_mae: 0.0972 - val_mse: 0.0176\n",
      "Epoch 10/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0160 - mae: 0.0907 - mse: 0.0160\n",
      "Epoch 00010: val_loss did not improve from 0.01655\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0159 - mae: 0.0907 - mse: 0.0159 - val_loss: 0.0191 - val_mae: 0.0930 - val_mse: 0.0191\n",
      "Epoch 11/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0142 - mae: 0.0847 - mse: 0.0142\n",
      "Epoch 00011: val_loss improved from 0.01655 to 0.01636, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0142 - mae: 0.0846 - mse: 0.0142 - val_loss: 0.0164 - val_mae: 0.0885 - val_mse: 0.0164\n",
      "Epoch 12/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0133 - mae: 0.0820 - mse: 0.0133\n",
      "Epoch 00012: val_loss did not improve from 0.01636\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0137 - mae: 0.0822 - mse: 0.0137 - val_loss: 0.0182 - val_mae: 0.1013 - val_mse: 0.0182\n",
      "Epoch 13/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0816 - mse: 0.0134\n",
      "Epoch 00013: val_loss did not improve from 0.01636\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0134 - mae: 0.0817 - mse: 0.0134 - val_loss: 0.0180 - val_mae: 0.0932 - val_mse: 0.0180\n",
      "Epoch 14/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0137 - mae: 0.0831 - mse: 0.0137\n",
      "Epoch 00014: val_loss improved from 0.01636 to 0.01567, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0137 - mae: 0.0831 - mse: 0.0137 - val_loss: 0.0157 - val_mae: 0.0892 - val_mse: 0.0157\n",
      "Epoch 15/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0127 - mae: 0.0787 - mse: 0.0127\n",
      "Epoch 00015: val_loss improved from 0.01567 to 0.01471, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0127 - mae: 0.0786 - mse: 0.0127 - val_loss: 0.0147 - val_mae: 0.0829 - val_mse: 0.0147\n",
      "Epoch 16/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0806 - mse: 0.0130\n",
      "Epoch 00016: val_loss improved from 0.01471 to 0.01420, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0129 - mae: 0.0804 - mse: 0.0129 - val_loss: 0.0142 - val_mae: 0.0803 - val_mse: 0.0142\n",
      "Epoch 17/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0125 - mae: 0.0792 - mse: 0.0125\n",
      "Epoch 00017: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0124 - mae: 0.0789 - mse: 0.0124 - val_loss: 0.0148 - val_mae: 0.0848 - val_mse: 0.0148\n",
      "Epoch 18/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0124 - mae: 0.0788 - mse: 0.0124\n",
      "Epoch 00018: val_loss did not improve from 0.01420\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0124 - mae: 0.0788 - mse: 0.0124 - val_loss: 0.0146 - val_mae: 0.0832 - val_mse: 0.0146\n",
      "Epoch 19/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0757 - mse: 0.0117\n",
      "Epoch 00019: val_loss improved from 0.01420 to 0.01415, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0117 - mae: 0.0756 - mse: 0.0117 - val_loss: 0.0141 - val_mae: 0.0811 - val_mse: 0.0141\n",
      "Epoch 20/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0734 - mse: 0.0112\n",
      "Epoch 00020: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0112 - mae: 0.0734 - mse: 0.0112 - val_loss: 0.0154 - val_mae: 0.0901 - val_mse: 0.0154\n",
      "Epoch 21/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0113 - mae: 0.0751 - mse: 0.0113\n",
      "Epoch 00021: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0113 - mae: 0.0749 - mse: 0.0113 - val_loss: 0.0179 - val_mae: 0.0923 - val_mse: 0.0179\n",
      "Epoch 22/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0113 - mae: 0.0747 - mse: 0.0113\n",
      "Epoch 00022: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0113 - mae: 0.0747 - mse: 0.0113 - val_loss: 0.0165 - val_mae: 0.0949 - val_mse: 0.0165\n",
      "Epoch 23/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0108 - mae: 0.0734 - mse: 0.0108\n",
      "Epoch 00023: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0108 - mae: 0.0736 - mse: 0.0108 - val_loss: 0.0169 - val_mae: 0.0872 - val_mse: 0.0169\n",
      "Epoch 24/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0701 - mse: 0.0101\n",
      "Epoch 00024: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0101 - mae: 0.0702 - mse: 0.0101 - val_loss: 0.0153 - val_mae: 0.0889 - val_mse: 0.0153\n",
      "Epoch 25/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0706 - mse: 0.0103\n",
      "Epoch 00025: val_loss did not improve from 0.01415\n",
      "14926/14926 [==============================] - 2s 123us/sample - loss: 0.0103 - mae: 0.0706 - mse: 0.0103 - val_loss: 0.0152 - val_mae: 0.0891 - val_mse: 0.0152\n",
      "Epoch 26/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0695 - mse: 0.0100\n",
      "Epoch 00026: val_loss improved from 0.01415 to 0.01412, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0100 - mae: 0.0695 - mse: 0.0100 - val_loss: 0.0141 - val_mae: 0.0816 - val_mse: 0.0141\n",
      "Epoch 27/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0686 - mse: 0.0096\n",
      "Epoch 00027: val_loss did not improve from 0.01412\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0096 - mae: 0.0686 - mse: 0.0096 - val_loss: 0.0142 - val_mae: 0.0811 - val_mse: 0.0142\n",
      "Epoch 28/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0698 - mse: 0.0099\n",
      "Epoch 00028: val_loss improved from 0.01412 to 0.01331, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0099 - mae: 0.0698 - mse: 0.0099 - val_loss: 0.0133 - val_mae: 0.0773 - val_mse: 0.0133\n",
      "Epoch 29/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0664 - mse: 0.0090\n",
      "Epoch 00029: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0091 - mae: 0.0664 - mse: 0.0091 - val_loss: 0.0160 - val_mae: 0.0859 - val_mse: 0.0160\n",
      "Epoch 30/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0684 - mse: 0.0094\n",
      "Epoch 00030: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0093 - mae: 0.0683 - mse: 0.0093 - val_loss: 0.0137 - val_mae: 0.0804 - val_mse: 0.0137\n",
      "Epoch 31/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0664 - mse: 0.0089\n",
      "Epoch 00031: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0089 - mae: 0.0663 - mse: 0.0089 - val_loss: 0.0137 - val_mae: 0.0799 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0091 - mae: 0.0673 - mse: 0.0091\n",
      "Epoch 00032: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0091 - mae: 0.0673 - mse: 0.0091 - val_loss: 0.0150 - val_mae: 0.0838 - val_mse: 0.0150\n",
      "Epoch 33/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0651 - mse: 0.0087\n",
      "Epoch 00033: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0087 - mae: 0.0651 - mse: 0.0087 - val_loss: 0.0134 - val_mae: 0.0795 - val_mse: 0.0134\n",
      "Epoch 34/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0643 - mse: 0.0085\n",
      "Epoch 00034: val_loss improved from 0.01331 to 0.01331, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0085 - mae: 0.0643 - mse: 0.0085 - val_loss: 0.0133 - val_mae: 0.0764 - val_mse: 0.0133\n",
      "Epoch 35/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0634 - mse: 0.0083\n",
      "Epoch 00035: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0083 - mae: 0.0634 - mse: 0.0083 - val_loss: 0.0147 - val_mae: 0.0844 - val_mse: 0.0147\n",
      "Epoch 36/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0622 - mse: 0.0079\n",
      "Epoch 00036: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0079 - mae: 0.0626 - mse: 0.0079 - val_loss: 0.0144 - val_mae: 0.0812 - val_mse: 0.0144\n",
      "Epoch 37/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0621 - mse: 0.0078\n",
      "Epoch 00037: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 2s 127us/sample - loss: 0.0079 - mae: 0.0621 - mse: 0.0079 - val_loss: 0.0143 - val_mae: 0.0806 - val_mse: 0.0143\n",
      "Epoch 38/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0630 - mse: 0.0079\n",
      "Epoch 00038: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0079 - mae: 0.0629 - mse: 0.0079 - val_loss: 0.0142 - val_mae: 0.0795 - val_mse: 0.0142\n",
      "Epoch 39/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0631 - mse: 0.0079\n",
      "Epoch 00039: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0079 - mae: 0.0632 - mse: 0.0079 - val_loss: 0.0142 - val_mae: 0.0825 - val_mse: 0.0142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0606 - mse: 0.0073\n",
      "Epoch 00040: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0075 - mae: 0.0606 - mse: 0.0075 - val_loss: 0.0134 - val_mae: 0.0801 - val_mse: 0.0134\n",
      "Epoch 41/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0618 - mse: 0.0077\n",
      "Epoch 00041: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0077 - mae: 0.0619 - mse: 0.0077 - val_loss: 0.0144 - val_mae: 0.0818 - val_mse: 0.0144\n",
      "Epoch 42/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0610 - mse: 0.0076\n",
      "Epoch 00042: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0076 - mae: 0.0611 - mse: 0.0076 - val_loss: 0.0138 - val_mae: 0.0791 - val_mse: 0.0138\n",
      "Epoch 43/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0071 - mae: 0.0595 - mse: 0.0071\n",
      "Epoch 00043: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0072 - mae: 0.0597 - mse: 0.0072 - val_loss: 0.0157 - val_mae: 0.0869 - val_mse: 0.0157\n",
      "Epoch 44/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0587 - mse: 0.0071\n",
      "Epoch 00044: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0071 - mae: 0.0587 - mse: 0.0071 - val_loss: 0.0134 - val_mae: 0.0780 - val_mse: 0.0134\n",
      "Epoch 45/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0071 - mae: 0.0580 - mse: 0.0071\n",
      "Epoch 00045: val_loss did not improve from 0.01331\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0070 - mae: 0.0579 - mse: 0.0070 - val_loss: 0.0148 - val_mae: 0.0871 - val_mse: 0.0148\n",
      "Elapsed time during model training:  65.23614764213562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rgur/.local/lib/python3.7/site-packages/skopt/optimizer/optimizer.py:409: UserWarning: The objective has been evaluated at this point before.\n",
      "  warnings.warn(\"The objective has been evaluated \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0456 - mae: 0.1491 - mse: 0.0456\n",
      "Epoch 00001: val_loss improved from inf to 0.02145, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0450,  mae:0.1480,  mse:0.0450,  val_loss:0.0215,  val_mae:0.1051,  val_mse:0.0215,  \n",
      "14926/14926 [==============================] - 2s 148us/sample - loss: 0.0450 - mae: 0.1480 - mse: 0.0450 - val_loss: 0.0215 - val_mae: 0.1051 - val_mse: 0.0215\n",
      "Epoch 2/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1074 - mse: 0.0216\n",
      "Epoch 00002: val_loss did not improve from 0.02145\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0216 - mae: 0.1073 - mse: 0.0216 - val_loss: 0.0240 - val_mae: 0.1146 - val_mse: 0.0240\n",
      "Epoch 3/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0214 - mae: 0.1074 - mse: 0.0214\n",
      "Epoch 00003: val_loss improved from 0.02145 to 0.01995, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 114us/sample - loss: 0.0213 - mae: 0.1074 - mse: 0.0213 - val_loss: 0.0199 - val_mae: 0.1029 - val_mse: 0.0199\n",
      "Epoch 4/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0185 - mae: 0.0984 - mse: 0.0185\n",
      "Epoch 00004: val_loss improved from 0.01995 to 0.01971, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 127us/sample - loss: 0.0185 - mae: 0.0984 - mse: 0.0185 - val_loss: 0.0197 - val_mae: 0.1029 - val_mse: 0.0197\n",
      "Epoch 5/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0176 - mae: 0.0957 - mse: 0.0176\n",
      "Epoch 00005: val_loss improved from 0.01971 to 0.01790, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0177 - mae: 0.0959 - mse: 0.0177 - val_loss: 0.0179 - val_mae: 0.0970 - val_mse: 0.0179\n",
      "Epoch 6/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0168 - mae: 0.0926 - mse: 0.0168\n",
      "Epoch 00006: val_loss improved from 0.01790 to 0.01571, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 103us/sample - loss: 0.0167 - mae: 0.0923 - mse: 0.0167 - val_loss: 0.0157 - val_mae: 0.0872 - val_mse: 0.0157\n",
      "Epoch 7/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0162 - mae: 0.0906 - mse: 0.0162\n",
      "Epoch 00007: val_loss did not improve from 0.01571\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0161 - mae: 0.0906 - mse: 0.0161 - val_loss: 0.0162 - val_mae: 0.0911 - val_mse: 0.0162\n",
      "Epoch 8/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0155 - mae: 0.0889 - mse: 0.0155\n",
      "Epoch 00008: val_loss did not improve from 0.01571\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0157 - mae: 0.0896 - mse: 0.0157 - val_loss: 0.0239 - val_mae: 0.1146 - val_mse: 0.0239\n",
      "Epoch 9/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0156 - mae: 0.0891 - mse: 0.0156\n",
      "Epoch 00009: val_loss did not improve from 0.01571\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0156 - mae: 0.0892 - mse: 0.0156 - val_loss: 0.0170 - val_mae: 0.0919 - val_mse: 0.0170\n",
      "Epoch 10/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0141 - mae: 0.0838 - mse: 0.0141\n",
      "Epoch 00010: val_loss improved from 0.01571 to 0.01425, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0140 - mae: 0.0836 - mse: 0.0140 - val_loss: 0.0143 - val_mae: 0.0821 - val_mse: 0.0143\n",
      "Epoch 11/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0136 - mae: 0.0822 - mse: 0.0136\n",
      "Epoch 00011: val_loss did not improve from 0.01425\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0136 - mae: 0.0823 - mse: 0.0136 - val_loss: 0.0148 - val_mae: 0.0849 - val_mse: 0.0148\n",
      "Epoch 12/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0809 - mse: 0.0131\n",
      "Epoch 00012: val_loss did not improve from 0.01425\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0131 - mae: 0.0810 - mse: 0.0131 - val_loss: 0.0160 - val_mae: 0.0928 - val_mse: 0.0160\n",
      "Epoch 13/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0810 - mse: 0.0131\n",
      "Epoch 00013: val_loss did not improve from 0.01425\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0131 - mae: 0.0810 - mse: 0.0131 - val_loss: 0.0159 - val_mae: 0.0850 - val_mse: 0.0159\n",
      "Epoch 14/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0125 - mae: 0.0787 - mse: 0.0125\n",
      "Epoch 00014: val_loss improved from 0.01425 to 0.01369, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0124 - mae: 0.0786 - mse: 0.0124 - val_loss: 0.0137 - val_mae: 0.0800 - val_mse: 0.0137\n",
      "Epoch 15/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0123 - mae: 0.0782 - mse: 0.0123\n",
      "Epoch 00015: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0123 - mae: 0.0782 - mse: 0.0123 - val_loss: 0.0139 - val_mae: 0.0803 - val_mse: 0.0139\n",
      "Epoch 16/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0766 - mse: 0.0119\n",
      "Epoch 00016: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0119 - mae: 0.0767 - mse: 0.0119 - val_loss: 0.0147 - val_mae: 0.0875 - val_mse: 0.0147\n",
      "Epoch 17/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00017: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0176 - val_mae: 0.0973 - val_mse: 0.0176\n",
      "Epoch 18/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0739 - mse: 0.0110\n",
      "Epoch 00018: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0110 - mae: 0.0739 - mse: 0.0110 - val_loss: 0.0141 - val_mae: 0.0786 - val_mse: 0.0141\n",
      "Epoch 19/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0726 - mse: 0.0107\n",
      "Epoch 00019: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0107 - mae: 0.0726 - mse: 0.0107 - val_loss: 0.0142 - val_mae: 0.0820 - val_mse: 0.0142\n",
      "Epoch 20/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0728 - mse: 0.0106\n",
      "Epoch 00020: val_loss did not improve from 0.01369\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0105 - mae: 0.0726 - mse: 0.0105 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 21/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0716 - mse: 0.0103\n",
      "Epoch 00021: val_loss improved from 0.01369 to 0.01359, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0103 - mae: 0.0717 - mse: 0.0103 - val_loss: 0.0136 - val_mae: 0.0808 - val_mse: 0.0136\n",
      "Epoch 22/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0095 - mae: 0.0678 - mse: 0.0095\n",
      "Epoch 00022: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0095 - mae: 0.0679 - mse: 0.0095 - val_loss: 0.0144 - val_mae: 0.0823 - val_mse: 0.0144\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0686 - mse: 0.0096\n",
      "Epoch 00023: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 121us/sample - loss: 0.0096 - mae: 0.0686 - mse: 0.0096 - val_loss: 0.0163 - val_mae: 0.0878 - val_mse: 0.0163\n",
      "Epoch 24/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0673 - mse: 0.0092\n",
      "Epoch 00024: val_loss did not improve from 0.01359\n",
      "14926/14926 [==============================] - 2s 115us/sample - loss: 0.0092 - mae: 0.0672 - mse: 0.0092 - val_loss: 0.0164 - val_mae: 0.0871 - val_mse: 0.0164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0091 - mae: 0.0670 - mse: 0.0091\n",
      "Epoch 00025: val_loss improved from 0.01359 to 0.01330, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0090 - mae: 0.0668 - mse: 0.0090 - val_loss: 0.0133 - val_mae: 0.0767 - val_mse: 0.0133\n",
      "Epoch 26/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0671 - mse: 0.0092\n",
      "Epoch 00026: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 90us/sample - loss: 0.0092 - mae: 0.0671 - mse: 0.0092 - val_loss: 0.0149 - val_mae: 0.0881 - val_mse: 0.0149\n",
      "Epoch 27/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0649 - mse: 0.0084\n",
      "Epoch 00027: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0087 - mae: 0.0650 - mse: 0.0087 - val_loss: 0.0134 - val_mae: 0.0805 - val_mse: 0.0134\n",
      "Epoch 28/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0645 - mse: 0.0084\n",
      "Epoch 00028: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0084 - mae: 0.0645 - mse: 0.0084 - val_loss: 0.0137 - val_mae: 0.0814 - val_mse: 0.0137\n",
      "Epoch 29/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0646 - mse: 0.0084\n",
      "Epoch 00029: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0083 - mae: 0.0646 - mse: 0.0083 - val_loss: 0.0137 - val_mae: 0.0802 - val_mse: 0.0137\n",
      "Epoch 30/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0635 - mse: 0.0082\n",
      "Epoch 00030: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0082 - mae: 0.0635 - mse: 0.0082 - val_loss: 0.0150 - val_mae: 0.0856 - val_mse: 0.0150\n",
      "Epoch 31/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0082 - mae: 0.0638 - mse: 0.0082\n",
      "Epoch 00031: val_loss did not improve from 0.01330\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0082 - mae: 0.0638 - mse: 0.0082 - val_loss: 0.0139 - val_mae: 0.0802 - val_mse: 0.0139\n",
      "Epoch 32/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0632 - mse: 0.0081\n",
      "Epoch 00032: val_loss improved from 0.01330 to 0.01311, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0081 - mae: 0.0631 - mse: 0.0081 - val_loss: 0.0131 - val_mae: 0.0754 - val_mse: 0.0131\n",
      "Epoch 33/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0623 - mse: 0.0079\n",
      "Epoch 00033: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0079 - mae: 0.0622 - mse: 0.0079 - val_loss: 0.0140 - val_mae: 0.0793 - val_mse: 0.0140\n",
      "Epoch 34/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0071 - mae: 0.0592 - mse: 0.0071\n",
      "Epoch 00034: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0071 - mae: 0.0593 - mse: 0.0071 - val_loss: 0.0144 - val_mae: 0.0865 - val_mse: 0.0144\n",
      "Epoch 35/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0593 - mse: 0.0072\n",
      "Epoch 00035: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0073 - mae: 0.0594 - mse: 0.0073 - val_loss: 0.0153 - val_mae: 0.0884 - val_mse: 0.0153\n",
      "Epoch 36/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0070 - mae: 0.0587 - mse: 0.0070\n",
      "Epoch 00036: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0070 - mae: 0.0588 - mse: 0.0070 - val_loss: 0.0144 - val_mae: 0.0793 - val_mse: 0.0144\n",
      "Epoch 37/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0565 - mse: 0.0066\n",
      "Epoch 00037: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 2s 122us/sample - loss: 0.0067 - mae: 0.0567 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0813 - val_mse: 0.0141\n",
      "Epoch 38/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0568 - mse: 0.0067\n",
      "Epoch 00038: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 2s 124us/sample - loss: 0.0068 - mae: 0.0572 - mse: 0.0068 - val_loss: 0.0146 - val_mae: 0.0858 - val_mse: 0.0146\n",
      "Epoch 39/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0572 - mse: 0.0068\n",
      "Epoch 00039: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0067 - mae: 0.0572 - mse: 0.0067 - val_loss: 0.0139 - val_mae: 0.0815 - val_mse: 0.0139\n",
      "Epoch 40/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0554 - mse: 0.0062\n",
      "Epoch 00040: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 98us/sample - loss: 0.0062 - mae: 0.0554 - mse: 0.0062 - val_loss: 0.0136 - val_mae: 0.0761 - val_mse: 0.0136\n",
      "Epoch 41/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0580 - mse: 0.0068\n",
      "Epoch 00041: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0067 - mae: 0.0579 - mse: 0.0067 - val_loss: 0.0141 - val_mae: 0.0823 - val_mse: 0.0141\n",
      "Epoch 42/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0549 - mse: 0.0061\n",
      "Epoch 00042: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0062 - mae: 0.0551 - mse: 0.0062 - val_loss: 0.0152 - val_mae: 0.0873 - val_mse: 0.0152\n",
      "Epoch 43/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0548 - mse: 0.0060\n",
      "Epoch 00043: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0064 - mae: 0.0551 - mse: 0.0064 - val_loss: 0.0146 - val_mae: 0.0890 - val_mse: 0.0146\n",
      "Epoch 44/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0558 - mse: 0.0062\n",
      "Epoch 00044: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0062 - mae: 0.0557 - mse: 0.0062 - val_loss: 0.0132 - val_mae: 0.0756 - val_mse: 0.0132\n",
      "Epoch 45/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0529 - mse: 0.0056\n",
      "Epoch 00045: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0056 - mae: 0.0529 - mse: 0.0056 - val_loss: 0.0151 - val_mae: 0.0848 - val_mse: 0.0151\n",
      "Epoch 46/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0057 - mae: 0.0528 - mse: 0.0057\n",
      "Epoch 00046: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0057 - mae: 0.0530 - mse: 0.0057 - val_loss: 0.0160 - val_mae: 0.0857 - val_mse: 0.0160\n",
      "Epoch 47/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0520 - mse: 0.0056\n",
      "Epoch 00047: val_loss did not improve from 0.01311\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0056 - mae: 0.0522 - mse: 0.0056 - val_loss: 0.0175 - val_mae: 0.0957 - val_mse: 0.0175\n",
      "Elapsed time during model training:  68.45599436759949\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0635 - mae: 0.1683 - mse: 0.0635\n",
      "Epoch 00001: val_loss improved from inf to 0.02280, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0627,  mae:0.1672,  mse:0.0627,  val_loss:0.0228,  val_mae:0.1122,  val_mse:0.0228,  \n",
      "14926/14926 [==============================] - 2s 143us/sample - loss: 0.0627 - mae: 0.1672 - mse: 0.0627 - val_loss: 0.0228 - val_mae: 0.1122 - val_mse: 0.0228\n",
      "Epoch 2/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0216 - mae: 0.1072 - mse: 0.0216\n",
      "Epoch 00002: val_loss improved from 0.02280 to 0.01996, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0216 - mae: 0.1072 - mse: 0.0216 - val_loss: 0.0200 - val_mae: 0.0992 - val_mse: 0.0200\n",
      "Epoch 3/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0195 - mae: 0.1006 - mse: 0.0195\n",
      "Epoch 00003: val_loss improved from 0.01996 to 0.01945, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0195 - mae: 0.1006 - mse: 0.0195 - val_loss: 0.0195 - val_mae: 0.1047 - val_mse: 0.0195\n",
      "Epoch 4/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0185 - mae: 0.0976 - mse: 0.0185\n",
      "Epoch 00004: val_loss did not improve from 0.01945\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0186 - mae: 0.0976 - mse: 0.0186 - val_loss: 0.0198 - val_mae: 0.1024 - val_mse: 0.0198\n",
      "Epoch 5/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0171 - mae: 0.0931 - mse: 0.0171\n",
      "Epoch 00005: val_loss improved from 0.01945 to 0.01708, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0171 - mae: 0.0931 - mse: 0.0171 - val_loss: 0.0171 - val_mae: 0.0928 - val_mse: 0.0171\n",
      "Epoch 6/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0165 - mae: 0.0912 - mse: 0.0165\n",
      "Epoch 00006: val_loss did not improve from 0.01708\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0165 - mae: 0.0911 - mse: 0.0165 - val_loss: 0.0173 - val_mae: 0.0930 - val_mse: 0.0173\n",
      "Epoch 7/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0167 - mae: 0.0936 - mse: 0.0167\n",
      "Epoch 00007: val_loss did not improve from 0.01708\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0172 - mae: 0.0940 - mse: 0.0172 - val_loss: 0.0210 - val_mae: 0.1069 - val_mse: 0.0210\n",
      "Epoch 8/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0157 - mae: 0.0892 - mse: 0.0157\n",
      "Epoch 00008: val_loss improved from 0.01708 to 0.01670, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0158 - mae: 0.0893 - mse: 0.0158 - val_loss: 0.0167 - val_mae: 0.0925 - val_mse: 0.0167\n",
      "Epoch 9/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0152 - mae: 0.0879 - mse: 0.0152\n",
      "Epoch 00009: val_loss improved from 0.01670 to 0.01481, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0151 - mae: 0.0878 - mse: 0.0151 - val_loss: 0.0148 - val_mae: 0.0845 - val_mse: 0.0148\n",
      "Epoch 10/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0149 - mae: 0.0860 - mse: 0.0149\n",
      "Epoch 00010: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0149 - mae: 0.0860 - mse: 0.0149 - val_loss: 0.0168 - val_mae: 0.0900 - val_mse: 0.0168\n",
      "Epoch 11/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0145 - mae: 0.0853 - mse: 0.0145\n",
      "Epoch 00011: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0145 - mae: 0.0856 - mse: 0.0145 - val_loss: 0.0180 - val_mae: 0.1008 - val_mse: 0.0180\n",
      "Epoch 12/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0832 - mse: 0.0140\n",
      "Epoch 00012: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0139 - mae: 0.0831 - mse: 0.0139 - val_loss: 0.0152 - val_mae: 0.0859 - val_mse: 0.0152\n",
      "Epoch 13/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0135 - mae: 0.0819 - mse: 0.0135\n",
      "Epoch 00013: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0135 - mae: 0.0819 - mse: 0.0135 - val_loss: 0.0158 - val_mae: 0.0864 - val_mse: 0.0158\n",
      "Epoch 14/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0131 - mae: 0.0803 - mse: 0.0131\n",
      "Epoch 00014: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 2s 117us/sample - loss: 0.0132 - mae: 0.0804 - mse: 0.0132 - val_loss: 0.0152 - val_mae: 0.0865 - val_mse: 0.0152\n",
      "Epoch 15/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0804 - mse: 0.0130\n",
      "Epoch 00015: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0129 - mae: 0.0803 - mse: 0.0129 - val_loss: 0.0161 - val_mae: 0.0860 - val_mse: 0.0161\n",
      "Epoch 16/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0806 - mse: 0.0130\n",
      "Epoch 00016: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0129 - mae: 0.0807 - mse: 0.0129 - val_loss: 0.0150 - val_mae: 0.0842 - val_mse: 0.0150\n",
      "Epoch 17/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0780 - mse: 0.0119\n",
      "Epoch 00017: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0123 - mae: 0.0785 - mse: 0.0123 - val_loss: 0.0158 - val_mae: 0.0867 - val_mse: 0.0158\n",
      "Epoch 18/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0121 - mae: 0.0777 - mse: 0.0121\n",
      "Epoch 00018: val_loss did not improve from 0.01481\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0121 - mae: 0.0777 - mse: 0.0121 - val_loss: 0.0167 - val_mae: 0.0878 - val_mse: 0.0167\n",
      "Epoch 19/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0773 - mse: 0.0120\n",
      "Epoch 00019: val_loss improved from 0.01481 to 0.01454, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0120 - mae: 0.0773 - mse: 0.0120 - val_loss: 0.0145 - val_mae: 0.0815 - val_mse: 0.0145\n",
      "Epoch 20/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0117 - mae: 0.0762 - mse: 0.0117\n",
      "Epoch 00020: val_loss did not improve from 0.01454\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0117 - mae: 0.0762 - mse: 0.0117 - val_loss: 0.0159 - val_mae: 0.0883 - val_mse: 0.0159\n",
      "Epoch 21/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0740 - mse: 0.0111\n",
      "Epoch 00021: val_loss did not improve from 0.01454\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0111 - mae: 0.0740 - mse: 0.0111 - val_loss: 0.0151 - val_mae: 0.0858 - val_mse: 0.0151\n",
      "Epoch 22/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0114 - mae: 0.0750 - mse: 0.0114\n",
      "Epoch 00022: val_loss did not improve from 0.01454\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0114 - mae: 0.0747 - mse: 0.0114 - val_loss: 0.0158 - val_mae: 0.0902 - val_mse: 0.0158\n",
      "Epoch 23/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0110 - mae: 0.0738 - mse: 0.0110\n",
      "Epoch 00023: val_loss did not improve from 0.01454\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0110 - mae: 0.0737 - mse: 0.0110 - val_loss: 0.0152 - val_mae: 0.0884 - val_mse: 0.0152\n",
      "Epoch 24/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0107 - mae: 0.0728 - mse: 0.0107\n",
      "Epoch 00024: val_loss did not improve from 0.01454\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0107 - mae: 0.0728 - mse: 0.0107 - val_loss: 0.0164 - val_mae: 0.0930 - val_mse: 0.0164\n",
      "Epoch 25/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0723 - mse: 0.0106\n",
      "Epoch 00025: val_loss improved from 0.01454 to 0.01431, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0106 - mae: 0.0723 - mse: 0.0106 - val_loss: 0.0143 - val_mae: 0.0827 - val_mse: 0.0143\n",
      "Epoch 26/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0715 - mse: 0.0103\n",
      "Epoch 00026: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0103 - mae: 0.0714 - mse: 0.0103 - val_loss: 0.0149 - val_mae: 0.0853 - val_mse: 0.0149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0709 - mse: 0.0101\n",
      "Epoch 00027: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0101 - mae: 0.0707 - mse: 0.0101 - val_loss: 0.0149 - val_mae: 0.0851 - val_mse: 0.0149\n",
      "Epoch 28/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0097 - mae: 0.0703 - mse: 0.0097\n",
      "Epoch 00028: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0100 - mae: 0.0705 - mse: 0.0100 - val_loss: 0.0179 - val_mae: 0.1021 - val_mse: 0.0179\n",
      "Epoch 29/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0103 - mae: 0.0719 - mse: 0.0103\n",
      "Epoch 00029: val_loss did not improve from 0.01431\n",
      "14926/14926 [==============================] - 2s 112us/sample - loss: 0.0103 - mae: 0.0720 - mse: 0.0103 - val_loss: 0.0157 - val_mae: 0.0862 - val_mse: 0.0157\n",
      "Epoch 30/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0096 - mae: 0.0689 - mse: 0.0096\n",
      "Epoch 00030: val_loss improved from 0.01431 to 0.01391, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0096 - mae: 0.0687 - mse: 0.0096 - val_loss: 0.0139 - val_mae: 0.0802 - val_mse: 0.0139\n",
      "Epoch 31/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0092 - mae: 0.0675 - mse: 0.0092\n",
      "Epoch 00031: val_loss did not improve from 0.01391\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0092 - mae: 0.0675 - mse: 0.0092 - val_loss: 0.0156 - val_mae: 0.0884 - val_mse: 0.0156\n",
      "Epoch 32/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0660 - mse: 0.0090\n",
      "Epoch 00032: val_loss improved from 0.01391 to 0.01390, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0090 - mae: 0.0661 - mse: 0.0090 - val_loss: 0.0139 - val_mae: 0.0820 - val_mse: 0.0139\n",
      "Epoch 33/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0667 - mse: 0.0090\n",
      "Epoch 00033: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0090 - mae: 0.0667 - mse: 0.0090 - val_loss: 0.0150 - val_mae: 0.0852 - val_mse: 0.0150\n",
      "Epoch 34/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0092 - mae: 0.0668 - mse: 0.0092\n",
      "Epoch 00034: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0091 - mae: 0.0668 - mse: 0.0091 - val_loss: 0.0149 - val_mae: 0.0798 - val_mse: 0.0149\n",
      "Epoch 35/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0647 - mse: 0.0087\n",
      "Epoch 00035: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0087 - mae: 0.0648 - mse: 0.0087 - val_loss: 0.0148 - val_mae: 0.0828 - val_mse: 0.0148\n",
      "Epoch 36/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0089 - mae: 0.0669 - mse: 0.0089\n",
      "Epoch 00036: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0089 - mae: 0.0671 - mse: 0.0089 - val_loss: 0.0158 - val_mae: 0.0877 - val_mse: 0.0158\n",
      "Epoch 37/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0651 - mse: 0.0086\n",
      "Epoch 00037: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0086 - mae: 0.0652 - mse: 0.0086 - val_loss: 0.0150 - val_mae: 0.0843 - val_mse: 0.0150\n",
      "Epoch 38/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0082 - mae: 0.0645 - mse: 0.0082\n",
      "Epoch 00038: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0085 - mae: 0.0648 - mse: 0.0085 - val_loss: 0.0154 - val_mae: 0.0935 - val_mse: 0.0154\n",
      "Epoch 39/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0084 - mae: 0.0647 - mse: 0.0084\n",
      "Epoch 00039: val_loss did not improve from 0.01390\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0084 - mae: 0.0647 - mse: 0.0084 - val_loss: 0.0143 - val_mae: 0.0831 - val_mse: 0.0143\n",
      "Epoch 40/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0611 - mse: 0.0077\n",
      "Epoch 00040: val_loss improved from 0.01390 to 0.01380, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 97us/sample - loss: 0.0077 - mae: 0.0611 - mse: 0.0077 - val_loss: 0.0138 - val_mae: 0.0790 - val_mse: 0.0138\n",
      "Epoch 41/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0626 - mse: 0.0079\n",
      "Epoch 00041: val_loss improved from 0.01380 to 0.01341, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0079 - mae: 0.0625 - mse: 0.0079 - val_loss: 0.0134 - val_mae: 0.0774 - val_mse: 0.0134\n",
      "Epoch 42/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0624 - mse: 0.0079\n",
      "Epoch 00042: val_loss improved from 0.01341 to 0.01335, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 2s 104us/sample - loss: 0.0079 - mae: 0.0626 - mse: 0.0079 - val_loss: 0.0133 - val_mae: 0.0779 - val_mse: 0.0133\n",
      "Epoch 43/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0615 - mse: 0.0077\n",
      "Epoch 00043: val_loss improved from 0.01335 to 0.01333, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0077 - mae: 0.0616 - mse: 0.0077 - val_loss: 0.0133 - val_mae: 0.0784 - val_mse: 0.0133\n",
      "Epoch 44/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0600 - mse: 0.0073\n",
      "Epoch 00044: val_loss improved from 0.01333 to 0.01321, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 100us/sample - loss: 0.0073 - mae: 0.0600 - mse: 0.0073 - val_loss: 0.0132 - val_mae: 0.0762 - val_mse: 0.0132\n",
      "Epoch 45/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0609 - mse: 0.0074\n",
      "Epoch 00045: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 2s 102us/sample - loss: 0.0074 - mae: 0.0609 - mse: 0.0074 - val_loss: 0.0145 - val_mae: 0.0809 - val_mse: 0.0145\n",
      "Epoch 46/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0589 - mse: 0.0071\n",
      "Epoch 00046: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 2s 111us/sample - loss: 0.0071 - mae: 0.0590 - mse: 0.0071 - val_loss: 0.0136 - val_mae: 0.0818 - val_mse: 0.0136\n",
      "Epoch 47/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0597 - mse: 0.0072\n",
      "Epoch 00047: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0072 - mae: 0.0597 - mse: 0.0072 - val_loss: 0.0145 - val_mae: 0.0832 - val_mse: 0.0145\n",
      "Epoch 48/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0598 - mse: 0.0073\n",
      "Epoch 00048: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 91us/sample - loss: 0.0073 - mae: 0.0600 - mse: 0.0073 - val_loss: 0.0136 - val_mae: 0.0780 - val_mse: 0.0136\n",
      "Epoch 49/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0601 - mse: 0.0072\n",
      "Epoch 00049: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0072 - mae: 0.0601 - mse: 0.0072 - val_loss: 0.0134 - val_mae: 0.0767 - val_mse: 0.0134\n",
      "Epoch 50/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0582 - mse: 0.0069\n",
      "Epoch 00050: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0069 - mae: 0.0583 - mse: 0.0069 - val_loss: 0.0141 - val_mae: 0.0792 - val_mse: 0.0141\n",
      "Epoch 51/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0567 - mse: 0.0066\n",
      "Epoch 00051: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0066 - mae: 0.0568 - mse: 0.0066 - val_loss: 0.0139 - val_mae: 0.0802 - val_mse: 0.0139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0579 - mse: 0.0067\n",
      "Epoch 00052: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0067 - mae: 0.0579 - mse: 0.0067 - val_loss: 0.0145 - val_mae: 0.0816 - val_mse: 0.0145\n",
      "Epoch 53/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0061 - mae: 0.0555 - mse: 0.0061\n",
      "Epoch 00053: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0064 - mae: 0.0558 - mse: 0.0064 - val_loss: 0.0158 - val_mae: 0.0873 - val_mse: 0.0158\n",
      "Epoch 54/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0570 - mse: 0.0068\n",
      "Epoch 00054: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 80us/sample - loss: 0.0068 - mae: 0.0570 - mse: 0.0068 - val_loss: 0.0140 - val_mae: 0.0815 - val_mse: 0.0140\n",
      "Epoch 55/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0563 - mse: 0.0064\n",
      "Epoch 00055: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0064 - mae: 0.0563 - mse: 0.0064 - val_loss: 0.0137 - val_mae: 0.0785 - val_mse: 0.0137\n",
      "Epoch 56/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0066 - mae: 0.0572 - mse: 0.0066\n",
      "Epoch 00056: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0066 - mae: 0.0573 - mse: 0.0066 - val_loss: 0.0138 - val_mae: 0.0776 - val_mse: 0.0138\n",
      "Epoch 57/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0556 - mse: 0.0063\n",
      "Epoch 00057: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0063 - mae: 0.0557 - mse: 0.0063 - val_loss: 0.0145 - val_mae: 0.0821 - val_mse: 0.0145\n",
      "Epoch 58/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0062 - mae: 0.0549 - mse: 0.0062\n",
      "Epoch 00058: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0062 - mae: 0.0550 - mse: 0.0062 - val_loss: 0.0141 - val_mae: 0.0813 - val_mse: 0.0141\n",
      "Epoch 59/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0542 - mse: 0.0060\n",
      "Epoch 00059: val_loss did not improve from 0.01321\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0060 - mae: 0.0543 - mse: 0.0060 - val_loss: 0.0140 - val_mae: 0.0783 - val_mse: 0.0140\n",
      "Elapsed time during model training:  79.47601413726807\n",
      "Size of training set 18658\n",
      "Train on 14926 samples, validate on 3732 samples\n",
      "Epoch 1/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0509 - mae: 0.1515 - mse: 0.0509\n",
      "Epoch 00001: val_loss improved from inf to 0.02229, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0507,  mae:0.1513,  mse:0.0507,  val_loss:0.0223,  val_mae:0.1057,  val_mse:0.0223,  \n",
      "14926/14926 [==============================] - 2s 148us/sample - loss: 0.0507 - mae: 0.1513 - mse: 0.0507 - val_loss: 0.0223 - val_mae: 0.1057 - val_mse: 0.0223\n",
      "Epoch 2/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0217 - mae: 0.1072 - mse: 0.0217\n",
      "Epoch 00002: val_loss did not improve from 0.02229\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0217 - mae: 0.1072 - mse: 0.0217 - val_loss: 0.0234 - val_mae: 0.1208 - val_mse: 0.0234\n",
      "Epoch 3/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0194 - mae: 0.1000 - mse: 0.0194\n",
      "Epoch 00003: val_loss improved from 0.02229 to 0.01919, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0194 - mae: 0.1000 - mse: 0.0194 - val_loss: 0.0192 - val_mae: 0.0978 - val_mse: 0.0192\n",
      "Epoch 4/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0185 - mae: 0.0976 - mse: 0.0185\n",
      "Epoch 00004: val_loss did not improve from 0.01919\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0184 - mae: 0.0974 - mse: 0.0184 - val_loss: 0.0200 - val_mae: 0.1077 - val_mse: 0.0200\n",
      "Epoch 5/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0178 - mae: 0.0955 - mse: 0.0178\n",
      "Epoch 00005: val_loss did not improve from 0.01919\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0177 - mae: 0.0955 - mse: 0.0177 - val_loss: 0.0193 - val_mae: 0.1076 - val_mse: 0.0193\n",
      "Epoch 6/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0164 - mae: 0.0913 - mse: 0.0164\n",
      "Epoch 00006: val_loss did not improve from 0.01919\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0164 - mae: 0.0913 - mse: 0.0164 - val_loss: 0.0204 - val_mae: 0.1023 - val_mse: 0.0204\n",
      "Epoch 7/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0159 - mae: 0.0898 - mse: 0.0159\n",
      "Epoch 00007: val_loss improved from 0.01919 to 0.01778, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0160 - mae: 0.0901 - mse: 0.0160 - val_loss: 0.0178 - val_mae: 0.0905 - val_mse: 0.0178\n",
      "Epoch 8/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0161 - mae: 0.0908 - mse: 0.0161\n",
      "Epoch 00008: val_loss improved from 0.01778 to 0.01751, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0162 - mae: 0.0909 - mse: 0.0162 - val_loss: 0.0175 - val_mae: 0.0920 - val_mse: 0.0175\n",
      "Epoch 9/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0858 - mse: 0.0146\n",
      "Epoch 00009: val_loss improved from 0.01751 to 0.01520, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0145 - mae: 0.0856 - mse: 0.0145 - val_loss: 0.0152 - val_mae: 0.0866 - val_mse: 0.0152\n",
      "Epoch 10/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0146 - mae: 0.0861 - mse: 0.0146\n",
      "Epoch 00010: val_loss improved from 0.01520 to 0.01421, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0145 - mae: 0.0859 - mse: 0.0145 - val_loss: 0.0142 - val_mae: 0.0820 - val_mse: 0.0142\n",
      "Epoch 11/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0140 - mae: 0.0839 - mse: 0.0140\n",
      "Epoch 00011: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0140 - mae: 0.0838 - mse: 0.0140 - val_loss: 0.0184 - val_mae: 0.0985 - val_mse: 0.0184\n",
      "Epoch 12/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0140 - mae: 0.0833 - mse: 0.0140\n",
      "Epoch 00012: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0139 - mae: 0.0832 - mse: 0.0139 - val_loss: 0.0167 - val_mae: 0.0925 - val_mse: 0.0167\n",
      "Epoch 13/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0130 - mae: 0.0796 - mse: 0.0130\n",
      "Epoch 00013: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0130 - mae: 0.0796 - mse: 0.0130 - val_loss: 0.0152 - val_mae: 0.0873 - val_mse: 0.0152\n",
      "Epoch 14/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0134 - mae: 0.0822 - mse: 0.0134\n",
      "Epoch 00014: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0135 - mae: 0.0825 - mse: 0.0135 - val_loss: 0.0184 - val_mae: 0.0937 - val_mse: 0.0184\n",
      "Epoch 15/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0122 - mae: 0.0774 - mse: 0.0122\n",
      "Epoch 00015: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0122 - mae: 0.0775 - mse: 0.0122 - val_loss: 0.0151 - val_mae: 0.0849 - val_mse: 0.0151\n",
      "Epoch 16/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0120 - mae: 0.0769 - mse: 0.0120\n",
      "Epoch 00016: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0120 - mae: 0.0770 - mse: 0.0120 - val_loss: 0.0165 - val_mae: 0.0933 - val_mse: 0.0165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0770 - mse: 0.0119\n",
      "Epoch 00017: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 2s 119us/sample - loss: 0.0119 - mae: 0.0772 - mse: 0.0119 - val_loss: 0.0167 - val_mae: 0.0948 - val_mse: 0.0167\n",
      "Epoch 18/1000\n",
      "14240/14926 [===========================>..] - ETA: 0s - loss: 0.0116 - mae: 0.0749 - mse: 0.0116\n",
      "Epoch 00018: val_loss did not improve from 0.01421\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0114 - mae: 0.0746 - mse: 0.0114 - val_loss: 0.0163 - val_mae: 0.0858 - val_mse: 0.0163\n",
      "Epoch 19/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0112 - mae: 0.0745 - mse: 0.0112\n",
      "Epoch 00019: val_loss improved from 0.01421 to 0.01406, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0112 - mae: 0.0747 - mse: 0.0112 - val_loss: 0.0141 - val_mae: 0.0796 - val_mse: 0.0141\n",
      "Epoch 20/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0111 - mae: 0.0742 - mse: 0.0111\n",
      "Epoch 00020: val_loss improved from 0.01406 to 0.01368, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0111 - mae: 0.0741 - mse: 0.0111 - val_loss: 0.0137 - val_mae: 0.0793 - val_mse: 0.0137\n",
      "Epoch 21/1000\n",
      "14624/14926 [============================>.] - ETA: 0s - loss: 0.0105 - mae: 0.0716 - mse: 0.0105\n",
      "Epoch 00021: val_loss improved from 0.01368 to 0.01355, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 88us/sample - loss: 0.0106 - mae: 0.0717 - mse: 0.0106 - val_loss: 0.0136 - val_mae: 0.0814 - val_mse: 0.0136\n",
      "Epoch 22/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0697 - mse: 0.0099\n",
      "Epoch 00022: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 89us/sample - loss: 0.0100 - mae: 0.0698 - mse: 0.0100 - val_loss: 0.0140 - val_mae: 0.0815 - val_mse: 0.0140\n",
      "Epoch 23/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0100 - mae: 0.0700 - mse: 0.0100\n",
      "Epoch 00023: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 84us/sample - loss: 0.0100 - mae: 0.0700 - mse: 0.0100 - val_loss: 0.0162 - val_mae: 0.0893 - val_mse: 0.0162\n",
      "Epoch 24/1000\n",
      "14688/14926 [============================>.] - ETA: 0s - loss: 0.0096 - mae: 0.0684 - mse: 0.0096\n",
      "Epoch 00024: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0096 - mae: 0.0685 - mse: 0.0096 - val_loss: 0.0143 - val_mae: 0.0796 - val_mse: 0.0143\n",
      "Epoch 25/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0101 - mae: 0.0701 - mse: 0.0101\n",
      "Epoch 00025: val_loss did not improve from 0.01355\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0101 - mae: 0.0703 - mse: 0.0101 - val_loss: 0.0144 - val_mae: 0.0841 - val_mse: 0.0144\n",
      "Epoch 26/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0098 - mae: 0.0698 - mse: 0.0098\n",
      "Epoch 00026: val_loss improved from 0.01355 to 0.01336, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 87us/sample - loss: 0.0098 - mae: 0.0698 - mse: 0.0098 - val_loss: 0.0134 - val_mae: 0.0795 - val_mse: 0.0134\n",
      "Epoch 27/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0652 - mse: 0.0088\n",
      "Epoch 00027: val_loss did not improve from 0.01336\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0088 - mae: 0.0652 - mse: 0.0088 - val_loss: 0.0139 - val_mae: 0.0790 - val_mse: 0.0139\n",
      "Epoch 28/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0654 - mse: 0.0088\n",
      "Epoch 00028: val_loss improved from 0.01336 to 0.01315, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 86us/sample - loss: 0.0088 - mae: 0.0654 - mse: 0.0088 - val_loss: 0.0131 - val_mae: 0.0772 - val_mse: 0.0131\n",
      "Epoch 29/1000\n",
      "14656/14926 [============================>.] - ETA: 0s - loss: 0.0088 - mae: 0.0659 - mse: 0.0088\n",
      "Epoch 00029: val_loss did not improve from 0.01315\n",
      "14926/14926 [==============================] - 1s 94us/sample - loss: 0.0088 - mae: 0.0659 - mse: 0.0088 - val_loss: 0.0135 - val_mae: 0.0820 - val_mse: 0.0135\n",
      "Epoch 30/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0086 - mae: 0.0650 - mse: 0.0086\n",
      "Epoch 00030: val_loss improved from 0.01315 to 0.01293, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 92us/sample - loss: 0.0085 - mae: 0.0648 - mse: 0.0085 - val_loss: 0.0129 - val_mae: 0.0748 - val_mse: 0.0129\n",
      "Epoch 31/1000\n",
      "14336/14926 [===========================>..] - ETA: 0s - loss: 0.0084 - mae: 0.0637 - mse: 0.0084\n",
      "Epoch 00031: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 2s 110us/sample - loss: 0.0084 - mae: 0.0635 - mse: 0.0084 - val_loss: 0.0137 - val_mae: 0.0811 - val_mse: 0.0137\n",
      "Epoch 32/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0079 - mae: 0.0615 - mse: 0.0079\n",
      "Epoch 00032: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 2s 106us/sample - loss: 0.0079 - mae: 0.0618 - mse: 0.0079 - val_loss: 0.0132 - val_mae: 0.0783 - val_mse: 0.0132\n",
      "Epoch 33/1000\n",
      "14912/14926 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0625 - mse: 0.0081\n",
      "Epoch 00033: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0081 - mae: 0.0625 - mse: 0.0081 - val_loss: 0.0147 - val_mae: 0.0849 - val_mse: 0.0147\n",
      "Epoch 34/1000\n",
      "14432/14926 [============================>.] - ETA: 0s - loss: 0.0078 - mae: 0.0614 - mse: 0.0078\n",
      "Epoch 00034: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0078 - mae: 0.0615 - mse: 0.0078 - val_loss: 0.0160 - val_mae: 0.0882 - val_mse: 0.0160\n",
      "Epoch 35/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0602 - mse: 0.0075\n",
      "Epoch 00035: val_loss improved from 0.01293 to 0.01293, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 93us/sample - loss: 0.0074 - mae: 0.0601 - mse: 0.0074 - val_loss: 0.0129 - val_mae: 0.0766 - val_mse: 0.0129\n",
      "Epoch 36/1000\n",
      "14720/14926 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0601 - mse: 0.0075\n",
      "Epoch 00036: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0074 - mae: 0.0600 - mse: 0.0074 - val_loss: 0.0135 - val_mae: 0.0793 - val_mse: 0.0135\n",
      "Epoch 37/1000\n",
      "14752/14926 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0602 - mse: 0.0074\n",
      "Epoch 00037: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 81us/sample - loss: 0.0075 - mae: 0.0604 - mse: 0.0075 - val_loss: 0.0139 - val_mae: 0.0798 - val_mse: 0.0139\n",
      "Epoch 38/1000\n",
      "14880/14926 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0609 - mse: 0.0076\n",
      "Epoch 00038: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0076 - mae: 0.0610 - mse: 0.0076 - val_loss: 0.0152 - val_mae: 0.0841 - val_mse: 0.0152\n",
      "Epoch 39/1000\n",
      "14592/14926 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0582 - mse: 0.0069\n",
      "Epoch 00039: val_loss did not improve from 0.01293\n",
      "14926/14926 [==============================] - 1s 96us/sample - loss: 0.0070 - mae: 0.0583 - mse: 0.0070 - val_loss: 0.0134 - val_mae: 0.0794 - val_mse: 0.0134\n",
      "Epoch 40/1000\n",
      "14272/14926 [===========================>..] - ETA: 0s - loss: 0.0068 - mae: 0.0570 - mse: 0.0068\n",
      "Epoch 00040: val_loss improved from 0.01293 to 0.01280, saving model to model_checkpoint.h5\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0068 - mae: 0.0569 - mse: 0.0068 - val_loss: 0.0128 - val_mae: 0.0757 - val_mse: 0.0128\n",
      "Epoch 41/1000\n",
      "14528/14926 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0596 - mse: 0.0073\n",
      "Epoch 00041: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0073 - mae: 0.0595 - mse: 0.0073 - val_loss: 0.0132 - val_mae: 0.0772 - val_mse: 0.0132\n",
      "Epoch 42/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0561 - mse: 0.0066\n",
      "Epoch 00042: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0066 - mae: 0.0562 - mse: 0.0066 - val_loss: 0.0137 - val_mae: 0.0800 - val_mse: 0.0137\n",
      "Epoch 43/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0063 - mae: 0.0555 - mse: 0.0063\n",
      "Epoch 00043: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 120us/sample - loss: 0.0063 - mae: 0.0555 - mse: 0.0063 - val_loss: 0.0142 - val_mae: 0.0831 - val_mse: 0.0142\n",
      "Epoch 44/1000\n",
      "14368/14926 [===========================>..] - ETA: 0s - loss: 0.0065 - mae: 0.0563 - mse: 0.0065\n",
      "Epoch 00044: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 2s 113us/sample - loss: 0.0065 - mae: 0.0563 - mse: 0.0065 - val_loss: 0.0135 - val_mae: 0.0771 - val_mse: 0.0135\n",
      "Epoch 45/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0059 - mae: 0.0547 - mse: 0.0059\n",
      "Epoch 00045: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0063 - mae: 0.0550 - mse: 0.0063 - val_loss: 0.0131 - val_mae: 0.0785 - val_mse: 0.0131\n",
      "Epoch 46/1000\n",
      "14464/14926 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0566 - mse: 0.0065\n",
      "Epoch 00046: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 95us/sample - loss: 0.0065 - mae: 0.0567 - mse: 0.0065 - val_loss: 0.0146 - val_mae: 0.0825 - val_mse: 0.0146\n",
      "Epoch 47/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0060 - mae: 0.0535 - mse: 0.0060\n",
      "Epoch 00047: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0060 - mae: 0.0535 - mse: 0.0060 - val_loss: 0.0131 - val_mae: 0.0772 - val_mse: 0.0131\n",
      "Epoch 48/1000\n",
      "14816/14926 [============================>.] - ETA: 0s - loss: 0.0058 - mae: 0.0528 - mse: 0.0058\n",
      "Epoch 00048: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0058 - mae: 0.0529 - mse: 0.0058 - val_loss: 0.0155 - val_mae: 0.0852 - val_mse: 0.0155\n",
      "Epoch 49/1000\n",
      "14560/14926 [============================>.] - ETA: 0s - loss: 0.0061 - mae: 0.0546 - mse: 0.0061\n",
      "Epoch 00049: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 82us/sample - loss: 0.0061 - mae: 0.0545 - mse: 0.0061 - val_loss: 0.0133 - val_mae: 0.0763 - val_mse: 0.0133\n",
      "Epoch 50/1000\n",
      "14496/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0510 - mse: 0.0054\n",
      "Epoch 00050: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0054 - mae: 0.0510 - mse: 0.0054 - val_loss: 0.0134 - val_mae: 0.0775 - val_mse: 0.0134\n",
      "Epoch 51/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0057 - mae: 0.0523 - mse: 0.0057\n",
      "Epoch 00051: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0057 - mae: 0.0521 - mse: 0.0057 - val_loss: 0.0135 - val_mae: 0.0770 - val_mse: 0.0135\n",
      "Epoch 52/1000\n",
      "14400/14926 [===========================>..] - ETA: 0s - loss: 0.0055 - mae: 0.0518 - mse: 0.0055\n",
      "Epoch 00052: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0055 - mae: 0.0518 - mse: 0.0055 - val_loss: 0.0134 - val_mae: 0.0770 - val_mse: 0.0134\n",
      "Epoch 53/1000\n",
      "14784/14926 [============================>.] - ETA: 0s - loss: 0.0056 - mae: 0.0519 - mse: 0.0056\n",
      "Epoch 00053: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 85us/sample - loss: 0.0056 - mae: 0.0520 - mse: 0.0056 - val_loss: 0.0132 - val_mae: 0.0776 - val_mse: 0.0132\n",
      "Epoch 54/1000\n",
      "14304/14926 [===========================>..] - ETA: 0s - loss: 0.0052 - mae: 0.0507 - mse: 0.0052\n",
      "Epoch 00054: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 83us/sample - loss: 0.0052 - mae: 0.0505 - mse: 0.0052 - val_loss: 0.0130 - val_mae: 0.0756 - val_mse: 0.0130\n",
      "Epoch 55/1000\n",
      "14848/14926 [============================>.] - ETA: 0s - loss: 0.0054 - mae: 0.0508 - mse: 0.0054\n",
      "Epoch 00055: val_loss did not improve from 0.01280\n",
      "14926/14926 [==============================] - 1s 99us/sample - loss: 0.0054 - mae: 0.0508 - mse: 0.0054 - val_loss: 0.0133 - val_mae: 0.0760 - val_mse: 0.0133\n",
      "Elapsed time during model training:  75.18348240852356\n",
      "\n",
      "Time elapsed for hp opt: 3486.756028652191\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "r = gp_minimize(objective, space, n_calls=60, n_jobs=n_core)\n",
    "#r = gp_minimize(objective, space, n_calls=20)\n",
    "end = time.time()\n",
    "print(\"\\nTime elapsed for hp opt: %s\" %(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[255, 0.001672542188205779, 11, 482, 0.8679237410076581]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot hp opt results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fca2073ae48>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from skopt.plots import plot_convergence\n",
    "plot_convergence(r, yscale=\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use best hps to train single model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#following must be defined\n",
    "algo = 'nn' #am I using XGBoost (xgb) or Neural Nets (nn)?\n",
    "total_frac = 1 #total fraction of data set to work with\n",
    "training_pct = .7 #how much percent of total fraction should be used for training\n",
    "random_split = True #make True if the training data should be chosen randomly\n",
    "n_remote = 10000 #the n_remote most remote points will be added to training set if random_split = False\n",
    "USE_PCA = True #should I use PCA?\n",
    "N_COMPONENTS=400 #how many PCA Components should I use?\n",
    "del_defective_mofs = False #make True if you want to remove all MOFs which a '0' value for at least one geometric property\n",
    "cat_si_sd = False #make True if you want to concatenate size-indep and size-dep fps\n",
    "add_size_fp = False #make True if you want to add 20 feature columns, where each feature is the number of atoms in a linker\n",
    "size_dependent = False #make True if the input ML-ready data contains fingerprint which does not normalize each PG feature$\n",
    "stacked = True #make True if the input ML-ready data contains pressure as feature\n",
    "n_core = 18 #number of cores to use\n",
    "if not stacked:\n",
    "    SD_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_no_norm/ml_data.csv' #path to size-dep data\n",
    "else:\n",
    "    SD_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_no_norm/stacked.csv'\n",
    "if not stacked:\n",
    "    SI_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_v1/ml_data.csv' #path to size-indep data\n",
    "else:\n",
    "    SI_ML_DATA_PATH = '/data/rgur/efrc/prep_data/all_v1/stacked.csv'\n",
    "if not stacked:\n",
    "    start_str_sd = 'CH4_v/v_248_bar'\n",
    "    end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "else:\n",
    "    start_str_sd = 'Density'\n",
    "    end_str_sd = 'norm_Dom._Pore_(ang.)'\n",
    "\n",
    "start_str_si = 'filename'\n",
    "end_str_si = 'valence_pa'\n",
    "del_geometric_fp = False #make True if you want to ignore the geometric features\n",
    "cat_col_names = ['oh_1', 'oh_2', 'oh_3', 'oh_4'] #names for interpenetration columns\n",
    "Y_DATA_PATH = '/data/rgur/efrc/data_DONOTTOUCH/hMOF_allData_March25_2013.xlsx' #path to original hMOF data\n",
    "default_params = {'objective':'reg:linear', 'colsample_bytree':0.3, 'learning_rate':0.1,\n",
    "                'max_depth':15, 'alpha':10, 'n_estimators':10}\n",
    "n_trees = 50 #number of weak learners. Bigger is better until 5000\n",
    "save_pp = False #make True if you want to save the parity plot\n",
    "#########################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/modules/anaconda3/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3296: DtypeWarning: Columns (5,6,7,8,9,10,11,12,13) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Using following 420 features\n",
      "Mafp_Br1_C2_C1\n",
      "Mafp_Br1_C2_C2\n",
      "Mafp_Br1_C2_C3\n",
      "Mafp_Br1_C3_Br1\n",
      "Mafp_Br1_C3_C1\n",
      "Mafp_Br1_C3_C2\n",
      "Mafp_Br1_C3_C3\n",
      "Mafp_Br1_C3_C4\n",
      "Mafp_Br1_C3_N1\n",
      "Mafp_Br1_C3_N2\n",
      "Mafp_Br1_C3_N3\n",
      "Mafp_Br1_C3_O1\n",
      "Mafp_Br1_C4_Br1\n",
      "Mafp_Br1_C4_C2\n",
      "Mafp_Br1_C4_C3\n",
      "Mafp_Br1_C4_C4\n",
      "Mafp_Br1_C4_H1\n",
      "Mafp_Br1_C4_N1\n",
      "Mafp_Br1_C4_N2\n",
      "Mafp_Br1_C4_N3\n",
      "Mafp_Br1_C4_O1\n",
      "Mafp_Br1_C4_O2\n",
      "Mafp_Br1_N2_C2\n",
      "Mafp_Br1_N2_C3\n",
      "Mafp_Br1_N2_C4\n",
      "Mafp_Br1_N2_N1\n",
      "Mafp_Br1_N2_N2\n",
      "Mafp_Br1_N2_N3\n",
      "Mafp_Br1_N3_Br1\n",
      "Mafp_Br1_N3_C2\n",
      "Mafp_Br1_N3_C3\n",
      "Mafp_Br1_N3_H1\n",
      "Mafp_Br1_N3_N2\n",
      "Mafp_Br1_N3_O2\n",
      "Mafp_Br1_O2_C2\n",
      "Mafp_Br1_O2_C3\n",
      "Mafp_Br1_O2_C4\n",
      "Mafp_C1_C2_C2\n",
      "Mafp_C1_C2_C3\n",
      "Mafp_C1_C2_C4\n",
      "Mafp_C1_C2_F1\n",
      "Mafp_C1_C2_H1\n",
      "Mafp_C1_C2_O1\n",
      "Mafp_C1_C2_O2\n",
      "Mafp_C1_C3_C2\n",
      "Mafp_C1_C3_C3\n",
      "Mafp_C1_C3_C4\n",
      "Mafp_C1_C3_Cl1\n",
      "Mafp_C1_C3_F1\n",
      "Mafp_C1_C3_H1\n",
      "Mafp_C1_C3_N2\n",
      "Mafp_C1_C3_N3\n",
      "Mafp_C1_C3_O1\n",
      "Mafp_C1_C3_O2\n",
      "Mafp_C1_C4_C2\n",
      "Mafp_C1_C4_C3\n",
      "Mafp_C1_C4_C4\n",
      "Mafp_C1_C4_H1\n",
      "Mafp_C1_C4_O1\n",
      "Mafp_C1_C4_O2\n",
      "Mafp_C1_N2_C2\n",
      "Mafp_C1_N2_C3\n",
      "Mafp_C1_N2_N2\n",
      "Mafp_C1_N2_N3\n",
      "Mafp_C1_N3_C3\n",
      "Mafp_C1_N3_C4\n",
      "Mafp_C1_N3_N2\n",
      "Mafp_C1_N3_N3\n",
      "Mafp_C1_N3_O1\n",
      "Mafp_C1_O2_C3\n",
      "Mafp_C1_O2_C4\n",
      "Mafp_C2_C2_C2\n",
      "Mafp_C2_C2_C3\n",
      "Mafp_C2_C2_C4\n",
      "Mafp_C2_C2_Cl1\n",
      "Mafp_C2_C2_F1\n",
      "Mafp_C2_C2_H1\n",
      "Mafp_C2_C2_N1\n",
      "Mafp_C2_C2_N2\n",
      "Mafp_C2_C2_N3\n",
      "Mafp_C2_C2_O1\n",
      "Mafp_C2_C2_O2\n",
      "Mafp_C2_C3_C2\n",
      "Mafp_C2_C3_C3\n",
      "Mafp_C2_C3_C4\n",
      "Mafp_C2_C3_Cl1\n",
      "Mafp_C2_C3_F1\n",
      "Mafp_C2_C3_H1\n",
      "Mafp_C2_C3_N1\n",
      "Mafp_C2_C3_N2\n",
      "Mafp_C2_C3_N3\n",
      "Mafp_C2_C3_O1\n",
      "Mafp_C2_C3_O2\n",
      "Mafp_C2_C4_C2\n",
      "Mafp_C2_C4_C3\n",
      "Mafp_C2_C4_C4\n",
      "Mafp_C2_C4_Cl1\n",
      "Mafp_C2_C4_F1\n",
      "Mafp_C2_C4_H1\n",
      "Mafp_C2_C4_N2\n",
      "Mafp_C2_C4_N3\n",
      "Mafp_C2_C4_O1\n",
      "Mafp_C2_C4_O2\n",
      "Mafp_C2_N2_C2\n",
      "Mafp_C2_N2_C3\n",
      "Mafp_C2_N2_C4\n",
      "Mafp_C2_N2_Cl1\n",
      "Mafp_C2_N2_F1\n",
      "Mafp_C2_N2_H1\n",
      "Mafp_C2_N2_N1\n",
      "Mafp_C2_N2_N2\n",
      "Mafp_C2_N2_N3\n",
      "Mafp_C2_N2_O1\n",
      "Mafp_C2_N2_O2\n",
      "Mafp_C2_N3_C2\n",
      "Mafp_C2_N3_C3\n",
      "Mafp_C2_N3_C4\n",
      "Mafp_C2_N3_F1\n",
      "Mafp_C2_N3_H1\n",
      "Mafp_C2_N3_N2\n",
      "Mafp_C2_N3_N3\n",
      "Mafp_C2_N3_O1\n",
      "Mafp_C2_N3_O2\n",
      "Mafp_C2_O2_C2\n",
      "Mafp_C2_O2_C3\n",
      "Mafp_C2_O2_C4\n",
      "Mafp_C2_O2_Cl1\n",
      "Mafp_C2_O2_H1\n",
      "Mafp_C2_O2_N2\n",
      "Mafp_C2_O2_N3\n",
      "Mafp_C3_C2_C3\n",
      "Mafp_C3_C2_C4\n",
      "Mafp_C3_C2_Cl1\n",
      "Mafp_C3_C2_F1\n",
      "Mafp_C3_C2_H1\n",
      "Mafp_C3_C2_N1\n",
      "Mafp_C3_C2_N2\n",
      "Mafp_C3_C2_N3\n",
      "Mafp_C3_C2_O1\n",
      "Mafp_C3_C2_O2\n",
      "Mafp_C3_C3_C3\n",
      "Mafp_C3_C3_C4\n",
      "Mafp_C3_C3_Cl1\n",
      "Mafp_C3_C3_F1\n",
      "Mafp_C3_C3_H1\n",
      "Mafp_C3_C3_N1\n",
      "Mafp_C3_C3_N2\n",
      "Mafp_C3_C3_N3\n",
      "Mafp_C3_C3_O1\n",
      "Mafp_C3_C3_O2\n",
      "Mafp_C3_C4_C3\n",
      "Mafp_C3_C4_C4\n",
      "Mafp_C3_C4_Cl1\n",
      "Mafp_C3_C4_F1\n",
      "Mafp_C3_C4_H1\n",
      "Mafp_C3_C4_N1\n",
      "Mafp_C3_C4_N2\n",
      "Mafp_C3_C4_N3\n",
      "Mafp_C3_C4_O1\n",
      "Mafp_C3_C4_O2\n",
      "Mafp_C3_N2_C3\n",
      "Mafp_C3_N2_C4\n",
      "Mafp_C3_N2_Cl1\n",
      "Mafp_C3_N2_F1\n",
      "Mafp_C3_N2_H1\n",
      "Mafp_C3_N2_N1\n",
      "Mafp_C3_N2_N2\n",
      "Mafp_C3_N2_N3\n",
      "Mafp_C3_N2_O1\n",
      "Mafp_C3_N2_O2\n",
      "Mafp_C3_N3_C3\n",
      "Mafp_C3_N3_C4\n",
      "Mafp_C3_N3_Cl1\n",
      "Mafp_C3_N3_F1\n",
      "Mafp_C3_N3_H1\n",
      "Mafp_C3_N3_N1\n",
      "Mafp_C3_N3_N2\n",
      "Mafp_C3_N3_N3\n",
      "Mafp_C3_N3_O2\n",
      "Mafp_C3_O2_C3\n",
      "Mafp_C3_O2_C4\n",
      "Mafp_C3_O2_Cl1\n",
      "Mafp_C3_O2_F1\n",
      "Mafp_C3_O2_H1\n",
      "Mafp_C3_O2_N2\n",
      "Mafp_C3_O2_N3\n",
      "Mafp_C3_O2_O1\n",
      "Mafp_C3_O2_O2\n",
      "Mafp_C4_C2_C4\n",
      "Mafp_C4_C2_H1\n",
      "Mafp_C4_C2_N1\n",
      "Mafp_C4_C2_N2\n",
      "Mafp_C4_C2_N3\n",
      "Mafp_C4_C2_O1\n",
      "Mafp_C4_C2_O2\n",
      "Mafp_C4_C3_C4\n",
      "Mafp_C4_C3_Cl1\n",
      "Mafp_C4_C3_F1\n",
      "Mafp_C4_C3_H1\n",
      "Mafp_C4_C3_N1\n",
      "Mafp_C4_C3_N2\n",
      "Mafp_C4_C3_N3\n",
      "Mafp_C4_C3_O1\n",
      "Mafp_C4_C3_O2\n",
      "Mafp_C4_C4_C4\n",
      "Mafp_C4_C4_Cl1\n",
      "Mafp_C4_C4_F1\n",
      "Mafp_C4_C4_H1\n",
      "Mafp_C4_C4_N1\n",
      "Mafp_C4_C4_N2\n",
      "Mafp_C4_C4_N3\n",
      "Mafp_C4_C4_O1\n",
      "Mafp_C4_C4_O2\n",
      "Mafp_C4_N2_C4\n",
      "Mafp_C4_N2_H1\n",
      "Mafp_C4_N2_N1\n",
      "Mafp_C4_N2_N2\n",
      "Mafp_C4_N2_N3\n",
      "Mafp_C4_N2_O1\n",
      "Mafp_C4_N3_C4\n",
      "Mafp_C4_N3_F1\n",
      "Mafp_C4_N3_H1\n",
      "Mafp_C4_N3_N1\n",
      "Mafp_C4_N3_N2\n",
      "Mafp_C4_N3_N3\n",
      "Mafp_C4_N3_O1\n",
      "Mafp_C4_N3_O2\n",
      "Mafp_C4_O2_C4\n",
      "Mafp_C4_O2_Cl1\n",
      "Mafp_C4_O2_F1\n",
      "Mafp_C4_O2_H1\n",
      "Mafp_C4_O2_N2\n",
      "Mafp_C4_O2_N3\n",
      "Mafp_C4_O2_O1\n",
      "Mafp_C4_O2_O2\n",
      "Mafp_Cl1_C3_Cl1\n",
      "Mafp_Cl1_C3_H1\n",
      "Mafp_Cl1_C3_N1\n",
      "Mafp_Cl1_C3_N2\n",
      "Mafp_Cl1_C3_N3\n",
      "Mafp_Cl1_C3_O1\n",
      "Mafp_Cl1_C4_Cl1\n",
      "Mafp_Cl1_C4_H1\n",
      "Mafp_Cl1_C4_N2\n",
      "Mafp_Cl1_C4_N3\n",
      "Mafp_Cl1_C4_O1\n",
      "Mafp_Cl1_C4_O2\n",
      "Mafp_Cl1_N2_N1\n",
      "Mafp_Cl1_N2_N2\n",
      "Mafp_Cl1_N3_Cl1\n",
      "Mafp_Cl1_N3_H1\n",
      "Mafp_Cl1_N3_N2\n",
      "Mafp_F1_C3_F1\n",
      "Mafp_F1_C3_N1\n",
      "Mafp_F1_C3_N2\n",
      "Mafp_F1_C3_N3\n",
      "Mafp_F1_C3_O1\n",
      "Mafp_F1_C3_O2\n",
      "Mafp_F1_C4_F1\n",
      "Mafp_F1_C4_H1\n",
      "Mafp_F1_C4_N2\n",
      "Mafp_F1_C4_N3\n",
      "Mafp_F1_C4_O1\n",
      "Mafp_F1_C4_O2\n",
      "Mafp_F1_N2_N2\n",
      "Mafp_F1_N3_F1\n",
      "Mafp_F1_N3_H1\n",
      "Mafp_F1_N3_N1\n",
      "Mafp_F1_N3_N2\n",
      "Mafp_F1_N3_N3\n",
      "Mafp_H1_C2_H1\n",
      "Mafp_H1_C2_N1\n",
      "Mafp_H1_C2_N2\n",
      "Mafp_H1_C2_N3\n",
      "Mafp_H1_C2_O1\n",
      "Mafp_H1_C2_O2\n",
      "Mafp_H1_C3_H1\n",
      "Mafp_H1_C3_N1\n",
      "Mafp_H1_C3_N2\n",
      "Mafp_H1_C3_N3\n",
      "Mafp_H1_C3_O1\n",
      "Mafp_H1_C3_O2\n",
      "Mafp_H1_C4_H1\n",
      "Mafp_H1_C4_N2\n",
      "Mafp_H1_C4_N3\n",
      "Mafp_H1_C4_O1\n",
      "Mafp_H1_C4_O2\n",
      "Mafp_H1_N2_H1\n",
      "Mafp_H1_N2_N1\n",
      "Mafp_H1_N2_N2\n",
      "Mafp_H1_N2_N3\n",
      "Mafp_H1_N3_H1\n",
      "Mafp_H1_N3_N1\n",
      "Mafp_H1_N3_N2\n",
      "Mafp_H1_N3_N3\n",
      "Mafp_H1_N3_O2\n",
      "Mafp_H1_O2_H1\n",
      "Mafp_H1_O2_N2\n",
      "Mafp_H1_O2_O1\n",
      "Mafp_H1_O2_O2\n",
      "Mafp_N1_C2_N2\n",
      "Mafp_N1_C2_N3\n",
      "Mafp_N1_C2_O2\n",
      "Mafp_N1_C3_N2\n",
      "Mafp_N1_C3_N3\n",
      "Mafp_N1_C3_O1\n",
      "Mafp_N1_C3_O2\n",
      "Mafp_N1_C4_N2\n",
      "Mafp_N1_C4_N3\n",
      "Mafp_N1_C4_O2\n",
      "Mafp_N1_N2_N3\n",
      "Mafp_N1_N3_N2\n",
      "Mafp_N1_N3_N3\n",
      "Mafp_N2_C2_N2\n",
      "Mafp_N2_C2_N3\n",
      "Mafp_N2_C2_O2\n",
      "Mafp_N2_C3_N2\n",
      "Mafp_N2_C3_N3\n",
      "Mafp_N2_C3_O1\n",
      "Mafp_N2_C3_O2\n",
      "Mafp_N2_C4_N2\n",
      "Mafp_N2_C4_N3\n",
      "Mafp_N2_C4_O1\n",
      "Mafp_N2_C4_O2\n",
      "Mafp_N2_N2_N2\n",
      "Mafp_N2_N2_N3\n",
      "Mafp_N2_N2_O2\n",
      "Mafp_N2_N3_N2\n",
      "Mafp_N2_N3_N3\n",
      "Mafp_N2_N3_O2\n",
      "Mafp_N2_O2_N3\n",
      "Mafp_N3_C2_O1\n",
      "Mafp_N3_C3_N3\n",
      "Mafp_N3_C3_O1\n",
      "Mafp_N3_C3_O2\n",
      "Mafp_N3_C4_N3\n",
      "Mafp_N3_C4_O1\n",
      "Mafp_N3_C4_O2\n",
      "Mafp_N3_N2_N3\n",
      "Mafp_N3_N2_O1\n",
      "Mafp_N3_N2_O2\n",
      "Mafp_N3_N3_N3\n",
      "Mafp_N3_N3_O1\n",
      "Mafp_N3_N3_O2\n",
      "Mafp_N3_O2_N3\n",
      "Mafp_O1_C2_O1\n",
      "Mafp_O1_C2_O2\n",
      "Mafp_O1_C3_O1\n",
      "Mafp_O1_C3_O2\n",
      "Mafp_O1_C4_O1\n",
      "Mafp_O1_C4_O2\n",
      "Mafp_O1_N3_O2\n",
      "Mafp_O2_C2_O2\n",
      "Mafp_O2_C3_O2\n",
      "Mafp_O2_C4_O2\n",
      "Mafp_O2_N3_O2\n",
      "Mefp_fam_acrylate\n",
      "Mefp_fam_carbonateester\n",
      "Mefp_fam_ketone\n",
      "Mefp_fam_polyamides\n",
      "Mefp_fam_single\n",
      "Mefp_norm_mol_wt\n",
      "Mefp_numatoms_none_H\n",
      "Mefp_ring\n",
      "Mmfp_Chi0n\n",
      "Mmfp_Chi0v\n",
      "Mmfp_Chi1n\n",
      "Mmfp_Chi1v\n",
      "Mmfp_Chi2n\n",
      "Mmfp_Chi2v\n",
      "Mmfp_HallKierAlpha\n",
      "Mmfp_MQNs13\n",
      "Mmfp_MQNs14\n",
      "Mmfp_MQNs15\n",
      "Mmfp_MQNs16\n",
      "Mmfp_MQNs17\n",
      "Mmfp_MQNs18\n",
      "Mmfp_MQNs19\n",
      "Mmfp_MQNs20\n",
      "Mmfp_MQNs21\n",
      "Mmfp_MQNs22\n",
      "Mmfp_MQNs23\n",
      "Mmfp_MQNs24\n",
      "Mmfp_MQNs25\n",
      "Mmfp_MQNs26\n",
      "Mmfp_MQNs27\n",
      "Mmfp_MQNs28\n",
      "Mmfp_MQNs29\n",
      "Mmfp_MQNs30\n",
      "Mmfp_MQNs31\n",
      "Mmfp_MQNs32\n",
      "Mmfp_MQNs33\n",
      "Mmfp_MQNs34\n",
      "Mmfp_MQNs35\n",
      "Mmfp_MQNs36\n",
      "Mmfp_MQNs37\n",
      "Mmfp_MQNs38\n",
      "Mmfp_MQNs39\n",
      "Mmfp_MQNs40\n",
      "Mmfp_MQNs41\n",
      "Mmfp_MQNs42\n",
      "Mmfp_NumAliphaticRings\n",
      "Mmfp_NumAromaticRings\n",
      "Mmfp_tpsa\n",
      "norm_valence_pa\n",
      "norm_atomic_rad_pa_(angstroms)\n",
      "norm_affinity_pa_(eV)\n",
      "norm_ionization_potential_pa_(eV)\n",
      "norm_electronegativity_pa\n",
      "norm_Dom._Pore_(ang.)\n",
      "norm_Max._Pore_(ang.)\n",
      "norm_Void_Fraction\n",
      "norm_Surf._Area_(m2/g)\n",
      "norm_Vol._Surf._Area\n",
      "norm_Density\n",
      "oh_1\n",
      "oh_2\n",
      "oh_3\n",
      "oh_4\n",
      "norm_log_pressure\n",
      "The following columns have been dropped: []\n",
      "Total len of test_df + train_df: 533430\n"
     ]
    }
   ],
   "source": [
    "if not stacked:\n",
    "    ml_data, property_used, target_mean, target_std, features = ml.prepToSplit(cat_si_sd, SD_ML_DATA_PATH, \n",
    "                                            SI_ML_DATA_PATH, start_str_sd, end_str_sd, start_str_si, end_str_si, \n",
    "                                            total_frac, del_defective_mofs, add_size_fp, size_dependent, stacked, n_core, \n",
    "                                            del_geometric_fp, cat_col_names, Y_DATA_PATH)\n",
    "if stacked:\n",
    "    ml_data, property_used, target_mean, target_std, features, p_info = ml.prepToSplit(cat_si_sd, SD_ML_DATA_PATH, \n",
    "                                            SI_ML_DATA_PATH, start_str_sd, end_str_sd, start_str_si, end_str_si, \n",
    "                                            total_frac, del_defective_mofs, add_size_fp, size_dependent, stacked, n_core, \n",
    "                                            del_geometric_fp, cat_col_names, Y_DATA_PATH)\n",
    "\n",
    "ml_data.head()\n",
    "\n",
    "train_df, test_df= ml.trainTestSplit(ml_data, property_used, training_pct, stacked, \n",
    "                                     n_core, random_split, n_remote, features, USE_PCA, N_COMPONENTS)\n",
    "\n",
    "if algo == 'xgb':\n",
    "    train_d, test_d, train_label, test_label = ml.alter_dtype(train_df, test_df, property_used, n_core, algo, features)\n",
    "else:\n",
    "    train_d, test_d, train_label, test_label = ml.alter_dtype(train_df, test_df, property_used, n_core, algo, features)\n",
    "\n",
    "len(train_label) + len(test_label)\n",
    "\n",
    "# Run Single Model\n",
    "\n",
    "#Good parameters\n",
    "\n",
    "SAVE_FIG = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 298661 samples, validate on 74666 samples\n",
      "Epoch 1/1000\n",
      "298592/298661 [============================>.] - ETA: 0s - loss: 0.0170 - mae: 0.0910 - mse: 0.0170\n",
      "Epoch 00001: val_loss improved from inf to 0.02687, saving model to model_checkpoint.h5\n",
      "\n",
      "Epoch: 0, loss:0.0170,  mae:0.0910,  mse:0.0170,  val_loss:0.0269,  val_mae:0.1218,  val_mse:0.0269,  \n",
      "298661/298661 [==============================] - 26s 87us/sample - loss: 0.0170 - mae: 0.0910 - mse: 0.0170 - val_loss: 0.0269 - val_mae: 0.1218 - val_mse: 0.0269\n",
      "Epoch 2/1000\n",
      "298048/298661 [============================>.] - ETA: 0s - loss: 0.0119 - mae: 0.0748 - mse: 0.0119\n",
      "Epoch 00002: val_loss improved from 0.02687 to 0.02030, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 26s 88us/sample - loss: 0.0119 - mae: 0.0748 - mse: 0.0119 - val_loss: 0.0203 - val_mae: 0.1055 - val_mse: 0.0203\n",
      "Epoch 3/1000\n",
      "298144/298661 [============================>.] - ETA: 0s - loss: 0.0106 - mae: 0.0701 - mse: 0.0106\n",
      "Epoch 00003: val_loss improved from 0.02030 to 0.01839, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 25s 84us/sample - loss: 0.0106 - mae: 0.0701 - mse: 0.0106 - val_loss: 0.0184 - val_mae: 0.1009 - val_mse: 0.0184\n",
      "Epoch 4/1000\n",
      "298560/298661 [============================>.] - ETA: 0s - loss: 0.0099 - mae: 0.0672 - mse: 0.0099\n",
      "Epoch 00004: val_loss did not improve from 0.01839\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0099 - mae: 0.0672 - mse: 0.0099 - val_loss: 0.0188 - val_mae: 0.1010 - val_mse: 0.0188\n",
      "Epoch 5/1000\n",
      "298304/298661 [============================>.] - ETA: 0s - loss: 0.0094 - mae: 0.0652 - mse: 0.0094\n",
      "Epoch 00005: val_loss did not improve from 0.01839\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0094 - mae: 0.0652 - mse: 0.0094 - val_loss: 0.0187 - val_mae: 0.1011 - val_mse: 0.0187\n",
      "Epoch 6/1000\n",
      "298272/298661 [============================>.] - ETA: 0s - loss: 0.0090 - mae: 0.0636 - mse: 0.0090\n",
      "Epoch 00006: val_loss improved from 0.01839 to 0.01838, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0090 - mae: 0.0636 - mse: 0.0090 - val_loss: 0.0184 - val_mae: 0.0996 - val_mse: 0.0184\n",
      "Epoch 7/1000\n",
      "298048/298661 [============================>.] - ETA: 0s - loss: 0.0087 - mae: 0.0625 - mse: 0.0087\n",
      "Epoch 00007: val_loss improved from 0.01838 to 0.01685, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 25s 83us/sample - loss: 0.0087 - mae: 0.0625 - mse: 0.0087 - val_loss: 0.0168 - val_mae: 0.0962 - val_mse: 0.0168\n",
      "Epoch 8/1000\n",
      "298528/298661 [============================>.] - ETA: 0s - loss: 0.0085 - mae: 0.0615 - mse: 0.0085\n",
      "Epoch 00008: val_loss did not improve from 0.01685\n",
      "298661/298661 [==============================] - 25s 82us/sample - loss: 0.0085 - mae: 0.0615 - mse: 0.0085 - val_loss: 0.0171 - val_mae: 0.0976 - val_mse: 0.0171\n",
      "Epoch 9/1000\n",
      "298528/298661 [============================>.] - ETA: 0s - loss: 0.0083 - mae: 0.0607 - mse: 0.0083\n",
      "Epoch 00009: val_loss did not improve from 0.01685\n",
      "298661/298661 [==============================] - 26s 88us/sample - loss: 0.0083 - mae: 0.0607 - mse: 0.0083 - val_loss: 0.0201 - val_mae: 0.1068 - val_mse: 0.0201\n",
      "Epoch 10/1000\n",
      "298112/298661 [============================>.] - ETA: 0s - loss: 0.0081 - mae: 0.0600 - mse: 0.0081\n",
      "Epoch 00010: val_loss improved from 0.01685 to 0.01608, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0081 - mae: 0.0600 - mse: 0.0081 - val_loss: 0.0161 - val_mae: 0.0953 - val_mse: 0.0161\n",
      "Epoch 11/1000\n",
      "298368/298661 [============================>.] - ETA: 0s - loss: 0.0079 - mae: 0.0592 - mse: 0.0079\n",
      "Epoch 00011: val_loss did not improve from 0.01608\n",
      "298661/298661 [==============================] - 27s 89us/sample - loss: 0.0079 - mae: 0.0592 - mse: 0.0079 - val_loss: 0.0216 - val_mae: 0.1111 - val_mse: 0.0216\n",
      "Epoch 12/1000\n",
      "298592/298661 [============================>.] - ETA: 0s - loss: 0.0077 - mae: 0.0588 - mse: 0.0077\n",
      "Epoch 00012: val_loss did not improve from 0.01608\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0078 - mae: 0.0588 - mse: 0.0078 - val_loss: 0.0259 - val_mae: 0.1292 - val_mse: 0.0259\n",
      "Epoch 13/1000\n",
      "298560/298661 [============================>.] - ETA: 0s - loss: 0.0076 - mae: 0.0582 - mse: 0.0076\n",
      "Epoch 00013: val_loss did not improve from 0.01608\n",
      "298661/298661 [==============================] - 25s 83us/sample - loss: 0.0076 - mae: 0.0582 - mse: 0.0076 - val_loss: 0.0259 - val_mae: 0.1228 - val_mse: 0.0259\n",
      "Epoch 14/1000\n",
      "298144/298661 [============================>.] - ETA: 0s - loss: 0.0075 - mae: 0.0577 - mse: 0.0075\n",
      "Epoch 00014: val_loss did not improve from 0.01608\n",
      "298661/298661 [==============================] - 27s 91us/sample - loss: 0.0075 - mae: 0.0577 - mse: 0.0075 - val_loss: 0.0178 - val_mae: 0.0991 - val_mse: 0.0178\n",
      "Epoch 15/1000\n",
      "298592/298661 [============================>.] - ETA: 0s - loss: 0.0074 - mae: 0.0573 - mse: 0.0074\n",
      "Epoch 00015: val_loss did not improve from 0.01608\n",
      "298661/298661 [==============================] - 26s 87us/sample - loss: 0.0074 - mae: 0.0573 - mse: 0.0074 - val_loss: 0.0212 - val_mae: 0.1101 - val_mse: 0.0212\n",
      "Epoch 16/1000\n",
      "298496/298661 [============================>.] - ETA: 0s - loss: 0.0073 - mae: 0.0567 - mse: 0.0073\n",
      "Epoch 00016: val_loss improved from 0.01608 to 0.01592, saving model to model_checkpoint.h5\n",
      "298661/298661 [==============================] - 27s 89us/sample - loss: 0.0073 - mae: 0.0567 - mse: 0.0073 - val_loss: 0.0159 - val_mae: 0.0941 - val_mse: 0.0159\n",
      "Epoch 17/1000\n",
      "298176/298661 [============================>.] - ETA: 0s - loss: 0.0072 - mae: 0.0565 - mse: 0.0072\n",
      "Epoch 00017: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0072 - mae: 0.0565 - mse: 0.0072 - val_loss: 0.0159 - val_mae: 0.0950 - val_mse: 0.0159\n",
      "Epoch 18/1000\n",
      "298112/298661 [============================>.] - ETA: 0s - loss: 0.0071 - mae: 0.0561 - mse: 0.0071\n",
      "Epoch 00018: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0071 - mae: 0.0561 - mse: 0.0071 - val_loss: 0.0179 - val_mae: 0.1002 - val_mse: 0.0179\n",
      "Epoch 19/1000\n",
      "298656/298661 [============================>.] - ETA: 0s - loss: 0.0070 - mae: 0.0559 - mse: 0.0070\n",
      "Epoch 00019: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 28s 93us/sample - loss: 0.0070 - mae: 0.0559 - mse: 0.0070 - val_loss: 0.0239 - val_mae: 0.1185 - val_mse: 0.0239\n",
      "Epoch 20/1000\n",
      "298272/298661 [============================>.] - ETA: 0s - loss: 0.0069 - mae: 0.0554 - mse: 0.0069\n",
      "Epoch 00020: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0069 - mae: 0.0554 - mse: 0.0069 - val_loss: 0.0169 - val_mae: 0.0975 - val_mse: 0.0169\n",
      "Epoch 21/1000\n",
      "298304/298661 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0551 - mse: 0.0068\n",
      "Epoch 00021: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0068 - mae: 0.0551 - mse: 0.0068 - val_loss: 0.0185 - val_mae: 0.1012 - val_mse: 0.0185\n",
      "Epoch 22/1000\n",
      "298208/298661 [============================>.] - ETA: 0s - loss: 0.0068 - mae: 0.0548 - mse: 0.0068\n",
      "Epoch 00022: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 86us/sample - loss: 0.0068 - mae: 0.0548 - mse: 0.0068 - val_loss: 0.0171 - val_mae: 0.0963 - val_mse: 0.0171\n",
      "Epoch 23/1000\n",
      "298016/298661 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0545 - mse: 0.0067\n",
      "Epoch 00023: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0067 - mae: 0.0545 - mse: 0.0067 - val_loss: 0.0202 - val_mae: 0.1064 - val_mse: 0.0202\n",
      "Epoch 24/1000\n",
      "298272/298661 [============================>.] - ETA: 0s - loss: 0.0067 - mae: 0.0543 - mse: 0.0067\n",
      "Epoch 00024: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 25s 85us/sample - loss: 0.0067 - mae: 0.0543 - mse: 0.0067 - val_loss: 0.0170 - val_mae: 0.0969 - val_mse: 0.0170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000\n",
      "298432/298661 [============================>.] - ETA: 0s - loss: 0.0066 - mae: 0.0540 - mse: 0.0066\n",
      "Epoch 00025: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 27s 90us/sample - loss: 0.0066 - mae: 0.0540 - mse: 0.0066 - val_loss: 0.0192 - val_mae: 0.1034 - val_mse: 0.0192\n",
      "Epoch 26/1000\n",
      "298560/298661 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0537 - mse: 0.0065\n",
      "Epoch 00026: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 87us/sample - loss: 0.0065 - mae: 0.0537 - mse: 0.0065 - val_loss: 0.0188 - val_mae: 0.1020 - val_mse: 0.0188\n",
      "Epoch 27/1000\n",
      "298432/298661 [============================>.] - ETA: 0s - loss: 0.0065 - mae: 0.0536 - mse: 0.0065\n",
      "Epoch 00027: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 87us/sample - loss: 0.0065 - mae: 0.0536 - mse: 0.0065 - val_loss: 0.0224 - val_mae: 0.1163 - val_mse: 0.0224\n",
      "Epoch 28/1000\n",
      "298592/298661 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0532 - mse: 0.0064\n",
      "Epoch 00028: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 27s 90us/sample - loss: 0.0064 - mae: 0.0532 - mse: 0.0064 - val_loss: 0.0166 - val_mae: 0.0978 - val_mse: 0.0166\n",
      "Epoch 29/1000\n",
      "298464/298661 [============================>.] - ETA: 0s - loss: 0.0064 - mae: 0.0531 - mse: 0.0064\n",
      "Epoch 00029: val_loss did not improve from 0.01592\n",
      "298661/298661 [==============================] - 26s 88us/sample - loss: 0.0064 - mae: 0.0531 - mse: 0.0064 - val_loss: 0.0164 - val_mae: 0.0948 - val_mse: 0.0164\n",
      "Elapsed time during model training:  751.3923723697662\n",
      "Test RMSE is 8.84577053149787\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    params = r.x\n",
    "except:\n",
    "    params = [255, 0.001672542188205779, 11, 482, 0.8679237410076581]\n",
    "\n",
    "MODEL = ml.run_model(algo, train_d, n_trees, params)\n",
    "ml.parity_plot(MODEL, train_d, test_d, stacked, algo, target_mean, target_std, property_used, test_label, train_label, save=SAVE_FIG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'08:47PM_on_April_12_2020'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.datetime.now().strftime(\"%I:%M%p_on_%B_%d_%Y\")\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h_units 146\n",
      "lr 0.001434587467144449\n",
      "patience 9\n"
     ]
    }
   ],
   "source": [
    "print(\"h_units %s\" %r.x[0])\n",
    "print(\"lr %s\" %r.x[1])\n",
    "print(\"patience %s\" %r.x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_FIG = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE is 8.697572496353896\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ml.parity_plot(MODEL, train_d, test_d, stacked, algo, target_mean, target_std, property_used, test_label, train_label, save=SAVE_FIG, fname=now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only run below to save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo=='xgb':\n",
    "    MODEL.save_model('/data/rgur/efrc/ml/models/%s/%s.xgb' %(now, now))\n",
    "else:\n",
    "    MODEL.save('/data/rgur/efrc/ml/models/%s/%s.h5' %(now, now),save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/modules/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train_df['filename'].to_csv('/data/rgur/efrc/ml/models/%s/train_%s.csv' %(now, now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/modules/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "test_df['filename'].to_csv('/data/rgur/efrc/ml/models/%s/test_%s.csv' %(now, now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/rgur/efrc/ml/models/%s/features_%s.pkl' %(now, now), 'wb') as f:\n",
    "    pickle.dump(features, f, protocol=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
